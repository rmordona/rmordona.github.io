<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 7 Bayesian Computation I | The Power and Art of Approximation</title>
  <meta name="description" content="Enthused by the promising future of self-learning machines and the continuous advancement of technology, we write this book to cover a compendium of analytical and numerical techniques conflated into a common idea that highlights the fundamental requirements of Data Science and Machine Learning (ML) Engineering. In this book, we review and give brief insights into numerous fundamental ideas around methods of approximation conceived by great experts. We aim to share them with those new to Data Science who are just beginning to develop an inclination toward this field but may not know where to begin. In addition, we hope to introduce some essential aspects of Data Science in a more progressive and possibly structured manner. This book avoids being specific to a target audience depending on interest. The premise is that Data Science can be for everybody, whether one is an engineer, a researcher within a particular domain, or, for that matter, an undergraduate student just trying to get into this field. While we note that our common theme across the book is intuition, contemplating more on basic operations than mathematical rigor, it is essential to revive our understanding of mathematical concepts first. That is founded upon the idea that we express most of what we do in Data Science in the language of mathematics, more numerically inclined in fact than analytical - meaning, we live to decide based on close approximation in many situations. Therefore, it is just right to have a historical perspective of the mathematical foundations which Machine Learning algorithms may have come about - if not at least what they depend upon fundamentally. For that reason, we cover a list of mathematical concepts that are no doubt valuable to eventually get us to Machine Learning concepts. However, only a particular elementary and introductory portion of each field of mathematics is covered as we emphasize only relevant and essential areas. That said, this book comes in three volumes. Volumes I and II of this book briefly cover common topics in Linear Algebra, Numerical Analysis, Statistical Analysis, and Bayesian Analysis. The third part (or volume III) of this book covers Machine Learning and Deep Learning in detail." />
  <meta name="generator" content="bookdown 0.32 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 7 Bayesian Computation I | The Power and Art of Approximation" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Enthused by the promising future of self-learning machines and the continuous advancement of technology, we write this book to cover a compendium of analytical and numerical techniques conflated into a common idea that highlights the fundamental requirements of Data Science and Machine Learning (ML) Engineering. In this book, we review and give brief insights into numerous fundamental ideas around methods of approximation conceived by great experts. We aim to share them with those new to Data Science who are just beginning to develop an inclination toward this field but may not know where to begin. In addition, we hope to introduce some essential aspects of Data Science in a more progressive and possibly structured manner. This book avoids being specific to a target audience depending on interest. The premise is that Data Science can be for everybody, whether one is an engineer, a researcher within a particular domain, or, for that matter, an undergraduate student just trying to get into this field. While we note that our common theme across the book is intuition, contemplating more on basic operations than mathematical rigor, it is essential to revive our understanding of mathematical concepts first. That is founded upon the idea that we express most of what we do in Data Science in the language of mathematics, more numerically inclined in fact than analytical - meaning, we live to decide based on close approximation in many situations. Therefore, it is just right to have a historical perspective of the mathematical foundations which Machine Learning algorithms may have come about - if not at least what they depend upon fundamentally. For that reason, we cover a list of mathematical concepts that are no doubt valuable to eventually get us to Machine Learning concepts. However, only a particular elementary and introductory portion of each field of mathematics is covered as we emphasize only relevant and essential areas. That said, this book comes in three volumes. Volumes I and II of this book briefly cover common topics in Linear Algebra, Numerical Analysis, Statistical Analysis, and Bayesian Analysis. The third part (or volume III) of this book covers Machine Learning and Deep Learning in detail." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 7 Bayesian Computation I | The Power and Art of Approximation" />
  
  <meta name="twitter:description" content="Enthused by the promising future of self-learning machines and the continuous advancement of technology, we write this book to cover a compendium of analytical and numerical techniques conflated into a common idea that highlights the fundamental requirements of Data Science and Machine Learning (ML) Engineering. In this book, we review and give brief insights into numerous fundamental ideas around methods of approximation conceived by great experts. We aim to share them with those new to Data Science who are just beginning to develop an inclination toward this field but may not know where to begin. In addition, we hope to introduce some essential aspects of Data Science in a more progressive and possibly structured manner. This book avoids being specific to a target audience depending on interest. The premise is that Data Science can be for everybody, whether one is an engineer, a researcher within a particular domain, or, for that matter, an undergraduate student just trying to get into this field. While we note that our common theme across the book is intuition, contemplating more on basic operations than mathematical rigor, it is essential to revive our understanding of mathematical concepts first. That is founded upon the idea that we express most of what we do in Data Science in the language of mathematics, more numerically inclined in fact than analytical - meaning, we live to decide based on close approximation in many situations. Therefore, it is just right to have a historical perspective of the mathematical foundations which Machine Learning algorithms may have come about - if not at least what they depend upon fundamentally. For that reason, we cover a list of mathematical concepts that are no doubt valuable to eventually get us to Machine Learning concepts. However, only a particular elementary and introductory portion of each field of mathematics is covered as we emphasize only relevant and essential areas. That said, this book comes in three volumes. Volumes I and II of this book briefly cover common topics in Linear Algebra, Numerical Analysis, Statistical Analysis, and Bayesian Analysis. The third part (or volume III) of this book covers Machine Learning and Deep Learning in detail." />
  

<meta name="author" content="Raymond Michael Ofiaza OrdoÃ±a" />


<meta name="date" content="2023-02-14" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="statistics.html"/>
<link rel="next" href="bayesian2.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">The Power and Art of Approximation</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="0.1" data-path="index.html"><a href="index.html#acknowledgment-and-motivations"><i class="fa fa-check"></i><b>0.1</b> Acknowledgment and Motivations</a></li>
<li class="chapter" data-level="0.2" data-path="index.html"><a href="index.html#caveat"><i class="fa fa-check"></i><b>0.2</b> Caveat</a></li>
<li class="chapter" data-level="0.3" data-path="index.html"><a href="index.html#about-the-author"><i class="fa fa-check"></i><b>0.3</b> About the Author</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="" data-path="mathematical-notation.html"><a href="mathematical-notation.html"><i class="fa fa-check"></i>Mathematical Notation</a><ul>
<li class="chapter" data-level="0.4" data-path="mathematical-notation.html"><a href="mathematical-notation.html#notation"><i class="fa fa-check"></i><b>0.4</b> Notation</a></li>
<li class="chapter" data-level="0.5" data-path="mathematical-notation.html"><a href="mathematical-notation.html#number-system"><i class="fa fa-check"></i><b>0.5</b> Number System</a></li>
<li class="chapter" data-level="0.6" data-path="mathematical-notation.html"><a href="mathematical-notation.html#implementation"><i class="fa fa-check"></i><b>0.6</b> Implementation</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="numericalmethods.html"><a href="numericalmethods.html"><i class="fa fa-check"></i><b>1</b> Direct and Indirect Methods</a><ul>
<li class="chapter" data-level="1.1" data-path="numericalmethods.html"><a href="numericalmethods.html#closed-form-equation"><i class="fa fa-check"></i><b>1.1</b> Closed-form equation</a></li>
<li class="chapter" data-level="1.2" data-path="numericalmethods.html"><a href="numericalmethods.html#analytical-and-numerical-solutions"><i class="fa fa-check"></i><b>1.2</b> Analytical and Numerical solutions  </a></li>
<li class="chapter" data-level="1.3" data-path="numericalmethods.html"><a href="numericalmethods.html#significant-figures"><i class="fa fa-check"></i><b>1.3</b> Significant figures</a></li>
<li class="chapter" data-level="1.4" data-path="numericalmethods.html"><a href="numericalmethods.html#accuracy"><i class="fa fa-check"></i><b>1.4</b> Accuracy</a></li>
<li class="chapter" data-level="1.5" data-path="numericalmethods.html"><a href="numericalmethods.html#precision"><i class="fa fa-check"></i><b>1.5</b> Precision </a></li>
<li class="chapter" data-level="1.6" data-path="numericalmethods.html"><a href="numericalmethods.html#stability-and-sensitivity"><i class="fa fa-check"></i><b>1.6</b> Stability and Sensitivity  </a></li>
<li class="chapter" data-level="1.7" data-path="numericalmethods.html"><a href="numericalmethods.html#stiffness-and-implicitness"><i class="fa fa-check"></i><b>1.7</b> Stiffness and Implicitness  </a></li>
<li class="chapter" data-level="1.8" data-path="numericalmethods.html"><a href="numericalmethods.html#conditioning-and-posedness"><i class="fa fa-check"></i><b>1.8</b> Conditioning and Posedness  </a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="linearalgebra.html"><a href="linearalgebra.html"><i class="fa fa-check"></i><b>2</b> Numerical Linear Algebra I</a><ul>
<li class="chapter" data-level="2.1" data-path="linearalgebra.html"><a href="linearalgebra.html#system-of-linear-equations"><i class="fa fa-check"></i><b>2.1</b> System of Linear Equations</a></li>
<li class="chapter" data-level="2.2" data-path="linearalgebra.html"><a href="linearalgebra.html#scalar-vector-and-matrix-tensor"><i class="fa fa-check"></i><b>2.2</b> Scalar, Vector, and Matrix, Tensor</a></li>
<li class="chapter" data-level="2.3" data-path="linearalgebra.html"><a href="linearalgebra.html#transposition-and-multiplication"><i class="fa fa-check"></i><b>2.3</b> Transposition and Multiplication</a><ul>
<li class="chapter" data-level="2.3.1" data-path="linearalgebra.html"><a href="linearalgebra.html#transposition"><i class="fa fa-check"></i><b>2.3.1</b> Transposition</a></li>
<li class="chapter" data-level="2.3.2" data-path="linearalgebra.html"><a href="linearalgebra.html#dot-product"><i class="fa fa-check"></i><b>2.3.2</b> Dot Product</a></li>
<li class="chapter" data-level="2.3.3" data-path="linearalgebra.html"><a href="linearalgebra.html#hadamard-product"><i class="fa fa-check"></i><b>2.3.3</b> Hadamard Product</a></li>
<li class="chapter" data-level="2.3.4" data-path="linearalgebra.html"><a href="linearalgebra.html#kronecker-product"><i class="fa fa-check"></i><b>2.3.4</b> Kronecker Product</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="linearalgebra.html"><a href="linearalgebra.html#magnitude-direction-unit-vectors"><i class="fa fa-check"></i><b>2.4</b> Magnitude, Direction, Unit Vectors</a></li>
<li class="chapter" data-level="2.5" data-path="linearalgebra.html"><a href="linearalgebra.html#linear-combination-and-independence"><i class="fa fa-check"></i><b>2.5</b> Linear Combination and Independence</a></li>
<li class="chapter" data-level="2.6" data-path="linearalgebra.html"><a href="linearalgebra.html#space-span-and-basis"><i class="fa fa-check"></i><b>2.6</b> Space, Span, and Basis</a></li>
<li class="chapter" data-level="2.7" data-path="linearalgebra.html"><a href="linearalgebra.html#determinants"><i class="fa fa-check"></i><b>2.7</b> Determinants </a></li>
<li class="chapter" data-level="2.8" data-path="linearalgebra.html"><a href="linearalgebra.html#minors-cofactors-and-adjugate-forms"><i class="fa fa-check"></i><b>2.8</b> Minors, Cofactors, and Adjugate Forms</a></li>
<li class="chapter" data-level="2.9" data-path="linearalgebra.html"><a href="linearalgebra.html#inverse-form-and-row-echelon-form"><i class="fa fa-check"></i><b>2.9</b> Inverse Form and Row-Echelon Form</a></li>
<li class="chapter" data-level="2.10" data-path="linearalgebra.html"><a href="linearalgebra.html#linear-transformations"><i class="fa fa-check"></i><b>2.10</b> Linear Transformations</a><ul>
<li class="chapter" data-level="2.10.1" data-path="linearalgebra.html"><a href="linearalgebra.html#scaling"><i class="fa fa-check"></i><b>2.10.1</b> Scaling </a></li>
<li class="chapter" data-level="2.10.2" data-path="linearalgebra.html"><a href="linearalgebra.html#transvection-shearing"><i class="fa fa-check"></i><b>2.10.2</b> Transvection (Shearing)  </a></li>
<li class="chapter" data-level="2.10.3" data-path="linearalgebra.html"><a href="linearalgebra.html#rotation"><i class="fa fa-check"></i><b>2.10.3</b> Rotation </a></li>
<li class="chapter" data-level="2.10.4" data-path="linearalgebra.html"><a href="linearalgebra.html#reflection"><i class="fa fa-check"></i><b>2.10.4</b> Reflection </a></li>
<li class="chapter" data-level="2.10.5" data-path="linearalgebra.html"><a href="linearalgebra.html#projection"><i class="fa fa-check"></i><b>2.10.5</b> Projection </a></li>
<li class="chapter" data-level="2.10.6" data-path="linearalgebra.html"><a href="linearalgebra.html#translation"><i class="fa fa-check"></i><b>2.10.6</b> Translation </a></li>
<li class="chapter" data-level="2.10.7" data-path="linearalgebra.html"><a href="linearalgebra.html#dilation-and-composition"><i class="fa fa-check"></i><b>2.10.7</b> Dilation and Composition  </a></li>
</ul></li>
<li class="chapter" data-level="2.11" data-path="linearalgebra.html"><a href="linearalgebra.html#rank-and-nullity"><i class="fa fa-check"></i><b>2.11</b> Rank and Nullity  </a></li>
<li class="chapter" data-level="2.12" data-path="linearalgebra.html"><a href="linearalgebra.html#singularity-and-triviality"><i class="fa fa-check"></i><b>2.12</b> Singularity and Triviality  </a></li>
<li class="chapter" data-level="2.13" data-path="linearalgebra.html"><a href="linearalgebra.html#orthogonality-and-orthonormality"><i class="fa fa-check"></i><b>2.13</b> Orthogonality and Orthonormality  </a></li>
<li class="chapter" data-level="2.14" data-path="linearalgebra.html"><a href="linearalgebra.html#eigenvectors-and-eigenvalues"><i class="fa fa-check"></i><b>2.14</b> Eigenvectors and Eigenvalues  </a></li>
<li class="chapter" data-level="2.15" data-path="linearalgebra.html"><a href="linearalgebra.html#matrix-reconstruction-using-eigenvalues-and-eigenvectors"><i class="fa fa-check"></i><b>2.15</b> Matrix Reconstruction using Eigenvalues and Eigenvectors</a></li>
<li class="chapter" data-level="2.16" data-path="linearalgebra.html"><a href="linearalgebra.html#diagonalizability-of-a-matrix"><i class="fa fa-check"></i><b>2.16</b> Diagonalizability of a Matrix </a></li>
<li class="chapter" data-level="2.17" data-path="linearalgebra.html"><a href="linearalgebra.html#trace-of-a-square-matrix"><i class="fa fa-check"></i><b>2.17</b> Trace of a Square Matrix </a></li>
<li class="chapter" data-level="2.18" data-path="linearalgebra.html"><a href="linearalgebra.html#algebraic-and-geometric-multiplicity"><i class="fa fa-check"></i><b>2.18</b> Algebraic and Geometric Multiplicity</a></li>
<li class="chapter" data-level="2.19" data-path="linearalgebra.html"><a href="linearalgebra.html#types-of-matrices"><i class="fa fa-check"></i><b>2.19</b> Types of Matrices</a></li>
<li class="chapter" data-level="2.20" data-path="linearalgebra.html"><a href="linearalgebra.html#matrix-factorization"><i class="fa fa-check"></i><b>2.20</b> Matrix Factorization </a><ul>
<li class="chapter" data-level="2.20.1" data-path="linearalgebra.html"><a href="linearalgebra.html#eigen-spectral-decomposition"><i class="fa fa-check"></i><b>2.20.1</b> Eigen (Spectral) Decomposition  </a></li>
<li class="chapter" data-level="2.20.2" data-path="linearalgebra.html"><a href="linearalgebra.html#ludecomposition"><i class="fa fa-check"></i><b>2.20.2</b> LU Decomposition (Doolittle Algorithm)</a></li>
<li class="chapter" data-level="2.20.3" data-path="linearalgebra.html"><a href="linearalgebra.html#ldu-factorization"><i class="fa fa-check"></i><b>2.20.3</b> LDU Factorization </a></li>
<li class="chapter" data-level="2.20.4" data-path="linearalgebra.html"><a href="linearalgebra.html#qr-factorization-gram-schmidt-householder-and-givens"><i class="fa fa-check"></i><b>2.20.4</b> QR Factorization (Gram-Schmidt, Householder, and Givens) </a></li>
<li class="chapter" data-level="2.20.5" data-path="linearalgebra.html"><a href="linearalgebra.html#cholesky-factorization"><i class="fa fa-check"></i><b>2.20.5</b> Cholesky Factorization </a></li>
<li class="chapter" data-level="2.20.6" data-path="linearalgebra.html"><a href="linearalgebra.html#svd-factorization"><i class="fa fa-check"></i><b>2.20.6</b> SVD Factorization </a></li>
<li class="chapter" data-level="2.20.7" data-path="linearalgebra.html"><a href="linearalgebra.html#jordan-decomposition"><i class="fa fa-check"></i><b>2.20.7</b> Jordan Decomposition </a></li>
<li class="chapter" data-level="2.20.8" data-path="linearalgebra.html"><a href="linearalgebra.html#other-decomposition"><i class="fa fa-check"></i><b>2.20.8</b> Other Decomposition</a></li>
</ul></li>
<li class="chapter" data-level="2.21" data-path="linearalgebra.html"><a href="linearalgebra.html#software-libraries"><i class="fa fa-check"></i><b>2.21</b> Software libraries    </a></li>
<li class="chapter" data-level="2.22" data-path="linearalgebra.html"><a href="linearalgebra.html#summary"><i class="fa fa-check"></i><b>2.22</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html"><i class="fa fa-check"></i><b>3</b> Numerical Linear Algebra II</a><ul>
<li class="chapter" data-level="3.1" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#iteration-and-convergence"><i class="fa fa-check"></i><b>3.1</b> Iteration and Convergence </a></li>
<li class="chapter" data-level="3.2" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#approximating-eigenvalues-and-eigenvectors-by-iteration-av-lambda-v"><i class="fa fa-check"></i><b>3.2</b> Approximating Eigenvalues and EigenVectors by Iteration (<span class="math inline">\(Av = \lambda v\)</span>)</a><ul>
<li class="chapter" data-level="3.2.1" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#power-method"><i class="fa fa-check"></i><b>3.2.1</b> Power Method </a></li>
<li class="chapter" data-level="3.2.2" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#inverse-power-method-using-lu-decomposition"><i class="fa fa-check"></i><b>3.2.2</b> Inverse Power Method (using LU Decomposition)</a></li>
<li class="chapter" data-level="3.2.3" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#rayleigh-quotient-method-using-lu-decomposition"><i class="fa fa-check"></i><b>3.2.3</b> Rayleigh Quotient Method (using LU Decomposition)</a></li>
<li class="chapter" data-level="3.2.4" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#qr-method-using-qr-decomposition-by-givens"><i class="fa fa-check"></i><b>3.2.4</b> QR Method (using QR Decomposition by Givens)</a></li>
<li class="chapter" data-level="3.2.5" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#jacobi-eigenvalue-method-using-jacobi-rotation"><i class="fa fa-check"></i><b>3.2.5</b> Jacobi Eigenvalue Method (using Jacobi Rotation)</a></li>
<li class="chapter" data-level="3.2.6" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#arnoldi-method-using-gram-schmidt-in-krylov-subspace"><i class="fa fa-check"></i><b>3.2.6</b> Arnoldi Method (using Gram-Schmidt in Krylov Subspace) </a></li>
<li class="chapter" data-level="3.2.7" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#lanczos-method-using-gram-schmidt-in-krylov-subspace"><i class="fa fa-check"></i><b>3.2.7</b> Lanczos Method (using Gram-Schmidt in Krylov Subspace)</a></li>
<li class="chapter" data-level="3.2.8" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#fine-tuning-of-iteration-and-convergence"><i class="fa fa-check"></i><b>3.2.8</b> Fine-Tuning of Iteration and Convergence</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#approximating-root-and-fixed-point-by-iteration"><i class="fa fa-check"></i><b>3.3</b> Approximating Root and Fixed-Point by Iteration</a><ul>
<li class="chapter" data-level="3.3.1" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#root-finding-method-fx-0"><i class="fa fa-check"></i><b>3.3.1</b> Root-Finding Method (<span class="math inline">\(f(x) = 0\)</span>) </a></li>
<li class="chapter" data-level="3.3.2" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#fixed-point-method-fx-x"><i class="fa fa-check"></i><b>3.3.2</b> Fixed-Point Method (<span class="math inline">\(f(x) = x\)</span>) </a></li>
<li class="chapter" data-level="3.3.3" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#bisection-method"><i class="fa fa-check"></i><b>3.3.3</b> Bisection Method </a></li>
<li class="chapter" data-level="3.3.4" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#newton-raphson-method-using-the-tangent-line"><i class="fa fa-check"></i><b>3.3.4</b> Newton-Raphson Method (using the Tangent Line)</a></li>
<li class="chapter" data-level="3.3.5" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#secant-method-using-the-secant-line"><i class="fa fa-check"></i><b>3.3.5</b> Secant Method (using the Secant Line)</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#approximating-solutions-to-systems-of-eqs-by-iteration-ax-b"><i class="fa fa-check"></i><b>3.4</b> Approximating Solutions to Systems of Eqs by Iteration (<span class="math inline">\(Ax = b\)</span>)</a><ul>
<li class="chapter" data-level="3.4.1" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#krylovmethods"><i class="fa fa-check"></i><b>3.4.1</b> Krylov Methods</a></li>
<li class="chapter" data-level="3.4.2" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#gmres-generalized-minimal-residual"><i class="fa fa-check"></i><b>3.4.2</b> GMRES (Generalized Minimal Residual)  </a></li>
<li class="chapter" data-level="3.4.3" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#conjugate-gradient-method-cg"><i class="fa fa-check"></i><b>3.4.3</b> Conjugate Gradient Method (CG)  </a></li>
<li class="chapter" data-level="3.4.4" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#jacobi-and-gauss-seidel-method"><i class="fa fa-check"></i><b>3.4.4</b> Jacobi and Gauss-Seidel Method </a></li>
<li class="chapter" data-level="3.4.5" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#successive-over-relaxation-sor-method"><i class="fa fa-check"></i><b>3.4.5</b> Successive Over-Relaxation (SOR) Method  </a></li>
<li class="chapter" data-level="3.4.6" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#newtons-method"><i class="fa fa-check"></i><b>3.4.6</b> Newtonâs Method </a></li>
<li class="chapter" data-level="3.4.7" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#broydens-method"><i class="fa fa-check"></i><b>3.4.7</b> Broydenâs Method </a></li>
<li class="chapter" data-level="3.4.8" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#bfgs-broyden-fletcher-goldfarb-shanno-method"><i class="fa fa-check"></i><b>3.4.8</b> BFGS (Broyden-Fletcher-Goldfarb-Shanno) method </a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#polynomialregression"><i class="fa fa-check"></i><b>3.5</b> Approximating Polynomial Functions by Regression</a><ul>
<li class="chapter" data-level="3.5.1" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#least-squares"><i class="fa fa-check"></i><b>3.5.1</b> Least-Squares </a></li>
<li class="chapter" data-level="3.5.2" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#linear-regression"><i class="fa fa-check"></i><b>3.5.2</b> Linear Regression </a></li>
<li class="chapter" data-level="3.5.3" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#higherdegreepolynomials"><i class="fa fa-check"></i><b>3.5.3</b> Higher Degree Polynomials</a></li>
<li class="chapter" data-level="3.5.4" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#non-linear-regression"><i class="fa fa-check"></i><b>3.5.4</b> Non-Linear Regression </a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#approximating-polynomial-functions-by-series-expansion"><i class="fa fa-check"></i><b>3.6</b> Approximating Polynomial Functions by Series Expansion </a></li>
<li class="chapter" data-level="3.7" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#polynomialinterpolation"><i class="fa fa-check"></i><b>3.7</b> Approximating Polynomial Functions by Interpolation</a><ul>
<li class="chapter" data-level="3.7.1" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#polynomial-interpolation"><i class="fa fa-check"></i><b>3.7.1</b> Polynomial interpolation </a></li>
<li class="chapter" data-level="3.7.2" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#lagrange-interpolation"><i class="fa fa-check"></i><b>3.7.2</b> Lagrange interpolation </a></li>
<li class="chapter" data-level="3.7.3" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#newton-interpolation"><i class="fa fa-check"></i><b>3.7.3</b> Newton interpolation </a></li>
<li class="chapter" data-level="3.7.4" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#newton-forward-interpolation"><i class="fa fa-check"></i><b>3.7.4</b> Newton Forward interpolation </a></li>
<li class="chapter" data-level="3.7.5" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#newton-backward-interpolation"><i class="fa fa-check"></i><b>3.7.5</b> Newton Backward interpolation </a></li>
<li class="chapter" data-level="3.7.6" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#interpolation-considerations"><i class="fa fa-check"></i><b>3.7.6</b> Interpolation Considerations</a></li>
<li class="chapter" data-level="3.7.7" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#lebesque-constant"><i class="fa fa-check"></i><b>3.7.7</b> Lebesque Constant </a></li>
<li class="chapter" data-level="3.7.8" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#horners-method"><i class="fa fa-check"></i><b>3.7.8</b> Hornerâs method </a></li>
<li class="chapter" data-level="3.7.9" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#piecewise-polynomial-interpolation"><i class="fa fa-check"></i><b>3.7.9</b> Piecewise Polynomial Interpolation </a></li>
<li class="chapter" data-level="3.7.10" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#b-spline-interpolation"><i class="fa fa-check"></i><b>3.7.10</b> B-Spline interpolation </a></li>
<li class="chapter" data-level="3.7.11" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#bspline"><i class="fa fa-check"></i><b>3.7.11</b> B-Spline Regression</a></li>
<li class="chapter" data-level="3.7.12" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#p-spline-regression"><i class="fa fa-check"></i><b>3.7.12</b> P-Spline Regression </a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#polynomialsmoothing"><i class="fa fa-check"></i><b>3.8</b> Approximating Polynomial Functions by Smoothing</a><ul>
<li class="chapter" data-level="3.8.1" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#bin-smoothing"><i class="fa fa-check"></i><b>3.8.1</b> Bin Smoothing </a></li>
<li class="chapter" data-level="3.8.2" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#kernel-smoothing"><i class="fa fa-check"></i><b>3.8.2</b> Kernel Smoothing </a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#polynomial-optimization"><i class="fa fa-check"></i><b>3.9</b> Polynomial Optimization </a><ul>
<li class="chapter" data-level="3.9.1" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#simplexmethod"><i class="fa fa-check"></i><b>3.9.1</b> Simplex Method</a></li>
<li class="chapter" data-level="3.9.2" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#dualsimplex"><i class="fa fa-check"></i><b>3.9.2</b> Dual Simplex</a></li>
<li class="chapter" data-level="3.9.3" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#primaldual"><i class="fa fa-check"></i><b>3.9.3</b> Primal-Dual Formulation</a></li>
<li class="chapter" data-level="3.9.4" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#lagrange-multiplier"><i class="fa fa-check"></i><b>3.9.4</b> Lagrange Multiplier </a></li>
<li class="chapter" data-level="3.9.5" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#karush-khun-tucker-conditions"><i class="fa fa-check"></i><b>3.9.5</b> Karush-Khun-Tucker Conditions </a></li>
</ul></li>
<li class="chapter" data-level="3.10" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#summary-1"><i class="fa fa-check"></i><b>3.10</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="numericalcalculus.html"><a href="numericalcalculus.html"><i class="fa fa-check"></i><b>4</b> Numerical Calculus</a><ul>
<li class="chapter" data-level="4.1" data-path="numericalcalculus.html"><a href="numericalcalculus.html#introductory-calculus"><i class="fa fa-check"></i><b>4.1</b> Introductory Calculus</a><ul>
<li class="chapter" data-level="4.1.1" data-path="numericalcalculus.html"><a href="numericalcalculus.html#function"><i class="fa fa-check"></i><b>4.1.1</b> Function</a></li>
<li class="chapter" data-level="4.1.2" data-path="numericalcalculus.html"><a href="numericalcalculus.html#slopes"><i class="fa fa-check"></i><b>4.1.2</b> Slopes</a></li>
<li class="chapter" data-level="4.1.3" data-path="numericalcalculus.html"><a href="numericalcalculus.html#limits"><i class="fa fa-check"></i><b>4.1.3</b> Limits</a></li>
<li class="chapter" data-level="4.1.4" data-path="numericalcalculus.html"><a href="numericalcalculus.html#derivatives"><i class="fa fa-check"></i><b>4.1.4</b> Derivatives</a></li>
<li class="chapter" data-level="4.1.5" data-path="numericalcalculus.html"><a href="numericalcalculus.html#integrals"><i class="fa fa-check"></i><b>4.1.5</b> Integrals </a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="numericalcalculus.html"><a href="numericalcalculus.html#approximation-by-numerical-integration"><i class="fa fa-check"></i><b>4.2</b> Approximation by Numerical Integration </a><ul>
<li class="chapter" data-level="4.2.1" data-path="numericalcalculus.html"><a href="numericalcalculus.html#newton-cotes-quadrature"><i class="fa fa-check"></i><b>4.2.1</b> Newton-Cotes Quadrature </a></li>
<li class="chapter" data-level="4.2.2" data-path="numericalcalculus.html"><a href="numericalcalculus.html#composite-and-adaptive-quadrature"><i class="fa fa-check"></i><b>4.2.2</b> Composite and Adaptive Quadrature </a></li>
<li class="chapter" data-level="4.2.3" data-path="numericalcalculus.html"><a href="numericalcalculus.html#gaussianquadrature"><i class="fa fa-check"></i><b>4.2.3</b> Gaussian Quadrature</a></li>
<li class="chapter" data-level="4.2.4" data-path="numericalcalculus.html"><a href="numericalcalculus.html#romberg-integration"><i class="fa fa-check"></i><b>4.2.4</b> Romberg integration </a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="numericalcalculus.html"><a href="numericalcalculus.html#approximation-by-numerical-differentiation"><i class="fa fa-check"></i><b>4.3</b> Approximation by Numerical Differentiation </a><ul>
<li class="chapter" data-level="4.3.1" data-path="numericalcalculus.html"><a href="numericalcalculus.html#order-of-accuracy"><i class="fa fa-check"></i><b>4.3.1</b> Order of Accuracy</a></li>
<li class="chapter" data-level="4.3.2" data-path="numericalcalculus.html"><a href="numericalcalculus.html#finite-difference"><i class="fa fa-check"></i><b>4.3.2</b> Finite Difference </a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="numericalcalculus.html"><a href="numericalcalculus.html#approximation-using-ordinary-differential-equations"><i class="fa fa-check"></i><b>4.4</b> Approximation using Ordinary Differential Equations  </a><ul>
<li class="chapter" data-level="4.4.1" data-path="numericalcalculus.html"><a href="numericalcalculus.html#eulers-method-explicit"><i class="fa fa-check"></i><b>4.4.1</b> Eulerâs Method (Explicit) </a></li>
<li class="chapter" data-level="4.4.2" data-path="numericalcalculus.html"><a href="numericalcalculus.html#eulers-method-implicit"><i class="fa fa-check"></i><b>4.4.2</b> Eulerâs Method (Implicit)</a></li>
<li class="chapter" data-level="4.4.3" data-path="numericalcalculus.html"><a href="numericalcalculus.html#heuns-method"><i class="fa fa-check"></i><b>4.4.3</b> Heunâs Method </a></li>
<li class="chapter" data-level="4.4.4" data-path="numericalcalculus.html"><a href="numericalcalculus.html#runge-kutta-method"><i class="fa fa-check"></i><b>4.4.4</b> Runge-Kutta Method </a></li>
<li class="chapter" data-level="4.4.5" data-path="numericalcalculus.html"><a href="numericalcalculus.html#shooting-method"><i class="fa fa-check"></i><b>4.4.5</b> Shooting Method </a></li>
<li class="chapter" data-level="4.4.6" data-path="numericalcalculus.html"><a href="numericalcalculus.html#finite-difference-method"><i class="fa fa-check"></i><b>4.4.6</b> Finite Difference Method  </a></li>
<li class="chapter" data-level="4.4.7" data-path="numericalcalculus.html"><a href="numericalcalculus.html#finite-element-method-based-on-wrm-and-vm"><i class="fa fa-check"></i><b>4.4.7</b> Finite Element Method (based on WRM and VM) </a></li>
<li class="chapter" data-level="4.4.8" data-path="numericalcalculus.html"><a href="numericalcalculus.html#least-square-method-using-wrm"><i class="fa fa-check"></i><b>4.4.8</b> Least-Square Method (using WRM)</a></li>
<li class="chapter" data-level="4.4.9" data-path="numericalcalculus.html"><a href="numericalcalculus.html#galerkin-method-using-wrm"><i class="fa fa-check"></i><b>4.4.9</b> Galerkin Method (using WRM)</a></li>
<li class="chapter" data-level="4.4.10" data-path="numericalcalculus.html"><a href="numericalcalculus.html#petrov-galerkin-method-using-wrm"><i class="fa fa-check"></i><b>4.4.10</b> Petrov-Galerkin Method (using WRM)</a></li>
<li class="chapter" data-level="4.4.11" data-path="numericalcalculus.html"><a href="numericalcalculus.html#rayleigh-ritz-method-using-wrm"><i class="fa fa-check"></i><b>4.4.11</b> Rayleigh-Ritz Method (using WRM)</a></li>
<li class="chapter" data-level="4.4.12" data-path="numericalcalculus.html"><a href="numericalcalculus.html#subdomain-method-using-subdomains"><i class="fa fa-check"></i><b>4.4.12</b> Subdomain Method (using subdomains)</a></li>
<li class="chapter" data-level="4.4.13" data-path="numericalcalculus.html"><a href="numericalcalculus.html#collocation-method-using-direct-location-points"><i class="fa fa-check"></i><b>4.4.13</b> Collocation Method (using direct location points) </a></li>
<li class="chapter" data-level="4.4.14" data-path="numericalcalculus.html"><a href="numericalcalculus.html#weighted-residual-summary"><i class="fa fa-check"></i><b>4.4.14</b> Weighted Residual Summary </a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="numericalcalculus.html"><a href="numericalcalculus.html#approximation-using-functional-differential-equations"><i class="fa fa-check"></i><b>4.5</b> Approximation using Functional Differential Equations </a><ul>
<li class="chapter" data-level="4.5.1" data-path="numericalcalculus.html"><a href="numericalcalculus.html#variational-functions"><i class="fa fa-check"></i><b>4.5.1</b> Variational Functions </a></li>
<li class="chapter" data-level="4.5.2" data-path="numericalcalculus.html"><a href="numericalcalculus.html#variational-methods"><i class="fa fa-check"></i><b>4.5.2</b> Variational Methods </a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="numericalcalculus.html"><a href="numericalcalculus.html#approximation-using-partial-differential-equations"><i class="fa fa-check"></i><b>4.6</b> Approximation using Partial Differential Equations </a><ul>
<li class="chapter" data-level="4.6.1" data-path="numericalcalculus.html"><a href="numericalcalculus.html#the-laplace-equation-elliptic-pde"><i class="fa fa-check"></i><b>4.6.1</b> The Laplace Equation (Elliptic PDE)  </a></li>
<li class="chapter" data-level="4.6.2" data-path="numericalcalculus.html"><a href="numericalcalculus.html#the-heat-equation-parabolic-pde"><i class="fa fa-check"></i><b>4.6.2</b> The Heat equation (Parabolic PDE)  </a></li>
<li class="chapter" data-level="4.6.3" data-path="numericalcalculus.html"><a href="numericalcalculus.html#the-wave-equation-hyperbolic-pde"><i class="fa fa-check"></i><b>4.6.3</b> The Wave equation (Hyperbolic PDE)  </a></li>
<li class="chapter" data-level="4.6.4" data-path="numericalcalculus.html"><a href="numericalcalculus.html#the-crank-nicolson-equation"><i class="fa fa-check"></i><b>4.6.4</b> The Crank-Nicolson Equation </a></li>
<li class="chapter" data-level="4.6.5" data-path="numericalcalculus.html"><a href="numericalcalculus.html#the-burgers-equation"><i class="fa fa-check"></i><b>4.6.5</b> The Burgerâs Equation </a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="numericalcalculus.html"><a href="numericalcalculus.html#approximation-using-fourier-series-and-transform"><i class="fa fa-check"></i><b>4.7</b> Approximation using Fourier Series And Transform </a><ul>
<li class="chapter" data-level="4.7.1" data-path="numericalcalculus.html"><a href="numericalcalculus.html#discrete-fourier-transform-dft"><i class="fa fa-check"></i><b>4.7.1</b> Discrete Fourier Transform (DFT)  </a></li>
<li class="chapter" data-level="4.7.2" data-path="numericalcalculus.html"><a href="numericalcalculus.html#inverse-discrete-fourier-transformation-idft"><i class="fa fa-check"></i><b>4.7.2</b> Inverse Discrete Fourier Transformation (IDFT)  </a></li>
<li class="chapter" data-level="4.7.3" data-path="numericalcalculus.html"><a href="numericalcalculus.html#fast-fourier-transform-fft"><i class="fa fa-check"></i><b>4.7.3</b> Fast Fourier Transform (FFT)  </a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="numericalcalculus.html"><a href="numericalcalculus.html#summary-2"><i class="fa fa-check"></i><b>4.8</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="numericalprobability.html"><a href="numericalprobability.html"><i class="fa fa-check"></i><b>5</b> Probability and Distribution</a><ul>
<li class="chapter" data-level="5.1" data-path="numericalprobability.html"><a href="numericalprobability.html#approximation-based-on-random-chances"><i class="fa fa-check"></i><b>5.1</b> Approximation based on Random Chances </a></li>
<li class="chapter" data-level="5.2" data-path="numericalprobability.html"><a href="numericalprobability.html#distribution"><i class="fa fa-check"></i><b>5.2</b> Distribution</a></li>
<li class="chapter" data-level="5.3" data-path="numericalprobability.html"><a href="numericalprobability.html#mass-and-density"><i class="fa fa-check"></i><b>5.3</b> Mass and Density  </a></li>
<li class="chapter" data-level="5.4" data-path="numericalprobability.html"><a href="numericalprobability.html#probability"><i class="fa fa-check"></i><b>5.4</b> Probability  </a></li>
<li class="chapter" data-level="5.5" data-path="numericalprobability.html"><a href="numericalprobability.html#probability-density-function-pdf"><i class="fa fa-check"></i><b>5.5</b> Probability Density Function (PDF)  </a></li>
<li class="chapter" data-level="5.6" data-path="numericalprobability.html"><a href="numericalprobability.html#probability-mass-function-pmf"><i class="fa fa-check"></i><b>5.6</b> Probability Mass function (PMF)  </a></li>
<li class="chapter" data-level="5.7" data-path="numericalprobability.html"><a href="numericalprobability.html#cumulative-distribution-function-cdf"><i class="fa fa-check"></i><b>5.7</b> Cumulative Distribution Function (CDF)  </a></li>
<li class="chapter" data-level="5.8" data-path="numericalprobability.html"><a href="numericalprobability.html#special-functions"><i class="fa fa-check"></i><b>5.8</b> Special Functions</a><ul>
<li class="chapter" data-level="5.8.1" data-path="numericalprobability.html"><a href="numericalprobability.html#gamma-function"><i class="fa fa-check"></i><b>5.8.1</b> Gamma function </a></li>
<li class="chapter" data-level="5.8.2" data-path="numericalprobability.html"><a href="numericalprobability.html#incomplete-gamma-function"><i class="fa fa-check"></i><b>5.8.2</b> Incomplete Gamma function </a></li>
<li class="chapter" data-level="5.8.3" data-path="numericalprobability.html"><a href="numericalprobability.html#digamma-function"><i class="fa fa-check"></i><b>5.8.3</b> Digamma Function </a></li>
<li class="chapter" data-level="5.8.4" data-path="numericalprobability.html"><a href="numericalprobability.html#beta-function"><i class="fa fa-check"></i><b>5.8.4</b> Beta function </a></li>
<li class="chapter" data-level="5.8.5" data-path="numericalprobability.html"><a href="numericalprobability.html#incomplete-beta-function"><i class="fa fa-check"></i><b>5.8.5</b> Incomplete Beta function </a></li>
<li class="chapter" data-level="5.8.6" data-path="numericalprobability.html"><a href="numericalprobability.html#regularized-beta-function"><i class="fa fa-check"></i><b>5.8.6</b> Regularized Beta function  </a></li>
<li class="chapter" data-level="5.8.7" data-path="numericalprobability.html"><a href="numericalprobability.html#hypergeometric-function"><i class="fa fa-check"></i><b>5.8.7</b> Hypergeometric function </a></li>
<li class="chapter" data-level="5.8.8" data-path="numericalprobability.html"><a href="numericalprobability.html#continued-fraction"><i class="fa fa-check"></i><b>5.8.8</b> Continued Fraction </a></li>
<li class="chapter" data-level="5.8.9" data-path="numericalprobability.html"><a href="numericalprobability.html#dirac-delta-function"><i class="fa fa-check"></i><b>5.8.9</b> Dirac Delta Function </a></li>
<li class="chapter" data-level="5.8.10" data-path="numericalprobability.html"><a href="numericalprobability.html#kronecker-delta-function"><i class="fa fa-check"></i><b>5.8.10</b> Kronecker Delta Function </a></li>
</ul></li>
<li class="chapter" data-level="5.9" data-path="numericalprobability.html"><a href="numericalprobability.html#distributiontypes"><i class="fa fa-check"></i><b>5.9</b> Types of Distribution</a><ul>
<li class="chapter" data-level="5.9.1" data-path="numericalprobability.html"><a href="numericalprobability.html#bernoulli-distribution"><i class="fa fa-check"></i><b>5.9.1</b> Bernoulli distribution </a></li>
<li class="chapter" data-level="5.9.2" data-path="numericalprobability.html"><a href="numericalprobability.html#binomial-distribution"><i class="fa fa-check"></i><b>5.9.2</b> Binomial distribution </a></li>
<li class="chapter" data-level="5.9.3" data-path="numericalprobability.html"><a href="numericalprobability.html#multinomial-distribution"><i class="fa fa-check"></i><b>5.9.3</b> Multinomial distribution </a></li>
<li class="chapter" data-level="5.9.4" data-path="numericalprobability.html"><a href="numericalprobability.html#geometric-distribution"><i class="fa fa-check"></i><b>5.9.4</b> Geometric distribution </a></li>
<li class="chapter" data-level="5.9.5" data-path="numericalprobability.html"><a href="numericalprobability.html#beta-distribution"><i class="fa fa-check"></i><b>5.9.5</b> Beta distribution </a></li>
<li class="chapter" data-level="5.9.6" data-path="numericalprobability.html"><a href="numericalprobability.html#dirichlet-distribution"><i class="fa fa-check"></i><b>5.9.6</b> Dirichlet distribution </a></li>
<li class="chapter" data-level="5.9.7" data-path="numericalprobability.html"><a href="numericalprobability.html#exponential-distribution"><i class="fa fa-check"></i><b>5.9.7</b> Exponential distribution </a></li>
<li class="chapter" data-level="5.9.8" data-path="numericalprobability.html"><a href="numericalprobability.html#gamma-distribution"><i class="fa fa-check"></i><b>5.9.8</b> Gamma distribution </a></li>
<li class="chapter" data-level="5.9.9" data-path="numericalprobability.html"><a href="numericalprobability.html#inverse-gamma-distribution"><i class="fa fa-check"></i><b>5.9.9</b> Inverse Gamma distribution </a></li>
<li class="chapter" data-level="5.9.10" data-path="numericalprobability.html"><a href="numericalprobability.html#weibull-distribution"><i class="fa fa-check"></i><b>5.9.10</b> Weibull distribution </a></li>
<li class="chapter" data-level="5.9.11" data-path="numericalprobability.html"><a href="numericalprobability.html#poisson-distribution"><i class="fa fa-check"></i><b>5.9.11</b> Poisson distribution </a></li>
<li class="chapter" data-level="5.9.12" data-path="numericalprobability.html"><a href="numericalprobability.html#pareto-distribution"><i class="fa fa-check"></i><b>5.9.12</b> Pareto distribution </a></li>
<li class="chapter" data-level="5.9.13" data-path="numericalprobability.html"><a href="numericalprobability.html#normal-distribution"><i class="fa fa-check"></i><b>5.9.13</b> Normal distribution </a></li>
<li class="chapter" data-level="5.9.14" data-path="numericalprobability.html"><a href="numericalprobability.html#wald-distribution"><i class="fa fa-check"></i><b>5.9.14</b> Wald Distribution </a></li>
<li class="chapter" data-level="5.9.15" data-path="numericalprobability.html"><a href="numericalprobability.html#log-normal-distribution"><i class="fa fa-check"></i><b>5.9.15</b> Log-normal Distribution </a></li>
<li class="chapter" data-level="5.9.16" data-path="numericalprobability.html"><a href="numericalprobability.html#uniform-distribution"><i class="fa fa-check"></i><b>5.9.16</b> Uniform Distribution </a></li>
<li class="chapter" data-level="5.9.17" data-path="numericalprobability.html"><a href="numericalprobability.html#t-distribution"><i class="fa fa-check"></i><b>5.9.17</b> T-Distribution </a></li>
<li class="chapter" data-level="5.9.18" data-path="numericalprobability.html"><a href="numericalprobability.html#f-distribution"><i class="fa fa-check"></i><b>5.9.18</b> F-Distribution </a></li>
<li class="chapter" data-level="5.9.19" data-path="numericalprobability.html"><a href="numericalprobability.html#chi-square-distribution"><i class="fa fa-check"></i><b>5.9.19</b> Chi-square Distribution </a></li>
<li class="chapter" data-level="5.9.20" data-path="numericalprobability.html"><a href="numericalprobability.html#wishartdistribution"><i class="fa fa-check"></i><b>5.9.20</b> Wishart distribution</a></li>
<li class="chapter" data-level="5.9.21" data-path="numericalprobability.html"><a href="numericalprobability.html#lkj-distribution"><i class="fa fa-check"></i><b>5.9.21</b> LKJ distribution </a></li>
<li class="chapter" data-level="5.9.22" data-path="numericalprobability.html"><a href="numericalprobability.html#mixture-distribution"><i class="fa fa-check"></i><b>5.9.22</b> Mixture distribution </a></li>
<li class="chapter" data-level="5.9.23" data-path="numericalprobability.html"><a href="numericalprobability.html#non-parametric-distribution"><i class="fa fa-check"></i><b>5.9.23</b> Non-parametric distribution </a></li>
<li class="chapter" data-level="5.9.24" data-path="numericalprobability.html"><a href="numericalprobability.html#multi-dimensional-density"><i class="fa fa-check"></i><b>5.9.24</b> Multi-dimensional Density </a></li>
</ul></li>
<li class="chapter" data-level="5.10" data-path="numericalprobability.html"><a href="numericalprobability.html#summary-3"><i class="fa fa-check"></i><b>5.10</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="statistics.html"><a href="statistics.html"><i class="fa fa-check"></i><b>6</b> Statistical Computation</a><ul>
<li class="chapter" data-level="6.1" data-path="statistics.html"><a href="statistics.html#descriptive-statistics"><i class="fa fa-check"></i><b>6.1</b> Descriptive Statistics</a><ul>
<li class="chapter" data-level="6.1.1" data-path="statistics.html"><a href="statistics.html#visual-representation"><i class="fa fa-check"></i><b>6.1.1</b> Visual Representation</a></li>
<li class="chapter" data-level="6.1.2" data-path="statistics.html"><a href="statistics.html#central-tendency"><i class="fa fa-check"></i><b>6.1.2</b> Central Tendency </a></li>
<li class="chapter" data-level="6.1.3" data-path="statistics.html"><a href="statistics.html#variability"><i class="fa fa-check"></i><b>6.1.3</b> Variability </a></li>
<li class="chapter" data-level="6.1.4" data-path="statistics.html"><a href="statistics.html#kurtosis-and-skewness"><i class="fa fa-check"></i><b>6.1.4</b> Kurtosis and Skewness  </a></li>
<li class="chapter" data-level="6.1.5" data-path="statistics.html"><a href="statistics.html#five-number-summary"><i class="fa fa-check"></i><b>6.1.5</b> Five Number Summary  </a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="statistics.html"><a href="statistics.html#inferential-statistics"><i class="fa fa-check"></i><b>6.2</b> Inferential Statistics</a></li>
<li class="chapter" data-level="6.3" data-path="statistics.html"><a href="statistics.html#the-significance-of-difference"><i class="fa fa-check"></i><b>6.3</b> The Significance of Difference </a><ul>
<li class="chapter" data-level="6.3.1" data-path="statistics.html"><a href="statistics.html#hypothesis"><i class="fa fa-check"></i><b>6.3.1</b> Hypothesis</a></li>
<li class="chapter" data-level="6.3.2" data-path="statistics.html"><a href="statistics.html#t-test-true-variance-unknown"><i class="fa fa-check"></i><b>6.3.2</b> T-Test (True Variance unknown) </a></li>
<li class="chapter" data-level="6.3.3" data-path="statistics.html"><a href="statistics.html#z-test-true-variance-known"><i class="fa fa-check"></i><b>6.3.3</b> Z-Test (True Variance known)</a></li>
<li class="chapter" data-level="6.3.4" data-path="statistics.html"><a href="statistics.html#f-test-using-f-ratio"><i class="fa fa-check"></i><b>6.3.4</b> F-Test using F-ratio  </a></li>
<li class="chapter" data-level="6.3.5" data-path="statistics.html"><a href="statistics.html#f-test-with-one-way-anova"><i class="fa fa-check"></i><b>6.3.5</b> F-Test with One-Way ANOVA </a></li>
<li class="chapter" data-level="6.3.6" data-path="statistics.html"><a href="statistics.html#f-test-with-two-way-anova"><i class="fa fa-check"></i><b>6.3.6</b> F-Test with Two-Way ANOVA </a></li>
<li class="chapter" data-level="6.3.7" data-path="statistics.html"><a href="statistics.html#pearsons-chi-square-test"><i class="fa fa-check"></i><b>6.3.7</b> Pearsonâs Chi-square Test </a></li>
<li class="chapter" data-level="6.3.8" data-path="statistics.html"><a href="statistics.html#wilcoxon-test"><i class="fa fa-check"></i><b>6.3.8</b> Wilcoxon Test  </a></li>
<li class="chapter" data-level="6.3.9" data-path="statistics.html"><a href="statistics.html#kruskal-wallis-test"><i class="fa fa-check"></i><b>6.3.9</b> Kruskal-Wallis Test </a></li>
<li class="chapter" data-level="6.3.10" data-path="statistics.html"><a href="statistics.html#friedman-test"><i class="fa fa-check"></i><b>6.3.10</b> Friedman Test </a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="statistics.html"><a href="statistics.html#post-hoc-analysis"><i class="fa fa-check"></i><b>6.4</b> Post-HOC Analysis </a><ul>
<li class="chapter" data-level="6.4.1" data-path="statistics.html"><a href="statistics.html#bonferroni-correction"><i class="fa fa-check"></i><b>6.4.1</b> Bonferroni Correction </a></li>
<li class="chapter" data-level="6.4.2" data-path="statistics.html"><a href="statistics.html#benjamini-hochberg-correction"><i class="fa fa-check"></i><b>6.4.2</b> Benjamini-Hochberg Correction </a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="statistics.html"><a href="statistics.html#multiple-comparison-tests"><i class="fa fa-check"></i><b>6.5</b> Multiple Comparison Tests </a><ul>
<li class="chapter" data-level="6.5.1" data-path="statistics.html"><a href="statistics.html#scheffes-test"><i class="fa fa-check"></i><b>6.5.1</b> Scheffeâs Test </a></li>
<li class="chapter" data-level="6.5.2" data-path="statistics.html"><a href="statistics.html#fishers-test"><i class="fa fa-check"></i><b>6.5.2</b> Fisherâs Test </a></li>
<li class="chapter" data-level="6.5.3" data-path="statistics.html"><a href="statistics.html#tukeys-test"><i class="fa fa-check"></i><b>6.5.3</b> Tukeyâs Test </a></li>
<li class="chapter" data-level="6.5.4" data-path="statistics.html"><a href="statistics.html#newman-keul-test"><i class="fa fa-check"></i><b>6.5.4</b> Newman-Keul Test  </a></li>
<li class="chapter" data-level="6.5.5" data-path="statistics.html"><a href="statistics.html#games-howell-test"><i class="fa fa-check"></i><b>6.5.5</b> Games-Howell Test </a></li>
<li class="chapter" data-level="6.5.6" data-path="statistics.html"><a href="statistics.html#dunnetts-test"><i class="fa fa-check"></i><b>6.5.6</b> Dunnettâs Test </a></li>
<li class="chapter" data-level="6.5.7" data-path="statistics.html"><a href="statistics.html#duncans-test"><i class="fa fa-check"></i><b>6.5.7</b> Duncanâs Test </a></li>
<li class="chapter" data-level="6.5.8" data-path="statistics.html"><a href="statistics.html#meta-analysis-test"><i class="fa fa-check"></i><b>6.5.8</b> Meta-Analysis Test </a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="statistics.html"><a href="statistics.html#statistical-modeling"><i class="fa fa-check"></i><b>6.6</b> Statistical Modeling </a><ul>
<li class="chapter" data-level="6.6.1" data-path="statistics.html"><a href="statistics.html#model-specification"><i class="fa fa-check"></i><b>6.6.1</b> Model Specification </a></li>
<li class="chapter" data-level="6.6.2" data-path="statistics.html"><a href="statistics.html#statistical-interaction"><i class="fa fa-check"></i><b>6.6.2</b> Statistical Interaction </a></li>
<li class="chapter" data-level="6.6.3" data-path="statistics.html"><a href="statistics.html#dummy-variables"><i class="fa fa-check"></i><b>6.6.3</b> Dummy Variables </a></li>
<li class="chapter" data-level="6.6.4" data-path="statistics.html"><a href="statistics.html#model-selection"><i class="fa fa-check"></i><b>6.6.4</b> Model Selection </a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="statistics.html"><a href="statistics.html#regression-analysis"><i class="fa fa-check"></i><b>6.7</b> Regression Analysis </a><ul>
<li class="chapter" data-level="6.7.1" data-path="statistics.html"><a href="statistics.html#assumptions"><i class="fa fa-check"></i><b>6.7.1</b> Assumptions</a></li>
<li class="chapter" data-level="6.7.2" data-path="statistics.html"><a href="statistics.html#correlation-coefficients"><i class="fa fa-check"></i><b>6.7.2</b> Correlation Coefficients </a></li>
<li class="chapter" data-level="6.7.3" data-path="statistics.html"><a href="statistics.html#homoscedasticity-and-heteroscedasticity"><i class="fa fa-check"></i><b>6.7.3</b> Homoscedasticity and Heteroscedasticity  </a></li>
<li class="chapter" data-level="6.7.4" data-path="statistics.html"><a href="statistics.html#normality-and-leverage"><i class="fa fa-check"></i><b>6.7.4</b> Normality and Leverage  </a></li>
<li class="chapter" data-level="6.7.5" data-path="statistics.html"><a href="statistics.html#collinearity"><i class="fa fa-check"></i><b>6.7.5</b> Collinearity </a></li>
<li class="chapter" data-level="6.7.6" data-path="statistics.html"><a href="statistics.html#dispersion"><i class="fa fa-check"></i><b>6.7.6</b> Dispersion </a></li>
<li class="chapter" data-level="6.7.7" data-path="statistics.html"><a href="statistics.html#diagnostic-plots"><i class="fa fa-check"></i><b>6.7.7</b> Diagnostic Plots</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="statistics.html"><a href="statistics.html#the-significance-of-regression"><i class="fa fa-check"></i><b>6.8</b> The Significance of Regression </a><ul>
<li class="chapter" data-level="6.8.1" data-path="statistics.html"><a href="statistics.html#simple-linear-regression"><i class="fa fa-check"></i><b>6.8.1</b> Simple Linear Regression</a></li>
<li class="chapter" data-level="6.8.2" data-path="statistics.html"><a href="statistics.html#multilinear-regression"><i class="fa fa-check"></i><b>6.8.2</b> Multilinear Regression </a></li>
<li class="chapter" data-level="6.8.3" data-path="statistics.html"><a href="statistics.html#logistic-regression"><i class="fa fa-check"></i><b>6.8.3</b> Logistic Regression </a></li>
<li class="chapter" data-level="6.8.4" data-path="statistics.html"><a href="statistics.html#poisson-regression"><i class="fa fa-check"></i><b>6.8.4</b> Poisson Regression </a></li>
<li class="chapter" data-level="6.8.5" data-path="statistics.html"><a href="statistics.html#cox-regression"><i class="fa fa-check"></i><b>6.8.5</b> Cox Regression </a></li>
<li class="chapter" data-level="6.8.6" data-path="statistics.html"><a href="statistics.html#polynomial-regression"><i class="fa fa-check"></i><b>6.8.6</b> Polynomial Regression </a></li>
<li class="chapter" data-level="6.8.7" data-path="statistics.html"><a href="statistics.html#b-splines-and-natural-splines"><i class="fa fa-check"></i><b>6.8.7</b> B-Splines and Natural Splines  </a></li>
<li class="chapter" data-level="6.8.8" data-path="statistics.html"><a href="statistics.html#spline-smoothing"><i class="fa fa-check"></i><b>6.8.8</b> Spline Smoothing </a></li>
<li class="chapter" data-level="6.8.9" data-path="statistics.html"><a href="statistics.html#loess-and-lowess"><i class="fa fa-check"></i><b>6.8.9</b> LOESS and LOWESS  </a></li>
</ul></li>
<li class="chapter" data-level="6.9" data-path="statistics.html"><a href="statistics.html#inference-for-regression"><i class="fa fa-check"></i><b>6.9</b> Inference for Regression</a><ul>
<li class="chapter" data-level="6.9.1" data-path="statistics.html"><a href="statistics.html#goodness-of-fit-linear-regression"><i class="fa fa-check"></i><b>6.9.1</b> Goodness of Fit (Linear Regression) </a></li>
<li class="chapter" data-level="6.9.2" data-path="statistics.html"><a href="statistics.html#goodness-of-fit-non-linear-regression"><i class="fa fa-check"></i><b>6.9.2</b> Goodness of Fit (Non-Linear Regression) </a></li>
<li class="chapter" data-level="6.9.3" data-path="statistics.html"><a href="statistics.html#confidence-interval"><i class="fa fa-check"></i><b>6.9.3</b> Confidence interval </a></li>
</ul></li>
<li class="chapter" data-level="6.10" data-path="statistics.html"><a href="statistics.html#summary-4"><i class="fa fa-check"></i><b>6.10</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="bayesian.html"><a href="bayesian.html"><i class="fa fa-check"></i><b>7</b> Bayesian Computation I</a><ul>
<li class="chapter" data-level="7.1" data-path="bayesian.html"><a href="bayesian.html#probability-1"><i class="fa fa-check"></i><b>7.1</b> Probability </a><ul>
<li class="chapter" data-level="7.1.1" data-path="bayesian.html"><a href="bayesian.html#marginal-probability"><i class="fa fa-check"></i><b>7.1.1</b> Marginal Probability </a></li>
<li class="chapter" data-level="7.1.2" data-path="bayesian.html"><a href="bayesian.html#joint-probability"><i class="fa fa-check"></i><b>7.1.2</b> Joint Probability </a></li>
<li class="chapter" data-level="7.1.3" data-path="bayesian.html"><a href="bayesian.html#conditional-probability"><i class="fa fa-check"></i><b>7.1.3</b> Conditional Probability </a></li>
<li class="chapter" data-level="7.1.4" data-path="bayesian.html"><a href="bayesian.html#negation-probability"><i class="fa fa-check"></i><b>7.1.4</b> Negation Probability </a></li>
<li class="chapter" data-level="7.1.5" data-path="bayesian.html"><a href="bayesian.html#combination-of-probabilities"><i class="fa fa-check"></i><b>7.1.5</b> Combination of Probabilities</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="bayesian.html"><a href="bayesian.html#probability-rules"><i class="fa fa-check"></i><b>7.2</b> Probability Rules</a><ul>
<li class="chapter" data-level="7.2.1" data-path="bayesian.html"><a href="bayesian.html#law-of-total-probability"><i class="fa fa-check"></i><b>7.2.1</b> Law of Total Probability</a></li>
<li class="chapter" data-level="7.2.2" data-path="bayesian.html"><a href="bayesian.html#law-of-total-expectation"><i class="fa fa-check"></i><b>7.2.2</b> Law of Total Expectation </a></li>
<li class="chapter" data-level="7.2.3" data-path="bayesian.html"><a href="bayesian.html#law-of-total-variance"><i class="fa fa-check"></i><b>7.2.3</b> Law of Total Variance </a></li>
<li class="chapter" data-level="7.2.4" data-path="bayesian.html"><a href="bayesian.html#law-of-total-covariance"><i class="fa fa-check"></i><b>7.2.4</b> Law of Total Covariance </a></li>
<li class="chapter" data-level="7.2.5" data-path="bayesian.html"><a href="bayesian.html#law-of-large-numbers"><i class="fa fa-check"></i><b>7.2.5</b> Law of Large Numbers </a></li>
<li class="chapter" data-level="7.2.6" data-path="bayesian.html"><a href="bayesian.html#central-limit-theorem"><i class="fa fa-check"></i><b>7.2.6</b> Central Limit Theorem </a></li>
<li class="chapter" data-level="7.2.7" data-path="bayesian.html"><a href="bayesian.html#rule-of-independence"><i class="fa fa-check"></i><b>7.2.7</b> Rule of Independence </a></li>
<li class="chapter" data-level="7.2.8" data-path="bayesian.html"><a href="bayesian.html#rule-of-exchangeability"><i class="fa fa-check"></i><b>7.2.8</b> Rule of Exchangeability </a></li>
<li class="chapter" data-level="7.2.9" data-path="bayesian.html"><a href="bayesian.html#rule-of-expectation-and-variance"><i class="fa fa-check"></i><b>7.2.9</b> Rule of Expectation and Variance</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="bayesian.html"><a href="bayesian.html#bayes-theorem"><i class="fa fa-check"></i><b>7.3</b> Bayes Theorem </a><ul>
<li class="chapter" data-level="7.3.1" data-path="bayesian.html"><a href="bayesian.html#naÃ¯ve-bayes"><i class="fa fa-check"></i><b>7.3.1</b> NaÃ¯ve Bayes </a></li>
<li class="chapter" data-level="7.3.2" data-path="bayesian.html"><a href="bayesian.html#likelihood"><i class="fa fa-check"></i><b>7.3.2</b> Likelihood</a></li>
<li class="chapter" data-level="7.3.3" data-path="bayesian.html"><a href="bayesian.html#posterior-probability"><i class="fa fa-check"></i><b>7.3.3</b> Posterior Probability  </a></li>
<li class="chapter" data-level="7.3.4" data-path="bayesian.html"><a href="bayesian.html#prior-probability"><i class="fa fa-check"></i><b>7.3.4</b> Prior Probability  </a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="bayesian.html"><a href="bayesian.html#conjugacy"><i class="fa fa-check"></i><b>7.4</b> Conjugacy</a><ul>
<li class="chapter" data-level="7.4.1" data-path="bayesian.html"><a href="bayesian.html#precision-1"><i class="fa fa-check"></i><b>7.4.1</b> Precision </a></li>
<li class="chapter" data-level="7.4.2" data-path="bayesian.html"><a href="bayesian.html#conjugate-prior"><i class="fa fa-check"></i><b>7.4.2</b> Conjugate Prior </a></li>
<li class="chapter" data-level="7.4.3" data-path="bayesian.html"><a href="bayesian.html#normal-normal-conjugacy"><i class="fa fa-check"></i><b>7.4.3</b> Normal-Normal Conjugacy </a></li>
<li class="chapter" data-level="7.4.4" data-path="bayesian.html"><a href="bayesian.html#normal-inverse-gamma-conjugacy"><i class="fa fa-check"></i><b>7.4.4</b> Normal-Inverse Gamma Conjugacy </a></li>
<li class="chapter" data-level="7.4.5" data-path="bayesian.html"><a href="bayesian.html#multivariate-normal-conjugacy"><i class="fa fa-check"></i><b>7.4.5</b> Multivariate Normal Conjugacy </a></li>
<li class="chapter" data-level="7.4.6" data-path="bayesian.html"><a href="bayesian.html#normal-wishart-conjugacy"><i class="fa fa-check"></i><b>7.4.6</b> Normal Wishart Conjugacy </a></li>
<li class="chapter" data-level="7.4.7" data-path="bayesian.html"><a href="bayesian.html#normal-inverse-wishart-conjugacy"><i class="fa fa-check"></i><b>7.4.7</b> Normal-Inverse Wishart Conjugacy </a></li>
<li class="chapter" data-level="7.4.8" data-path="bayesian.html"><a href="bayesian.html#normal-lkj-conjugacy"><i class="fa fa-check"></i><b>7.4.8</b> Normal-LKJ Conjugacy </a></li>
<li class="chapter" data-level="7.4.9" data-path="bayesian.html"><a href="bayesian.html#binomial-beta-conjugacy"><i class="fa fa-check"></i><b>7.4.9</b> Binomial-Beta Conjugacy </a></li>
<li class="chapter" data-level="7.4.10" data-path="bayesian.html"><a href="bayesian.html#geometric-beta-conjugacy"><i class="fa fa-check"></i><b>7.4.10</b> Geometric-Beta Conjugacy </a></li>
<li class="chapter" data-level="7.4.11" data-path="bayesian.html"><a href="bayesian.html#poisson-gamma-conjugacy"><i class="fa fa-check"></i><b>7.4.11</b> Poisson-Gamma Conjugacy </a></li>
<li class="chapter" data-level="7.4.12" data-path="bayesian.html"><a href="bayesian.html#exponential-gamma-conjugacy"><i class="fa fa-check"></i><b>7.4.12</b> Exponential-Gamma Conjugacy </a></li>
<li class="chapter" data-level="7.4.13" data-path="bayesian.html"><a href="bayesian.html#multinomial-dirichlet-conjugacy"><i class="fa fa-check"></i><b>7.4.13</b> Multinomial-Dirichlet Conjugacy </a></li>
<li class="chapter" data-level="7.4.14" data-path="bayesian.html"><a href="bayesian.html#hyperparameters"><i class="fa fa-check"></i><b>7.4.14</b> Hyperparameters </a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="bayesian.html"><a href="bayesian.html#information-theory"><i class="fa fa-check"></i><b>7.5</b> Information Theory </a><ul>
<li class="chapter" data-level="7.5.1" data-path="bayesian.html"><a href="bayesian.html#information"><i class="fa fa-check"></i><b>7.5.1</b> Information </a></li>
<li class="chapter" data-level="7.5.2" data-path="bayesian.html"><a href="bayesian.html#entropy"><i class="fa fa-check"></i><b>7.5.2</b> Entropy </a></li>
<li class="chapter" data-level="7.5.3" data-path="bayesian.html"><a href="bayesian.html#gini-index"><i class="fa fa-check"></i><b>7.5.3</b> Gini Index </a></li>
<li class="chapter" data-level="7.5.4" data-path="bayesian.html"><a href="bayesian.html#information-gain"><i class="fa fa-check"></i><b>7.5.4</b> Information Gain </a></li>
<li class="chapter" data-level="7.5.5" data-path="bayesian.html"><a href="bayesian.html#mutual-information"><i class="fa fa-check"></i><b>7.5.5</b> Mutual Information </a></li>
<li class="chapter" data-level="7.5.6" data-path="bayesian.html"><a href="bayesian.html#kullback-leibler-divergence"><i class="fa fa-check"></i><b>7.5.6</b> Kullback-Leibler Divergence  </a></li>
<li class="chapter" data-level="7.5.7" data-path="bayesian.html"><a href="bayesian.html#jensens-inequality"><i class="fa fa-check"></i><b>7.5.7</b> Jensenâs Inequality</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="bayesian.html"><a href="bayesian.html#bayesianinference"><i class="fa fa-check"></i><b>7.6</b> Bayesian Inference</a><ul>
<li class="chapter" data-level="7.6.1" data-path="bayesian.html"><a href="bayesian.html#maximum-likelihood-mle"><i class="fa fa-check"></i><b>7.6.1</b> Maximum Likelihood (MLE)  </a></li>
<li class="chapter" data-level="7.6.2" data-path="bayesian.html"><a href="bayesian.html#maximum-a-posteriori-map"><i class="fa fa-check"></i><b>7.6.2</b> Maximum A-posteriori (MAP)  </a></li>
<li class="chapter" data-level="7.6.3" data-path="bayesian.html"><a href="bayesian.html#laplace-approximation"><i class="fa fa-check"></i><b>7.6.3</b> Laplace Approximation </a></li>
<li class="chapter" data-level="7.6.4" data-path="bayesian.html"><a href="bayesian.html#expectation-maximization-em"><i class="fa fa-check"></i><b>7.6.4</b> Expectation-Maximization (EM)  </a></li>
<li class="chapter" data-level="7.6.5" data-path="bayesian.html"><a href="bayesian.html#variational-inference"><i class="fa fa-check"></i><b>7.6.5</b> Variational Inference </a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="bayesian2.html"><a href="bayesian2.html"><i class="fa fa-check"></i><b>8</b> Bayesian Computation II</a><ul>
<li class="chapter" data-level="8.1" data-path="bayesian2.html"><a href="bayesian2.html#bayesian-models"><i class="fa fa-check"></i><b>8.1</b> Bayesian Models </a><ul>
<li class="chapter" data-level="8.1.1" data-path="bayesian2.html"><a href="bayesian2.html#belief-propagation"><i class="fa fa-check"></i><b>8.1.1</b> Belief Propagation </a></li>
<li class="chapter" data-level="8.1.2" data-path="bayesian2.html"><a href="bayesian2.html#expectation-propagation"><i class="fa fa-check"></i><b>8.1.2</b> Expectation Propagation </a></li>
<li class="chapter" data-level="8.1.3" data-path="bayesian2.html"><a href="bayesian2.html#markov-chain"><i class="fa fa-check"></i><b>8.1.3</b> Markov Chain </a></li>
<li class="chapter" data-level="8.1.4" data-path="bayesian2.html"><a href="bayesian2.html#hidden-markov-model"><i class="fa fa-check"></i><b>8.1.4</b> Hidden Markov Model  </a></li>
<li class="chapter" data-level="8.1.5" data-path="bayesian2.html"><a href="bayesian2.html#dynamic-system-model"><i class="fa fa-check"></i><b>8.1.5</b> Dynamic System Model</a></li>
<li class="chapter" data-level="8.1.6" data-path="bayesian2.html"><a href="bayesian2.html#bayes-filter"><i class="fa fa-check"></i><b>8.1.6</b> Bayes Filter </a></li>
<li class="chapter" data-level="8.1.7" data-path="bayesian2.html"><a href="bayesian2.html#kalman-filter"><i class="fa fa-check"></i><b>8.1.7</b> Kalman Filter </a></li>
<li class="chapter" data-level="8.1.8" data-path="bayesian2.html"><a href="bayesian2.html#extended-kalman-filter"><i class="fa fa-check"></i><b>8.1.8</b> Extended Kalman Filter </a></li>
<li class="chapter" data-level="8.1.9" data-path="bayesian2.html"><a href="bayesian2.html#unscented-kalman-filter"><i class="fa fa-check"></i><b>8.1.9</b> Unscented Kalman Filter </a></li>
<li class="chapter" data-level="8.1.10" data-path="bayesian2.html"><a href="bayesian2.html#particle-filter"><i class="fa fa-check"></i><b>8.1.10</b> Particle Filter </a></li>
<li class="chapter" data-level="8.1.11" data-path="bayesian2.html"><a href="bayesian2.html#ensemble-kalman-filter"><i class="fa fa-check"></i><b>8.1.11</b> Ensemble Kalman Filter </a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="bayesian2.html"><a href="bayesian2.html#simulation-and-sampling"><i class="fa fa-check"></i><b>8.2</b> Simulation and Sampling</a><ul>
<li class="chapter" data-level="8.2.1" data-path="bayesian2.html"><a href="bayesian2.html#monte-carlo-estimation"><i class="fa fa-check"></i><b>8.2.1</b> Monte Carlo Estimation </a></li>
<li class="chapter" data-level="8.2.2" data-path="bayesian2.html"><a href="bayesian2.html#monte-carlo-simulation"><i class="fa fa-check"></i><b>8.2.2</b> Monte Carlo Simulation </a></li>
<li class="chapter" data-level="8.2.3" data-path="bayesian2.html"><a href="bayesian2.html#markov-chain-monte-carlo"><i class="fa fa-check"></i><b>8.2.3</b> Markov Chain Monte Carlo  </a></li>
<li class="chapter" data-level="8.2.4" data-path="bayesian2.html"><a href="bayesian2.html#metropolis-hastings-monte-carlo"><i class="fa fa-check"></i><b>8.2.4</b> Metropolis-Hastings Monte Carlo  </a></li>
<li class="chapter" data-level="8.2.5" data-path="bayesian2.html"><a href="bayesian2.html#hamiltonian-monte-carlo"><i class="fa fa-check"></i><b>8.2.5</b> Hamiltonian Monte Carlo  </a></li>
<li class="chapter" data-level="8.2.6" data-path="bayesian2.html"><a href="bayesian2.html#gibbs-sampling"><i class="fa fa-check"></i><b>8.2.6</b> Gibbs Sampling </a></li>
<li class="chapter" data-level="8.2.7" data-path="bayesian2.html"><a href="bayesian2.html#importance-sampling"><i class="fa fa-check"></i><b>8.2.7</b> Importance Sampling </a></li>
<li class="chapter" data-level="8.2.8" data-path="bayesian2.html"><a href="bayesian2.html#rejection-sampling"><i class="fa fa-check"></i><b>8.2.8</b> Rejection Sampling </a></li>
<li class="chapter" data-level="8.2.9" data-path="bayesian2.html"><a href="bayesian2.html#jags-modeling"><i class="fa fa-check"></i><b>8.2.9</b> JAGS Modeling </a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="bayesian2.html"><a href="bayesian2.html#bayesian-analysis"><i class="fa fa-check"></i><b>8.3</b> Bayesian Analysis</a><ul>
<li class="chapter" data-level="8.3.1" data-path="bayesian2.html"><a href="bayesian2.html#autocorrelation"><i class="fa fa-check"></i><b>8.3.1</b> Autocorrelation </a></li>
<li class="chapter" data-level="8.3.2" data-path="bayesian2.html"><a href="bayesian2.html#predictive-probability"><i class="fa fa-check"></i><b>8.3.2</b> Predictive Probability </a></li>
<li class="chapter" data-level="8.3.3" data-path="bayesian2.html"><a href="bayesian2.html#posterior-interval"><i class="fa fa-check"></i><b>8.3.3</b> Posterior Interval </a></li>
<li class="chapter" data-level="8.3.4" data-path="bayesian2.html"><a href="bayesian2.html#bayes-factor"><i class="fa fa-check"></i><b>8.3.4</b> Bayes Factor </a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="bayesian2.html"><a href="bayesian2.html#summary-5"><i class="fa fa-check"></i><b>8.4</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="machinelearning1.html"><a href="machinelearning1.html"><i class="fa fa-check"></i><b>9</b> Computational Learning I</a><ul>
<li class="chapter" data-level="9.1" data-path="machinelearning1.html"><a href="machinelearning1.html#observation-and-measurement"><i class="fa fa-check"></i><b>9.1</b> Observation and Measurement</a><ul>
<li class="chapter" data-level="9.1.1" data-path="machinelearning1.html"><a href="machinelearning1.html#levels-of-measurements"><i class="fa fa-check"></i><b>9.1.1</b> Levels of Measurements</a></li>
<li class="chapter" data-level="9.1.2" data-path="machinelearning1.html"><a href="machinelearning1.html#levels-of-categorical-measurements"><i class="fa fa-check"></i><b>9.1.2</b> Levels of Categorical measurements</a></li>
<li class="chapter" data-level="9.1.3" data-path="machinelearning1.html"><a href="machinelearning1.html#levels-of-continuous-measurements"><i class="fa fa-check"></i><b>9.1.3</b> Levels of Continuous measurements</a></li>
<li class="chapter" data-level="9.1.4" data-path="machinelearning1.html"><a href="machinelearning1.html#discrete-vs-continuous-measurements"><i class="fa fa-check"></i><b>9.1.4</b> Discrete vs Continuous measurements</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="machinelearning1.html"><a href="machinelearning1.html#input-data"><i class="fa fa-check"></i><b>9.2</b> Input Data</a><ul>
<li class="chapter" data-level="9.2.1" data-path="machinelearning1.html"><a href="machinelearning1.html#structured-data"><i class="fa fa-check"></i><b>9.2.1</b> Structured Data</a></li>
<li class="chapter" data-level="9.2.2" data-path="machinelearning1.html"><a href="machinelearning1.html#non-structured-data"><i class="fa fa-check"></i><b>9.2.2</b> Non-Structured Data</a></li>
<li class="chapter" data-level="9.2.3" data-path="machinelearning1.html"><a href="machinelearning1.html#statistical-data"><i class="fa fa-check"></i><b>9.2.3</b> Statistical Data</a></li>
<li class="chapter" data-level="9.2.4" data-path="machinelearning1.html"><a href="machinelearning1.html#real-time-and-near-real-time-data"><i class="fa fa-check"></i><b>9.2.4</b> Real-Time and Near Real-Time Data</a></li>
<li class="chapter" data-level="9.2.5" data-path="machinelearning1.html"><a href="machinelearning1.html#oltp-and-datawarehouse"><i class="fa fa-check"></i><b>9.2.5</b> OLTP and Datawarehouse</a></li>
<li class="chapter" data-level="9.2.6" data-path="machinelearning1.html"><a href="machinelearning1.html#data-lake"><i class="fa fa-check"></i><b>9.2.6</b> Data lake</a></li>
<li class="chapter" data-level="9.2.7" data-path="machinelearning1.html"><a href="machinelearning1.html#natural-language-nl"><i class="fa fa-check"></i><b>9.2.7</b> Natural Language (NL)</a></li>
<li class="chapter" data-level="9.2.8" data-path="machinelearning1.html"><a href="machinelearning1.html#multimedia-md"><i class="fa fa-check"></i><b>9.2.8</b> Multimedia (MD)</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="machinelearning1.html"><a href="machinelearning1.html#primitive-methods"><i class="fa fa-check"></i><b>9.3</b> Primitive Methods</a><ul>
<li class="chapter" data-level="9.3.1" data-path="machinelearning1.html"><a href="machinelearning1.html#weighting"><i class="fa fa-check"></i><b>9.3.1</b> Weighting</a></li>
<li class="chapter" data-level="9.3.2" data-path="machinelearning1.html"><a href="machinelearning1.html#smoothing"><i class="fa fa-check"></i><b>9.3.2</b> Smoothing</a></li>
<li class="chapter" data-level="9.3.3" data-path="machinelearning1.html"><a href="machinelearning1.html#normalizing"><i class="fa fa-check"></i><b>9.3.3</b> Normalizing</a></li>
<li class="chapter" data-level="9.3.4" data-path="machinelearning1.html"><a href="machinelearning1.html#standardizing"><i class="fa fa-check"></i><b>9.3.4</b> Standardizing </a></li>
<li class="chapter" data-level="9.3.5" data-path="machinelearning1.html"><a href="machinelearning1.html#centering"><i class="fa fa-check"></i><b>9.3.5</b> Centering </a></li>
<li class="chapter" data-level="9.3.6" data-path="machinelearning1.html"><a href="machinelearning1.html#scaling-1"><i class="fa fa-check"></i><b>9.3.6</b> Scaling </a></li>
<li class="chapter" data-level="9.3.7" data-path="machinelearning1.html"><a href="machinelearning1.html#transforming"><i class="fa fa-check"></i><b>9.3.7</b> Transforming</a></li>
<li class="chapter" data-level="9.3.8" data-path="machinelearning1.html"><a href="machinelearning1.html#clipping"><i class="fa fa-check"></i><b>9.3.8</b> Clipping </a></li>
<li class="chapter" data-level="9.3.9" data-path="machinelearning1.html"><a href="machinelearning1.html#regularizing"><i class="fa fa-check"></i><b>9.3.9</b> Regularizing</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="machinelearning1.html"><a href="machinelearning1.html#distance-metrics"><i class="fa fa-check"></i><b>9.4</b> Distance Metrics</a><ul>
<li class="chapter" data-level="9.4.1" data-path="machinelearning1.html"><a href="machinelearning1.html#cosine-similarity"><i class="fa fa-check"></i><b>9.4.1</b> Cosine Similarity</a></li>
<li class="chapter" data-level="9.4.2" data-path="machinelearning1.html"><a href="machinelearning1.html#manhattan-and-euclidean-distance"><i class="fa fa-check"></i><b>9.4.2</b> Manhattan and Euclidean Distance  </a></li>
<li class="chapter" data-level="9.4.3" data-path="machinelearning1.html"><a href="machinelearning1.html#minkowski-and-chebyshev-supremum-distance"><i class="fa fa-check"></i><b>9.4.3</b> Minkowski and Chebyshev (Supremum) Distance  </a></li>
<li class="chapter" data-level="9.4.4" data-path="machinelearning1.html"><a href="machinelearning1.html#jaccard-similarity-and-distance"><i class="fa fa-check"></i><b>9.4.4</b> Jaccard (Similarity and Distance) </a></li>
<li class="chapter" data-level="9.4.5" data-path="machinelearning1.html"><a href="machinelearning1.html#hamming-distance"><i class="fa fa-check"></i><b>9.4.5</b> Hamming Distance </a></li>
<li class="chapter" data-level="9.4.6" data-path="machinelearning1.html"><a href="machinelearning1.html#mahalanobis-distance"><i class="fa fa-check"></i><b>9.4.6</b> Mahalanobis Distance </a></li>
<li class="chapter" data-level="9.4.7" data-path="machinelearning1.html"><a href="machinelearning1.html#precision-and-accuracy"><i class="fa fa-check"></i><b>9.4.7</b> Precision and Accuracy  </a></li>
<li class="chapter" data-level="9.4.8" data-path="machinelearning1.html"><a href="machinelearning1.html#auc-on-roc"><i class="fa fa-check"></i><b>9.4.8</b> AUC on ROC </a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="machinelearning1.html"><a href="machinelearning1.html#exploratory-data-analysis"><i class="fa fa-check"></i><b>9.5</b> Exploratory Data Analysis</a><ul>
<li class="chapter" data-level="9.5.1" data-path="machinelearning1.html"><a href="machinelearning1.html#data-cleaning-wrangling"><i class="fa fa-check"></i><b>9.5.1</b> Data Cleaning (Wrangling)  </a></li>
<li class="chapter" data-level="9.5.2" data-path="machinelearning1.html"><a href="machinelearning1.html#association"><i class="fa fa-check"></i><b>9.5.2</b> Association</a></li>
<li class="chapter" data-level="9.5.3" data-path="machinelearning1.html"><a href="machinelearning1.html#pattern-discovery"><i class="fa fa-check"></i><b>9.5.3</b> Pattern Discovery</a></li>
<li class="chapter" data-level="9.5.4" data-path="machinelearning1.html"><a href="machinelearning1.html#null-invariance"><i class="fa fa-check"></i><b>9.5.4</b> Null Invariance </a></li>
<li class="chapter" data-level="9.5.5" data-path="machinelearning1.html"><a href="machinelearning1.html#correlation-and-collinearity"><i class="fa fa-check"></i><b>9.5.5</b> Correlation and Collinearity  </a></li>
<li class="chapter" data-level="9.5.6" data-path="machinelearning1.html"><a href="machinelearning1.html#covariance"><i class="fa fa-check"></i><b>9.5.6</b> Covariance </a></li>
<li class="chapter" data-level="9.5.7" data-path="machinelearning1.html"><a href="machinelearning1.html#outliers-leverage-influence"><i class="fa fa-check"></i><b>9.5.7</b> Outliers, Leverage, Influence   </a></li>
<li class="chapter" data-level="9.5.8" data-path="machinelearning1.html"><a href="machinelearning1.html#dominating-factors"><i class="fa fa-check"></i><b>9.5.8</b> Dominating Factors </a></li>
<li class="chapter" data-level="9.5.9" data-path="machinelearning1.html"><a href="machinelearning1.html#missingness-and-imputation"><i class="fa fa-check"></i><b>9.5.9</b> Missingness and Imputation  </a></li>
<li class="chapter" data-level="9.5.10" data-path="machinelearning1.html"><a href="machinelearning1.html#confounding-variable"><i class="fa fa-check"></i><b>9.5.10</b> Confounding Variable </a></li>
<li class="chapter" data-level="9.5.11" data-path="machinelearning1.html"><a href="machinelearning1.html#data-leakage"><i class="fa fa-check"></i><b>9.5.11</b> Data Leakage </a></li>
<li class="chapter" data-level="9.5.12" data-path="machinelearning1.html"><a href="machinelearning1.html#one-hot-encoding"><i class="fa fa-check"></i><b>9.5.12</b> One Hot Encoding </a></li>
<li class="chapter" data-level="9.5.13" data-path="machinelearning1.html"><a href="machinelearning1.html#winsorization-and-trimming"><i class="fa fa-check"></i><b>9.5.13</b> Winsorization and Trimming  </a></li>
<li class="chapter" data-level="9.5.14" data-path="machinelearning1.html"><a href="machinelearning1.html#discretization"><i class="fa fa-check"></i><b>9.5.14</b> Discretization </a></li>
<li class="chapter" data-level="9.5.15" data-path="machinelearning1.html"><a href="machinelearning1.html#stratification"><i class="fa fa-check"></i><b>9.5.15</b> Stratification </a></li>
<li class="chapter" data-level="9.5.16" data-path="machinelearning1.html"><a href="machinelearning1.html#fine-and-coarse-classing"><i class="fa fa-check"></i><b>9.5.16</b> Fine and Coarse Classing</a></li>
<li class="chapter" data-level="9.5.17" data-path="machinelearning1.html"><a href="machinelearning1.html#embedding"><i class="fa fa-check"></i><b>9.5.17</b> Embedding </a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="machinelearning1.html"><a href="machinelearning1.html#featureengineering"><i class="fa fa-check"></i><b>9.6</b> Feature Engineering</a><ul>
<li class="chapter" data-level="9.6.1" data-path="machinelearning1.html"><a href="machinelearning1.html#machine-learning-features"><i class="fa fa-check"></i><b>9.6.1</b> Machine Learning Features</a></li>
<li class="chapter" data-level="9.6.2" data-path="machinelearning1.html"><a href="machinelearning1.html#dimensionality-reduction"><i class="fa fa-check"></i><b>9.6.2</b> Dimensionality Reduction </a></li>
<li class="chapter" data-level="9.6.3" data-path="machinelearning1.html"><a href="machinelearning1.html#principal-component-analysis"><i class="fa fa-check"></i><b>9.6.3</b> Principal Component Analysis  </a></li>
<li class="chapter" data-level="9.6.4" data-path="machinelearning1.html"><a href="machinelearning1.html#linear-discriminant-analysis-lda"><i class="fa fa-check"></i><b>9.6.4</b> Linear Discriminant Analysis (LDA)  </a></li>
<li class="chapter" data-level="9.6.5" data-path="machinelearning1.html"><a href="machinelearning1.html#feature-construction"><i class="fa fa-check"></i><b>9.6.5</b> Feature Construction </a></li>
<li class="chapter" data-level="9.6.6" data-path="machinelearning1.html"><a href="machinelearning1.html#featureselection"><i class="fa fa-check"></i><b>9.6.6</b> Feature Selection</a></li>
<li class="chapter" data-level="9.6.7" data-path="machinelearning1.html"><a href="machinelearning1.html#feature-transformation"><i class="fa fa-check"></i><b>9.6.7</b> Feature Transformation </a></li>
<li class="chapter" data-level="9.6.8" data-path="machinelearning1.html"><a href="machinelearning1.html#model-specification-1"><i class="fa fa-check"></i><b>9.6.8</b> Model Specification </a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="machinelearning1.html"><a href="machinelearning1.html#general-modeling"><i class="fa fa-check"></i><b>9.7</b> General Modeling</a><ul>
<li class="chapter" data-level="9.7.1" data-path="machinelearning1.html"><a href="machinelearning1.html#training-learning"><i class="fa fa-check"></i><b>9.7.1</b> Training (Learning)</a></li>
<li class="chapter" data-level="9.7.2" data-path="machinelearning1.html"><a href="machinelearning1.html#validation-tuning"><i class="fa fa-check"></i><b>9.7.2</b> Validation (Tuning) </a></li>
<li class="chapter" data-level="9.7.3" data-path="machinelearning1.html"><a href="machinelearning1.html#testing-assessing"><i class="fa fa-check"></i><b>9.7.3</b> Testing (Assessing) </a></li>
<li class="chapter" data-level="9.7.4" data-path="machinelearning1.html"><a href="machinelearning1.html#cross-validation-cv"><i class="fa fa-check"></i><b>9.7.4</b> Cross-Validation (CV)  </a></li>
<li class="chapter" data-level="9.7.5" data-path="machinelearning1.html"><a href="machinelearning1.html#bias-and-variance"><i class="fa fa-check"></i><b>9.7.5</b> Bias and Variance </a></li>
<li class="chapter" data-level="9.7.6" data-path="machinelearning1.html"><a href="machinelearning1.html#loss-and-cost-functions"><i class="fa fa-check"></i><b>9.7.6</b> Loss and Cost Functions  </a></li>
<li class="chapter" data-level="9.7.7" data-path="machinelearning1.html"><a href="machinelearning1.html#global-and-local-minima"><i class="fa fa-check"></i><b>9.7.7</b> Global and Local Minima  </a></li>
<li class="chapter" data-level="9.7.8" data-path="machinelearning1.html"><a href="machinelearning1.html#regularization"><i class="fa fa-check"></i><b>9.7.8</b> Regularization</a></li>
</ul></li>
<li class="chapter" data-level="9.8" data-path="machinelearning1.html"><a href="machinelearning1.html#supervised-vs.unsupervised-learning"><i class="fa fa-check"></i><b>9.8</b> Supervised vs.Â Unsupervised Learning  </a></li>
<li class="chapter" data-level="9.9" data-path="machinelearning1.html"><a href="machinelearning1.html#summary-6"><i class="fa fa-check"></i><b>9.9</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="machinelearning2.html"><a href="machinelearning2.html"><i class="fa fa-check"></i><b>10</b> Computational Learning II</a><ul>
<li class="chapter" data-level="10.1" data-path="machinelearning2.html"><a href="machinelearning2.html#regression"><i class="fa fa-check"></i><b>10.1</b> Regression (Supervised)</a><ul>
<li class="chapter" data-level="10.1.1" data-path="machinelearning2.html"><a href="machinelearning2.html#regression-trees"><i class="fa fa-check"></i><b>10.1.1</b> Regression Trees </a></li>
<li class="chapter" data-level="10.1.2" data-path="machinelearning2.html"><a href="machinelearning2.html#ensemble-methods"><i class="fa fa-check"></i><b>10.1.2</b> Ensemble Methods </a></li>
<li class="chapter" data-level="10.1.3" data-path="machinelearning2.html"><a href="machinelearning2.html#random-forest"><i class="fa fa-check"></i><b>10.1.3</b> Random Forest </a></li>
<li class="chapter" data-level="10.1.4" data-path="machinelearning2.html"><a href="machinelearning2.html#Adaoost"><i class="fa fa-check"></i><b>10.1.4</b> AdaBoost</a></li>
<li class="chapter" data-level="10.1.5" data-path="machinelearning2.html"><a href="machinelearning2.html#gradient-boost"><i class="fa fa-check"></i><b>10.1.5</b> Gradient Boost </a></li>
<li class="chapter" data-level="10.1.6" data-path="machinelearning2.html"><a href="machinelearning2.html#xgboost"><i class="fa fa-check"></i><b>10.1.6</b> XGBoost </a></li>
<li class="chapter" data-level="10.1.7" data-path="machinelearning2.html"><a href="machinelearning2.html#generalized-linear-modeling-glm"><i class="fa fa-check"></i><b>10.1.7</b> Generalized Linear Modeling (GLM)  </a></li>
<li class="chapter" data-level="10.1.8" data-path="machinelearning2.html"><a href="machinelearning2.html#logisticregression"><i class="fa fa-check"></i><b>10.1.8</b> Logistic Regression (GLM)</a></li>
<li class="chapter" data-level="10.1.9" data-path="machinelearning2.html"><a href="machinelearning2.html#poisson"><i class="fa fa-check"></i><b>10.1.9</b> Poisson Regression (GLM)</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="machinelearning2.html"><a href="machinelearning2.html#binary-classification-supervised"><i class="fa fa-check"></i><b>10.2</b> Binary Classification (Supervised)</a><ul>
<li class="chapter" data-level="10.2.1" data-path="machinelearning2.html"><a href="machinelearning2.html#linear-svm-sgdpegasos"><i class="fa fa-check"></i><b>10.2.1</b> Linear SVM (SGD/PEGASOS)  </a></li>
<li class="chapter" data-level="10.2.2" data-path="machinelearning2.html"><a href="machinelearning2.html#kernel-svm-smo"><i class="fa fa-check"></i><b>10.2.2</b> Kernel SVM (SMO)  </a></li>
<li class="chapter" data-level="10.2.3" data-path="machinelearning2.html"><a href="machinelearning2.html#sdca-based-svm"><i class="fa fa-check"></i><b>10.2.3</b> SDCA-based SVM </a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="machinelearning2.html"><a href="machinelearning2.html#multi-class-classification-supervised"><i class="fa fa-check"></i><b>10.3</b> Multi-class Classification (Supervised) </a><ul>
<li class="chapter" data-level="10.3.1" data-path="machinelearning2.html"><a href="machinelearning2.html#bayesian-classification"><i class="fa fa-check"></i><b>10.3.1</b> Bayesian Classification </a></li>
<li class="chapter" data-level="10.3.2" data-path="machinelearning2.html"><a href="machinelearning2.html#classification-trees"><i class="fa fa-check"></i><b>10.3.2</b> Classification Trees </a></li>
<li class="chapter" data-level="10.3.3" data-path="machinelearning2.html"><a href="machinelearning2.html#ensemble-methods-1"><i class="fa fa-check"></i><b>10.3.3</b> Ensemble Methods </a></li>
<li class="chapter" data-level="10.3.4" data-path="machinelearning2.html"><a href="machinelearning2.html#random-forest-1"><i class="fa fa-check"></i><b>10.3.4</b> Random Forest </a></li>
<li class="chapter" data-level="10.3.5" data-path="machinelearning2.html"><a href="machinelearning2.html#AdaBoost"><i class="fa fa-check"></i><b>10.3.5</b> AdaBoost &amp; SAMME</a></li>
<li class="chapter" data-level="10.3.6" data-path="machinelearning2.html"><a href="machinelearning2.html#logitboost-j-classes"><i class="fa fa-check"></i><b>10.3.6</b> LogitBoost (J Classes)</a></li>
<li class="chapter" data-level="10.3.7" data-path="machinelearning2.html"><a href="machinelearning2.html#gradient-boost-1"><i class="fa fa-check"></i><b>10.3.7</b> Gradient Boost </a></li>
<li class="chapter" data-level="10.3.8" data-path="machinelearning2.html"><a href="machinelearning2.html#k-next-neighbors-knn"><i class="fa fa-check"></i><b>10.3.8</b> K-Next Neighbors (KNN)  </a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="machinelearning3.html"><a href="machinelearning3.html"><i class="fa fa-check"></i><b>11</b> Computational Learning III</a><ul>
<li class="chapter" data-level="11.1" data-path="machinelearning3.html"><a href="machinelearning3.html#clustering-unsupervised"><i class="fa fa-check"></i><b>11.1</b> Clustering (Unsupervised) </a><ul>
<li class="chapter" data-level="11.1.1" data-path="machinelearning3.html"><a href="machinelearning3.html#k-means-clustering"><i class="fa fa-check"></i><b>11.1.1</b> K-means (clustering) </a></li>
<li class="chapter" data-level="11.1.2" data-path="machinelearning3.html"><a href="machinelearning3.html#hierarchical-clustering"><i class="fa fa-check"></i><b>11.1.2</b> Hierarchical (clustering) </a></li>
<li class="chapter" data-level="11.1.3" data-path="machinelearning3.html"><a href="machinelearning3.html#dbscan-clustering"><i class="fa fa-check"></i><b>11.1.3</b> DBSCAN (clustering) </a></li>
<li class="chapter" data-level="11.1.4" data-path="machinelearning3.html"><a href="machinelearning3.html#quality-of-clustering"><i class="fa fa-check"></i><b>11.1.4</b> Quality of Clustering</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="machinelearning3.html"><a href="machinelearning3.html#meta-learning"><i class="fa fa-check"></i><b>11.2</b> Meta-Learning </a></li>
<li class="chapter" data-level="11.3" data-path="machinelearning3.html"><a href="machinelearning3.html#natural-language-processing-nlp"><i class="fa fa-check"></i><b>11.3</b> Natural Language Processing (NLP)  </a><ul>
<li class="chapter" data-level="11.3.1" data-path="machinelearning3.html"><a href="machinelearning3.html#pre-processing-texts"><i class="fa fa-check"></i><b>11.3.1</b> Pre-Processing Texts</a></li>
<li class="chapter" data-level="11.3.2" data-path="machinelearning3.html"><a href="machinelearning3.html#ranking-and-scoring"><i class="fa fa-check"></i><b>11.3.2</b> Ranking and Scoring </a></li>
<li class="chapter" data-level="11.3.3" data-path="machinelearning3.html"><a href="machinelearning3.html#document-similarity"><i class="fa fa-check"></i><b>11.3.3</b> Document Similarity </a></li>
<li class="chapter" data-level="11.3.4" data-path="machinelearning3.html"><a href="machinelearning3.html#linguistic-analysis"><i class="fa fa-check"></i><b>11.3.4</b> Linguistic Analysis </a></li>
<li class="chapter" data-level="11.3.5" data-path="machinelearning3.html"><a href="machinelearning3.html#lexical-analysis"><i class="fa fa-check"></i><b>11.3.5</b> Lexical Analysis </a></li>
<li class="chapter" data-level="11.3.6" data-path="machinelearning3.html"><a href="machinelearning3.html#semantic-analysis"><i class="fa fa-check"></i><b>11.3.6</b> Semantic Analysis </a></li>
<li class="chapter" data-level="11.3.7" data-path="machinelearning3.html"><a href="machinelearning3.html#named-entity-recognition-ner"><i class="fa fa-check"></i><b>11.3.7</b> Named Entity Recognition (NER)  </a></li>
<li class="chapter" data-level="11.3.8" data-path="machinelearning3.html"><a href="machinelearning3.html#sentiment-and-opinion-analysis"><i class="fa fa-check"></i><b>11.3.8</b> Sentiment and Opinion Analysis  </a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="machinelearning3.html"><a href="machinelearning3.html#time-series-forecasting"><i class="fa fa-check"></i><b>11.4</b> Time-Series Forecasting </a><ul>
<li class="chapter" data-level="11.4.1" data-path="machinelearning3.html"><a href="machinelearning3.html#seasonal-trend-decomposition-using-loess-stl"><i class="fa fa-check"></i><b>11.4.1</b> Seasonal Trend Decomposition using LOESS (STL)  </a></li>
<li class="chapter" data-level="11.4.2" data-path="machinelearning3.html"><a href="machinelearning3.html#forecasting-models"><i class="fa fa-check"></i><b>11.4.2</b> Forecasting Models </a></li>
<li class="chapter" data-level="11.4.3" data-path="machinelearning3.html"><a href="machinelearning3.html#time-series-linear-model-tslm"><i class="fa fa-check"></i><b>11.4.3</b> Time-Series Linear Model (TSLM)  </a></li>
<li class="chapter" data-level="11.4.4" data-path="machinelearning3.html"><a href="machinelearning3.html#autoregressive-integrated-moving-average-arima"><i class="fa fa-check"></i><b>11.4.4</b> AutoRegressive Integrated Moving Average (ARIMA)  </a></li>
<li class="chapter" data-level="11.4.5" data-path="machinelearning3.html"><a href="machinelearning3.html#multiplicative-seasonal-arima-sarima"><i class="fa fa-check"></i><b>11.4.5</b> Multiplicative Seasonal ARIMA (SARIMA) </a></li>
<li class="chapter" data-level="11.4.6" data-path="machinelearning3.html"><a href="machinelearning3.html#time-series-decomposition"><i class="fa fa-check"></i><b>11.4.6</b> Time-Series Decomposition </a></li>
<li class="chapter" data-level="11.4.7" data-path="machinelearning3.html"><a href="machinelearning3.html#stl-with-aicbic"><i class="fa fa-check"></i><b>11.4.7</b> STL with AIC/BIC</a></li>
<li class="chapter" data-level="11.4.8" data-path="machinelearning3.html"><a href="machinelearning3.html#multivariate-time-series"><i class="fa fa-check"></i><b>11.4.8</b> Multivariate Time-Series</a></li>
<li class="chapter" data-level="11.4.9" data-path="machinelearning3.html"><a href="machinelearning3.html#forecasting-considerations"><i class="fa fa-check"></i><b>11.4.9</b> Forecasting Considerations</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="machinelearning3.html"><a href="machinelearning3.html#recommender-systems"><i class="fa fa-check"></i><b>11.5</b> Recommender Systems </a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="deeplearning1.html"><a href="deeplearning1.html"><i class="fa fa-check"></i><b>12</b> Computational Deep Learning I</a><ul>
<li class="chapter" data-level="12.1" data-path="deeplearning1.html"><a href="deeplearning1.html#simple-perceptron"><i class="fa fa-check"></i><b>12.1</b> Simple Perceptron  </a></li>
<li class="chapter" data-level="12.2" data-path="deeplearning1.html"><a href="deeplearning1.html#adaptive-linear-neuron-adaline"><i class="fa fa-check"></i><b>12.2</b> Adaptive Linear Neuron (ADALINE)  </a></li>
<li class="chapter" data-level="12.3" data-path="deeplearning1.html"><a href="deeplearning1.html#multi-layer-perceptron-mlp"><i class="fa fa-check"></i><b>12.3</b> Multi Layer Perceptron (MLP)  </a><ul>
<li class="chapter" data-level="12.3.1" data-path="deeplearning1.html"><a href="deeplearning1.html#forward-feed"><i class="fa fa-check"></i><b>12.3.1</b> Forward Feed </a></li>
<li class="chapter" data-level="12.3.2" data-path="deeplearning1.html"><a href="deeplearning1.html#backward-feed"><i class="fa fa-check"></i><b>12.3.2</b> Backward Feed </a></li>
<li class="chapter" data-level="12.3.3" data-path="deeplearning1.html"><a href="deeplearning1.html#backpropagation"><i class="fa fa-check"></i><b>12.3.3</b> BackPropagation </a></li>
<li class="chapter" data-level="12.3.4" data-path="deeplearning1.html"><a href="deeplearning1.html#mlp-example"><i class="fa fa-check"></i><b>12.3.4</b> MLP Example</a></li>
<li class="chapter" data-level="12.3.5" data-path="deeplearning1.html"><a href="deeplearning1.html#activation-function"><i class="fa fa-check"></i><b>12.3.5</b> Activation Function </a></li>
<li class="chapter" data-level="12.3.6" data-path="deeplearning1.html"><a href="deeplearning1.html#mlp-implementation"><i class="fa fa-check"></i><b>12.3.6</b> MLP Implementation</a></li>
<li class="chapter" data-level="12.3.7" data-path="deeplearning1.html"><a href="deeplearning1.html#deep-neural-network-dnn"><i class="fa fa-check"></i><b>12.3.7</b> Deep Neural Network (DNN)  </a></li>
<li class="chapter" data-level="12.3.8" data-path="deeplearning1.html"><a href="deeplearning1.html#vanishing-and-exploding-gradient"><i class="fa fa-check"></i><b>12.3.8</b> Vanishing and Exploding Gradient  </a></li>
<li class="chapter" data-level="12.3.9" data-path="deeplearning1.html"><a href="deeplearning1.html#dead-relu"><i class="fa fa-check"></i><b>12.3.9</b> Dead Relu </a></li>
<li class="chapter" data-level="12.3.10" data-path="deeplearning1.html"><a href="deeplearning1.html#gradient-clipping-gc"><i class="fa fa-check"></i><b>12.3.10</b> Gradient Clipping (GC) </a></li>
<li class="chapter" data-level="12.3.11" data-path="deeplearning1.html"><a href="deeplearning1.html#parameter-initialization"><i class="fa fa-check"></i><b>12.3.11</b> Parameter Initialization </a></li>
<li class="chapter" data-level="12.3.12" data-path="deeplearning1.html"><a href="deeplearning1.html#regularization-by-dropouts"><i class="fa fa-check"></i><b>12.3.12</b> Regularization by Dropouts </a></li>
<li class="chapter" data-level="12.3.13" data-path="deeplearning1.html"><a href="deeplearning1.html#batch-normalization"><i class="fa fa-check"></i><b>12.3.13</b> Batch Normalization </a></li>
<li class="chapter" data-level="12.3.14" data-path="deeplearning1.html"><a href="deeplearning1.html#optimization"><i class="fa fa-check"></i><b>12.3.14</b> Optimization </a></li>
<li class="chapter" data-level="12.3.15" data-path="deeplearning1.html"><a href="deeplearning1.html#interpretability"><i class="fa fa-check"></i><b>12.3.15</b> Interpretability</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="deeplearning1.html"><a href="deeplearning1.html#convolutional-neural-network-cnn"><i class="fa fa-check"></i><b>12.4</b> Convolutional Neural Network (CNN)  </a><ul>
<li class="chapter" data-level="12.4.1" data-path="deeplearning1.html"><a href="deeplearning1.html#computer-graphics"><i class="fa fa-check"></i><b>12.4.1</b> Computer Graphics</a></li>
<li class="chapter" data-level="12.4.2" data-path="deeplearning1.html"><a href="deeplearning1.html#convolution"><i class="fa fa-check"></i><b>12.4.2</b> Convolution </a></li>
<li class="chapter" data-level="12.4.3" data-path="deeplearning1.html"><a href="deeplearning1.html#stride-and-padding"><i class="fa fa-check"></i><b>12.4.3</b> Stride and Padding  </a></li>
<li class="chapter" data-level="12.4.4" data-path="deeplearning1.html"><a href="deeplearning1.html#kernels-and-filters"><i class="fa fa-check"></i><b>12.4.4</b> Kernels And Filters</a></li>
<li class="chapter" data-level="12.4.5" data-path="deeplearning1.html"><a href="deeplearning1.html#dilation"><i class="fa fa-check"></i><b>12.4.5</b> Dilation </a></li>
<li class="chapter" data-level="12.4.6" data-path="deeplearning1.html"><a href="deeplearning1.html#pooling"><i class="fa fa-check"></i><b>12.4.6</b> Pooling </a></li>
<li class="chapter" data-level="12.4.7" data-path="deeplearning1.html"><a href="deeplearning1.html#cnn-architectures"><i class="fa fa-check"></i><b>12.4.7</b> CNN Architectures</a></li>
<li class="chapter" data-level="12.4.8" data-path="deeplearning1.html"><a href="deeplearning1.html#forward-feed-1"><i class="fa fa-check"></i><b>12.4.8</b> Forward Feed </a></li>
<li class="chapter" data-level="12.4.9" data-path="deeplearning1.html"><a href="deeplearning1.html#backpropagation-1"><i class="fa fa-check"></i><b>12.4.9</b> BackPropagation </a></li>
<li class="chapter" data-level="12.4.10" data-path="deeplearning1.html"><a href="deeplearning1.html#optimization-1"><i class="fa fa-check"></i><b>12.4.10</b> Optimization</a></li>
<li class="chapter" data-level="12.4.11" data-path="deeplearning1.html"><a href="deeplearning1.html#normalization"><i class="fa fa-check"></i><b>12.4.11</b> Normalization</a></li>
<li class="chapter" data-level="12.4.12" data-path="deeplearning1.html"><a href="deeplearning1.html#step-decay"><i class="fa fa-check"></i><b>12.4.12</b> Step Decay</a></li>
<li class="chapter" data-level="12.4.13" data-path="deeplearning1.html"><a href="deeplearning1.html#gemm-matrix-multiplication"><i class="fa fa-check"></i><b>12.4.13</b> GEMM (Matrix Multiplication) </a></li>
<li class="chapter" data-level="12.4.14" data-path="deeplearning1.html"><a href="deeplearning1.html#depthwise-separable-convolution-dsc"><i class="fa fa-check"></i><b>12.4.14</b> Depthwise Separable Convolution (DSC)  </a></li>
<li class="chapter" data-level="12.4.15" data-path="deeplearning1.html"><a href="deeplearning1.html#cnn-implementation"><i class="fa fa-check"></i><b>12.4.15</b> CNN Implementation</a></li>
<li class="chapter" data-level="12.4.16" data-path="deeplearning1.html"><a href="deeplearning1.html#cnn-application"><i class="fa fa-check"></i><b>12.4.16</b> CNN Application</a></li>
<li class="chapter" data-level="12.4.17" data-path="deeplearning1.html"><a href="deeplearning1.html#summary-7"><i class="fa fa-check"></i><b>12.4.17</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="deeplearning2.html"><a href="deeplearning2.html"><i class="fa fa-check"></i><b>13</b> Computational Deep Learning II</a><ul>
<li class="chapter" data-level="13.1" data-path="deeplearning2.html"><a href="deeplearning2.html#residual-network-resnet"><i class="fa fa-check"></i><b>13.1</b> Residual Network (ResNet)  </a></li>
<li class="chapter" data-level="13.2" data-path="deeplearning2.html"><a href="deeplearning2.html#recurrent-neural-network-rnn"><i class="fa fa-check"></i><b>13.2</b> Recurrent Neural Network (RNN)  </a><ul>
<li class="chapter" data-level="13.2.1" data-path="deeplearning2.html"><a href="deeplearning2.html#vanilla-rnn"><i class="fa fa-check"></i><b>13.2.1</b> Vanilla RNN</a></li>
<li class="chapter" data-level="13.2.2" data-path="deeplearning2.html"><a href="deeplearning2.html#long-short-term-memory-lstm"><i class="fa fa-check"></i><b>13.2.2</b> Long Short-Term Memory (LSTM)  </a></li>
<li class="chapter" data-level="13.2.3" data-path="deeplearning2.html"><a href="deeplearning2.html#gated-recurrent-units-gru"><i class="fa fa-check"></i><b>13.2.3</b> Gated Recurrent Units (GRU)  </a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="deeplearning2.html"><a href="deeplearning2.html#deep-stacked-rnn"><i class="fa fa-check"></i><b>13.3</b> Deep Stacked RNN </a></li>
<li class="chapter" data-level="13.4" data-path="deeplearning2.html"><a href="deeplearning2.html#deep-stacked-bidirectional-rnn"><i class="fa fa-check"></i><b>13.4</b> Deep Stacked Bidirectional RNN </a></li>
<li class="chapter" data-level="13.5" data-path="deeplearning2.html"><a href="deeplearning2.html#transformer-neural-network-tnn"><i class="fa fa-check"></i><b>13.5</b> Transformer Neural Network (TNN)  </a><ul>
<li class="chapter" data-level="13.5.1" data-path="deeplearning2.html"><a href="deeplearning2.html#attention"><i class="fa fa-check"></i><b>13.5.1</b> Attention </a></li>
<li class="chapter" data-level="13.5.2" data-path="deeplearning2.html"><a href="deeplearning2.html#self-attention-and-trainability"><i class="fa fa-check"></i><b>13.5.2</b> Self-Attention and Trainability </a></li>
<li class="chapter" data-level="13.5.3" data-path="deeplearning2.html"><a href="deeplearning2.html#multi-head-attention"><i class="fa fa-check"></i><b>13.5.3</b> Multi-Head Attention </a></li>
<li class="chapter" data-level="13.5.4" data-path="deeplearning2.html"><a href="deeplearning2.html#word-embedding"><i class="fa fa-check"></i><b>13.5.4</b> Word Embedding </a></li>
<li class="chapter" data-level="13.5.5" data-path="deeplearning2.html"><a href="deeplearning2.html#positional-embedding"><i class="fa fa-check"></i><b>13.5.5</b> Positional Embedding </a></li>
<li class="chapter" data-level="13.5.6" data-path="deeplearning2.html"><a href="deeplearning2.html#sequence-alignment"><i class="fa fa-check"></i><b>13.5.6</b> Sequence Alignment</a></li>
<li class="chapter" data-level="13.5.7" data-path="deeplearning2.html"><a href="deeplearning2.html#transformer-architectures"><i class="fa fa-check"></i><b>13.5.7</b> Transformer Architectures </a></li>
</ul></li>
<li class="chapter" data-level="13.6" data-path="deeplearning2.html"><a href="deeplearning2.html#applications-using-tnn-and-rnn"><i class="fa fa-check"></i><b>13.6</b> Applications using TNN (and RNN)</a><ul>
<li class="chapter" data-level="13.6.1" data-path="deeplearning2.html"><a href="deeplearning2.html#speech-recognition"><i class="fa fa-check"></i><b>13.6.1</b> Speech Recognition </a></li>
<li class="chapter" data-level="13.6.2" data-path="deeplearning2.html"><a href="deeplearning2.html#mel-coefficients-feature-extraction"><i class="fa fa-check"></i><b>13.6.2</b> Mel Coefficients (Feature Extraction) </a></li>
<li class="chapter" data-level="13.6.3" data-path="deeplearning2.html"><a href="deeplearning2.html#connectionist-temporal-classification-ctc"><i class="fa fa-check"></i><b>13.6.3</b> Connectionist Temporal Classification (CTC)  </a></li>
<li class="chapter" data-level="13.6.4" data-path="deeplearning2.html"><a href="deeplearning2.html#model-evaluation"><i class="fa fa-check"></i><b>13.6.4</b> Model Evaluation</a></li>
</ul></li>
<li class="chapter" data-level="13.7" data-path="deeplearning2.html"><a href="deeplearning2.html#generative-adversarial-network-gan"><i class="fa fa-check"></i><b>13.7</b> Generative Adversarial Network (GAN)  </a></li>
<li class="chapter" data-level="13.8" data-path="deeplearning2.html"><a href="deeplearning2.html#deep-reinforcement-network-dqn"><i class="fa fa-check"></i><b>13.8</b> Deep Reinforcement Network (DQN)  </a></li>
<li class="chapter" data-level="13.9" data-path="deeplearning2.html"><a href="deeplearning2.html#summary-8"><i class="fa fa-check"></i><b>13.9</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="distributedcomputation.html"><a href="distributedcomputation.html"><i class="fa fa-check"></i><b>14</b> Distributed Computation</a><ul>
<li class="chapter" data-level="14.1" data-path="distributedcomputation.html"><a href="distributedcomputation.html#integration-and-interoperability"><i class="fa fa-check"></i><b>14.1</b> Integration and Interoperability</a></li>
<li class="chapter" data-level="14.2" data-path="distributedcomputation.html"><a href="distributedcomputation.html#ml-pipelines"><i class="fa fa-check"></i><b>14.2</b> ML Pipelines</a></li>
<li class="chapter" data-level="14.3" data-path="distributedcomputation.html"><a href="distributedcomputation.html#open-standards"><i class="fa fa-check"></i><b>14.3</b> Open Standards</a><ul>
<li class="chapter" data-level="14.3.1" data-path="distributedcomputation.html"><a href="distributedcomputation.html#predictive-model-markup-language-pmml"><i class="fa fa-check"></i><b>14.3.1</b> Predictive Model Markup Language (PMML)</a></li>
<li class="chapter" data-level="14.3.2" data-path="distributedcomputation.html"><a href="distributedcomputation.html#portable-format-for-analytics-pfa"><i class="fa fa-check"></i><b>14.3.2</b> Portable Format for Analytics (PFA)</a></li>
<li class="chapter" data-level="14.3.3" data-path="distributedcomputation.html"><a href="distributedcomputation.html#open-neural-network-exchange-onnx"><i class="fa fa-check"></i><b>14.3.3</b> Open Neural Network Exchange (ONNX)</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="distributedcomputation.html"><a href="distributedcomputation.html#general-summary"><i class="fa fa-check"></i><b>14.4</b> General Summary</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i><b>15</b> Appendix</a><ul>
<li class="chapter" data-level="15.1" data-path="appendix.html"><a href="appendix.html#appendix-a"><i class="fa fa-check"></i><b>15.1</b> Appendix A</a><ul>
<li class="chapter" data-level="15.1.1" data-path="appendix.html"><a href="appendix.html#trigonometry"><i class="fa fa-check"></i><b>15.1.1</b> Trigonometry</a></li>
<li class="chapter" data-level="15.1.2" data-path="appendix.html"><a href="appendix.html#logarithms"><i class="fa fa-check"></i><b>15.1.2</b> Logarithms</a></li>
<li class="chapter" data-level="15.1.3" data-path="appendix.html"><a href="appendix.html#category-theory"><i class="fa fa-check"></i><b>15.1.3</b> Category Theory</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="appendix.html"><a href="appendix.html#appendix-b"><i class="fa fa-check"></i><b>15.2</b> Appendix B</a><ul>
<li class="chapter" data-level="15.2.1" data-path="appendix.html"><a href="appendix.html#on-random-chances"><i class="fa fa-check"></i><b>15.2.1</b> On Random chances</a></li>
<li class="chapter" data-level="15.2.2" data-path="appendix.html"><a href="appendix.html#on-replacements"><i class="fa fa-check"></i><b>15.2.2</b> On Replacements</a></li>
<li class="chapter" data-level="15.2.3" data-path="appendix.html"><a href="appendix.html#on-permutations-and-combinations"><i class="fa fa-check"></i><b>15.2.3</b> On Permutations and Combinations</a></li>
<li class="chapter" data-level="15.2.4" data-path="appendix.html"><a href="appendix.html#on-conditional-probabilities"><i class="fa fa-check"></i><b>15.2.4</b> On Conditional Probabilities</a></li>
<li class="chapter" data-level="15.2.5" data-path="appendix.html"><a href="appendix.html#the-arithmetic-of-probabilities"><i class="fa fa-check"></i><b>15.2.5</b> The Arithmetic of Probabilities</a></li>
<li class="chapter" data-level="15.2.6" data-path="appendix.html"><a href="appendix.html#on-dependent-and-independent-events"><i class="fa fa-check"></i><b>15.2.6</b> On Dependent and Independent Events</a></li>
<li class="chapter" data-level="15.2.7" data-path="appendix.html"><a href="appendix.html#on-mutual-exclusivity"><i class="fa fa-check"></i><b>15.2.7</b> On Mutual Exclusivity</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="appendix.html"><a href="appendix.html#appendix-c"><i class="fa fa-check"></i><b>15.3</b> Appendix C</a></li>
<li class="chapter" data-level="15.4" data-path="appendix.html"><a href="appendix.html#appendix-d"><i class="fa fa-check"></i><b>15.4</b> Appendix D</a><ul>
<li class="chapter" data-level="15.4.1" data-path="appendix.html"><a href="appendix.html#lubridate-library"><i class="fa fa-check"></i><b>15.4.1</b> Lubridate Library</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="bibliography.html"><a href="bibliography.html"><i class="fa fa-check"></i>Bibliography</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">The Power and Art of Approximation</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="bayesian" class="section level1 hasAnchor">
<h1><span class="header-section-number">Chapter 7</span> Bayesian Computation I<a href="bayesian.html#bayesian" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { 
      equationNumbers: {
            autoNumber: "AMS",
            formatNumber: function (n) {return '7.'+n}
      } 
  }
});
</script>
<p>Naturally unpredictable events, such as the outcome of a presidential election or the rise and fall of the stock market, are the main subjects of Bayesian Analysis. Here, we try to work around the <strong>uncertainty</strong> of such events.</p>
<p>In this chapter, we focus on Bayesian Analysis instead of Non-Bayesian Analysis. The use of <strong>probabilistic</strong> means and reliance on <strong>prior</strong> knowledge make Bayesian Analysis different from Non-Bayesian Analysis. Here, we recognize the randomness of events occurring, represented by <strong>random variables</strong>. Similar to Non-Bayesian Analysis, we sample data, but we consider each sample as the occurrence of some random event. Our objective in this respect is to predict or approximate the probability of an event occurring. Then we use <strong>credible intervals</strong> in the same way we use <strong>confidence intervals</strong> in Statistics to gauge the accuracy of our prediction.</p>
<p>The most notable point here is to be aware that <strong>prior knowledge</strong> is not discounted even before we sample or see the data.</p>
<p>In this chapter and the next, we continue to focus on Numerical Analysis in the context of Bayesian Analysis as we reference the great works of Vapnik V. <span class="citation">(<a href="bibliography.html#ref-ref572v">2000</a>)</span>, Stewart W.J. <span class="citation">(<a href="bibliography.html#ref-ref233w">2009</a>)</span>, Murphy K.P. <span class="citation">(<a href="bibliography.html#ref-ref224k">2012</a>)</span>, Gelman A. et al. <span class="citation">(<a href="bibliography.html#ref-ref250a">2013</a>)</span>, Kruschke J.K. <span class="citation">(<a href="bibliography.html#ref-ref241j">2015</a>)</span>, and Lambert B. <span class="citation">(<a href="bibliography.html#ref-ref240b">2018</a>)</span>, along with other additional references for consistency.</p>
<div id="probability-1" class="section level2 hasAnchor">
<h2><span class="header-section-number">7.1</span> Probability <a href="bayesian.html#probability-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We extend the concept of probability from Chapter <strong>5</strong> (<strong>Numerical Probability and Distribution</strong>). Here, we come from the idea of sampling (or making random observations) from a population. Such a list of random observations may follow a particular distribution. For example, one of the most common distributions is the Bell-shaped Gaussian distribution using a normal probability density function (<strong>PDF</strong>). Other types of distributions are discussed in detail in Chapter <strong>5</strong> (<strong>Numerical Probability and Distribution</strong>) under the <strong>Types of Distribution</strong> Section.</p>
<p>Recall the symbol <span class="math inline">\(\rho(x)\)</span> as a notation for a probability density function. Here, we use the small-case <span class="math inline">\(f(x)\)</span> for our purposes instead.</p>
<p><span class="math display">\[\begin{align}
\rho(x;\mu, \sigma^2)  = f(x; u, \sigma2) = \text{&lt;normal density function&gt;}
\end{align}\]</span></p>
<p>The density of a random variable <strong>x</strong> with parameters <span class="math inline">\(\mathbf{\mu}\)</span> and <span class="math inline">\(\mathbf{\sigma^2}\)</span>.</p>
<p>For example, to compute for the probability of a single event, <strong>x</strong> equal to 1, we express it as such (granting <strong>x</strong> follows a normal distribution):</p>
<p><span class="math display">\[\begin{align}
f(x;\mu, \sigma^2) = P(x = 1 | \mu, \sigma^2)\ \ \ \rightarrow\ \ \ \ \ X ~ \sim \mathcal{N}(\mu, \sigma^2)
\end{align}\]</span></p>
<p>Hereafter, we may be using different notations for probabilities. For example, we can use any notations to mean that the probability of <strong>X</strong> (uppercase) is equal to a value <strong>x</strong> (lowercase).</p>
<p><span class="math display">\[\begin{align}
P(X = x) \equiv P_X(X = x) \equiv P_X(x)
\end{align}\]</span></p>
<div id="marginal-probability" class="section level3 hasAnchor">
<h3><span class="header-section-number">7.1.1</span> Marginal Probability <a href="bayesian.html#marginal-probability" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Marginal probability</strong> is a probability in which an event does not depend on the outcome of another event. For example, suppose <strong>X</strong> is a random variable, and <strong>x</strong> is an observable event. In terms of density with the probability of one event occurring, we have the following expression (we use small-case notation <strong>f(x)</strong>):</p>
<p><span class="math display">\[\begin{align}
f_X(x) = P_X(X = x)
\end{align}\]</span></p>
<p>It reads as <strong>Probability of X</strong>. It can also be said that <strong>X</strong> is <strong>not constrained</strong> by any event.</p>
<p>Therefore, <strong>Marginal Probability</strong> is also known as <strong>Unconditional Probability</strong>.</p>
<p>In terms of cumulative density with a range of probabilities (of multiple observable events occurring), we have the following expression (we use upper-case notation <strong>F(x)</strong>):</p>
<p><span class="math display">\[\begin{align}
\mathcal{F}_X(X = x) = \begin{cases}
\sum_x P_X(x)  &amp; \text{if x is discrete}\\
\\
\int P_X(x) dx &amp; \text{if x is continuous}
\end{cases} \label{eqn:eqnnumber36}
\end{align}\]</span></p>
<p>Note that for continuous cumulative probability, we can use the integrated probability to obtain the density probability by derivatives:</p>
<p><span class="math display">\[\begin{align}
f_X(x) = \frac{d}{dx} \mathcal{F}_X(X = x)\ \ \ \rightarrow\ \ \ \ \mathcal{F}x(X = x) = \int f_X(x) dx  
\end{align}\]</span></p>
</div>
<div id="joint-probability" class="section level3 hasAnchor">
<h3><span class="header-section-number">7.1.2</span> Joint Probability <a href="bayesian.html#joint-probability" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Joint probability</strong> is the probability of two or more events occurring together - it represents the intersection of two or more events. Suppose <strong>X</strong> and <strong>Y</strong> are two random variables and that <strong>x</strong> and <strong>y</strong> are the corresponding observable events.</p>
<p>In terms of density with the probability of one event occurring per random variable, we have the following expression:</p>
<p><span class="math display">\[\begin{align}
f_{X,Y}(x,y) = P_{X,Y}(X = x, Y = y)
\end{align}\]</span></p>
<p>That is also denoted by any of the following notations:</p>
<p><span class="math display">\[\begin{align}
P(X \perp\!\!\perp Y) = P(X \cap Y) = P(X\ and\ Y) = P(XY),\ \ \ \ \ \ \ e.g.  P(X = 5, Y = 5) 
\end{align}\]</span></p>
<p>The probability of drawing a card from a deck and a heart from another is calculated as:</p>
<p><span class="math display">\[\begin{align}
P(X = 9\ and\ Y = heart) = 1/52 + 13/52 = 7/26
\end{align}\]</span></p>
<p>In terms of cumulative density with a range of probabilities, we have the following expression:</p>
<p><span class="math display">\[\begin{align}
\mathcal{F}_{X,Y}(x, y)  = 
\begin{cases}
\sum_x \sum_y P_{X,Y}(x,y)  &amp; \text{if x,y are discrete}\\
\\
\int \int P_{X,Y}(x,y) dx dy  &amp; \text{if x,y are continuous}
\end{cases}  \label{eqn:eqnnumber37}
\end{align}\]</span></p>
<p>One rule worth mentioning is the <strong>Sum rule</strong>, which involves the use of <strong>marginal and joint probabilities</strong> and is expressed in general as:</p>
<p><span class="math display">\[\begin{align}
P(X) = \begin{cases}
\sum_{Y} P_{X,Y}(x,y) &amp; \text{if y is discrete}\\
\\
\int_y P_{X,Y}(x,y) dy &amp; \text{if y is continuous}\\
\end{cases} \label{eqn:eqnnumber38}
\end{align}\]</span></p>
<p>Similarly, because <span class="math inline">\(P_{X,Y}(x,y) = P_{X,Y}(x|y)P_Y(y)\)</span>, then we get:</p>
<p><span class="math display">\[\begin{align}
P(X) = \begin{cases}
\sum_{Y} P_{X|Y}(x|y)P_Y(y) &amp; \text{if y is discrete}\\
\\
\int_y P_{X|Y}(x|y)P_Y(y) dy &amp; \text{if y is continuous}\\
\end{cases}  \label{eqn:eqnnumber39}
\end{align}\]</span></p>
<p>That states that the density <span class="math inline">\(P(X)\)</span> can be expressed as the joint distribution between X and Y, namely <span class="math inline">\(P(X, Y)\)</span>, with the sum of all possible values of Y, granting that Y has a proper distribution (in which its cumulative probability sums up or integrates to 1). That is called <strong>marginalization</strong>. We marginalize the probability of <strong>X</strong>.</p>
<p>For example:</p>
<p><span class="math display">\[\begin{align}
P(X) = P(X,Y = y_1) + P(X, Y = y_2)
\end{align}\]</span></p>
<p>where <span class="math inline">\(P(Y = y_1)=0.50,\ P(Y = y_2)=0.50\)</span>.</p>
<p>Another example:</p>
<p><span class="math display">\[\begin{align}
P(X) = P(X,Y = y_1) + P(X, Y = y_2) + P(X, Y = y_3)
\end{align}\]</span></p>
<p>where <span class="math inline">\(P(Y = y_1)=0.25,\ P(Y = y_2)=0.25,\ P(Y = y_3)=0.50\)</span>.</p>
<p>If we sum (e.g., discrete) or integrate (e.g., continuous) all probabilities of <strong>Y</strong>, then we end up with only the probability of X: <span class="math inline">\(P(X)\)</span>. <strong>Sum rule</strong> is further discussed in the <strong>Law of total probability</strong> section.</p>
<p>In terms of <strong>joint distribution</strong>, we can show the following:</p>
<p><span class="math display">\[\begin{align}
P(X) = P(X_1, X_2) \sim \mathcal{N}(\mu, \Sigma)
\ \ \ \ where\ \mu = \binom{\mu_1}{\mu_2}\ and\ \Sigma =
\left[ \begin{array}{cc}
\Sigma_{1,1} &amp; \Sigma_{1,2}\\ 
\Sigma_{2,1} &amp; \Sigma_{2,2}
\end{array}
\right] \label{eqn:eqnnumber40}
\end{align}\]</span></p>
</div>
<div id="conditional-probability" class="section level3 hasAnchor">
<h3><span class="header-section-number">7.1.3</span> Conditional Probability <a href="bayesian.html#conditional-probability" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Conditional probability</strong>, on the other hand, is a probability in which an event is conditioned on (or is constrained by) another event.</p>
<p>In terms of density with one probability, we have the following expression:</p>
<p><span class="math display">\[\begin{align}
f_{X|Y}(x | y) = P_{X|Y}(X = x | Y = y)
\end{align}\]</span></p>
<p>It reads: <strong>Probability of X given Y</strong>.</p>
<p>For example, if we have two baskets of fruits. One basket contains three apples and two oranges. The other basket contains one apple and four oranges. Given a basket, the probability of choosing an apple is:</p>
<p><span class="math display">\[
P(\text{an apple}|\text{1st basket}) = 3/5\ \ \ \ \ \ 
P(\text{an apple}|\text{2nd basket}) = 1/5
\]</span></p>
<p>Note here that the problem statement does not say that we randomly choose a basket. If it were so, then the computation becomes different:</p>
<p><span class="math display">\[\begin{align*}
{}&amp;P(\text{an apple}|\text{1st basket})P(\text{1st basket}) = 3/5 \times 1/2 = 3/10 \\
&amp;P(\text{an apple}|\text{2nd basket})P(\text{2nd basket}) = 1/5 \times 1/2 = 1/10 
\end{align*}\]</span></p>
<p>In terms of cumulative density with a range of probabilities, we have the following expression:</p>
<p><span class="math display">\[\begin{align}
\mathcal{F}_{X|Y}(x|y) = 
\begin{cases}
\sum_x P_{X|Y}(x|y)  &amp; \text{if x is discrete}\\
\\
\int P_{X|Y}(x|y) dx &amp; \text{if x is continuous}
\end{cases} \label{eqn:eqnnumber41}
\end{align}\]</span></p>
<p>One rule worth mentioning as it involves the use of <strong>joint and conditional probabilities</strong> is the <strong>Chain rule</strong>, which is expressed in general as:</p>
<p><span class="math display">\[\begin{align}
P(X_1,X_2,...Xn) = P(X_1|X_2,...,X_n)P(X_2|X_3,...,X_n)P(X_{n-1}|X_n)P(X_n)
\end{align}\]</span></p>
<p>For example, the joint probability of two events using <strong>chain rule</strong>:</p>
<p><span class="math display">\[\begin{align}
P(X=x, Y=y) = P(x,y) = P(x|y)P(y)
\end{align}\]</span></p>
<p>In a <strong>Bayesian setting</strong>, if two random events are independent, then the <strong>joint probability</strong> enforces a <strong>product rule</strong>:</p>
<p><span class="math display">\[\begin{align}
P(X=x, Y=y) = P(x,y) = P(x)P(y)
\end{align}\]</span></p>
<p>For another example, the joint probability of three events using <strong>chain rule</strong>:</p>
<p><span class="math display">\[\begin{align}
P(X=x, Y=y, Z=z) =  P(x,y,z) = P(x|y,z)P(y,z) = P(x|y,z)P(y|z)P(z)
\end{align}\]</span></p>
</div>
<div id="negation-probability" class="section level3 hasAnchor">
<h3><span class="header-section-number">7.1.4</span> Negation Probability <a href="bayesian.html#negation-probability" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Negation probability</strong> is the complement (reverse) of a probability. For example, any of the following notations denotes this:</p>
<p><span class="math display">\[\begin{align}
P(X&#39;) = 1 - P(X)\ \ \ \ \ \text{negation}
\end{align}\]</span></p>
<p><span class="math display">\[\begin{align}
P(Y|X&#39;)P(X&#39;)\ \ \rightarrow\ \ \ \ P(Y|X)P(X)\ \ \ \ \ \text{negation}
\end{align}\]</span></p>
<p><span class="math display">\[\begin{align}
P(X&#39;|Y,X) = P(X&#39;|Y)\ \ \ \ \ \text{negation}
\end{align}\]</span></p>
</div>
<div id="combination-of-probabilities" class="section level3 hasAnchor">
<h3><span class="header-section-number">7.1.5</span> Combination of Probabilities<a href="bayesian.html#combination-of-probabilities" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We can use the different types of probabilities above to perform mathematical manipulation such as below.</p>
<p>The <strong>Marginal probability</strong> is also expressed as such:</p>
<p><span class="math display">\[\begin{align}
\text{Marginal prob.} = \frac{\text{Joint prob.}} {\text{Conditional prob.}}
\ \ \rightarrow\ \ \ P(X) = \frac{P(X,Y)}{P(X|Y)}
\end{align}\]</span></p>
<p>The <strong>Joint Probability</strong> has the following expression:</p>
<p><span class="math display">\[\begin{align}
\text{Joint prob.} = (\text{Marginal prob.}) (\text{Conditional prob.})
\ \ \rightarrow\ \ \ P(X,Y) = P(Y)P(X|Y)
\end{align}\]</span></p>
<p>The <strong>Conditional Probability</strong> has the following expression:</p>
<p><span class="math display">\[\begin{align}
\text{Conditional prob.} = \frac{\text{Joint prob.}}{\text{Marginal prob.}}
\ \ \ \ \rightarrow\ \ \ \ \ P(X|Y) = \frac{P(X,Y)}{P(Y)}
\end{align}\]</span></p>
<p>For a continuous random variable <strong>X</strong> and a discrete random variable <strong>Y</strong>, we can obtain marginal probabilities such as:</p>
<p><span class="math display">\[\begin{align}
P(X) = \int P(y) P(x | y) dy\\
P(Y) = \int P(z) P(y | z) dz\\
P(Z) = \int P(x) P(z | x) dx
\end{align}\]</span></p>
<p>For <strong>Joint probability</strong> of three continuous random variables <strong>X</strong>, <strong>Y</strong>, and <strong>Z</strong>, we can obtain lower-order marginal probabilities and lower-order joint probabilities, respectively, this way:</p>
<p><span class="math display">\[\begin{align}
P(X) {}&amp;= \int \int P(x, y, z) dy dz\ \ \ \ \ \ \ \ P(X,Y) = \int \int P(x, y, z) dz\\
P(Y) &amp;= \int \int P(x, y, z) dx dz\ \ \ \ \ \ \ \ P(Y,Z) = \int \int P(x, y, z) dx\\
P(Z) &amp;= \int \int P(x, y, z) dx dy\ \ \ \ \ \ \ \ P(Z,X) = \int \int P(x, y, z) dy
\end{align}\]</span></p>
<p>For <strong>Joint probability</strong> of two continuous random variables <strong>X</strong>, <strong>Y</strong> given <strong>Z</strong>, we can obtain a conditional probability:</p>
<p><span class="math display">\[\begin{align}
P(X|Y) {}&amp; = \int P(X,Z|Y) dz\\
P(Y|Z) {}&amp; = \int P(Y,X|Z) dx\\
P(Z|X) {}&amp; = \int P(Z,Y|X) dy
\end{align}\]</span></p>
<p>We can also obtain a marginalized probability with the other combinations:</p>
<p><span class="math display">\[\begin{align}
P(X) {}&amp;= \int \int P(z)P(y|z)P(x|y,z) dy dz = \int \int P(y)P(z|y)P(x|z,y) dz dy\\
P(Y) &amp;= \int \int P(x)P(z|x)P(y|z,x) dz dx = \int \int P(z)P(x|z)P(y|x,z) dx dz\\
P(Z) &amp;= \int \int P(y)P(x|y)P(z|x,y) dx dy = \int \int P(x)P(y|x)P(z|y,x) dy dx
\end{align}\]</span></p>
</div>
</div>
<div id="probability-rules" class="section level2 hasAnchor">
<h2><span class="header-section-number">7.2</span> Probability Rules<a href="bayesian.html#probability-rules" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Let us review a few rules and theorems that govern <strong>Probabilities</strong>.</p>
<div id="law-of-total-probability" class="section level3 hasAnchor">
<h3><span class="header-section-number">7.2.1</span> Law of Total Probability<a href="bayesian.html#law-of-total-probability" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The axiom says that the total of all probabilities in a given sample space (or a population) equates to 1. In another way to say it, a <strong>sample space</strong> denoted as <span class="math inline">\(\mathbf{\Omega}\)</span> refers to the set of all possible outcomes in which the sum of all probabilities equates to 1.</p>
<p>A few of the notations below reflect the axiom above:</p>
<p><span class="math display">\[\begin{align}
P(X) + P(X&#39;) = 1 
\end{align}\]</span></p>
<p>It reads: the probability of X plus the probability of the rest (the complement of X) equals 1.</p>
<p><span class="math display">\[\begin{align}
P(X|Y) + P(X&#39;|Y) = 1 
\end{align}\]</span></p>
<p>It reads as the probability of X given Y plus the probability of the rest (the complement of X) given the same B equals 1.</p>
<p><span class="math display">\[\begin{align}
P(X,Y) = P(X|Y)P(Y) =  P(Y,X) = P(Y|X)P(X)
\end{align}\]</span></p>
<p><span class="math display">\[\begin{align}
P(X|Y&#39;) =  \frac{P(X,Y&#39;)}{P(Y)} = \frac{P(X) - P(X,Y)}{1-P(Y)}
\end{align}\]</span></p>
<p>Let us use R code to simulate a sample that is distributed as a binary distribution:</p>
<p><span class="math display">\[\begin{align}
X \sim Bin(n, \rho)
\end{align}\]</span></p>

<div class="sourceCode" id="cb800"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb800-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">142</span>)</a>
<a class="sourceLine" id="cb800-2" data-line-number="2"><span class="co"># Simulate a binary sample of size=1 and of 20 data points </span></a>
<a class="sourceLine" id="cb800-3" data-line-number="3"><span class="co"># with a success probability of 30%.</span></a>
<a class="sourceLine" id="cb800-4" data-line-number="4">(<span class="dt">X =</span> <span class="kw">rbinom</span>(<span class="dt">n=</span><span class="dv">20</span>, <span class="dt">size=</span><span class="dv">1</span>, <span class="dt">prob=</span><span class="fl">0.30</span>))</a></code></pre></div>
<pre><code>##  [1] 1 0 1 0 1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0</code></pre>
<div class="sourceCode" id="cb802"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb802-1" data-line-number="1"><span class="co"># Proportion of the sample that has value = 1</span></a>
<a class="sourceLine" id="cb802-2" data-line-number="2"><span class="kw">mean</span>(X<span class="op">==</span><span class="dv">1</span>)</a></code></pre></div>
<pre><code>## [1] 0.35</code></pre>
<div class="sourceCode" id="cb804"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb804-1" data-line-number="1"><span class="co"># Proportion of the sample that has value = 0</span></a>
<a class="sourceLine" id="cb804-2" data-line-number="2"><span class="kw">mean</span>(X<span class="op">==</span><span class="dv">0</span>)</a></code></pre></div>
<pre><code>## [1] 0.65</code></pre>

<p>Based on the law of total probability, we have the following:</p>
<p><span class="math display">\[P(X=1) = 0.35\]</span>
<span class="math display">\[P(X=0) = 0.65\]</span></p>
<p>therefore:</p>
<p><span class="math display">\[P(X=1) + P(X=0) = 0.35 + 0.65 = 1\]</span></p>
<p>Note that this is also called the <strong>Sum Rule</strong>.</p>
</div>
<div id="law-of-total-expectation" class="section level3 hasAnchor">
<h3><span class="header-section-number">7.2.2</span> Law of Total Expectation <a href="bayesian.html#law-of-total-expectation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Expectation</strong> refers to the expected value of a random variable. The average value (the mean) and expected value are often interchangeable. In that respect, <strong>Expectation</strong> can also be considered as one of the <strong>central tendencies</strong> in statistics and has the familiar notation as:</p>
<p><span class="math display">\[\begin{align}
\mathbb{E}(X) = \mu = \frac{1}{n}\sum_{i=1}^n X_i 
\end{align}\]</span></p>
<p>However, there are cases in which the expected value is the <strong>weighted sum</strong> of the random variable, e.g.:</p>
<p><span class="math display">\[\begin{align}
\mathbb{E}(X) = \underbrace{\sum_{i=1}^n X_i \omega_i(X_i)}_{\text{Arbitrary Weight}}
\ \ \ \ \ \ \ \ \ \
\mathbb{E}(X) = \underbrace{\sum_{i=1}^n X_i P_i(X_i)}_{
\begin{array}{l}
\text{Weighted based} \\
\text{on Probability} 
\end{array} \label{eqn:eqnnumber310}
}
\end{align}\]</span></p>
<p>The <strong>Law of Total Expectation (or Total Mean)</strong> is also known as the <strong>Law of iterated expectation or conditional expectation</strong> and is expressed as such:</p>
<p><span class="math display">\[\begin{align}
\mathbb{E}(Y) = \mathbb{E}_X(\mathbb{E}_Y(Y|X)\ )
\end{align}\]</span></p>
<p>The expression <span class="math inline">\(\mathbb{E}_Y(Y|X)\)</span> is interpreted as the <strong>expected value</strong> of Y given X. It has the following derived formula:</p>
<p><span class="math display">\[\begin{align}
\mathbb{E}_Y(Y|X) = \sum_{y \in R(Y)} y \times P(Y=y|X)
\end{align}\]</span></p>
<p>Note that <span class="math inline">\(R(Y) = Range(Y)\)</span> contains all possible values of <span class="math inline">\(Y\)</span> and does not have to be sequential or ordinal.</p>
<p>The expression <span class="math inline">\(\mathbb{E}_X(\mathbb{E}_Y(Y|X)\ )\)</span> is interpreted as the <strong>conditional expectation </strong> (or conditional expected value) of Y given X. It can also be expressed in its general form, given a sample space <span class="math inline">\(\Omega = \{ x_1, x_2, x_3,...,x_n\}\)</span>:</p>
<p><span class="math display">\[\begin{align}
\mathbb{E}(Y) {}&amp;= \sum_{x \in \Omega} \mathbb{E}(Y|X = x)\times P_X(x) \\
&amp;= \sum_{x \in \Omega} \sum_{y \in R(Y)} y \times P_{Y|X}(y|x)\times P_X(x)\\
&amp;= \sum_{y \in R(Y)}\sum_{x \in \Omega}  y \times P_{Y|X}(y|x)\times P_X(x)\\
&amp;= \sum_{y \in R(Y)} y \times P_{Y}(y)
\end{align}\]</span></p>
<p>where <span class="math inline">\(P_X(x_{1}) + P_X(x_{2})\ + ...\ + P_XP(x_{n})\)</span> = 1.</p>
<p>To illustrate, suppose we have three challenging problems to solve; each one bears distinct weight in terms of staffing requirements. All three problems require ten, twenty, and thirty staffing hours, respectively, to solve. All else being equal, the probability of solving the first, second, and third problems is 35%, 25%, and 40%, respectively. Estimate the expected number of staffing hours to solve the problem.</p>
<p>Let: <strong>S</strong> be the solutions to the problem, and <strong>H</strong> be the staffing hours.</p>
<p><span class="math display">\[\begin{align}
\mathbb{E}(H) {}&amp;= \mathbb{E}(H|S_1)P(S_1) + \mathbb{E}(H|S_2)P(S_2) + \mathbb{E}(H|S_3)P(S_3)\\
&amp;= 10 \times 0.35 + 20 \times 0.25 + 30 \times 0.40 \nonumber \\
&amp;= 20.5\ \text{manpower hours} \nonumber
\end{align}\]</span></p>
</div>
<div id="law-of-total-variance" class="section level3 hasAnchor">
<h3><span class="header-section-number">7.2.3</span> Law of Total Variance <a href="bayesian.html#law-of-total-variance" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The <strong>Law of Total Variance</strong> is also known as <strong>Law of iterated variance or conditional variance</strong> and is expressed as:</p>
<p><span class="math display">\[\begin{align}
Var(Y) {}&amp;= Var(Y_{within}|X)   + Var(Y_{between}|X) \\
&amp;= \mathbb{E}(Var(Y|X)) + Var(\mathbb{E}(Y|X))
\end{align}\]</span></p>
<p>Here, the average variance of Y given X is expressed as:</p>
<p><span class="math display">\[\begin{align}
Var(Y_{within}|X) = \mathbb{E}(Var(Y|X))
\end{align}\]</span></p>
<p>However, that may not be enough to compute the total variance. That is because we computed the variance within each sample but not between samples. We need to compute the variance between the individual sample means - this is the variability of the mean of <span class="math inline">\(Y\)</span> given <span class="math inline">\(X\)</span>.</p>
<p><span class="math display">\[\begin{align}
Var(Y_{between}|X) = Var(\mathbb{E}(Y|X))
\end{align}\]</span></p>
<p>To derive the <strong>within-sample variance</strong> from law of total expectation, we have the following:</p>
<p><span class="math display">\[\begin{align}
Var(Y_{within}|X) {}&amp;= \mathbb{E}(Var(Y|X)) = \mathbb{E}\left[\mathbb{E}(Y^2|X)\right] - \mathbb{E}\left[\mathbb{E}(Y|X)^2 \right]\\
&amp;=\mathbb{E}(Y^2) - \mathbb{E}\left[\mathbb{E}(Y|X)^2\right]
\end{align}\]</span></p>
<p>To derive the <strong>between-sample variance</strong> from the law of total expectation, we have the following:</p>
<p><span class="math display">\[\begin{align}
Var(Y_{between}|X) {}&amp;= Var(\mathbb{E}(Y|X)) = \mathbb{E}\left[\mathbb{E}(Y|X)^2 \right] - \mathbb{E}\left[\mathbb{E}(Y|X)^2 \right]^2\\
&amp;= \mathbb{E}\left[\mathbb{E}(Y|X)^2\right] - \mathbb{E}(Y)^2
\end{align}\]</span></p>
<p>Therefore, combining the two variances, we get:</p>
<p><span class="math display">\[\begin{align}
Var(Y) {}&amp;= \left( \mathbb{E}(Y^2) - \mathbb{E}\left[\mathbb{E}(Y|X)^2\right] \right) + \left(  \mathbb{E}\left[\mathbb{E}(Y|X)^2\right] - \mathbb{E}(Y)^2 \right)\\ 
&amp;=  \mathbb{E}(Y^2) - \mathbb{E}(Y)^2
\end{align}\]</span></p>
</div>
<div id="law-of-total-covariance" class="section level3 hasAnchor">
<h3><span class="header-section-number">7.2.4</span> Law of Total Covariance <a href="bayesian.html#law-of-total-covariance" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Similarly, if we decompose the total covariance, we also get two terms:</p>
<p><span class="math display">\[\begin{align}
Cov(Y,X) = \mathbb{E}(\ Cov(Y,X|Z)\ ) + Cov(\ \mathbb{E}(Y|Z),\mathbb{E}(X|Z)\ )
\end{align}\]</span></p>
<p>The first term is the average covariance within samples, and the second is the covariance between samples.</p>
</div>
<div id="law-of-large-numbers" class="section level3 hasAnchor">
<h3><span class="header-section-number">7.2.5</span> Law of Large Numbers <a href="bayesian.html#law-of-large-numbers" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The theorem has it that if we keep repeating our trials up to a considerably large number of repetitions (perhaps closer to infinity), at some point, our test results will get closer to the actual value. At times, this can be regarded as the <strong>fate of the average</strong> if our test result is about getting the average mean. In effect, errors or biases decrease and cancel each other out.</p>
</div>
<div id="central-limit-theorem" class="section level3 hasAnchor">
<h3><span class="header-section-number">7.2.6</span> Central Limit Theorem <a href="bayesian.html#central-limit-theorem" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We start from the premise that any single sample of a population does not accurately reflect the actual value of the entire population. If we are to compute for the average (or mean) from one single sample, the result may not necessarily reflect the average (or mean) from another sample, and another, and another. Therefore, it is proper to aggregate the mean of many samples to get closer to the actual value of the mean - in fact, the larger the number of samples, the more accurate we may get to the true mean. Another way to say this is that as we process a more significant number of samples, the sample means start to follow a normal distribution.</p>
</div>
<div id="rule-of-independence" class="section level3 hasAnchor">
<h3><span class="header-section-number">7.2.7</span> Rule of Independence <a href="bayesian.html#rule-of-independence" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In a multivariate setting in which we deal with more than one random variable, e.g., X, Y, Z, it helps to know if they are independent of the others and, perhaps more so, still share the same distribution characteristic - following the same (identical) distribution. Such property of a random variable is called <strong>independent and identical distribution</strong> or commonly written as <strong>IID</strong>.  </p>
<p>It is easy to point out that while a random variable forms a distribution, it is probabilistically independent if it does not affect the outcome of other random variables. However, to say that a random variable is both independent and identical with respect to other random variables, such property has to prove, <strong>based on central limit theorem</strong>, that the average mean of a collection of random variables tends to form a normal distribution.</p>
<p>Now, for two <strong>independent</strong> random variables, <span class="math inline">\(X \in U\)</span> and <span class="math inline">\(Y \in V\)</span>, their <strong>joint probability</strong> can be expressed as:</p>
<p><span class="math display">\[\begin{align}
P(X,Y) = P(X)\cdot P(Y)
\end{align}\]</span></p>
<p>For the same two <strong>independent</strong> random variables, X and Y, their <strong>conditional probability</strong> can be expressed as:</p>
<p><span class="math display">\[\begin{align}
P(X|Y) = P(X)\ \ \ \ \ \ \ \ \ \ \text{where P(X) is marginal probability for Y} 
\end{align}\]</span></p>
<p>Given three <strong>independent</strong> random variables, X and Y, and Z, the <strong>conditional probability</strong> of X and Y, given Z, is expressed as:</p>
<p><span class="math display">\[\begin{align}
P(X,Y\ |\ Z) = P(X|Z)\cdot P(Y|Z)
\end{align}\]</span></p>
</div>
<div id="rule-of-exchangeability" class="section level3 hasAnchor">
<h3><span class="header-section-number">7.2.8</span> Rule of Exchangeability <a href="bayesian.html#rule-of-exchangeability" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>When it comes to being exchangeable - or the <strong>exchangeability of random variables</strong>, any unforeseen data for the random variables will follow the same sequence or pattern as existing data regardless of order or arrangement. In any case, exchangeable random variables are conditionally independent.</p>
<p>In a sampling distribution where <span class="math inline">\(\theta = \{\theta_{1},\theta_{2}, \theta_{3},...,\theta_{n}\}\)</span>
and ordering of <span class="math inline">\(\theta_{i}\)</span> can be exhangeable if it does not affect the overall <span class="math inline">\(\theta\)</span> distribution.</p>
<p>Here are a few other items to be aware of:</p>
<ul>
<li>IIDs are exchangeable.</li>
<li>Exchangeable sequences are not necessarily IIDs</li>
<li>However, every exchangeable sequence is an identical distribution but does not necessarily require independence.</li>
</ul>
</div>
<div id="rule-of-expectation-and-variance" class="section level3 hasAnchor">
<h3><span class="header-section-number">7.2.9</span> Rule of Expectation and Variance<a href="bayesian.html#rule-of-expectation-and-variance" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The expected value of a marginal probability of one random variable is expressed as:</p>
<p><span class="math display">\[\begin{align}
\mathbb{E}(X) = 
\begin{cases}
\sum_{x} xf(x) &amp; \text{if x is discrete}\\
\\
 \int_{-\infty}^{\infty} xf(x)dx &amp;\text{if x is continuous}
 \end{cases} \label{eqn:eqnnumber42}
\end{align}\]</span></p>
<p>and if a random variable is represented by a function, <strong>g(X)</strong>, then we have the following expression:</p>
<p><span class="math display">\[\begin{align}
\mathbb{E}[g(X)] = 
\begin{cases}
\sum_{x} g(x)f(x) &amp; \text{if x is discrete}\\
\\
\int_{-\infty}^{\infty} g(x)f(x)dx &amp; \text{if x is continuous}
\end{cases} \label{eqn:eqnnumber43}
\end{align}\]</span></p>
<p>The expected value of a joint probability of two random variables of which the variables are represented by a function, <strong>g(X,Y)</strong>, is expressed as:</p>
<p><span class="math display">\[\begin{align}
\mathbb{E}[g(X,Y)] =
\begin{cases}
\sum_{x} \sum_{y} g(x,y)f(x,y) &amp; \text{if x is discrete}\\
\\
\int_{-\infty}^{\infty} \int_{-\infty}^{\infty} g(x,y)f(x,y)dx dy &amp;  \text{if x is continuous}
\end{cases} \label{eqn:eqnnumber44}
\end{align}\]</span></p>
<p>The expected value of a conditional probability of two random variables, X and Y, of which X is represented by a function, <strong>g(X)</strong>, is expressed as:</p>
<p><span class="math display">\[\begin{align}
\mathbb{E}[g(X) | Y] =
\begin{cases}
\sum_{x} g(x)f(x|y) &amp; \text{if x is discrete}\\
\\
\int_{-\infty}^{\infty} g(x)f(x|y)dx &amp; \text{if x is continuous}
\end{cases} \label{eqn:eqnnumber45}
\end{align}\]</span></p>
<p>The variance of a conditional probability is written as:</p>
<p><span class="math display">\[\begin{align}
Var(X|(f(x))) = \mathbb{E}\left[\left(X - \mathbb{E}(X|f(x))\right)\right]^2
\end{align}\]</span></p>
</div>
</div>
<div id="bayes-theorem" class="section level2 hasAnchor">
<h2><span class="header-section-number">7.3</span> Bayes Theorem <a href="bayesian.html#bayes-theorem" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The formula for Bayes Rule (or Bayes Theorem) is expressed this way <span class="citation">(Bruyninckx H. <a href="bibliography.html#ref-ref930h">2002</a>)</span>:</p>
<p><span class="math display">\[\begin{align}
\text{Posterior} = \frac{\text{Likelihood}\times \text{Prior}}{\text{Marginal Likelihood}}\ \ \ \ \rightarrow\ \ \ \ \ \ P(X|Y) = \frac{P(Y|X)\times P(X)}{P(Y)}
\end{align}\]</span></p>
<p>where <span class="math inline">\(P(Y|X)P(X)\)</span> is an expanded version of joint probability:</p>
<p><span class="math display">\[\begin{align}
P(X,Y) = P(Y|X)\times P(X)
\end{align}\]</span></p>
<p>and where <span class="math inline">\(P(Y)\)</span> is the observed probability (the evidence) and can be expanded as:</p>
<p><span class="math display">\[\begin{align}
P(Y) =  P(Y|X)\times P(X) + P(Y|X&#39;)\times P(X&#39;)
\end{align}\]</span></p>
<p>Note that <strong>marginal likelihood</strong> is also called <strong>evidence</strong>.</p>
<p>Therefore, we have:</p>
<p><span class="math display">\[\begin{align}
P(X|Y) = \frac{P(X,Y)}{P(Y)} = \frac{P(Y|X)\times P(X)}{P(Y|X)\times P(X) + P(Y|X&#39;)\times P(X&#39;)} 
\end{align}\]</span></p>
<p>To illustrate, let us use Figure <a href="bayesian.html#fig:bayestheorem">7.1</a>. Note that, hereafter, we also use the figure to illustrate other concepts around <strong>estimation</strong> and <strong>inference</strong> in later chapters, such as the <strong>Variational Inference</strong>.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:bayestheorem"></span>
<img src="bayestheorem.png" alt="Bi-variate Mixture Model" width="70%" />
<p class="caption">
Figure 7.1: Bi-variate Mixture Model
</p>
</div>

<p>Figure <a href="bayesian.html#fig:bayestheorem">7.1</a> shows diagram of a bivariate mixture model with three circular contours representing a cluster (or classification), namely <span class="math inline">\(\mathbf{c} = \{ c_1, c_2, c_3\}\)</span>. There are two random variables, namely <span class="math inline">\(X1\)</span> and <span class="math inline">\(X2\)</span>. Each random variable is characterized by a univariate gaussian mixture distribution - it is a mixture of possibly three individual <strong>gaussian distributions</strong>.</p>
<p>We start with the <strong>prior</strong> of the <strong>Bayes Theorem</strong>, which is written, in this case, as the initial proportion of each classification like so:</p>
<p><span class="math display">\[\begin{align}
P(c_1) = \pi_1 = \frac{ c_1}{ \sum_i^k c_i}\ \ \ \ \ \ \ \ \ \ \ \
P(c_2) = \pi_2 = \frac{ c_2}{ \sum_i^k c_i}\ \ \ \ \ \ \ \ \ \ \ \
P(c_3) = \pi_3 = \frac{ c_3}{ \sum_i^k c_i}
\end{align}\]</span></p>
<p>Then we follow that by computing the <strong>likelihood</strong>. For that, we first calculate the probability of a random event (a random variable) belonging to a cluster.</p>
<p><span class="math display">\[\begin{align}
\begin{array}{ll}
P(x^{(1)}|c_1) \sim \mathcal{N}\left(\mu^{(1)}_1, \sigma^{2(1)}_1\right) &amp;
P(x^{(2)}|c_1) \sim \mathcal{N}\left(\mu^{(2)}_1, \sigma^{2(2)}_1\right)\\
P(x^{(1)}|c_2) \sim \mathcal{N}\left(\mu^{(1)}_2, \sigma^{2(1)}_2\right) &amp;
P(x^{(2)}|c_2) \sim \mathcal{N}\left(\mu^{(2)}_2, \sigma^{2(2)}_2\right)\\
P(x^{(1)}|c_3) \sim \mathcal{N}\left(\mu^{(1)}_3, \sigma^{2(1)}_3\right) &amp;
P(x^{(2)}|c_3) \sim \mathcal{N}\left(\mu^{(2)}_3, \sigma^{2(2)}_3\right)\\
\end{array} \label{eqn:eqnnumber47}
\end{align}\]</span></p>
<p>Then we construct the <strong>likelihood</strong>:</p>
<p><span class="math display">\[\begin{align}
\begin{array}{l}
P(X|c_1)  = P(x^{(1)},x^{(2)}| c_1 ) = P(x^{(1)}| c_1 )P(x^{(2)}| c_1 )\\
P(X|c_2)  = P(x^{(1)},x^{(2)}| c_2 ) = P(x^{(1)}| c_2 )P(x^{(2)}| c_2 )\\
P(X|c_3)  = P(x^{(1)},x^{(2)}| c_3 ) = P(x^{(1)}| c_3 )P(x^{(2)}| c_3 )
\end{array} \label{eqn:eqnnumber48}
\end{align}\]</span></p>
<p>Finally, we construct the <strong>posterior</strong>:</p>
<p><span class="math display">\[\begin{align}
P(c_1|X) = \frac{P(X|c_1)P(c_1)}
{\sum_i P(X|c_i)P(c_i)}
\ \ \ \ \ \ \ \ 
P(c_2|X) = \frac{P(X|c_2)P(c_2)}
{\sum_i P(X|c_i)P(c_i)} \nonumber \\
P(c_3|X) = \frac{P(X|c_3)P(c_3)}
{\sum_i P(X|c_i)P(c_i)}
\end{align}\]</span></p>
<p>To illustrate the <strong>Bayes Theorem</strong>, suppose we perform an analysis of strange flu-like symptoms and a particular pathogen currently floating around a small local community. Suppose, after reviewing historical records, that 25% of the locals reported similar flu-like symptoms in the past. However, in testing individuals, we find that 10% are positive for the pathogen. Additionally, 3% of the locals with flu-like symptoms also carry the pathogen. Let us determine the probability of locals being positive for flu-like symptoms.</p>
<p>Let X be locals with flu-like symptoms and Y be locals tested positive for a particular pathogen. Therefore:</p>
<p><span class="math display">\[\begin{align*}
P(X) {}&amp;= 25\% = 0.25\\
P(Y) &amp;= 10\% = 0.10\\
P(Y|X) &amp;= 3\% = 0.03 
\end{align*}\]</span></p>
<p>Using <strong>Bayes Theorem</strong>, we compute the following:</p>
<p><span class="math display">\[
P(X|Y) = \frac{P(Y|X)\times P(X)}{P(Y)}
= \frac{(0.03)\times (0.25)}{(0.10)} = 0.075 = 7.5\% 
\]</span></p>
<p>That means that the probability of developing flu-like symptoms for subjects found to have the pathogen is 7.5%.</p>
<div id="naÃ¯ve-bayes" class="section level3 hasAnchor">
<h3><span class="header-section-number">7.3.1</span> NaÃ¯ve Bayes <a href="bayesian.html#naÃ¯ve-bayes" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>NaÃ¯ve Bayes</strong> is the normalized form of <strong>Bayes Theorem</strong> formula.</p>
<p>Recall the following Bayes Formula:</p>
<p><span class="math display">\[\begin{align}
P(X|Y) = \frac{P(X,Y)}{P(Y)} = \frac{P(Y|X) \times P(X)}{P(Y|X) \times P(X) + P(Y|X&#39;)\times P(X&#39;)} 
\end{align}\]</span></p>
<p>With multivariate probabilities, the equation expands into the following:</p>
<p><span class="math display">\[\begin{align}
P(X_{1}, X_{2},X_{3},...|Y) = \frac{P(X_{1},X_{2},X_{3},...,Y)}{P(Y)}
\end{align}\]</span></p>
<p>where <span class="math inline">\(P(Y)\)</span> is a normalizing (scaling) factor.</p>
<p>For discrete densities, the normalizing factor is summed up using the following expression:</p>
<p><span class="math display">\[\begin{align}
P(Y) = \sum_{X_{i}=1}^{N_{1}}\sum_{X_{2}=1}^{N_{2}}
\sum_{X_{3}=1}^{N_{3}} ... P(X_{1},X_{2},X_{3},...,Y)
\end{align}\]</span></p>
<p>For continuous densities, the normalizing factor integrates using the following expression:</p>
<p><span class="math display">\[\begin{align}
P(Y) = \int_{-\infty}^{\infty}\int_{-\infty}^{\infty}
\int_{-\infty}^{\infty} ... P(X_{1},X_{2},X_{3},...,Y)...dX_{3}dX_{2}dX_{1}
\end{align}\]</span></p>
<p>Note that every observed density added becomes a challenge to integrate. As a result, it can lead to being <strong>intractable</strong>. Fortunately, we use <span class="math inline">\(P(Y)\)</span> for normalization, and so with or without it, the proportionality remains intact (which we can use for approximation). Because of that, we end up with the below <strong>NaÃ¯ve</strong> formula:</p>
<p><span class="math display">\[\begin{align}
\underbrace{P(X|Y)}_\text{posterior}\ \propto\ \underbrace{P(Y|X)}_\text{likelihood} \times \underbrace{P(X)}_\text{prior}
\end{align}\]</span></p>
<p>It is also common to see the following equivalent notation to emphasize evidence versus hypothesis:</p>
<p><span class="math display">\[\begin{align}
P(H|E) \propto P(E|H) \times P(H)
\ \ \ \ \ \leftarrow\ \ \ \ \ \ \ P(H|E)  = \frac{ P(E|H) \times P(H) }{ P(E)}
\end{align}\]</span></p>
<p>The notation starts with the premise that we need to evaluate the state (or probability) of a <strong>hypothesis</strong> given a set of observations - our evidence. This is our <strong>posterior</strong> probability denoted as <span class="math inline">\(P(H|E)\)</span>. Our <strong>posterior</strong> hypothesis remains to be <strong>weak</strong> until proven to hold. Here, <strong>weak</strong> may refer to being subjective (or even anecdotal) in describing (or proving) a piece of evidence. Our goal is apparently to collect more evidence (e.g., perform more clinical tests). If we can collect more (objective) evidence backed by our (subjective) <strong>prior</strong> hypothesis, we can give weight to the collected evidence, generating a newly updated <strong>posterior</strong> knowledge which becomes less <strong>weak</strong> and closer to describing a piece of objective evidence; nonetheless, it is a newly updated information. In a sense, we begin to see the scheme of things. A <strong>prior</strong> knowledge becomes a <strong>posterior</strong> knowledge for every new evidence, and a <strong>posterior</strong> knowledge becomes a <strong>prior</strong> knowledge for the next evidence.</p>
<p>To illustrate, when testing positive for symptoms (or signs) of a particular disease (whether cancer or COVID-19 infection as an example), we find that complex solutions tend to root or reference back the below fundamental equation. Note that <strong>symptoms</strong> (or signs) of disease remains <strong>hypothetical</strong> until tested positive:</p>
<p><span class="math display">\[\begin{align}
P(\text{symptom}|\mathbf{+}) \propto  
P(\mathbf{+}|\text{symptom}) \times P(\text{symptom})
\end{align}\]</span></p>
<p>where normalizing factor <span class="math inline">\(P(+)\)</span> is omitted:</p>
<p><span class="math display">\[\begin{align}
P(+) = P(\mathbf{+}|\text{symptom})\times P(\text{symptom}) +  
P(\mathbf{+}|\text{no symptom})\times  P(\text{no symptom})
\end{align}\]</span></p>
<p>Let us continue to further our discussion of <strong>hypothesis</strong> in the next section. Note that our description of <strong>hypothesis</strong> in the next section focuses on <strong>parameter estimation</strong> using the theta <span class="math inline">\(\theta\)</span> symbol.</p>
</div>
<div id="likelihood" class="section level3 hasAnchor">
<h3><span class="header-section-number">7.3.2</span> Likelihood<a href="bayesian.html#likelihood" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In this section, it is essential to distinguish two statements that can help us understand <strong>likelihood</strong>: </p>
<ol style="list-style-type: decimal">
<li>The likelihood of observing data given a sampled distribution.</li>
<li>The most likely distribution that produces observed data.</li>
</ol>
<p>Both statements focus around the parameter theta <span class="math inline">\(\theta\)</span> for a <strong>data distribution</strong>. The symbol theta <span class="math inline">\(\theta\)</span> represents a <strong>set (or vector) of parameter quantities</strong>, particularly the <strong>mean</strong> (<span class="math inline">\(\mu\)</span>) and <strong>variance</strong> (<span class="math inline">\(\sigma^2\)</span>) for a <strong>normal distribution</strong>. Note that other types of distributions have their own corresponding set of parameters for <strong>theta</strong>, <span class="math inline">\(\theta\)</span>. Here, we use <strong>normal distribution</strong> to explain a case.</p>
<p>We begin our discussion by mentioning - in the Bayesian sense - that there is uncertainty in the parameter theta <span class="math inline">\(\theta\)</span>. The uncertainty comes about because of the idea, for example, that the average height (the mean height) of the world population is difficult to exact because it requires a global census which is impossible to achieve. For that reason, we settle on our observations - a sampled data limited in terms of the distribution it follows in comparison to the actual distribution of an entire population. We use Figure <a href="bayesian.html#fig:likelihood">7.2</a> as reference.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:likelihood"></span>
<img src="likelihood.png" alt="Likelihood" width="100%" />
<p class="caption">
Figure 7.2: Likelihood
</p>
</div>

<p>It is fair to assume that, given a distribution characterizes by <span class="math inline">\(\theta = (\mu=2, \sigma=1)\)</span>, the <strong>likelihood</strong> of observing data (e.g.Â x=3) is 0.242. This is illustrated by the left-side diagram.</p>

<div class="sourceCode" id="cb806"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb806-1" data-line-number="1"><span class="kw">dnorm</span>(<span class="dt">x=</span><span class="dv">3</span>, <span class="dt">mean=</span><span class="dv">2</span>, <span class="dt">sd=</span> <span class="dv">1</span>)</a></code></pre></div>
<pre><code>## [1] 0.242</code></pre>

<p>It is also fair to assume that, given a list of distribution - for example, a distribution characterized by <span class="math inline">\(\theta = (\mu=2, \sigma=1)\)</span> and another distribution characterized by <span class="math inline">\(\theta = (\mu=3, \sigma=1)\)</span>, the one distribution that most likely produces the data (e.g.Â x=3) has an assumed <strong>maximum likelihood estimate (MLE)</strong> that is equal to 0.3989. This is illustrated by the right-side diagram which references our second statement.</p>

<div class="sourceCode" id="cb808"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb808-1" data-line-number="1"><span class="kw">dnorm</span>(<span class="dt">x=</span><span class="dv">3</span>, <span class="dt">mean=</span><span class="dv">3</span>, <span class="dt">sd=</span> <span class="dv">1</span>)</a></code></pre></div>
<pre><code>## [1] 0.3989</code></pre>

<p>As we note, we assume an initial <strong>MLE</strong> in the diagram. We know that this is not necessarily accurate because of the insufficient number of sampling distributions. Regarding <strong>likelihood</strong>, we are most often interested in knowing which <strong>sample distribution</strong> closely relates to the <strong>actual distribution</strong> (such as one representing the population). We can achieve such a close estimate by way of <strong>MLE</strong>. We expand on the concept of <strong>MLE</strong> in the <strong>Bayesian Inference</strong> section.</p>
<p>As we expound further, <strong>likelihood</strong> comes into the picture every time we have limited access to a complete set of data, albeit the parameter <span class="math inline">\(\theta\)</span> is known. To illustrate, assume by luck that we have a distribution that is as complete a set as we can gather. Consider this to be almost the actual distribution. Ignore that we are using <strong>sampling</strong> to generate our actual distribution. Let us take the mean and variance - our parameter model - like so:</p>

<div class="sourceCode" id="cb810"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb810-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">2020</span>)</a>
<a class="sourceLine" id="cb810-2" data-line-number="2">range =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">1</span>, <span class="dv">50</span>)</a>
<a class="sourceLine" id="cb810-3" data-line-number="3">true.distribution =<span class="st"> </span><span class="kw">sample</span>(range, <span class="dt">size=</span><span class="dv">1000</span>, <span class="dt">prob=</span><span class="ot">NULL</span>, <span class="dt">replace=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb810-4" data-line-number="4">( <span class="dt">theta =</span> <span class="kw">c</span>(<span class="st">&quot;mean&quot;</span> =<span class="st"> </span><span class="kw">mean</span>(true.distribution), </a>
<a class="sourceLine" id="cb810-5" data-line-number="5">            <span class="st">&quot;sd&quot;</span>   =<span class="st"> </span><span class="kw">sd</span>(true.distribution)))</a></code></pre></div>
<pre><code>##  mean    sd 
## 25.11 14.45</code></pre>

<p>The characteristic of the true distribution is recorded as such: <span class="math inline">\(\theta\)</span> = (<span class="math inline">\(\mu\)</span> = 25.11, <span class="math inline">\(\sigma\)</span> = 14.45).</p>
<p>Suppose now that we have limited access to the actual data in that we only have a significantly small portion of the data set. Let us start with three small samples. See below:</p>

<div class="sourceCode" id="cb812"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb812-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">2020</span>)</a>
<a class="sourceLine" id="cb812-2" data-line-number="2"><span class="co"># suppose  each sample is IID (identical distribution)</span></a>
<a class="sourceLine" id="cb812-3" data-line-number="3">sample1 =<span class="st"> </span><span class="kw">sample</span>(true.distribution, <span class="dt">size=</span><span class="dv">7</span>, <span class="dt">prob=</span><span class="ot">NULL</span>, <span class="dt">replace=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb812-4" data-line-number="4">sample2 =<span class="st"> </span><span class="kw">sample</span>(true.distribution, <span class="dt">size=</span><span class="dv">4</span>, <span class="dt">prob=</span><span class="ot">NULL</span>, <span class="dt">replace=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb812-5" data-line-number="5">sample3 =<span class="st"> </span><span class="kw">sample</span>(true.distribution, <span class="dt">size=</span><span class="dv">3</span>, <span class="dt">prob=</span><span class="ot">NULL</span>, <span class="dt">replace=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb812-6" data-line-number="6">samples =<span class="st"> </span><span class="kw">matrix</span>(</a>
<a class="sourceLine" id="cb812-7" data-line-number="7">     <span class="kw">c</span>( <span class="kw">paste0</span>(sample1, <span class="dt">collapse=</span><span class="st">&quot;, &quot;</span>), <span class="kw">round</span>(<span class="kw">mean</span>(sample1),<span class="dv">3</span>),  </a>
<a class="sourceLine" id="cb812-8" data-line-number="8">        <span class="kw">round</span>(<span class="kw">sd</span>(sample1),<span class="dv">3</span>), </a>
<a class="sourceLine" id="cb812-9" data-line-number="9">        <span class="kw">paste0</span>(sample2, <span class="dt">collapse=</span><span class="st">&quot;, &quot;</span>), <span class="kw">round</span>(<span class="kw">mean</span>(sample2),<span class="dv">3</span>),  </a>
<a class="sourceLine" id="cb812-10" data-line-number="10">        <span class="kw">round</span>(<span class="kw">sd</span>(sample2),<span class="dv">3</span>), </a>
<a class="sourceLine" id="cb812-11" data-line-number="11">        <span class="kw">paste0</span>(sample3, <span class="dt">collapse=</span><span class="st">&quot;, &quot;</span>), <span class="kw">round</span>(<span class="kw">mean</span>(sample3),<span class="dv">3</span>),  </a>
<a class="sourceLine" id="cb812-12" data-line-number="12">        <span class="kw">round</span>(<span class="kw">sd</span>(sample3),<span class="dv">3</span>)</a>
<a class="sourceLine" id="cb812-13" data-line-number="13">      ) , <span class="dt">nrow=</span><span class="dv">3</span>, <span class="dt">ncol=</span><span class="dv">3</span>, <span class="dt">byrow=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb812-14" data-line-number="14"><span class="kw">colnames</span>(samples) =<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;observations&quot;</span>, <span class="st">&quot;sample mean&quot;</span>, <span class="st">&quot;sample sd&quot;</span>)</a>
<a class="sourceLine" id="cb812-15" data-line-number="15"><span class="kw">rownames</span>(samples) =<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;sample.1&quot;</span>, <span class="st">&quot;sample.2&quot;</span>, <span class="st">&quot;sample.3&quot;</span>)</a>
<a class="sourceLine" id="cb812-16" data-line-number="16"><span class="kw">as.data.frame</span>(samples)</a></code></pre></div>
<pre><code>##                        observations sample mean sample sd
## sample.1 40, 16, 22, 28, 27, 29, 31      27.571     7.458
## sample.2              7, 31, 27, 14       19.75    11.177
## sample.3                 37, 32, 21          30     8.185</code></pre>

<p>Notice how the mean and standard deviation for each sample are very disproportionate compared to the actual mean and standard deviation of the true data distribution. See Figure <a href="bayesian.html#fig:muvar">7.3</a>.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:muvar"></span>
<img src="DS_files/figure-html/muvar-1.png" alt="Disproportioned parameters" width="70%" />
<p class="caption">
Figure 7.3: Disproportioned parameters
</p>
</div>

<p>In Figure <a href="bayesian.html#fig:muvar">7.3</a>, we have one single observation, namely <span class="math inline">\(x=14\)</span>. Let us get the likelihood of the four distributions:</p>

<pre><code>##            sample mean sample sd likelihood
## population       25.11    14.446   0.020546
## sample.1         27.57     7.458   0.010216
## sample.2         19.75    11.177   0.031269
## sample.3         30.00     8.185   0.007213</code></pre>

<p>At first glance, the data, x=14, is likely to be observed from each of the three sample distributions; however, we see that <strong>sample.2</strong> has the most likelihood of observing data (x=14) at 0.0072. Therefore, we can assume that <strong>sample.2</strong> is the closest estimate (or can be a good representative) of the actual distribution. In other words, <strong>sample.2</strong> has a better parameter model that can characterize (or can be proportional to) the actual distribution.</p>
<p>However, we have to note that our assumption is based only on one observation (x=14) and on only three samplings. Our goal is to find a better parameter model proportional to that of the actual distribution, but we need sufficient observations and sufficient samplings.</p>
<p>We need to maximize the <strong>likelihood</strong> that a set of observed data (not just one data point) belongs to a sample distribution (of a list of sample distributions) represented by theta <span class="math inline">\(\theta\)</span> that hopefully can characterize the actual distribution. As we pointed out, we can achieve this using <strong>MLE</strong>.</p>
<p>Now, <strong>likelihood</strong> is expressed in the form of a <strong>PDF</strong> formula:</p>
<p><span class="math display">\[\begin{align}
Lik(\theta|X) \equiv P(X|\theta)\ \ \ \leftarrow \ \ f(x; \theta)\ \ or\ \ f(x; \mu, \sigma^2)
\end{align}\]</span></p>
<p>The <span class="math inline">\(Lik(\theta|X)\)</span> is the likelihood function for the probability of a random event to occur, given that we have observed such occurrence.</p>
<p>Notice that the parameters in the <strong>likelihood</strong> notation get swapped (for semantics), and we use the equivalence (<span class="math inline">\(\equiv\)</span>) notation. While the meaning or interpretation is different, we compute the likelihood using the equation from <strong>Density function</strong>. However, to avoid confusing this equation as a <strong>Density function</strong>, we can call it a <strong>Likelihood function</strong>. Also, a <strong>Density function</strong> forms the curve (as we discussed in Chapter <strong>5</strong> (<strong>Numerical Probability and Distribution</strong>)), and the <strong>probability</strong> forms the area in the curve. In the case of <strong>Likelihood function</strong>, it is a function of theta <span class="math inline">\(\theta\)</span> conditioned on the observed data.</p>
<p>We can perform point estimates for marginal sampling density or joint density likelihood like so:</p>
<p><span class="math display">\[\begin{align}
 Lik(\mu, \sigma^2  |  X = x_1) {}&amp;\equiv P(X = x_1| \mu, \sigma^2 ) &amp; \text{marginal-density likelihood} \\ 
 \nonumber \\
 Lik(\mu, \sigma^2  |  x_1,\ ....,\ x_n) &amp;\equiv P(x_1,\ ....,\ x_n| \mu, \sigma^2 )  &amp; \text{joint-density likelihood}
\end{align}\]</span></p>
<p><strong>MLE</strong> works best with <strong>joint-density likelihood</strong>.</p>
<p>The formula for both likelihoods for different types of densities is provided in later sections under <strong>Conjugacy</strong> and also in Table <a href="bayesian.html#tab:familylik">7.2</a>. The formula helps to compute the <strong>joint-density</strong> likelihood.</p>
<p>Recall that the <span class="math inline">\(\mu\)</span> parameter controls the <strong>location</strong> of the <strong>bell-shape</strong> curve and that the <span class="math inline">\(\sigma\)</span> parameter controls the <strong>scale</strong> (or spread) of the curve. In terms of evaluating multiple sampling densities, it is easy to visualize the shape of each sample density curve based on the location (via the mean) and the spread (via the variance).</p>
<p>To illustrate the likelihood of observing a single data point, namely <span class="math inline">\(x = 71\)</span>, given known constant standard deviation, namely <span class="math inline">\(\sigma = 2.5\)</span> and an unknown mean <span class="math inline">\(\mu\)</span>, let us treat <span class="math inline">\(\mu\)</span> as a random variable and plug in a few random values for the mean like so: <span class="math inline">\(\mu = (67,\ 68.5,\ 70.5,\ 72.5)\)</span>. Then, we use Figure <a href="bayesian.html#fig:likelihoodmu">7.4</a> to show four bell-shaped curves for each of the random <span class="math inline">\(\mu\)</span> values.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:likelihoodmu"></span>
<img src="DS_files/figure-html/likelihoodmu-1.png" alt="Likelihood (constant variance but variant mean)" width="70%" />
<p class="caption">
Figure 7.4: Likelihood (constant variance but variant mean)
</p>
</div>

<p>The likelihood estimate of observing <span class="math inline">\(x=71\)</span> for each of the means <span class="math inline">\(\mu\)</span> is as follows:</p>
<p><span class="math inline">\(Lik\mu_1\)</span> = 0.0444, <span class="math inline">\(Lik\mu_2\)</span> = 0.0968, <span class="math inline">\(Lik\mu_3\)</span> = 0.1564, <span class="math inline">\(Lik\mu_4\)</span> = 0.1333.</p>
<p>We derive that from the following example implementation of <strong>likelihood</strong> using our <strong>likelihood function</strong> for normal distribution:</p>

<div class="sourceCode" id="cb815"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb815-1" data-line-number="1">normal.likelihood &lt;-<span class="st"> </span><span class="cf">function</span>(x, mean, sd) { <span class="co"># for normal outcome</span></a>
<a class="sourceLine" id="cb815-2" data-line-number="2">   variance =<span class="st"> </span>sd<span class="op">^</span><span class="dv">2</span></a>
<a class="sourceLine" id="cb815-3" data-line-number="3">   (<span class="dv">1</span> <span class="op">/</span><span class="st"> </span>(<span class="kw">sqrt</span>( <span class="dv">2</span> <span class="op">*</span><span class="st"> </span>pi <span class="op">*</span><span class="st"> </span>variance ))) <span class="op">*</span><span class="st">  </span></a>
<a class="sourceLine" id="cb815-4" data-line-number="4"><span class="st">         </span><span class="kw">exp</span>(<span class="op">-</span>(x <span class="op">-</span><span class="st"> </span>mean)<span class="op">^</span><span class="dv">2</span><span class="op">/</span>(<span class="dv">2</span> <span class="op">*</span><span class="st"> </span>variance))</a>
<a class="sourceLine" id="cb815-5" data-line-number="5">}</a>
<a class="sourceLine" id="cb815-6" data-line-number="6"><span class="co"># log likelihood for joint density</span></a>
<a class="sourceLine" id="cb815-7" data-line-number="7">loglikelihood &lt;-<span class="st"> </span><span class="cf">function</span>(density) {</a>
<a class="sourceLine" id="cb815-8" data-line-number="8">  loglik =<span class="st"> </span><span class="kw">log</span>(density, <span class="kw">exp</span>(<span class="dv">1</span>))</a>
<a class="sourceLine" id="cb815-9" data-line-number="9">  <span class="op">-</span><span class="kw">sum</span>(loglik) <span class="co"># for iid</span></a>
<a class="sourceLine" id="cb815-10" data-line-number="10">}</a></code></pre></div>

<p>For <strong>binomial likelihood</strong>, we have the following implementation:</p>

<div class="sourceCode" id="cb816"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb816-1" data-line-number="1">binomial.likelihood &lt;-<span class="st"> </span><span class="cf">function</span>(x, rho, n) { <span class="co"># for binomial outcome</span></a>
<a class="sourceLine" id="cb816-2" data-line-number="2">   rho<span class="op">^</span>x <span class="op">*</span><span class="st"> </span>( <span class="dv">1</span> <span class="op">-</span><span class="st"> </span>rho)<span class="op">^</span>(n <span class="op">-</span><span class="st"> </span>x) <span class="co"># rho = probability of success</span></a>
<a class="sourceLine" id="cb816-3" data-line-number="3">}</a></code></pre></div>

<p>For <strong>poisson likelihood</strong>, see Chapter <strong>10</strong> (<strong>Computational Learning II</strong>) under <strong>Poisson Regression</strong> Subsection under <strong>Regression</strong> Section.</p>
<p>Using the <strong>normal likehood</strong>, we get the following:</p>

<div class="sourceCode" id="cb817"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb817-1" data-line-number="1">(<span class="dt">likelihood =</span> <span class="kw">normal.likelihood</span>(x, <span class="dt">mean =</span> mean, <span class="dt">sd =</span> sigma))</a></code></pre></div>
<pre><code>## [1] 0.04437 0.09679 0.15642 0.13329</code></pre>

<p>From there, we take the maximum likelihood (assumed <strong>MLE</strong>) for the mean:</p>

<div class="sourceCode" id="cb819"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb819-1" data-line-number="1">(<span class="dt">MLE =</span> <span class="kw">max</span>(likelihood))</a></code></pre></div>
<pre><code>## [1] 0.1564</code></pre>

<p>Finally, we get the optimal paramater - the <strong>mean</strong> <span class="math inline">\(\hat{\mu}\)</span> - based on the <strong>MLE</strong>:</p>

<div class="sourceCode" id="cb821"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb821-1" data-line-number="1">(<span class="dt">mean.est =</span> mean[ <span class="kw">which.max</span>(likelihood) ] ) <span class="co"># MLE</span></a></code></pre></div>
<pre><code>## [1] 70.5</code></pre>

<p>Because we deal with a random variable for <strong>mean</strong>, we can also visualize its distribution. Note that this is <strong>mean distribution</strong> and not <strong>data distribution</strong>. We show the <strong>ML</strong>, which is located at the peak of the bell-shaped curve where the slope is zero. See Figure <a href="bayesian.html#fig:mlemean">7.5</a>.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:mlemean"></span>
<img src="DS_files/figure-html/mlemean-1.png" alt="Likelihood (parameter mean distribution)" width="70%" />
<p class="caption">
Figure 7.5: Likelihood (parameter mean distribution)
</p>
</div>

<p>In other words, by maximizing the likelihood, we can get a parameter model, namely the mean <span class="math inline">\(\mu\)</span> = 70.5 and standard deviation <span class="math inline">\(\sigma\)</span> = 2.5, that describes the sample distribution as a possible representative of (and possibly proportional to) our actual distribution. We can also say that this distribution is the one that produced our observed data.</p>
<p>Next, to illustrate the likelihood of observing a single data point, namely <span class="math inline">\(x = 71\)</span>, given known constant mean, namely <span class="math inline">\(\mu = 71\)</span> and an unknown variance <span class="math inline">\(\sigma^2\)</span>, let us treat <span class="math inline">\(\sigma\)</span> as a random variable and plug-in a few random values like so: <span class="math inline">\(\sigma = (1.5,\ 2.0,\ 2.5,\ 3.5)\)</span>. See Figure <a href="bayesian.html#fig:likelihoodsd">7.6</a> for each of the random <span class="math inline">\(\sigma\)</span> values.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:likelihoodsd"></span>
<img src="DS_files/figure-html/likelihoodsd-1.png" alt="Likelihood (constant variance but variant mean)" width="70%" />
<p class="caption">
Figure 7.6: Likelihood (constant variance but variant mean)
</p>
</div>

<p>Similarly, the probability of observing <span class="math inline">\(x=71\)</span> for each of the variance <span class="math inline">\(\sigma^2\)</span> is as follows:</p>
<p><span class="math inline">\(Lik\sigma_1\)</span> = 0.266, <span class="math inline">\(Lik\sigma_2\)</span> = 0.1995, <span class="math inline">\(Lik\sigma_3\)</span> = 0.1596, <span class="math inline">\(Lik\sigma_4\)</span> = 0.114.</p>

<div class="sourceCode" id="cb823"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb823-1" data-line-number="1">(<span class="dt">likelihood =</span> <span class="kw">normal.likelihood</span>(x, <span class="dt">mean =</span> mean, <span class="dt">sd =</span> sd))</a></code></pre></div>
<pre><code>## [1] 0.2660 0.1995 0.1596 0.1140</code></pre>

<p>From there, we take the maximum likelihood (alsu assumed <strong>MLE</strong>) for <strong>variance</strong>:</p>

<div class="sourceCode" id="cb825"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb825-1" data-line-number="1">(<span class="dt">MLE =</span> <span class="kw">max</span>(likelihood))</a></code></pre></div>
<pre><code>## [1] 0.266</code></pre>

<p>Finally, we get the optimal parameter - the <strong>variance</strong> <span class="math inline">\(\hat{\sigma}^2\)</span> estimate (or <strong>sd</strong> <span class="math inline">\(\hat{\sigma}\)</span> estimate for that matter) - based on our <strong>MLE</strong>:</p>

<div class="sourceCode" id="cb827"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb827-1" data-line-number="1">(<span class="dt">sd.est =</span> sd[ <span class="kw">which.max</span>(likelihood) ] ) <span class="co">#MLE</span></a></code></pre></div>
<pre><code>## [1] 1.5</code></pre>

<p>Because we deal with a random variable for <strong>variance</strong>, we can also visualize its distribution and show the assumed <strong>MLE</strong> at the peak of the curve. See Figure <a href="bayesian.html#fig:mlesigma">7.7</a>.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:mlesigma"></span>
<img src="DS_files/figure-html/mlesigma-1.png" alt="Likelihood (parameter variance distribution)" width="70%" />
<p class="caption">
Figure 7.7: Likelihood (parameter variance distribution)
</p>
</div>

<p>For a joint-density likelihood, let us introduce <strong>negative log-likelihood (NLL)</strong> - a counterpart version of <strong>ML</strong>. We use <strong>NLL</strong> to avoid multiplication overflows (but more importantly, for our loss function - see Chapter <strong>9</strong> (<strong>Computational Learning I</strong>) under the <strong>General Modeling</strong> section. Also, for more discussion around <strong>maximum estimation</strong> and <strong>negative log-likelihood (NLL)</strong>, see <strong>parameter estimation</strong> in a later section.</p>


<p>To compute for joint-density likelihood, let us first suppose that the <strong>known</strong> parameters are derived from an actual distribution (these parameters become our reference for validation):</p>

<div class="sourceCode" id="cb829"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb829-1" data-line-number="1"><span class="kw">c</span>(<span class="st">&quot;known mean&quot;</span>=true.mean, <span class="st">&quot;known sd&quot;</span>=<span class="st"> </span>true.sigma)</a></code></pre></div>
<pre><code>## known mean   known sd 
##     50.222      2.534</code></pre>

<p>Next, let us perform sampling. In the later section, we discuss a list of more advanced <strong>sampling techniques</strong> such as the <strong>Markov Chain Monte Carlo (MCMC)</strong> technique using <strong>JAGS</strong>. For now, to perform a simple sampling, let us use the <strong>rnorm()</strong> function:</p>

<div class="sourceCode" id="cb831"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb831-1" data-line-number="1">(<span class="dt">sample =</span> <span class="kw">round</span>( <span class="kw">rnorm</span>(<span class="dt">n =</span> <span class="dv">10</span>, <span class="dt">mean =</span> true.mean, <span class="dt">sd =</span> true.sigma), <span class="dv">3</span>))</a></code></pre></div>
<pre><code>##  [1] 48.06 52.53 53.25 49.28 49.91 54.78 54.54 42.52 44.42 50.37</code></pre>

<p>The sample may provide the initial estimates of the parameters (they are quite close to the known parameters):</p>

<div class="sourceCode" id="cb833"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb833-1" data-line-number="1"><span class="kw">c</span>(<span class="st">&quot;initial mean&quot;</span> =<span class="st"> </span><span class="kw">mean</span>(sample), <span class="st">&quot;initial sd&quot;</span>=<span class="st"> </span><span class="kw">sqrt</span>( <span class="kw">var</span>(sample) ) )</a></code></pre></div>
<pre><code>## initial mean   initial sd 
##       49.966        4.108</code></pre>

<p>Suppose now that we only know the variance <span class="math inline">\(\sigma\)</span> = 2.5339. The mean <span class="math inline">\(\mu\)</span> is unknown. Let us compute for the mean estimate <span class="math inline">\(\hat{\mu}\)</span> of the true mean <span class="math inline">\(\mu\)</span>.</p>

<div class="sourceCode" id="cb835"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb835-1" data-line-number="1">loglike.mean =<span class="st"> </span><span class="kw">c</span>()</a>
<a class="sourceLine" id="cb835-2" data-line-number="2"><span class="cf">for</span> (mu <span class="cf">in</span> mean) {</a>
<a class="sourceLine" id="cb835-3" data-line-number="3">  lk.mean  =<span class="st"> </span><span class="kw">loglikelihood</span>( <span class="kw">normal.likelihood</span>(sample, </a>
<a class="sourceLine" id="cb835-4" data-line-number="4">                                      <span class="dt">mean=</span>mu, <span class="dt">sd =</span> true.sigma) )</a>
<a class="sourceLine" id="cb835-5" data-line-number="5">  loglike.mean =<span class="st"> </span><span class="kw">cbind</span>(loglike.mean, lk.mean )</a>
<a class="sourceLine" id="cb835-6" data-line-number="6">}</a>
<a class="sourceLine" id="cb835-7" data-line-number="7">loglike.mean =<span class="st"> </span><span class="kw">round</span>(loglike.mean, <span class="dv">3</span>)</a></code></pre></div>

<p>The overall <strong>NLL</strong> for <strong>mean</strong> and its corresponding value <span class="math inline">\(\mu^*\)</span>:</p>

<div class="sourceCode" id="cb836"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb836-1" data-line-number="1">mean.nll  =<span class="st"> </span><span class="kw">round</span>( <span class="kw">min</span>(loglike.mean), <span class="dv">3</span>) </a>
<a class="sourceLine" id="cb836-2" data-line-number="2">mean.est =<span class="st"> </span><span class="kw">round</span>( mean[ <span class="kw">which.min</span>(loglike.mean) ], <span class="dv">3</span>)</a>
<a class="sourceLine" id="cb836-3" data-line-number="3"><span class="kw">c</span>(<span class="st">&quot;NLL&quot;</span>=<span class="st"> </span>mean.nll, <span class="st">&quot;mean&quot;</span> =<span class="st"> </span>mean.est)</a></code></pre></div>
<pre><code>##  NLL mean 
## 31.0 50.9</code></pre>

<p>Next, suppose that we only know the mean <span class="math inline">\(\mu\)</span> = 50.2218. The variance <span class="math inline">\(\sigma\)</span> is unknown. Let us solve for the <span class="math inline">\(\sigma\)</span>.</p>

<div class="sourceCode" id="cb838"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb838-1" data-line-number="1">loglike.sd =<span class="st"> </span><span class="kw">c</span>()</a>
<a class="sourceLine" id="cb838-2" data-line-number="2"><span class="cf">for</span> (sd <span class="cf">in</span> sigma) {</a>
<a class="sourceLine" id="cb838-3" data-line-number="3">  lk.sigma  =<span class="st"> </span><span class="kw">loglikelihood</span>( <span class="kw">normal.likelihood</span>(sample, </a>
<a class="sourceLine" id="cb838-4" data-line-number="4">                                        <span class="dt">mean=</span> true.mean, <span class="dt">sd =</span> sd) )</a>
<a class="sourceLine" id="cb838-5" data-line-number="5">  loglike.sd =<span class="st"> </span><span class="kw">cbind</span>(loglike.sd, <span class="kw">min</span>(lk.sigma) )</a>
<a class="sourceLine" id="cb838-6" data-line-number="6">}</a>
<a class="sourceLine" id="cb838-7" data-line-number="7">loglike.sd =<span class="st"> </span><span class="kw">round</span>(loglike.sd, <span class="dv">3</span>)</a></code></pre></div>

<p>The overall <strong>NLL</strong> for <strong>sd</strong> and its corresponding value <span class="math inline">\(\sigma^*\)</span>:</p>

<div class="sourceCode" id="cb839"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb839-1" data-line-number="1">sd.nll    =<span class="st"> </span><span class="kw">round</span> ( <span class="kw">min</span>(loglike.sd), <span class="dv">3</span>) </a>
<a class="sourceLine" id="cb839-2" data-line-number="2">sd.est    =<span class="st"> </span><span class="kw">round</span>( sigma[ <span class="kw">which.min</span>(loglike.sd)], <span class="dv">3</span>) </a>
<a class="sourceLine" id="cb839-3" data-line-number="3"><span class="kw">c</span>(<span class="st">&quot;NLL&quot;</span>=<span class="st"> </span>sd.nll, <span class="st">&quot;sd&quot;</span>=<span class="st"> </span>sd.est)</a></code></pre></div>
<pre><code>##    NLL     sd 
## 28.014  3.412</code></pre>

<p>Here is a table of the likelihood for mean and variance with corresponding overall <strong>NLL</strong> (see Table <a href="bayesian.html#tab:likelihoodtab">7.1</a>).</p>

<table>
<caption><span id="tab:likelihoodtab">Table 7.1: </span>Parameter Estimation</caption>
<thead>
<tr class="header">
<th align="right">mean</th>
<th align="right">minimum NLL (<span class="math inline">\(\theta_{\mu}^*\)</span>)</th>
<th align="right">sd</th>
<th align="right">minimum NLL (<span class="math inline">\(\theta_{\sigma}^*\)</span>)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">54.70</td>
<td align="right">47.76</td>
<td align="right">2.910</td>
<td align="right">28.88</td>
</tr>
<tr class="even">
<td align="right">50.90</td>
<td align="right">31.00</td>
<td align="right">2.859</td>
<td align="right">29.02</td>
</tr>
<tr class="odd">
<td align="right">54.29</td>
<td align="right">44.84</td>
<td align="right">3.073</td>
<td align="right">28.49</td>
</tr>
<tr class="even">
<td align="right">52.14</td>
<td align="right">34.01</td>
<td align="right">2.055</td>
<td align="right">34.45</td>
</tr>
<tr class="odd">
<td align="right">47.03</td>
<td align="right">37.03</td>
<td align="right">2.018</td>
<td align="right">34.95</td>
</tr>
<tr class="even">
<td align="right">45.98</td>
<td align="right">42.71</td>
<td align="right">2.344</td>
<td align="right">31.59</td>
</tr>
<tr class="odd">
<td align="right">46.92</td>
<td align="right">37.56</td>
<td align="right">3.412</td>
<td align="right">28.01</td>
</tr>
<tr class="even">
<td align="right">50.90</td>
<td align="right">31.00</td>
<td align="right">2.633</td>
<td align="right">29.87</td>
</tr>
<tr class="odd">
<td align="right">45.04</td>
<td align="right">49.23</td>
<td align="right">2.369</td>
<td align="right">31.40</td>
</tr>
<tr class="even">
<td align="right">54.32</td>
<td align="right">45.10</td>
<td align="right">1.666</td>
<td align="right">41.78</td>
</tr>
</tbody>
</table>

<p>where:</p>
<p>minimum NLL (<span class="math inline">\(\theta_{\mu}^*\)</span>) <span class="math inline">\(\rightarrow\)</span> min (-<span class="math inline">\(nl Lik (\theta_{\mu}^* = 50.902| X )) =30.998\)</span> and</p>
<p>minimum NLL (<span class="math inline">\(\theta_{\sigma}^*\)</span>) <span class="math inline">\(\rightarrow\)</span> min (-<span class="math inline">\(nl Lik (\theta_{\sigma}^* = 3.412 | X )) =28.014\)</span>.</p>
<p>Let us introduce a few family of joint likelihood formulas (suppose data is <strong>IID</strong>):</p>

<table>
<caption><span id="tab:familylik">Table 7.2: </span>Family of Likelihood</caption>
<colgroup>
<col width="5%" />
<col width="1%" />
<col width="47%" />
<col width="37%" />
<col width="7%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Family</th>
<th align="left">â</th>
<th align="left"><span class="math inline">\(Lik (\theta\)</span>|<span class="math inline">\(x_1,...,x_n\)</span>)</th>
<th align="left"><span class="math inline">\(logLik (\theta\)</span>|<span class="math inline">\(x_1,...,x_n\)</span>)</th>
<th align="left"><span class="math inline">\(\theta\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Uniform</td>
<td align="left"></td>
<td align="left"><span class="math inline">\(\prod_{i=1}^n\frac{1}{\theta}, 0 \le x_i \le \theta\)</span></td>
<td align="left"><span class="math inline">\(-n \cdot ln(\theta)\)</span></td>
<td align="left"><span class="math inline">\(\theta\)</span></td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left"></td>
<td align="left"><span class="math inline">\(\text{ }\)</span></td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Normal</td>
<td align="left"></td>
<td align="left"><span class="math inline">\(\prod_{i=1}^n\frac{1}{\sqrt{2\pi\sigma^2}} \cdot exp\left(-\frac{(x_i - \mu)^2}{2\sigma^2}\right)\)</span></td>
<td align="left"><span class="math inline">\(\frac{n}{2}ln(2\pi\sigma^2) - \frac{1}{2\sigma^2} \sum_{i=1}^n(x_i - \mu)^2\)</span></td>
<td align="left"><span class="math inline">\(\mu,\sigma^2\)</span></td>
</tr>
<tr class="even">
<td align="left">Binomial</td>
<td align="left"></td>
<td align="left"><span class="math inline">\(\prod_{i=1}^m \binom{n}{x_i}\cdot \rho^{x_i}(1 - \rho)^{n-x_i}\)</span></td>
<td align="left"><span class="math inline">\(ln \binom{n}{x} + x ln(\rho) + (n - x) ln (1 - \rho)\)</span></td>
<td align="left"><span class="math inline">\(\rho\)</span></td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="left"></td>
<td align="left"><span class="math inline">\(\rho^X( 1 - \rho)^{n-X}, X = \sum_{i=1}^n x_i\)</span></td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">Geometric</td>
<td align="left"></td>
<td align="left"><span class="math inline">\(\prod_{i=1}^n \rho^n( 1 - \rho)^{x_i - n}\)</span></td>
<td align="left"><span class="math inline">\(n\cdot ln (\rho) + \left(\sum_{i=1}^n x_i - n \right) ln ( 1 - \rho)\)</span></td>
<td align="left"><span class="math inline">\(\rho\)</span></td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="left"></td>
<td align="left"><span class="math inline">\(\rho^n ( 1 - \rho)^{\sum_{i=1} (x_i - n)}\)</span></td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">Poisson</td>
<td align="left"></td>
<td align="left"><span class="math inline">\(\prod_{i=1}^n \frac{\lambda^{x_i}}{x_i!} \cdot exp(-\lambda)\)</span></td>
<td align="left"><span class="math inline">\(\sum_{i=1}^n\left( x_i ln(\lambda) - ln(x_i!) - \lambda \right )\)</span></td>
<td align="left"><span class="math inline">\(\lambda\)</span></td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="left"></td>
<td align="left"><span class="math inline">\(\frac{\lambda \sum_{i=1}^n x_i}{\prod_{i=1}^n x_i} \cdot exp(-n \lambda)\)</span></td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">Exponential</td>
<td align="left"></td>
<td align="left"><span class="math inline">\(\prod_{i=1}^n \lambda \cdot exp(-\lambda x), x\ge 0\)</span></td>
<td align="left"><span class="math inline">\(-n ln(\lambda) - \frac{1}{\lambda} \sum_{i=1}^n x_i, 0 &lt; \lambda &lt; \infty\)</span></td>
<td align="left"><span class="math inline">\(\lambda\)</span></td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="left"></td>
<td align="left"><span class="math inline">\(\frac{1}{\lambda^n} \cdot exp\left(\frac{-\sum_{i=1}^n x_i}{\lambda}\right)\)</span></td>
<td align="left"></td>
<td align="left"></td>
</tr>
</tbody>
</table>

<p>Note that the likelihood for Normal Distribution can also be written as:</p>
<p><span class="math display">\[
Lik (\theta|x_1,...,x_n) = 
\left(\frac{1}{\sqrt{2\pi\sigma^2}}\right)^n \cdot exp \left[\frac{-1}{2\sigma^2} \sum_{i=1}^n (x_i - \mu)^2\right]
\]</span></p>
<p>One other topic relevant to <strong>Likelihood</strong> is around <strong>base rate fallacy</strong>, which is often the cause of <strong>missing pertinent evidence</strong> (e.g., due to subjective (bias) decisions such as omitting relevant information).</p>
<p><strong>Base Rate Fallacy</strong> can also be called <strong>base rate neglect</strong> or <strong>base rate bias</strong>. It is Likelihood not measured based on frequency or commonality; rather based on the causal bias for which the Likelihood of an event to occur is based on information from other events based on premonition or irrational belief or feeling.</p>
<p>We leave readers to investigate this topic further, including the <strong>Uncertainty Quantification</strong>, which discusses <strong>Aleatoric uncertainty</strong> (Statistical uncertainty) and <strong>Epistemic uncertainty</strong> (Systematic uncertainty) - balancing knowledge vs.Â practice.</p>
</div>
<div id="posterior-probability" class="section level3 hasAnchor">
<h3><span class="header-section-number">7.3.3</span> Posterior Probability  <a href="bayesian.html#posterior-probability" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The term <strong>Posterior</strong> can be defined generally as <strong>that which comes after</strong>. In <strong>Bayesian</strong> statistics, a <strong>Posterior probability</strong>, also called <strong>a-posteriori probability</strong>, refers to the <strong>proportion of uncertainty</strong> of a random event <strong>after</strong> evidence is taken into consideration. Other terms are relevant to <strong>Posterior</strong> such as <strong>posterior odds, posterior uncertainty, posterior density, or posterior distribution</strong>.</p>
<p>A posterior probability, <span class="math inline">\(P(\theta|X)\)</span>, is obtained using the following formula:</p>
<p><span class="math display">\[\begin{align}
\underbrace{P(\theta|X)}_\text{posterior}\ \propto\ \underbrace{Lik(\theta|X)}_\text{likelihood} \times \underbrace{P(\theta)}_\text{prior}\ \ \ \ \ where\ \ \ \ Lik(\theta|X) \equiv P(X|\theta)
\end{align}\]</span></p>
<p>Or for multiple observations, we have the following notation:</p>
<p><span class="math display">\[\begin{align}
P(\theta|x_1,...x_n) \propto  Lik(\theta|x_1,...x_n) \times P(\theta) 
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li>the <strong>sampling density (likelihood)</strong> represents the new evidence (new observation)</li>
<li>the <strong>prior</strong> is a-priori probability that represents weight for the <strong>likelihood</strong></li>
<li>the <strong>posterior</strong> is a-posteriori probability that represents the new summary (new model) for theta (<span class="math inline">\(\theta\)</span>), e.g.Â the mean and variance that characterize an updated <strong>posterior</strong> normal distribution.</li>
</ul>
<p>Note that for <strong>IIDs</strong>, we can drop the normalizing factor: <span class="math inline">\(P(x_1,...,x_n)\)</span>.</p>
<p>Now, recall the following equivalent equation again when testing positive for symptoms of a certain disease:</p>
<p><span class="math display">\[\begin{align}
P(\text{symptom}|\mathbf{+})_{(posterior)} \propto  
P(\mathbf{+}|\text{symptom}) \times P(\text{symptom})
\end{align}\]</span></p>
<p>In previous sections, we analyze flu-like symptoms in the presence of a particular pathogen in a small local community. We denote flu-like symptoms with theta (<span class="math inline">\(\theta\)</span>). We also denote the presence of the pathogen with the variable <strong>X</strong>. There is a previous recording of about 25% of the local community experiencing similar strange flu-like symptoms in that particular case. That is a <strong>prior</strong> knowledge.</p>
<p>Based on our posterior probability computation in our previous case, we know that the resulting probability is 7.5%, <span class="math inline">\(P(\theta|X) = 7.5\%\)</span>. Therefore, we can make this our new prior knowledge to further our analysis.</p>
<p><span class="math display">\[\begin{align}
P(\theta)\ \ \leftarrow P(\theta|X)\ \ \ \ \ \ \ where\ \ new\ P(\theta) = 7.5\%
\end{align}\]</span></p>
<p>If we are to perform another analysis today, granting today we find a piece of new evidence that 11% are found positive with the pathogen, and 4% of the locals with flu-like symptoms also carry the pathogen, then we have a new posterior probability using the new prior knowledge and new evidence:</p>
<p><span class="math display">\[
P(\theta|X) = \frac{Lik(\theta|X)P(\theta)}{P(X)}
= \frac{(0.04)(0.075)}{(0.11)} = 0.0273 = 2.73\%
\]</span></p>
</div>
<div id="prior-probability" class="section level3 hasAnchor">
<h3><span class="header-section-number">7.3.4</span> Prior Probability  <a href="bayesian.html#prior-probability" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The term <strong>Prior</strong> can be defined generally as <strong>that which comes before</strong>. In <strong>Bayesian</strong> statistics, a <strong>Prior probability</strong>, also called <strong>a-priori probability</strong>, refers to the <strong>proportion of uncertainty</strong> of a random event <strong>before</strong> evidence is taken into consideration. There are other terms relevant to <strong>prior</strong> such as <strong>prior odds, prior uncertainty, prior density, or prior distribution</strong>.</p>
<p>A prior probability, <span class="math inline">\(P(\theta)\)</span>, is formulated based on <strong>prior knowledge</strong> and is applied to a <strong>likelihood</strong> of observing data given theta (<span class="math inline">\(\theta\)</span>).</p>
<p><span class="math display">\[\begin{align}
P(\theta|x_1,...x_n) \propto  Lik(\theta|x_1,...x_n)\times P(\theta)\ \ \leftarrow\ \ \ \ \
\text{posterior} \propto \text{likelihood} \times  \text{prior}
\end{align}\]</span></p>
<p>For example, recall the following equivalent equation when testing positive (<span class="math inline">\(\mathbf{+}\)</span>) for symptoms of a particular disease:</p>
<p><span class="math display">\[\begin{align}
P(\text{symptom}|\mathbf{+}) \propto  
P(\mathbf{+}|\text{symptom})\times  P(\text{symptom})_{(prior)}
\end{align}\]</span></p>
<p>We may show cold-like or flu-like symptoms when contracting certain diseases, for an illustrative example. These symptoms feed into our initial <strong>hypothetical</strong> prognosis. This prognosis describes an initial temporary belief of the state or condition of our health until we visit our general physician for professional diagnosis to know the cause of our symptoms - actual evidence of what we contracted. Our prognosis is mere <strong>hypothetical</strong> and becomes an initial <strong>prior</strong> knowledge. However, we can be creative and start imagining all sorts of other <strong>hypothetical</strong> predispositions of our condition, but that, of course, does not help our physician to reach a better recommendation or conclusion. To help guide our physician, we have to provide our most accurate condition or risk a less accurate diagnosis. In other words, we start with the premise that our prior is merely an <strong>uninformed</strong> belief - our prognosis. It can be regarded as a <strong>weakly informed prior</strong>. Such weak belief requires a doctorâs diagnostics. Therefore, more diagnostic evidence allows us to offset our belief and thus creates a more evidence-based, diagnostic-based (or data-based) posterior result. Otherwise, partial analysis (likelihood) and prognosis (prior belief) may need to be combined for a proper posterior if the diagnostic analysis is insufficient.</p>
<p>Also, mathematically, our <strong>prior distribution</strong> becomes <strong>improper</strong> if we end up with an infinite range of prognostic possibilities, meaning that our prior does not integrate to 1. An <strong>improper prior</strong> happens when corresponding prior probability does not integrate to a finite number:</p>
<p><span class="math display">\[\begin{align}
P(\theta) = \int f(\theta) d\theta = +\infty
\end{align}\]</span></p>
<p>Nonetheless, as long as the posterior probability is <strong>proper</strong> - meaning that it integrates to 1 - then our prior probability does not have to be <strong>proper</strong>. We continue to extend our discussion on <strong>informative prior</strong> in the <strong>Hyperparameters</strong> section.</p>
</div>
</div>
<div id="conjugacy" class="section level2 hasAnchor">
<h2><span class="header-section-number">7.4</span> Conjugacy<a href="bayesian.html#conjugacy" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>This section and the subsections listing conjugate priors include additional references from Daniel Fink <span class="citation">(<a href="bibliography.html#ref-ref437d">1997</a>)</span>, Ben Lambart <span class="citation">(<a href="bibliography.html#ref-ref457b">2014</a>)</span>, and Deetorah <span class="citation">(<a href="bibliography.html#ref-ref447d">2013</a>)</span> as the basis for a long list of Conjugacy Prior derivations.</p>
<p>When dealing with bayesian probabilities, we may think of data distribution as normal distribution by default. So if we see the following <strong>NaÃ¯ve Bayes</strong> formula: </p>
<p><span class="math display">\[\begin{align}
posterior \propto likelihood \times prior,
\end{align}\]</span></p>
<p>It may be appropriate if only we highlight the type of distribution used. So let us do that:</p>
<p><span class="math display">\[\begin{align}
\underbrace{posterior}_\text{normal} \propto \underbrace{likelihood}_\text{normal} \times \underbrace{prior}_\text{normal}
\end{align}\]</span></p>
<p>Both the <strong>posterior</strong> and <strong>prior</strong> components of a <strong>Bayesian</strong> formula are considered conjugate if they share the same family of probability distributions. It means that the parameters of both components follow the same family of distribution, e.g., a normal distribution.</p>
<div id="precision-1" class="section level3 hasAnchor">
<h3><span class="header-section-number">7.4.1</span> Precision <a href="bayesian.html#precision-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Before discussing a few conjugate combinations, let us introduce the concept of <strong>Precision</strong>.</p>
<p>A normal distribution has two common parameters: mean and variance. However, there is one other parameter that we can use for normal distribution called <strong>precision</strong> (let us use the <strong>L</strong>ambda <span class="math inline">\(\Lambda\)</span> symbol for this) which is the inverse of variance, <span class="math inline">\(\Lambda = \frac{1}{\sigma^2} = (\sigma^2)^{-1}\)</span>. <strong>Precision</strong> has an advantage over variance in that it has an <strong>additive property</strong>, which is useful for multivariate normal distribution.</p>
<p>For <strong>multivariate normal distribution</strong>, we have the following adjusted <strong>normal density function</strong>:</p>
<p><span class="math display">\[\begin{align}
f(x; \theta) = \frac{1}{\sqrt{(2\pi)^d \Sigma}} exp\left[-\frac{1}{2}\underbrace{(x - \mu)^T{\Sigma}^{-1}(x - \mu)}_\text{squared mahalanobis distance}\right]
\end{align}\]</span></p>
<p>where:</p>
<p><span class="math display">\[\begin{align}
{\Sigma}^{-1} = \sum uu^T\ \ \ \ \ \ \  \text{(an inverse covariance positive definite matrix)}
\end{align}\]</span></p>
<p>Note that <strong>Squared Mahalanobis distance</strong> measures the distance between distributions (e.g.Â between <strong>x</strong> and <span class="math inline">\(\mu\)</span>). See a brief definition in Chapter <strong>9</strong> (<strong>Computational Learning I</strong>) under <strong>Distance metrics</strong> Section.</p>
</div>
<div id="conjugate-prior" class="section level3 hasAnchor">
<h3><span class="header-section-number">7.4.2</span> Conjugate Prior <a href="bayesian.html#conjugate-prior" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A way for a <strong>posterior</strong> to characterize a <strong>proper density</strong> is to have a <strong>prior</strong> density be applied to a <strong>sampling density (likelihood)</strong>. Therefore, it is essential to be able to choose an appropriate prior density that leads to a proper posterior density. We need to choose a prior distribution that fits a good distribution for the posterior. We call this chosen prior distribution a <strong>conjugate prior</strong>.</p>
<p>In <strong>machine learning</strong>, it is common to regard <strong>prior</strong> as a weighing factor denoted as <span class="math inline">\(\omega(.)\)</span> or <span class="math inline">\(\pi(.)\)</span>, e.g.:</p>

<p><span class="math display">\[\begin{align}
P(\mu|x) \propto P(\mu) \times Lik(\mu|x)
\rightarrow P(\mu|x) \propto \mathcal{\pi}(\mu) \times Lik(\mu|x)
\end{align}\]</span>
</p>
</div>
<div id="normal-normal-conjugacy" class="section level3 hasAnchor">
<h3><span class="header-section-number">7.4.3</span> Normal-Normal Conjugacy <a href="bayesian.html#normal-normal-conjugacy" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The idea is to be able to tailor a <strong>Normal density</strong> distribution for <strong>posterior</strong> given that a <strong>Normal density</strong> is <strong>conjugate prior</strong> for a <strong>Normal likelihood</strong> where the mean <span class="math inline">\(\mu\)</span> is unknown. For a notation, we use the following:</p>

<p><span class="math display">\[\begin{align}
P(\mu|x) \propto P(\mu) \times Lik(\mu|x)
\ \ \ \ \ \ \text{for } -\infty &lt; \mu\ &lt; \infty
\end{align}\]</span>
</p>
<p>For <strong>likelihood</strong>, we have the following distribution:</p>

<p><span class="math display">\[\begin{align}
x|\mu,\sigma^2 \sim \mathcal{N}(\mu, \sigma^2)\ \ \ \ \ \text{where}\ \sigma^2\ \text{ is known, but}\ \mu\ \text{is unknown}
\end{align}\]</span>
</p>
<p>For <strong>marginal-density</strong> likelihood:</p>

<p><span class="math display">\[\begin{align}
Lik_X(\mu, \sigma^2|x) {}&amp;\equiv P_X(X=x|\mu, \sigma^2)\\
&amp;= \frac{1}{\sqrt{2\pi\sigma^2}} exp\left[-\frac{(x - \mu)^2}{2\sigma^2}\right]
\end{align}\]</span>
</p>
<p>For <strong>joint-density</strong> likelihood (where <strong>n</strong> is sample size):</p>

<p><span class="math display">\[\begin{align}
Lik_X(\mu, \sigma^2|x_1,...,x_n) &amp;\equiv P_X(x_1,...,x_n|\mu, \sigma^2) \\
&amp;= \prod_{i=1}^n\frac{1}{\sqrt{2\pi\sigma^2}} exp\left[-\frac{(x_i - \mu)^2}{2\sigma^2}\right]\\
&amp;= \left(\frac{1}{\sqrt{2\pi\sigma^2}}\right)^n exp\left[-\frac{\sum_{i=1}^n (x_i - \mu)^2}{2\sigma^2}\right]
\end{align}\]</span>
</p>
<p>For <strong>prior</strong>, we choose a <strong>Normal</strong> distribution for the <span class="math inline">\(\mu\)</span> parameter:</p>

<p><span class="math display">\[\begin{align}
\mu \sim \mathcal{N}(\mu_0, \sigma^2_0)\ \ \ \ \ \text{where}\ \mu_0\ \text{and}\ \sigma^2_0 \text{ are known } \mathbf{hyperparameters} 
\end{align}\]</span></p>
<p><span class="math display">\[\begin{align}
\mathcal{\pi}(\mu) = P(\mu; \mu_0, \sigma^2_0) = \frac{1}{\sqrt{2\pi\sigma^2_0}} exp\left[-\frac{(\mu - \mu_0)^2}{2\sigma^2_0}\right] 
\end{align}\]</span>
</p>
<p>For <strong>posterior</strong>, we want to arrive at a <strong>Normal density</strong> given an observed data:</p>

<p><span class="math display">\[\begin{align}
\mu, \sigma^2|x \sim \mathcal{N}(\mu_1, \sigma^2_1) 
\end{align}\]</span>
</p>
<p>However, first, let us derive the <strong>posterior density</strong> with respect to <span class="math inline">\(\mu\)</span> by <strong>dropping the constants</strong> that do not affect the shape or proportionality of the distribution (e.g., expressed by the exponents).</p>
<p>For a <strong>Normal posterior</strong> with <strong>marginal-density</strong> likelihood:</p>

<p><span class="math display">\[\begin{align}
P(\mu,\sigma^2|x) {}&amp;\propto  
\underbrace { \frac{1}{\sqrt{2\pi\sigma^2_0}} exp\left[-\frac{(\mu - \mu_0)^2}{2\sigma^2_0}\right]}_\text{normal prior} \times 
\underbrace { \frac{1}{\sqrt{2\pi\sigma^2}} exp\left[-\frac{(x - \mu)^2}{2\sigma^2}\right] }_\text{normal likelihood}\\
P(\mu,\sigma^2|x) &amp;\propto exp\left[-\frac{(\mu - \mu_0)^2}{2\sigma^2_0}\right] \times
exp\left[-\frac{(x - \mu)^2}{2\sigma^2}\right]\ \ \text{(drop constant)} \\
&amp;\propto exp\left[-\frac{(\mu - \mu_0)^2}{2\sigma^2_0}
-\frac{(x - \mu)^2}{2\sigma^2}\right] \\
&amp; \propto exp\left[-\left(\frac{\sigma^2}{\sigma^2}\right)\frac{(\mu - \mu_0)^2}{2\sigma^2_0} 
-\left(\frac{\sigma^2_0}{\sigma^2_0}\right)\frac{(x - \mu)^2}{2\sigma^2}\right] \\
&amp;\propto exp\left[-\frac{\sigma^2(\mu - \mu_0)^2}{2\sigma^2_0\sigma^2}
-\frac{\sigma^2_0(x - \mu)^2}{2\sigma^2\sigma^2_0}\right] \\
&amp;\propto exp\left[\frac{
      -\sigma^2(\mu^2 - 2\mu\mu_0 + \mu^2_0) + -\sigma^2_0(x^2 - 2x\mu + \mu^2)}
      {2\sigma^2\sigma^2_0}\right] \\
&amp;\propto exp\left[\frac{
      (-\mu^2\sigma^2 + 2\mu\mu_0\sigma^2 - \mu^2_0\sigma^2) + (-x^2\sigma^2_0 + 2x\mu\sigma^2_0 - \mu^2\sigma^2_0)}
      {2\sigma^2\sigma^2_0}\right] 
\end{align}\]</span></p>

<p>Let us pull out contents of the exponent and drop the constants with respect to <span class="math inline">\(\mu\)</span>, then simplify further:</p>

<p><span class="math display">\[\begin{align}
{}&amp;\rightarrow \frac{
      (-\mu^2\sigma^2 + 2\mu\mu_0\sigma^2) + (2x\mu\sigma^2_0 - \mu^2\sigma^2_0)}
      {2\sigma^2\sigma^2_0} \\
&amp;\rightarrow \frac{1}{2}\frac{
      -\mu^2(\sigma^2 + \sigma^2_0) +2\mu(\mu_0\sigma^2 + x\sigma^2_0)} 
      {\sigma^2\sigma^2_0} \\
&amp;\rightarrow \frac{1}{2}\frac{
      -\mu^2(\sigma^2 + \sigma^2_0) +2\mu(\mu_0\sigma^2 + x\sigma^2_0)} 
      {\sigma^2\sigma^2_0} \left(\frac{\frac{1}{\sigma^2 + \sigma^2_0}}{\frac{1}{\sigma^2 + \sigma^2_0}}\right)\\
&amp;\rightarrow -\frac{1}{2}\left(\frac{
      \mu^2 - 2\mu
         \frac{ \mu_0\sigma^2 + x\sigma^2_0 }{\sigma^2 + \sigma^2_0}
      } 
      {\frac{\sigma^2\sigma^2_0}{\sigma^2 + \sigma^2_0}  } \right)\ \ \
  \rightarrow -\frac{1}{2}\left(\frac{
       \left( \mu - 
        \frac{ \mu_0\sigma^2 + x\sigma^2_0 }{\sigma^2 + \sigma^2_0}\right)^2
      } 
      {\frac{\sigma^2\sigma^2_0}{\sigma^2 + \sigma^2_0}  } \right) 
\end{align}\]</span>
</p>
<p>If we then put back the equation inside the exponent, we then have the following:</p>

<p><span class="math display">\[\begin{align}
P(\mu,\sigma^2|x) \propto 
 exp\left[-\frac{(\mu - \mu_1)^2}{2\sigma^2_1}\right] = 
 exp 
 \left[
   -\frac{1}{2}\left(\frac{
      \left(  \mu - 
         \frac{ \mu_0\sigma^2 + x\sigma^2_0}{\sigma^2 + \sigma^2_0}
         \right)^2
      } 
      {\frac{\sigma^2\sigma^2_0}{\sigma^2 + n\sigma^2_0}  } \right)
 \right]
\end{align}\]</span>
</p>
<p>Notice that given a <strong>Normal posterior</strong> distribution, it becomes apparent that the parameters <span class="math inline">\(\alpha_1\)</span> and <span class="math inline">\(\beta_1\)</span> correspond to the following:</p>

<p><span class="math display">\[\begin{align}
\mu_1 = \frac{ \mu_0\sigma^2 + x\sigma^2_0}{\sigma^2 + \sigma^2_0} =
\frac{\left(\frac{\mu_0}{\sigma^2_0} + \frac{x}{\sigma^2}\right)}
      {\left(\frac{1}{\sigma^2_0} + \frac{1}{\sigma^2}\right) }
\ \ \ \ \ \ \ \ \ \ \ \ \ \
\sigma^2_1 = \frac{\sigma^2\sigma^2_0}{\sigma^2 + \sigma^2_0} = 
\left(\frac{1}{\sigma^2_0} + \frac{1}{\sigma^2}\right)^{-1}
\end{align}\]</span>
</p>
<p>Therefore, we arrive at the following reparameterized <strong>posterior distribution</strong>:</p>

<p><span class="math display">\[\begin{align}
\mu,\sigma^2|x \sim ~ N(\alpha_1, \beta_1)\ \ \ \rightarrow 
N\left[ \sigma^2_1\left(\frac{\mu_0}{\sigma^2_0} + \frac{x}{\sigma^2}\right),
 \left(\frac{1}{\sigma^2_0} + \frac{1}{\sigma^2}\right)^{-1} \right] 
\end{align}\]</span>
</p>
<p>For a <strong>Normal posterior</strong> with <strong>joint-density</strong> likelihood:</p>

<p><span class="math display">\[\begin{align}
P(\mu,\sigma^2|x_1,...,x_n) {}&amp;\propto  
\underbrace{ \frac{1}{\sqrt{2\pi\sigma^2_0}} exp\left[-\frac{(\mu - \mu_0)^2}{2\sigma^2_0}\right]}_\text{normal prior} \times
\underbrace{ \left(\frac{1}{\sqrt{2\pi\sigma^2}}\right)^n exp\left[-\frac{\sum_{i=1}^n (x_i - \mu)^2}{2\sigma^2}\right]}_\text{normal likelihood}\\
P(\mu,\sigma^2|x_1,...,x_n) &amp;\propto exp\left[-\frac{(\mu - \mu_0)^2}{2\sigma^2_0}\right] \times
exp\left[-\frac{\sum_{i=1}^n (x_i - \mu)^2}{2\sigma^2}\right]\ \\
&amp;\propto exp\left[-\frac{(\mu - \mu_0)^2}{2\sigma^2_0}
-\frac{\sum_{i=1}^n(x_i - \mu)^2}{2\sigma^2}\right] \\
&amp; \propto exp\left[-\left(\frac{\sigma^2}{\sigma^2}\right)\frac{(\mu - \mu_0)^2}{2\sigma^2_0} 
-\left(\frac{\sigma^2_0}{\sigma^2_0}\right)\frac{\sum_{i=1}^n(x_i  - \mu)^2}{2\sigma^2}\right] \\
&amp;\propto exp\left[-\frac{\sigma^2(\mu - \mu_0)^2}{2\sigma^2_0\sigma^2}
-\frac{\sigma^2_0\sum_{i=1}^n(x_i  - \mu)^2}{2\sigma^2\sigma^2_0}\right] \\
&amp;\propto exp\left[\frac{
      -\sigma^2(\mu^2 - 2\mu\mu_0 + \mu^2_0) + -\sigma^2_0(\sum_{i=1}^nx_i^2 - 2n\bar{x}\mu + n\mu^2)}
      {2\sigma^2\sigma^2_0}\right] 
\end{align}\]</span>
<span class="math display">\[\begin{align}
&amp;\propto exp\left[\frac{
      (-\mu^2\sigma^2 + 2\mu\mu_0\sigma^2 - \mu^2_0\sigma^2) + (-\sigma^2_0 \sum_{i=1}^nx_i^2 + 2n \bar{x}\mu\sigma^2_0 - n\mu^2\sigma^2_0)}
      {2\sigma^2\sigma^2_0}\right] 
\end{align}\]</span>
</p>
<p>Let us pull out contents of the exponent and drop the constants with respect to <span class="math inline">\(\mu\)</span>:</p>

<p><span class="math display">\[\begin{align}
{}&amp;\rightarrow \frac{
      (-\mu^2\sigma^2 + 2\mu\mu_0\sigma^2) + (2n\bar{x}\mu\sigma^2_0 - n\mu^2\sigma^2_0)}
      {2\sigma^2\sigma^2_0} \\
&amp;\rightarrow \frac{
      -\mu^2(\sigma^2 + n\sigma^2_0) + 2\mu(\mu_0\sigma^2 + \bar{x}n\sigma^2_0)}
      {2\sigma^2\sigma^2_0} \\
&amp;\rightarrow \frac{
      -\mu^2(\sigma^2 + n\sigma^2_0) + 2\mu(\mu_0\sigma^2 + \bar{x}n\sigma^2_0)}
      {2\sigma^2\sigma^2_0}  \left(\frac{\frac{1}{\sigma^2 + n\sigma^2_0}}{\frac{1}{\sigma^2 + n\sigma^2_0}}\right)\\
&amp;\rightarrow -\frac{1}{2}\left(\frac{
      \mu^2 - 
         2\mu \frac{ \mu_0\sigma^2 + n\bar{x}\sigma^2_0}{\sigma^2 + n\sigma^2_0}
      } 
      {\frac{\sigma^2\sigma^2_0}{\sigma^2 + n\sigma^2_0}  } \right)\ \ \ 
  \rightarrow\ \ \
   -\frac{1}{2}\left(\frac{
       \left( \mu - 
          \frac{ \mu_0\sigma^2 + n\bar{x}\sigma^2_0}{\sigma^2 + n\sigma^2_0}
         \right)^2
      } 
      {\frac{\sigma^2\sigma^2_0}{\sigma^2 + n\sigma^2_0}  } \right) 
\end{align}\]</span>
</p>
<p>If we then put back the equation inside the exponent, we then have the following:</p>

<p><span class="math display">\[\begin{align}
P(\mu,\sigma^2|x1,...,x_n) \propto 
 exp\left[-\frac{(\mu - \mu_1)^2}{2\sigma^2_1}\right] = 
 exp \left[
   -\frac{1}{2}\left(\frac{
       \left( \mu - 
         \frac{ \mu_0\sigma^2 + n\bar{x}\sigma^2_0}{\sigma^2 + n\sigma^2_0}
         \right)^2
      } 
      {\frac{\sigma^2\sigma^2_0}{\sigma^2 + n\sigma^2_0}  } \right)
 \right]
\end{align}\]</span>
</p>
<p>Notice that given a <strong>Normal posterior</strong> distribution, it becomes apparent that the parameters <span class="math inline">\(\alpha_1\)</span> and <span class="math inline">\(\beta_1\)</span> correspond to the following:</p>

<p><span class="math display">\[\begin{align}
\mu_1 {}= \frac{ \mu_0\sigma^2 + n\bar{x}\sigma^2_0}{\sigma^2 + n\sigma^2_0} =
\frac{\left(\frac{\mu_0}{\sigma^2_0} + \frac{n\bar{x}}{\sigma^2}\right)}
      {\left(\frac{1}{\sigma^2_0} + \frac{n}{\sigma^2}\right) }
\ \ \ \ \ \ \ \ \ \ \ \ \ \
\sigma^2_1 = \frac{\sigma^2\sigma^2_0}{\sigma^2 + n\sigma^2_0} = 
\left(\frac{1}{\sigma^2_0} + \frac{n}{\sigma^2}\right)^{-1}
\end{align}\]</span>
</p>
<p>Therefore, we arrive at the following reparameterized <strong>posterior distribution</strong>:</p>

<p><span class="math display">\[\begin{align}
\mu,\sigma^2|x_1,...,x_n \sim ~ N(\alpha_1, \beta_1)\ \ \ \rightarrow 
N\left[ \sigma^2_1\left(\frac{\mu_0}{\sigma^2_0} + \frac{n\bar{x}}{\sigma^2}\right),
 \left(\frac{1}{\sigma^2_0} + \frac{n}{\sigma^2}\right)^{-1} \right] 
\end{align}\]</span>
</p>
</div>
<div id="normal-inverse-gamma-conjugacy" class="section level3 hasAnchor">
<h3><span class="header-section-number">7.4.4</span> Normal-Inverse Gamma Conjugacy <a href="bayesian.html#normal-inverse-gamma-conjugacy" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The idea is to be able to tailor an <strong>Inverse Gamma density</strong> distribution for <strong>posterior</strong> given that an <strong>Inverse Gamma density</strong> is <strong>conjugate prior</strong> for a <strong>Normal likelihood</strong> where the variance <span class="math inline">\(\sigma^2\)</span> is unknown. For a notation, we use the following:</p>

<p><span class="math display">\[\begin{align}
P(\sigma^2|x) \propto P(\sigma^2) \times Lik(\sigma^2|x)
\ \ \ \ \ \ \text{for } -\infty &lt; \sigma^2\ &lt; \infty 
\end{align}\]</span>
</p>
<p>For <strong>likelihood</strong>, we have the following distribution:</p>

<p><span class="math display">\[\begin{align}
x|\mu,\sigma^2 \sim \mathcal{N}(\mu, \sigma^2)\ \ \ \ \ \text{where}\ \mu\ \text{ is known, but}\ \sigma^2\ \text{is unknown}
\end{align}\]</span>
</p>
<p>For <strong>marginal-density</strong> likelihood:</p>

<p><span class="math display">\[\begin{align}
Lik_X(\mu,\sigma^2|x) {}&amp;\equiv P(X=x|\mu,\sigma^2)\\
&amp;= \frac{1}{\sqrt{2\pi\sigma^2}} exp\left[-\frac{(x - \mu)^2}{2\sigma^2}\right]
\end{align}\]</span>
</p>
<p>For <strong>joint-density</strong> likelihood:</p>

<p><span class="math display">\[\begin{align}
Lik_X(\mu, \sigma^2|x_1,...,x_n) &amp;\equiv P_X(x_1,...,x_n|\mu,\sigma^2) \\
&amp;= \prod_{i=1}^n\frac{1}{\sqrt{2\pi\sigma^2}} exp\left[-\frac{(x_i - \mu)^2}{2\sigma^2}\right]\\
&amp;= \left(\frac{1}{\sqrt{2\pi\sigma^2}}\right)^n exp\left[-\frac{\sum_{i=1}^n (x_i - \mu)^2}{2\sigma^2}\right]
\end{align}\]</span>
</p>
<p>For <strong>prior</strong>, we choose an <strong>Inverse Gamma</strong> distribution for the <span class="math inline">\(\sigma^2\)</span> parameter:</p>

<p><span class="math display">\[\begin{align}
\sigma^2 \sim Inv.\ Gamma(\alpha_0,\beta_0)\ \ \ \ \ \text{where}\ \alpha_0\ \text{and}\ \beta_0 \text{ are known } \mathbf{hyperparameters}
\end{align}\]</span></p>
<p><span class="math display">\[\begin{align}
\mathcal{\pi}(\sigma^2) = P(\sigma^2; \alpha_0, \beta_0) =
\frac{\beta_0^{\alpha_0}}{\Gamma(\alpha_0)}{(\sigma^2)}^{-(\alpha_0+1)}exp\left({-\frac{\beta_0}{\sigma^2}}\right)\ \ \text{(inverse)}
\end{align}\]</span>
</p>
<p>For <strong>posterior</strong>, we want to arrive at an <strong>Inv. Gamma density</strong> given an observed data:</p>

<p><span class="math display">\[\begin{align}
\sigma^2|x \sim Inv.\ Gamma(\alpha_1,\beta_1)
\end{align}\]</span>
</p>
<p>But first, let us derive the <strong>posterior density</strong> with respect to <span class="math inline">\(\sigma^2\)</span> by <strong>dropping the constants</strong> that do not affect the shape or proportionality of the distribution (e.g., expressed by the exponents).</p>
<p>For an <strong>Inv. Gamma posterior</strong> with <strong>marginal-density</strong> likelihood:</p>

<p><span class="math display">\[\begin{align}
P(\mu,\sigma^2|x) {}&amp;\propto  \underbrace{ \frac{\beta_0^{\alpha_0}}{\Gamma(\alpha_0)}{(\sigma^2)}^{-(\alpha_0+1)}exp\left({-\frac{\beta_0}{\sigma^2}}\right) }_\text{inverse-gamma prior} \times 
\underbrace{ \frac{1}{\sqrt{2\pi\sigma^2}} exp\left[-\frac{(x - \mu)^2}{2\sigma^2}\right]}_\text{normal likelihood} \\
&amp;\propto\frac{\beta_0^{\alpha_0}}{\Gamma(\alpha_0)}{(\sigma^2)}^{-(\alpha_0+1)}exp\left({-\frac{\beta_0}{\sigma^2}}\right) \times
(2\pi)^{-\frac{1}{2}} (\sigma^2)^{-\frac{1}{2}}  exp\left[-\frac{(x - \mu)^2}{2\sigma^2}\right]\\
P(\mu,\sigma^2|x) 
&amp;\propto \left[{(\sigma^2)}^{-(\alpha_0+1)}exp\left({-\frac{\beta_0}{\sigma^2}}\right) \right] \times
 (\sigma^2)^{-\frac{1}{2}}  exp\left[-\frac{(x - \mu)^2}{2\sigma^2}\right] \ \text{(drop const.)} \\
&amp;\propto \left[{(\sigma^2)}^{-(\alpha_0+\frac{1}{2} + 1)}
   exp\left( 
   -\frac{1}{\sigma^2} \left(\beta_0 + \frac{(x - \mu)^2}{2} \right)
   \right) 
 \right] 
\end{align}\]</span>
</p>
<p>Notice that given an <strong>Inv. Gamma posterior</strong> distribution, it becomes apparent that the parameters <span class="math inline">\(\alpha_1\)</span> and <span class="math inline">\(\beta_1\)</span> correspond to the following:</p>

<p><span class="math display">\[\begin{align}
\alpha_1 = \alpha_0  + \frac{1}{2}
\ \ \ \ \ \ \ \ \ \ \ \ \ \
\beta_1 = \left(\beta_0 + \frac{(x - \mu)^2}{2} \right)
\end{align}\]</span>
</p>
<p>Therefore, we arrive at the following reparameterized <strong>posterior distribution</strong>:</p>

<p><span class="math display">\[\begin{align}
\rho|x \sim Inv. Gamma(\alpha_1, \beta_1)\ \ \ \rightarrow 
Inv. Gamma \left[\alpha_0  + \frac{1}{2}, \left(\beta_0 + \frac{(x - \mu)^2}{2} \right) \right]
\end{align}\]</span>
</p>
<p>For an <strong>Inv. Gamma posterior</strong> with <strong>joint-density</strong> likelihood:</p>

<p><span class="math display">\[\begin{align}
P(\mu&amp;,\sigma^2|x_1,...,x_n) \propto \nonumber \\
&amp;\underbrace{ \frac{\beta_0^{\alpha_0}}{\Gamma(\alpha_0)}{(\sigma^2)}^{-(\alpha_0+1)}exp\left({-\frac{\beta_0}{\sigma^2}}\right)}_\text{inverse-gamma prior}
\times 
\underbrace{ \left(\frac{1}{\sqrt{2\pi\sigma^2}}\right)^n exp\left[-\frac{\sum_{i=1}^n(x_i - \mu)^2}{2\sigma^2}\right] }_\text{normal likelihood} \\
&amp;\propto   \frac{\beta_0^{\alpha_0}}{\Gamma(\alpha_0)}{(\sigma^2)}^{-(\alpha_0+1)}exp\left({-\frac{\beta_0}{\sigma^2}}\right) \times
(2\pi)^{-\frac{n}{2}} (\sigma^2)^{-\frac{n}{2}}  exp\left[-\frac{\sum_{i=1}^n(x_i - \mu)^2}{2\sigma^2}\right] 
\end{align}\]</span>
<span class="math display">\[\begin{align}
P(\mu,\sigma^2|x_1,...,x_n) 
&amp;\propto \left[{(\sigma^2)}^{-(\alpha_0+1)}exp\left({-\frac{\beta_0}{\sigma^2}}\right) \right] \times
 (\sigma^2)^{-\frac{n}{2}}  exp\left[-\frac{\sum_{i=1}^n(x_i - \mu)^2}{2\sigma^2}\right] \\
&amp;\propto \left[{(\sigma^2)}^{-(\alpha_0+\frac{n}{2} + 1)}
   exp\left( 
   -\frac{1}{\sigma^2} \left(\beta_0 + \frac{\sum_{i=1}^n(x_i - \mu)^2}{2} \right)
   \right) 
 \right] 
\end{align}\]</span>
</p>
<p>Notice that given an <strong>Inv. Gamma posterior</strong> distribution, it becomes apparent that the parameters <span class="math inline">\(\alpha_1\)</span> and <span class="math inline">\(\beta_1\)</span> correspond to the following:</p>

<p><span class="math display">\[\begin{align}
\alpha_1 = \alpha_0  + \frac{n}{2}
\ \ \ \ \ \ \ \ \ \ \ \ \ \
\beta_1 =  \beta_0 + \frac{\sum_{i=1}^n(x_i - \mu)^2}{2}  
\end{align}\]</span>
</p>
<p>Therefore, we arrive at the following reparameterized <strong>posterior distribution</strong>:</p>

<p><span class="math display">\[\begin{align}
\rho|x_1,...,x_n \sim Inv. Gamma(\alpha_1, \beta_1)\ \ \ \rightarrow 
Inv. Gamma \left[\alpha_0  + \frac{n}{2},  \beta_0 + \frac{\sum_{i=1}^n(x_i - \mu)^2}{2}  \right ]
\end{align}\]</span>
</p>
</div>
<div id="multivariate-normal-conjugacy" class="section level3 hasAnchor">
<h3><span class="header-section-number">7.4.5</span> Multivariate Normal Conjugacy <a href="bayesian.html#multivariate-normal-conjugacy" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The idea is to be able to tailor a <strong>Multivariate Normal (MVN)</strong> distribution for <strong>posterior</strong> given that <strong>MVN density</strong> is <strong>conjugate prior</strong> for the mean parameter, <span class="math inline">\(\mu\)</span>. For a notation, we use the following:</p>

<p><span class="math display">\[\begin{align}
P(\mu|x) \propto P(\mu) \times Lik(\mu|x)
\end{align}\]</span>
</p>
<p>For <strong>likelihood</strong>, we have the following <strong>p-variate normal</strong> distribution:</p>

<p><span class="math display">\[\begin{align}
X_m|\mu,\Sigma \sim \mathcal{N}_p(\mu, \Sigma)\ \ \ \ \ \text{where}\ \mu\ \text{is unknown and }\ \Sigma \text{ is  known }
\end{align}\]</span>
</p>
<p>and where:</p>

<p><span class="math display">\[\begin{align*}
X = \left[\begin{array}{rrrr}x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1p}\\ x_{21} &amp; x_{22} &amp; \cdots &amp; x_{2p} \\ \vdots &amp;  \vdots &amp;  \ddots &amp;  \vdots \\ x_{n1} &amp; x_{n2} &amp; \cdots &amp; x_{np} \end{array}\right]_\text{(nxp)}
 \ \ \ \ 
\mu = \left[\begin{array}{c}\bar{x}_1 \\ \bar{x}_2 \\ \vdots \\ \bar{x}_p \end{array}\right]
= \left[\begin{array}{c}\mu_1 \\ \mu_2 \\ \vdots \\ \mu_p \end{array}\right]_\text{(1xp)}
\end{align*}\]</span></p>
<p><span class="math display">\[\begin{align*}
\Sigma = \left[\begin{array}{rrrr}\sigma^2_{1} &amp; \sigma_{12} &amp; \cdots &amp; \sigma_{1p}\\ \sigma_{21} &amp; \sigma^2_{2} &amp; \cdots &amp; \sigma_{2p} \\ \vdots &amp;  \vdots &amp;  \ddots &amp;  \vdots \\ \sigma_{p1} &amp; \sigma_{p2} &amp; \cdots &amp; \sigma^2_{p} \end{array}\right]_\text{(pxp)}
\end{align*}\]</span>
</p>
<p>The notation <span class="math inline">\(\Sigma\)</span> above represents a <strong>p-variate</strong> <strong>positive-definite</strong> variance-covariance matrix.</p>
<p>For <strong>joint-density</strong> likelihood:</p>

<p><span class="math display">\[\begin{align}
Lik_X(\mu, {}&amp;\Sigma|x_1,...,x_n) \equiv P_X(x_1,...,x_n|\mu,\Sigma) \\
&amp;= \prod_{i=1}^n\frac{|\Sigma|^{-\frac{1}{2}}}{(2\pi)^{\frac{p}{2}}} exp\left[-\frac{1}{2}(x_i - \mu)^T\Sigma^{-1}(x_i - \mu)\right]\\
&amp;= \left(\frac{|\Sigma|^{-\frac{1}{2}}}{(2\pi)^{\frac{p}{2}}}\right)^n exp\left[-\frac{1}{2}\sum_{i=1}^n (x_i - \mu)^T\Sigma^{-1}(x_i - \mu)\right]\\
&amp;= \left(\frac{|\Sigma|^{-\frac{1}{2}}}{(2\pi)^{\frac{p}{2}}}\right)^n exp\left[-\frac{n}{2} (\bar{x} - \mu)^T\Sigma^{-1}(\bar{x} - \mu)\right]\\
&amp;= \left(\frac{|\Sigma|^{-\frac{1}{2}}}{(2\pi)^{\frac{p}{2}}}\right)^n exp\left[-\frac{n}{2} (\bar{x}^T\Sigma^{-1}\bar{x} - \bar{x}^T\Sigma^{-1}\mu - \mu^T\Sigma^{-1}\bar{x} + \mu^T\Sigma^{-1}\mu )\right]
\end{align}\]</span>
</p>
<p>For <strong>prior</strong>, we choose a <strong>Multivariate normal</strong> distribution for the <span class="math inline">\(\mu\)</span> parameter:</p>

<p><span class="math display">\[\begin{align}
\mu \sim \mathcal{N}_p(\mu_0,\Sigma_0)\ \ \ \ \ \text{where}\ \mu_0\ \text{and}\ \Sigma_0 \text{ are known } \mathbf{hyperparameters}
\end{align}\]</span></p>
<p><span class="math display">\[\begin{align}
\mathcal{\pi}(\mu) = P(\mu; \mu_0, \Sigma_0) {}&amp;= \frac{|\Sigma_0|^{-\frac{1}{2}}}{(2\pi)^{\frac{p}{2}}} exp\left[-\frac{1}{2}(\mu - \mu_0)^T\Sigma_0^{-1}(\mu - \mu_0)\right]\\
&amp;= \frac{|\Sigma_0|^{-\frac{1}{2}}}{(2\pi)^{\frac{p}{2}}} 
exp\left[-\frac{1}{2}\left( \mu^T \Sigma_0^{-1} \mu - \mu^T\Sigma_0^{-1} \mu_0 -  \mu_0^T\Sigma_0^{-1} \mu  + {\mu_0}^T \Sigma_0^{-1}\mu_0  \right)\right]
\end{align}\]</span>
</p>
<p>For <strong>posterior</strong>, we want to arrive at a <strong>Multivariate normal density</strong> given some observed data:</p>

<p><span class="math display">\[\begin{align}
\mu|X \sim \mathcal{N}_p(\mu_1,\Sigma_1) 
\end{align}\]</span>
</p>
<p>But first, let us derive the <strong>posterior density</strong> with respect to <span class="math inline">\(\mu\)</span> by dropping the constants that do not affect the shape or proportionality of the distribution.</p>
<p>For a <strong>multivariate normal posterior</strong>:
</p>
<p><span class="math display">\[\begin{align}
P(\mu|x) &amp;= 
\underbrace{\frac{|\Sigma_0|^{-\frac{1}{2}}}{(2\pi)^{\frac{p}{2}}} 
exp\left[-\frac{1}{2}\left( \mu^T \Sigma_0^{-1} \mu - \mu^T\Sigma_0^{-1} \mu_0 -  {\mu_0}^T\Sigma_0^{-1} \mu  + {\mu_0}^T \Sigma_0^{-1}\mu_0 \right)\right]}_\text{MVN prior} \nonumber \\
&amp;\times \underbrace{\left(\frac{|\Sigma|^{-\frac{1}{2}}}{(2\pi)^{\frac{p}{2}}}\right)^n 
exp\left[-\frac{n}{2} (\bar{x}^T\Sigma^{-1}\bar{x} - \bar{x}^T\Sigma^{-1}\mu - \mu^T\Sigma^{-1}\bar{x} + \mu^T\Sigma^{-1}\mu ) \right] }_\text{MVN likelihood}
\end{align}\]</span></p>
<p><span class="math display">\[\begin{align}
\rightarrow &amp; \text{(drop constants not relevant to } \mu \text{. Also, recall matrix transposition properties)} \nonumber \\
&amp;\propto  exp\left[-\frac{1}{2}\left( \mu^T \Sigma_0^{-1} \mu -  \mu^T\Sigma_0^{-1} \mu_0 - {\mu_0} ^T\Sigma_0^{-1} \mu \right)\right]\\
&amp;\times exp\left[-\frac{n}{2} \left( -  \bar{x} ^T\Sigma^{-1}\mu -  \mu^T\Sigma^{-1}\bar{x}  +   \mu^T\Sigma^{-1}\mu\right)\right] \\
 &amp;\propto  exp\biggl[-\frac{1}{2}\biggl(\left[ \mu^T \Sigma_0^{-1} \mu -  \mu^T\Sigma_0^{-1} \mu_0 - {\mu_0} ^T\Sigma_0^{-1}\mu \right]  + \left[  -  n\bar{x} ^T\Sigma^{-1}\mu -  n\mu^T\Sigma^{-1}\bar{x}  +   n\mu^T\Sigma^{-1}\mu\right]\biggr)\biggr]\\
  &amp;\propto  exp\biggl[-\frac{1}{2}\biggl( \mu^T \left[ \Sigma_0^{-1} + n\Sigma^{-1}\right] \mu -  \mu^T \left[ \Sigma_0^{-1}\mu_0 + \Sigma^{-1}n\bar{x}\right]  - \left[\Sigma_0^{-1}\mu_0 + \Sigma^{-1}n\bar{x}\right]^T\mu
  \biggr)\biggr]\\
  &amp;\propto  exp\biggl[-\frac{1}{2}\biggl( \mu^T \left[ \Sigma_0^{-1} + n\Sigma^{-1}\right] \mu -  2\mu^T \left[ \Sigma_0^{-1}\mu_0 + \Sigma^{-1}n\bar{x}\right]  
  \biggr)\biggr]\\
&amp;\propto  exp\biggl[-\frac{1}{2}\biggl(
    \left(\mu -   \left[ \Sigma_0^{-1} + n\Sigma^{-1}\right]^{-1}
            \left[ \Sigma_0^{-1}\mu_0 + \Sigma^{-1}n\bar{x}\right] \right)^T
            \left( \Sigma_0^{-1} + n\Sigma^{-1} \right) \nonumber \\
&amp;\ \ \ \ \ \ \ \ \ \ \ \left(\mu -   \left[ \Sigma_0^{-1} + n\Sigma^{-1}\right]^{-1}
            \left[ \Sigma_0^{-1}\mu_0 + \Sigma^{-1}n\bar{x}\right] \right)     
  \biggr)\biggr]
\end{align}\]</span>
</p>
<p>Notice that given an <strong>MVN posterior</strong> distribution, it becomes apparent that the parameters <span class="math inline">\(\mu_1\)</span> and <span class="math inline">\(\Sigma_1\)</span> correspond to the following:</p>

<p><span class="math display">\[\begin{align}
\Sigma_1 =  \left[ \Sigma_0^{-1} + n\Sigma^{-1}\right]^{-1}\ \ \ \ \ \ \ \ \ \ \ \ 
\mu_1 = \Sigma_1 \left[ \Sigma_0^{-1}\mu_0 + \Sigma^{-1}n\bar{x}\right]
\end{align}\]</span>
</p>
<p>Therefore, we arrive at the following reparameterized <strong>p-variate posterior distribution</strong>:</p>

<p><span class="math display">\[\begin{align}
\mu|x \sim \mathcal{N}_p(\mu_1,\Sigma_1) \ \ \ \rightarrow 
\mathcal{N}_p \left(  \Sigma_1 \left[ \Sigma_0^{-1}\mu_0 + \Sigma^{-1}n\bar{x}\right],\  \left[ \Sigma_0^{-1} + n\Sigma^{-1}\right]^{-1} \right)
\end{align}\]</span>
</p>
</div>
<div id="normal-wishart-conjugacy" class="section level3 hasAnchor">
<h3><span class="header-section-number">7.4.6</span> Normal Wishart Conjugacy <a href="bayesian.html#normal-wishart-conjugacy" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The idea is to be able to tailor a <strong>Normal Wishart</strong> distribution for <strong>posterior</strong> given that <strong>Normal Wishart density</strong> is <strong>conjugate prior</strong> for <strong>mean</strong>, <span class="math inline">\(\mu\)</span>, and <strong>positive-definite</strong> <strong>precision</strong> matrix parameter, <span class="math inline">\(\Lambda\)</span>, of a <strong>Multivariate normal likelihood</strong>. For a notation, we use the following:</p>

<p><span class="math display">\[\begin{align}
P(\mu, \Lambda|x) \propto P(\mu,\Lambda) \times Lik(\mu, \Lambda|x)
\end{align}\]</span>
</p>
<p>For <strong>likelihood</strong>, we have the following <strong>p-variate normal</strong> distribution:</p>

<p><span class="math display">\[\begin{align}
X|\mu,\Lambda \sim \mathcal{N}_p(X; \mu, \Lambda)  \ \ \ \ \ \text{where}\ \mu\ and\ \Lambda\ \text{are unknown }
\end{align}\]</span>
</p>
<p>Recall the below structure. See Chapter <strong>5</strong> (<strong>Numerical Probability and Distribution</strong>) under <strong>Wishart Distribution</strong> section:</p>

<p><span class="math display">\[\begin{align*}
X = \left[\begin{array}{rrrr}x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1p}\\ x_{21} &amp; x_{22} &amp; \cdots &amp; x_{2p} \\ \vdots &amp;  \vdots &amp;  \ddots &amp;  \vdots \\ x_{n1} &amp; x_{n2} &amp; \cdots &amp; x_{np} \end{array}\right]_\text{(nxp)}
 \ \ \ \ 
\mu = \left[\begin{array}{c}\bar{x}_1 \\ \bar{x}_2 \\ \vdots \\ \bar{x}_p \end{array}\right]
= \left[\begin{array}{c}\mu_1 \\ \mu_2 \\ \vdots \\ \mu_p \end{array}\right]_\text{(1xp)}
\end{align*}\]</span></p>
<p><span class="math display">\[\begin{align*}
\Lambda = \left[\begin{array}{rrrr}\sigma^2_{1} &amp; \sigma_{12} &amp; \cdots &amp; \sigma_{1p}\\ \sigma_{21} &amp; \sigma^2_{2} &amp; \cdots &amp; \sigma_{2p} \\ \vdots &amp;  \vdots &amp;  \ddots &amp;  \vdots \\ \sigma_{p1} &amp; \sigma_{p2} &amp; \cdots &amp; \sigma^2_{p} \end{array}\right]_\text{(pxp)}^{(-1)}
\end{align*}\]</span>
</p>
<p>For <strong>multivariate joint-density</strong> likelihood:</p>

<p><span class="math display">\[\begin{align}
Lik_X(\mu, \Lambda|x_1,...,x_n) &amp;\equiv P_X(x_1,...,x_n|\mu,\Lambda) \\
&amp;= \prod_{i=1}^n\frac{|\Lambda|^{\frac{1}{2}}}{(2\pi)^{\frac{p}{2}}} exp\left[-\frac{1}{2}(x_i - \mu)^T\Lambda(x_i - \mu)\right]\\
&amp;= \left(\frac{|\Lambda|^{\frac{1}{2}}}{(2\pi)^{\frac{p}{2}}}\right)^n exp\left[-\frac{1}{2}\sum_{i=1}^n (x_i - \mu)^T\Lambda(x_i - \mu)\right]\\
&amp;= \left(\frac{|\Lambda|^{\frac{1}{2}}}{(2\pi)^{\frac{p}{2}}}\right)^n exp\left[-\frac{1}{2}\sum_{i=1}^n \Lambda(x_i - \mu)(x_i - \mu)^T\right]\\
&amp;= \left(\frac{|\Lambda|^{\frac{1}{2}}}{(2\pi)^{\frac{p}{2}}}\right)^n exp\left[-\frac{1}{2}\Lambda\left(\sum_{i=1}^n x_i x_i^T - \mu (n\bar{x})^T - (n\bar{x})\mu^T + n\mu\mu^T\right)\right]
\end{align}\]</span>
</p>
<p>It helps to be aware of the following mathematical manipulation (derivation not included):</p>

<p><span class="math display">\[\begin{align}
\sum_{i=1}^n (x_i - \mu)^T\Lambda(x_i - \mu) = tr( \Sigma \Lambda)\ \ \ \ \  where\ \ \ \Sigma = \sum_{i=1}^n (x_i - \mu)(x_i - \mu)^T
\end{align}\]</span>
</p>
<p>For <strong>prior</strong>, we choose a <strong>Normal-Wishart</strong> distribution for both <span class="math inline">\(\Lambda\)</span> and <span class="math inline">\(\mu\)</span> parameters. Recall description of <strong>Central Wishart</strong> notation under <strong>Wishart distribution</strong> in Chapter <strong>5</strong> (<strong>Numerical Probability and Distribution</strong>.</p>

<p><span class="math display">\[\begin{align}
\Lambda {}&amp;\sim \mathcal{W}_p(v_0, \Sigma_0)\ \ \ \ \ \text{where}\ v_0\ and\ \Sigma_0 \text{ are known } \mathbf{hyperparameters}\\
\nonumber \\
\mathcal{\pi}(\Lambda) &amp;= P(\Lambda; \nu_0, \Sigma_0) 
    =  \frac{|\Lambda|^{\frac{\nu_0-p-1}{2}} exp\left[-\frac{1}{2}tr(\Sigma_0^{-1}\Lambda)\right]}
    {2^{\frac{\nu_0 p}{2}}|\Sigma_0|^{\frac{\nu_0}{2}}\ \Gamma_p\left(\frac{\nu_0}{2}\right)}
\end{align}\]</span></p>
<p><span class="math display">\[\begin{align}
\mu|\Lambda {}&amp;\sim \mathcal{N}_p(\alpha_0, (\beta_0\Lambda)^{-1})\ \ \ \ \ \text{where}\ \alpha_0\ and\ \beta_0\Lambda \text{ are known } \mathbf{hyperparameters}\\
\nonumber  \\
\mathcal{\pi}(\mu|\Lambda) &amp;= P(\mu; \alpha_0, (\beta_0\Lambda)^{-1})
    =  \frac{|\beta_0\Lambda|^{\frac{1}{2}}}{(2\pi)^{\frac{p}{2}}} exp\left[-\frac{1}{2}(\mu - \alpha_0)^T\beta_0\Lambda(\mu - \alpha_0)\right]
\end{align}\]</span></p>
<p><span class="math display">\[\begin{align}
\rightarrow &amp; \text{(join distributions and drop constants)} \nonumber \\
\nonumber \\
P(\mu, \Lambda) 
&amp;\propto  \underbrace{ |\beta_0\Lambda|^{\frac{1}{2}} 
  exp\left[-\frac{1}{2}(\mu -     \alpha_0)^T\beta_0\Lambda(\mu - \alpha_0)\right]}_\text{gaussian prior}
      \times
       \underbrace{ |\Lambda|^{\frac{\nu_0-p-1}{2}}  
  exp\left[-\frac{1}{2}tr(\Sigma_0^{-1}\Lambda)\right]}_\text{wishart  prior}\\
&amp;\propto    |\beta_0|^\frac{1}{2} |\Lambda|^{\frac{1}{2}}  |\Lambda|^{\frac{\nu_0-p-1}{2}}  exp\left[-\frac{\beta_0}{2}\Lambda(\mu - \alpha_0)(\mu - \alpha_0)^T + -\frac{1}{2}tr(\Sigma_0^{-1}\Lambda) \right] \\
&amp;\propto   |\beta_0|^\frac{1}{2} |\Lambda|^{\frac{\nu_0-p}{2}}  exp\left[-\frac{\beta_0}{2}\Lambda(\mu\mu^T - \mu{\alpha_0}^T - {\alpha_0}\mu^T + \alpha_0{\alpha_0}^T) + -\frac{1}{2}tr(\Sigma_0^{-1}\Lambda) \right]
\end{align}\]</span>
</p>
<p>where:</p>
<ul>
<li><span class="math inline">\(\alpha_0\)</span> is hyper mean for <span class="math inline">\(\mu\)</span>.</li>
<li><span class="math inline">\(\beta_0\Lambda\)</span> is hyper precision for <span class="math inline">\(\mu\)</span>. See Figure <a href="bayesian.html#fig:mixturebayes">7.19</a> as reference model.</li>
<li><span class="math inline">\(\Lambda\)</span> is <strong>positive-definite</strong> precision matrix that follows a <strong>wishart</strong> distribution.</li>
</ul>
<p>For <strong>posterior</strong>, we want to join the likelihood and the normal-wishart prior:</p>

<p><span class="math display">\[\begin{align}
\mu, \Lambda|x \sim \ \mathcal{NW}_p(\mu, \Lambda; \alpha_1, (\beta_1\Lambda), v_1, \Sigma_1)
\end{align}\]</span>
</p>
<p>However, let us first derive the <strong>posterior density</strong> with respect to <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\Lambda\)</span> by dropping the constants that do not affect the shape or proportionality of the distribution (e.g., expressed by the exponents).</p>
<p>For a <strong>Normal-Wishart posterior</strong> with <strong>joint-density</strong> likelihood:</p>

<p><span class="math display">\[\begin{align}
P{}&amp;(\mu,\Lambda|X) \propto  \underbrace{ |\beta_0|^\frac{1}{2} |\Lambda|^{\frac{\nu_0-p}{2}}  exp\left[-\frac{\beta_0}{2}\Lambda(\mu\mu^T - \mu{\alpha_0}^T - {\alpha_0}\mu^T + \alpha_0{\alpha_0}^T) + -\frac{1}{2}tr(\Sigma_0^{-1}\Lambda) \right] }_\text{normal-wishart prior} \nonumber \\
&amp;\times 
\underbrace{\left(\frac{|\Lambda|^{\frac{1}{2}}}{(2\pi)^{\frac{p}{2}}}\right)^n exp\left[-\frac{1}{2}\Lambda\left(\sum_{i=1}^n x_i {x_i}^T - \mu (n\bar{x})^T - (n\bar{x})\mu^T + n\mu\mu^T\right)\right]}_\text{normal likelihood} 
\end{align}\]</span></p>
<p><span class="math display">\[\begin{align}
\rightarrow &amp; \text{(drop constants and simplify. Recall matrix transposition properties)} \nonumber \\
&amp;\propto   |\Lambda|^{\frac{\nu_0-p}{2}} |\Lambda|^{\frac{n}{2}} exp\biggl[-\frac{\beta_0}{2}\Lambda(\mu\mu^T - \mu{\alpha_0}^T - {\alpha_0}\mu^T + \alpha_0{\alpha_0}^T) +  -\frac{1}{2}tr(\Sigma_0^{-1}\Lambda) \nonumber \\
&amp;+ -\frac{1}{2}\Lambda\biggl(\sum_{i=1}^n x_i {x_i}^T - \mu (n\bar{x})^T - (n\bar{x})\mu^T + n\mu\mu^T\biggr) \biggr] \\
&amp;\propto    |\Lambda|^{\frac{\nu_0+n-p}{2}} \nonumber  \\
&amp;exp\biggl[-\frac{1}{2}\Lambda\biggl((\beta_0 + n) \mu\mu^T - (\alpha_0\beta_0 + n\bar{x})\mu^T  - \mu(\alpha_0\beta_0 + n\bar{x})^T + \beta_0\alpha_0{\alpha_0}^T  + \sum_{i=1}^n x_i {x_i}^T \biggr)  + \nonumber \\
&amp; -\frac{1}{2}tr(\Sigma_0^{-1}\Lambda) \biggr]
\end{align}\]</span></p>
<p><span class="math display">\[\begin{align}
\rightarrow &amp; \text{(inject placeholders)} \nonumber \\
\rightarrow  &amp;\text{let}\ a = (\beta_0 + n)\ and\ b = (\alpha_0\beta_0 + n\bar{x})\\
&amp;\propto    |\Lambda|^{\frac{\nu_0+n-p}{2}} \nonumber  \\
&amp;exp\biggl[-\frac{1}{2}\Lambda\biggl((a) \mu\mu^T - (b)\mu^T  - \mu(b)^T + \beta_0\alpha_0{\alpha_0}^T  + \sum_{i=1}^n x_i {x_i}^T \biggr)  + -\frac{1}{2}tr(\Sigma_0^{-1}\Lambda) \biggr]
\end{align}\]</span></p>
<p><span class="math display">\[\begin{align}
\rightarrow  &amp;\text{(add terms so that}\ bb^T - bb^T = 0\ \text{)} \nonumber \\
&amp;\propto    |\Lambda|^{\frac{\nu_0+n-p}{2}} \nonumber  \\
&amp;exp\biggl[-\frac{1}{2}\Lambda\biggl((a) \mu\mu^T-(b)\mu^T  - \mu(b)^T \mathbf{\ + bb^T - bb^T} + \beta_0\alpha_0{\alpha_0}^T  + \sum_{i=1}^n x_i {x_i}^T \biggr) -\frac{1}{2}tr(\Sigma_0^{-1}\Lambda) \biggr]\\
\rightarrow &amp; \text{(add factor so that}\ \frac{a}{a} = 1\ \text{)} \nonumber \\
&amp;\propto    |\Lambda|^{\frac{\nu_0+n-p}{2}} \nonumber  \\
&amp;exp\biggl[-\frac{1}{2}\Lambda\biggl(\frac{a}{a}\biggl[(a) \mu\mu^T - (b)\mu^T  - \mu(b)^T  bb^T-bb^T \biggr] + \beta_0\alpha_0{\alpha_0}^T  + \sum_{i=1}^n x_i {x_i}^T \biggr) \nonumber \\
&amp;-\frac{1}{2}tr(\Sigma_0^{-1}\Lambda) \biggr]
\end{align}\]</span></p>
<p><span class="math display">\[\begin{align}
\rightarrow  &amp;\text{(split exponentials and re-arrange terms)} \nonumber \\
&amp;\propto    |\Lambda|^{\frac{\nu_0+n-p}{2}} \nonumber  \\
&amp;exp\biggl[-\frac{1}{2}\Lambda\biggl((a) \biggl[ \mu\mu^T - \frac{1}{(a)}(b)\mu^T  - \frac{1}{(a)}\mu(b)^T + \frac{1}{(a)}bb^T \biggr] \biggr) \biggr] \times \nonumber \\
&amp;exp\biggl[-\frac{1}{2}\Lambda\biggl(- \frac{1}{(a)}bb^T + \beta_0\alpha_0{\alpha_0}^T + \sum_{i=1}^n x_i {x_i}^T  \biggr) + -\frac{1}{2}tr(\Sigma_0^{-1}\Lambda) \biggr]\\
&amp;\propto    |\Lambda|^{\frac{\nu_0+n-p}{2}} \nonumber  \\
&amp;exp\biggl[-\frac{1}{2}\Lambda\biggl((a) \biggl( \mu - \frac{(b)}{(a)} \biggr)\biggl( \mu - \frac{(b)}{(a)} \biggr)^T  \biggr) \biggr] \times \nonumber \\
&amp;exp\biggl[-\frac{1}{2}\Lambda\biggl(- \frac{1}{(a)}bb^T + \beta_0\alpha_0{\alpha_0}^T +  \sum_{i=1}^n x_i {x_i}^T \biggr)  + -\frac{1}{2}tr(\Sigma_0^{-1}\Lambda) \biggr]
\end{align}\]</span></p>
<p><span class="math display">\[\begin{align}
\rightarrow &amp; \text{(substitute placeholder)} \nonumber \\
&amp;\propto    |\Lambda|^{\frac{\nu_0+n-p}{2}} \nonumber  \\
&amp;exp\biggl[-\frac{1}{2}\Lambda\biggl((\beta_0 + n) \biggl( \mu - \frac{(\alpha_0\beta_0 + n\bar{x})}{(\beta_0 + n)} \biggr)\biggl( \mu - \frac{(\alpha_0\beta_0 + n\bar{x})}{(\beta_0 + n)} \biggr)^T  \biggr) \biggr] \times \nonumber \\
&amp;exp\biggl[-\frac{1}{2}\Lambda\biggl(- \frac{(\alpha_0\beta_0 + n\bar{x})(\alpha_0\beta_0 + n\bar{x})^T }{(\beta_0 + n)} + \beta_0\alpha_0{\alpha_0}^T  +  \sum_{i=1}^n x_i {x_i}^T \biggr) + -\frac{1}{2}tr(\Sigma_0^{-1}\Lambda) \biggr]
\end{align}\]</span>
</p>
<p>Let us extract terms from the second exponential equation to simplify.</p>
<p>First, add terms so that <span class="math inline">\(- n\bar{x}\bar{x}^T + n\bar{x}\bar{x}^T = 0\)</span>, and then simplify (a.l.a sum of squares).</p>

<p><span class="math display">\[\begin{align}
&amp;\rightarrow  \sum_{i=1}^nx_i {x_i}^T \mathbf{\ - n\bar{x}\bar{x}^T +  n\bar{x}\bar{x}^T}  \\
&amp;\rightarrow  \sum_{i=1}^n\biggl(x_i {x_i}^T - \bar{x}\bar{x}^T\biggr) + \mathbf{n\bar{x}\bar{x}^T} \\
&amp;\rightarrow  \sum_{i=1}^n\biggl(x_i {x_i}^T - \bar{x}{x_i}^T - x_i\bar{x}^T + \bar{x}\bar{x}^T \biggr) +  \mathbf{\ n\bar{x}\bar{x}^T} \\
&amp;\rightarrow \sum_{i=1}^n (x_i - \bar{x})(x_i - \bar{x})^T + n\bar{x}\bar{x}^T
\end{align}\]</span>
</p>
<p>Let <strong>S</strong> = <span class="math inline">\(\sum_{i=1}^n (x_i - \bar{x})(x_i - \bar{x})^T\)</span>.</p>
<p>Therefore, we get:</p>

<p><span class="math display">\[\begin{align}
P{}&amp;(\mu,\Lambda|X) \propto    |\Lambda|^{\frac{\nu_0+n-p}{2}} \nonumber \\
&amp;exp\biggl[-\frac{1}{2}\Lambda\biggl((\beta_0 + n) \biggl( \mu - \frac{(\alpha_0\beta_0 + n\bar{x})}{(\beta_0 + n)} \biggr)\biggl( \mu - \frac{(\alpha_0\beta_0 + n\bar{x})}{(\beta_0 + n)} \biggr)^T  \biggr) \biggr] \times \nonumber \\
&amp;exp\biggl[-\frac{1}{2}\Lambda\biggl(- \frac{(\alpha_0\beta_0 + n\bar{x})(\alpha_0\beta_0 + n\bar{x})^T }{(\beta_0 + n)} + \beta_0\alpha_0{\alpha_0}^T  +  \mathbf{n\bar{x}\bar{x}^T + S} \biggr) + -\frac{1}{2}tr(\Sigma_0^{-1}\Lambda) \biggr]
\end{align}\]</span>
</p>
<p>Second, add a factor so that <span class="math inline">\(\frac{(\beta_0 + n)}{(\beta_0 + n)} = 1\)</span>, and then expand the first three terms of the second exponential equation.</p>

<p><span class="math display">\[\begin{align}
&amp;\rightarrow \biggl(- \frac{(\alpha_0\beta_0 + n\bar{x})(\alpha_0\beta_0 + n\bar{x})^T }{(\beta_0 + n)} + \beta_0\alpha_0{\alpha_0}^T  + n \bar{x}\bar{x}^T\biggr) \\
&amp;\rightarrow - \frac{(\alpha_0\beta_0 + n\bar{x})(\alpha_0\beta_0 + n\bar{x})^T }{(\beta_0 + n)} + \beta_0\alpha_0{\alpha_0}^T \frac{(\beta_0 + n)}{(\beta_0 + n)} + n \bar{x}\bar{x}^T \frac{(\beta_0 + n)}{(\beta_0 + n)}  \\
&amp;\rightarrow \frac{-(\alpha_0\beta_0 + n\bar{x})(\alpha_0\beta_0 + n\bar{x})^T  + 
     \beta_0^2\alpha_0{\alpha_0}^T  +  n \beta_0\alpha_0{\alpha_0}^T + n \beta_0 \bar{x}\bar{x}^T + n^2 \bar{x}\bar{x}^T
      }{(\beta_0 + n)}  \\
&amp;\rightarrow \frac{ - (\beta_0^2\alpha_0\alpha_0^T + n\beta_0\alpha_0\bar{x}T + n\beta_0\bar{x}\alpha_0^T + n^2\bar{x}\bar{x}^T ) +  \beta_0^2\alpha_0{\alpha_0}^T  +  n \beta_0\alpha_0{\alpha_0}^T +n \beta_0 \bar{x}\bar{x}^T +n^2 \bar{x}\bar{x}^T }{(\beta_0 + n)}\\
&amp;\rightarrow \frac{ - n\beta_0\alpha_0\bar{x}^T - n\beta_0\bar{x}{\alpha_0}^T +  n \beta_0\alpha_0{\alpha_0}^T +  n \beta_0 \bar{x}\bar{x}^T }{(\beta_0 + n)}\\
&amp;\rightarrow \frac{ n\beta_0(\bar{x}\bar{x}^T - \alpha_0\bar{x}^T - \bar{x}{\alpha_0}^T + \alpha_0{\alpha_0}^T   ) }{(\beta_0 + n)}\\
&amp;\rightarrow \frac{ n\beta_0}{(\beta_0 + n)}(\bar{x} - \alpha_0)(\bar{x} - \alpha_0  )^T 
\end{align}\]</span>
</p>
<p>Finally, we get the following <strong>gaussian-wishart</strong> equation:</p>

<p><span class="math display">\[\begin{align}
P(\mu,\Lambda|X) {}&amp;\propto    |\Lambda|^{\frac{\nu_0+n-p}{2}} \nonumber \\
&amp;exp\biggl[-\frac{1}{2}\Lambda\biggl((\beta_0 + n) \biggl( \mu - \frac{(\alpha_0\beta_0 + n\bar{x})}{(\beta_0 + n)} \biggr)\biggl( \mu - \frac{(\alpha_0\beta_0 + n\bar{x})}{(\beta_0 + n)} \biggr)^T  \biggr) \biggr] \times \nonumber \\
&amp;exp\biggl[-\frac{1}{2}\Lambda\biggl(  \frac{ n\beta_0}{(\beta_0 + n)}(\bar{x} - \alpha_0)( \bar{x} - \alpha_0 )^T + S \biggr) + -\frac{1}{2}tr(\Sigma_0^{-1}\Lambda) \biggr]\\
\nonumber \\
&amp;\propto    |\Lambda|^{\frac{\nu_0+n-p}{2}}   \nonumber \\
&amp;\underbrace{ exp\biggl[-\frac{(\beta_0 + n) }{2}\biggl( \mu - \frac{(\alpha_0\beta_0 + n\bar{x})}{(\beta_0 + n)} \biggr)^T\Lambda\biggl( \mu - \frac{(\alpha_0\beta_0 + n\bar{x})}{(\beta_0 + n)} \biggr) \biggr]}_\text{gaussian} \times \nonumber \\
&amp;\underbrace{exp\biggl[-\frac{1}{2}tr\biggl(  \frac{ n\beta_0}{(\beta_0 + n)}(\bar{x} - \alpha_0)( \bar{x} - \alpha_0 )^T + S  + \Sigma_0^{-1} \biggr) \Lambda \biggr]}_\text{wishart}
\end{align}\]</span>
</p>
<p>Notice that given a <strong>Normal Wishart posterior</strong> distribution, it becomes apparent that the parameters correspond to the following:</p>

<p><span class="math display">\[\begin{align}
\alpha_1 &amp;=  \frac{(\alpha_0\beta_0 + n\bar{x})}{(\beta_0 + n)}\\
\beta_1 &amp;= \beta_0 + n \\
\nu_1 {}&amp;= \nu_0 + n \\
\Sigma_1 &amp;=  \frac{ n\beta_0}{(\beta_0 + n)}(\bar{x} - \alpha_0)( \bar{x} - \alpha_0 )^T + S  + \Sigma_0^{-1} 
\end{align}\]</span>
</p>
<p>Therefore, we arrive at the following reparameterized <strong>posterior distribution</strong> using a <strong>gaussian-wishart</strong> joint distribution:</p>

<p><span class="math display">\[\begin{align}
\mu, \Lambda|x\sim \ \mathcal{NW}_p(\alpha_1, \beta_1, \nu_1,\Sigma_1) 
= \mathcal{N}_p(\alpha_1, \beta_1)\times\mathcal{W}_p(\nu_1, \Sigma_1)
\end{align}\]</span>
</p>
</div>
<div id="normal-inverse-wishart-conjugacy" class="section level3 hasAnchor">
<h3><span class="header-section-number">7.4.7</span> Normal-Inverse Wishart Conjugacy <a href="bayesian.html#normal-inverse-wishart-conjugacy" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The idea is to be able to tailor an <strong>Inverse Wishart</strong> distribution for <strong>posterior</strong> given that <strong>Inverse Wishart density</strong> is <strong>conjugate prior</strong> for a <strong>positive-definite</strong> <strong>covariance matrix</strong> parameter, <span class="math inline">\(\Lambda\)</span>, of a <strong>Multivariate Normal Likelihood</strong>; the same as we use <strong>Inverse Gamma density</strong> as <strong>conjugate prior</strong> for the variance parameter, <span class="math inline">\(\sigma^2\)</span>, of a <strong>Univariate Normal Likelihood</strong>. For a notation, we use the following:</p>

<p><span class="math display">\[\begin{align}
P(\Lambda|x) \propto P(\Lambda) \times Lik(\Lambda|x)
\end{align}\]</span>
</p>
<p>For <strong>likelihood</strong>, we have the following <strong>p-variate normal</strong> distribution:</p>

<p><span class="math display">\[\begin{align}
X|\mu,\Lambda \sim \mathcal{N}_p(X; \mu, \Lambda)  \ \ \ \ \ \text{where}\ \mu\ \text{is known and }\ \Lambda \text{ is unknown } 
\end{align}\]</span>
</p>
<p>Recall the below structure. See Chapter <strong>5</strong> (<strong>Numerical Probability and Distribution</strong>) under <strong>Wishart Distribution</strong> Section as reference:</p>

<p><span class="math display">\[\begin{align}
X = \left[\begin{array}{rrrr}x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1p}\\ x_{21} &amp; x_{22} &amp; \cdots &amp; x_{2p} \\ \vdots &amp;  \vdots &amp;  \ddots &amp;  \vdots \\ x_{n1} &amp; x_{n2} &amp; \cdots &amp; x_{np} \end{array}\right]_\text{(nxp)}
 \ \ \ \ 
\mu = \left[\begin{array}{c}\bar{x}_1 \\ \bar{x}_2 \\ \vdots \\ \bar{x}_p \end{array}\right]
= \left[\begin{array}{c}\mu_1 \\ \mu_2 \\ \vdots \\ \mu_p \end{array}\right]_\text{(1xp)} \label{eqn:eqnnumber311}
\end{align}\]</span></p>
<p><span class="math display">\[\begin{align}
\Lambda = \left[\begin{array}{rrrr}\sigma^2_{1} &amp; \sigma_{12} &amp; \cdots &amp; \sigma_{1p}\\ \sigma_{21} &amp; \sigma^2_{2} &amp; \cdots &amp; \sigma_{2p} \\ \vdots &amp;  \vdots &amp;  \ddots &amp;  \vdots \\ \sigma_{p1} &amp; \sigma_{p2} &amp; \cdots &amp; \sigma^2_{p} \end{array}\right]_\text{(pxp)} \label{eqn:eqnnumber312}
\end{align}\]</span>
</p>
<p>For <strong>multivariate joint-density</strong> likelihood:</p>

<p><span class="math display">\[\begin{align}
Lik_X(\mu, \Lambda|x_1,...,x_n) &amp;\equiv P_X(x_1,...,x_n|\mu,\Lambda) \\
&amp;= \prod_{i=1}^n\frac{|\Lambda|^{-\frac{1}{2}}}{(2\pi)^{\frac{p}{2}}} exp\left[-\frac{1}{2}(x_i - \mu)^T\Lambda^{-1}(x_i - \mu)\right]\\
&amp;= \left(\frac{|\Lambda|^{-\frac{1}{2}}}{(2\pi)^{\frac{p}{2}}}\right)^n exp\left[-\frac{1}{2}\sum_{i=1}^n (x_i - \mu)^T\Lambda^{-1}(x_i - \mu)\right]\\
&amp;= \left(\frac{|\Lambda|^{-\frac{1}{2}}}{(2\pi)^{\frac{p}{2}}}\right)^n 
exp\left[-\frac{1}{2}tr(\Lambda^{-1} \Sigma)\right]
\end{align}\]</span>
</p>
<p>It helps to be aware of the following mathematical manipulation (derivation not included):</p>

<p><span class="math display">\[\begin{align}
\sum_{i=1}^n (x_i - \mu)^T\Lambda^{-1}(x_i - \mu) = tr( \Lambda^{-1} \Sigma)\ \ \ \ \  where\ \ \ \Sigma = \sum_{i=1}^n (x_i - \mu)(x_i - \mu)^T
\end{align}\]</span>
</p>
<p>For <strong>prior</strong>, we choose an <strong>Inverse Wishart</strong> distribution for the <span class="math inline">\(\Lambda\)</span> parameter:</p>

<p><span class="math display">\[\begin{align}
\Lambda \sim IW_p(v_0, \Sigma_0)\ \ \ \ \ \text{where}\ v_0\ and\ \Sigma_0 \text{ are known } \mathbf{hyperparameters}
\end{align}\]</span></p>
<p><span class="math display">\[\begin{align}
\mathcal{\pi}(\Lambda) = P(\Lambda; \nu_0, \Sigma_0) 
    =  \frac{ |\Lambda|^{-\frac{\nu_0 +p+1}{2}}  exp\left[-\frac{1}{2}tr(\Lambda^{-1}\Sigma_0)\right]}
    {2^{\frac{\nu_0 p}{2}}|\Sigma_0|^{-\frac{\nu_0}{2}}\ \Gamma_p\left(\frac{\nu_0}{2}\right)}
\end{align}\]</span>
</p>
<p>Recall description of <strong>Inverse Wishart</strong> notation in Chapter <strong>5</strong> (<strong>Numerical Probability and Distribution</strong>) under <strong>Wishart Distribution</strong> Section.</p>
<p>For <strong>posterior</strong>, we want to arrive at an <strong>Inverse Wishart density</strong> given an observed data:</p>

<p><span class="math display">\[\begin{align}
\Lambda|x \sim \ \mathcal{W}^{-1}_p(v_1,\Sigma_1)
\end{align}\]</span>
</p>
<p>However, let us first derive the <strong>posterior density</strong> with respect to <span class="math inline">\(\Lambda\)</span> by dropping the constants that do not affect the shape or proportionality of the distribution (e.g., expressed by the exponents).</p>
<p>For an <strong>Inverse Wishart posterior</strong> with <strong>joint-density</strong> likelihood:</p>

<p><span class="math display">\[\begin{align}
\mathcal{W}(\Lambda|x_{1:n}) {}&amp;\propto  \underbrace{  \frac{ |\Lambda|^{-\frac{\nu_0 +p+1}{2}}  exp\left[-\frac{1}{2}tr(\Lambda^{-1}\Sigma_0)\right]}
    {2^{\frac{\nu_0 p}{2}}|\Sigma_0|^{-\frac{\nu_0}{2}}\ \Gamma_p\left(\frac{\nu_0}{2}\right)} }_\text{wishart prior} \times 
\underbrace{  \left(\frac{|\Lambda|^{\frac{1}{2}}}{\sqrt{2\pi}}\right)^n exp\left[\Lambda^{-1}\Sigma  \right]}_\text{normal likelihood} \\
\rightarrow  &amp;\text{(drop constants)} \nonumber \\
&amp;\propto |\Lambda|^{-\frac{(\nu_0+n)+p+1}{2}}  exp\left[-\frac{1}{2}tr(\Lambda^{-1}\Sigma_0)\right] \times   exp\left[\Lambda^{-1} \Sigma \right] \\
&amp;\propto |\Lambda|^{-\frac{(\nu_0+n)+ p + 1}{2}} exp\left[-\frac{1}{2}  tr\left( \Lambda^{-1}\Sigma_0 + \Sigma^{-1}  \Sigma \right) \right] \\
&amp;\propto |\Lambda|^{-\frac{(\nu_0+n) + p+1}{2}} exp\left[-\frac{1}{2}  tr\left( \Lambda^{-1} ( \Sigma_0 +  \Sigma)\right)  \right] 
\end{align}\]</span>
</p>
<p>Notice that given an <strong>Inverse Wishart posterior</strong> distribution, it becomes apparent that the parameters <span class="math inline">\(v_1\)</span> and <span class="math inline">\(\Sigma_1\)</span> correspond to the following:</p>

<p><span class="math display">\[\begin{align}
\Sigma_1 = (\Sigma_0 + \Sigma)^{-1}\ \ \ \ \ \ \ \
\nu_1 = \nu_0 + n 
\end{align}\]</span>
</p>
<p>Therefore, we arrive at the following reparameterized <strong>posterior distribution</strong>:</p>

<p><span class="math display">\[\begin{align}
\Lambda|x_1,...,x_n \sim \ \mathcal{IW}_p(\nu_1,\Sigma_1)\ \ \ \rightarrow \mathcal{W}^{-1}_p(\nu_0 + n\ ,\ (\Sigma_0 + \Sigma)^{-1})
\end{align}\]</span>
</p>
<p>For <strong>MAP</strong> we can use the following equation:</p>

<p><span class="math display">\[\begin{align}
\Lambda_{(map)} = \frac{\Lambda_1}{\nu_1 + p + 1}
\end{align}\]</span>
</p>
</div>
<div id="normal-lkj-conjugacy" class="section level3 hasAnchor">
<h3><span class="header-section-number">7.4.8</span> Normal-LKJ Conjugacy <a href="bayesian.html#normal-lkj-conjugacy" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The idea is to be able to tailor an <strong>LKJ</strong> distribution for <strong>posterior</strong>.</p>
<p>We leave readers to investigate this conjugacy as a modern alternative to the <strong>normal Wishart</strong> conjugacy. While <strong>normal Wishart conjugacy</strong> operates on the covariance of <strong>MVN</strong>, <strong>normal LKJ conjugacy</strong> operates on correlation.</p>
</div>
<div id="binomial-beta-conjugacy" class="section level3 hasAnchor">
<h3><span class="header-section-number">7.4.9</span> Binomial-Beta Conjugacy <a href="bayesian.html#binomial-beta-conjugacy" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The idea is to be able to tailor a <strong>Beta density</strong> distribution for <strong>posterior</strong> given that <strong>Beta density</strong> is <strong>conjugate prior</strong> for a <strong>Binomial likelihood</strong>. For a notation, let us use the following:</p>

<p><span class="math display">\[\begin{align}
P(\rho|x) \propto P(\rho) \times Lik(n,\rho|x)
\ \ \ \ \ \ \text{for } 0 \le \rho\ \le 1 
\end{align}\]</span>
</p>
<p>For <strong>likelihood</strong>, we have the following distribution:</p>

<p><span class="math display">\[\begin{align}
x|n,\rho \sim Binom(n,\rho)
\end{align}\]</span>
</p>
<p>For <strong>marginal</strong> (Bernoulli) likelihood:</p>

<p><span class="math display">\[\begin{align}
Lik_X(n,\rho|x) \equiv P(X=x|n,\rho) = \binom{n}{x}\rho^x(1 - \rho)^{n-x}
\end{align}\]</span>
</p>
<p>For <strong>joint</strong> (Binomial) likelihood:</p>

<p><span class="math display">\[\begin{align}
Lik_X(n_1,...,n_m,\rho|x_1,...,x_m) \equiv P_X(x_1,...,x_m|n_1,...,n_m,\rho) = \prod_{i=1}^m \binom{n_i}{x_i}\rho^{x_i}(1 - \rho)^{n_i - x_i}
\end{align}\]</span>
</p>
<p>For <strong>prior</strong>, we choose a <strong>Beta</strong> distribution for the <span class="math inline">\(\rho\)</span> parameter:</p>

<p><span class="math display">\[\begin{align}
\rho \sim Beta(\alpha_0,\beta_0)\ \ \ \ \ \text{where}\ \alpha_0\ \text{and}\ \beta_0 \text{ are known } \mathbf{hyperparameters}
\end{align}\]</span></p>
<p><span class="math display">\[\begin{align}
\mathcal{\pi}(\rho) = P(\rho; \alpha_0, \beta_0) = \frac{1}{\mathcal{B}(\alpha_0,\beta_0)}\rho^{\alpha_0-1}(1 - \rho)^{\beta_0 - 1}
\end{align}\]</span>
</p>
<p>For <strong>posterior</strong>, we want to arrive at a <strong>Beta density</strong> given an observed data:</p>

<p><span class="math display">\[\begin{align}
\rho|x \sim Beta(\alpha_1,\beta_1) 
\end{align}\]</span>
</p>
<p>However, let us first derive the <strong>posterior density</strong> with respect to <span class="math inline">\(\rho\)</span> by dropping the constants that do not affect the shape or proportionality of the distribution.</p>
<p>For a <strong>Beta posterior</strong> with <strong>marginal</strong> (Bernoulli) likelihood:</p>

<p><span class="math display">\[\begin{align}
P(\rho|x)  {}&amp;\propto  
\underbrace{ \frac{1}{\mathcal{B}(\alpha_0,\beta_0)}\rho^{\alpha_0-1}(1 - \rho)^{\beta_0 - 1}}_\text{beta prior} \times
\underbrace{ \binom{n}{x}\rho^x(1 - \rho)^{n-x} }_\text{binomial likelihood} \\
\rightarrow  &amp;\text{(drop constants)} \nonumber \\
P(\rho|x)  &amp;\propto \left(\rho^{\alpha_0-1}(1 - \rho)^{\beta_0 - 1} \right) \times  \left( \rho^x(1 - \rho)^{n-x} \right) \\
&amp;\propto \left(\rho^{(\alpha_0 + x) - 1}(1 - \rho)^{(\beta_0 + n - x) - 1} \right) 
\end{align}\]</span>
</p>
<p>Notice that given a <strong>Beta posterior</strong> distribution, it becomes apparent that the parameters <span class="math inline">\(\alpha_1\)</span> and <span class="math inline">\(\beta_1\)</span> correspond to the following:</p>

<p><span class="math display">\[\begin{align}
\alpha_1 = \alpha_0 + x
\ \ \ \ \ \ \ \ \ \ \ \ \ \
\beta_1 = \beta_0 + (n - x)
\end{align}\]</span>
</p>
<p>Therefore, we arrive at the following reparameterized <strong>posterior distribution</strong>:</p>

<p><span class="math display">\[\begin{align}
\rho|x \sim Beta(\alpha_1, \beta_1)\ \ \ \rightarrow Beta(\alpha_0 + x,\ \beta_0 + (n - x))
\end{align}\]</span>
</p>
<p>For a <strong>Beta posterior</strong> with <strong>joint</strong> (Binomial) likelihood:</p>

<p><span class="math display">\[\begin{align}
P(n_{1:m},\rho|x_1,...,x_m)  {}&amp;\propto  
\underbrace{ \frac{1}{\mathcal{B}(\alpha_0,\beta_0)}\rho^{\alpha_0-1}(1 - \rho)^{\beta_0 - 1} 
 }_\text{beta prior} \times
\underbrace{ \prod_{i=1}^m  \binom{n_i}{x_i}\rho^{x_i}(1 - \rho)^{n-x_i} }_\text{binomial likelihood} \\
\rightarrow &amp; \text{(drop constants)} \nonumber \\
P(n_{1:m},\rho|x_1,...,x_m)  &amp;\propto \left(\rho^{\alpha_0-1}(1 - \rho)^{\beta_0 - 1} \right) \times  \left( \rho^{\sum_{i=1}^m x_i}(1 - \rho)^{\sum_{i=1}^m n_i-\sum_{i=1}^m x_i} \right) \\
&amp;\propto \left(\rho^{(\sum_{i=1}^m x_i + \alpha_0) - 1}(1 - \rho)^{(\sum_{i=1}^m n_i + \beta_0 - \sum_{i=1}^m x_i) - 1} \right) \\
&amp;\propto \left(\rho^{(\alpha_0 + m \bar{x} ) - 1}(1 - \rho)^{( \beta_0 + ( m \bar{n} - m \bar{x})) - 1} \right) 
\end{align}\]</span>
</p>
<p>Notice that given a <strong>Beta posterior</strong> distribution, it becomes apparent that the parameters <span class="math inline">\(\alpha_1\)</span> and <span class="math inline">\(\beta_1\)</span> correspond to the following:</p>

<p><span class="math display">\[\begin{align}
\alpha_1 = \alpha_0 + m \bar{x} 
\ \ \ \ \ \ \ \ \ \ \ \ \ \
\beta_1 = \beta_0 + ( m \bar{n} - m \bar{x})
\end{align}\]</span>
</p>
<p>Therefore, we arrive at the following reparameterized <strong>posterior distribution</strong>:</p>

<p><span class="math display">\[\begin{align}
\rho|x_1,...,x_n \sim Beta(\alpha_1, \beta_1)\ \ \ \rightarrow Beta(\alpha_0 + m \bar{x},\ \beta_0 + ( m \bar{n} - m \bar{x}))
\end{align}\]</span>
</p>
</div>
<div id="geometric-beta-conjugacy" class="section level3 hasAnchor">
<h3><span class="header-section-number">7.4.10</span> Geometric-Beta Conjugacy <a href="bayesian.html#geometric-beta-conjugacy" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The idea is to be able to tailor a <strong>Beta density</strong> distribution for <strong>posterior</strong> given that <strong>Beta density</strong> is <strong>conjugate prior</strong> for a <strong>Geometric likelihood</strong>. For a notation, let us use the following:</p>

<p><span class="math display">\[\begin{align}
P(\rho|x) \propto P(\rho) \times Lik(\rho|x) 
\end{align}\]</span>
</p>
<p>For <strong>likelihood</strong>, we have the following distribution:</p>

<p><span class="math display">\[\begin{align}
x|\rho \sim Geo(\rho)
\end{align}\]</span>
</p>
<p>For <strong>marginal-density</strong> likelihood:</p>

<p><span class="math display">\[\begin{align}
Lik_X(\rho|x) \equiv P(X=x|\rho) = \rho(1 - \rho)^{x - 1}
\end{align}\]</span>
</p>
<p>For <strong>joint-density</strong> likelihood:</p>

<p><span class="math display">\[\begin{align}
Lik_X(\rho|x_1,...,x_n) \equiv P_X(x_1,...,x_n|\rho) = \prod_{i=1}^n \rho(1 - \rho)^{x - 1}
\end{align}\]</span>
</p>
<p>For <strong>prior</strong>, we choose a <strong>Beta</strong> distribution for the <span class="math inline">\(\rho\)</span> parameter:</p>

<p><span class="math display">\[\begin{align}
\rho \sim Beta(\alpha_0,\beta_0)\ \ \ \ \ \text{where}\ \alpha_0\ \text{and}\ \beta_0 \text{ are known } \mathbf{hyperparameters}
\end{align}\]</span></p>
<p><span class="math display">\[\begin{align}
\mathcal{\pi}(\rho)  = P(\rho; \alpha_0, \beta_0) = \frac{1}{\mathcal{B}(\alpha_0,\beta_0)}\rho^{\alpha_0-1}(1 - \rho)^{\beta_0 - 1}
\end{align}\]</span>
</p>
<p>For <strong>posterior</strong>, we want to arrive at a <strong>Beta density</strong> given an observed data:</p>

<p><span class="math display">\[\begin{align}
\rho|x \sim Beta(\alpha_1,\beta_1) 
\end{align}\]</span>
</p>
<p>However, let us first derive the <strong>posterior density</strong> with respect to <span class="math inline">\(\rho\)</span> by dropping the constants that do not affect the shape or proportionality of the distribution.</p>
<p>For a <strong>Beta posterior</strong> with <strong>marginal-density</strong> likelihood:</p>

<p><span class="math display">\[\begin{align}
P(\rho|x)  {}&amp;\propto  
\underbrace{ \frac{1}{\mathcal{B}(\alpha_0,\beta_0)}\rho^{\alpha_0-1}(1 - \rho)^{\beta_0 - 1}}_\text{beta prior} \times \underbrace{ \rho(1 - \rho)^{x - 1} }_\text{geometric likelihood} \\
\rightarrow &amp; \text{(drop constants)} \nonumber \\
P(\rho|x)  &amp;\propto \left(\rho^{\alpha_0-1}(1 - \rho)^{\beta_0 - 1} \right) \times  \left( \rho (1 - \rho)^{x - 1} \right) \\
&amp;\propto \left(\rho^{(1 + \alpha_0) - 1}(1 - \rho)^{(x + \beta_0 - 1) - 1} \right) 
\end{align}\]</span>
</p>
<p>Notice that given a <strong>Beta posterior</strong> distribution, it becomes apparent that the parameters <span class="math inline">\(\alpha_1\)</span> and <span class="math inline">\(\beta_1\)</span> correspond to the following:</p>

<p><span class="math display">\[\begin{align}
\alpha_1 = 1 + \alpha_0
\ \ \ \ \ \ \ \ \ \ \ \ \ \
\beta_1 = x + \beta_0  - 1
\end{align}\]</span>
</p>
<p>Therefore, we arrive at the following reparameterized <strong>posterior distribution</strong>:</p>

<p><span class="math display">\[\begin{align}
\rho|x \sim Beta(\alpha_1, \beta_1)\ \ \ \rightarrow Beta(1 + \alpha_0,\ x + \beta_0 - 1 )
\end{align}\]</span>
</p>
<p>For a <strong>Beta posterior</strong> with <strong>joint-density</strong> likelihood:</p>

<p><span class="math display">\[\begin{align}
P(\rho|x_1,...,x_n)  {}&amp;\propto  
\underbrace{ \frac{1}{\mathcal{B}(\alpha_0,\beta_0)}\rho^{\alpha_0-1}(1 - \rho)^{\beta_0 - 1}}_\text{beta prior} \times \underbrace{ \prod_{i=1}^n \rho(1 - \rho)^{x_i - 1}}_\text{geometric likelihood} \\
\rightarrow &amp; \text{(drop constants)} \nonumber \\
P(\rho|x_1,...,x_n)  &amp;\propto \left(\rho^{\alpha_0-1}(1 - \rho)^{\beta_0 - 1} \right) \times  \left( \rho^n(1 - \rho)^{\sum_{i=1}^n x_i - n} \right) \\
&amp;\propto \left(\rho^{(n + \alpha_0) - 1}(1 - \rho)^{(\sum_{i=1}^n x_i + \beta_0 - n ) - 1} \right) \\
&amp;\propto \left(\rho^{(n + \alpha_0) - 1}(1 - \rho)^{(n \bar{x} + \beta_0 - n) - 1} \right) 
\end{align}\]</span>
</p>
<p>Notice that given a <strong>Beta posterior</strong> distribution, it becomes apparent that the parameters <span class="math inline">\(\alpha_1\)</span> and <span class="math inline">\(\beta_1\)</span> correspond to the following:</p>
<p><span class="math display">\[\begin{align}
\alpha_1 = n + \alpha_0
\ \ \ \ \ \ \ \ \ \ \ \ \ \
\beta_1 = n \bar{x} + \beta_0 - n
\end{align}\]</span></p>
<p>Therefore, we arrive at the following reparameterized <strong>posterior distribution</strong>:</p>

<p><span class="math display">\[\begin{align}
\rho|x_1,...,x_n \sim Beta(\alpha_1, \beta_1)\ \ \ \rightarrow Beta(n + \alpha_0,\ n \bar{x} + \beta_0 - n)
\end{align}\]</span>
</p>
</div>
<div id="poisson-gamma-conjugacy" class="section level3 hasAnchor">
<h3><span class="header-section-number">7.4.11</span> Poisson-Gamma Conjugacy <a href="bayesian.html#poisson-gamma-conjugacy" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The idea is to be able to tailor a <strong>Gamma density</strong> distribution for <strong>posterior</strong> given that <strong>Gamma density</strong> is <strong>conjugate prior</strong> for a <strong>Poisson likelihood</strong>. For a notation, let us use the following:</p>

<p><span class="math display">\[\begin{align}
P(\lambda|x) \propto P(\lambda) \times Lik(\lambda|x) 
\end{align}\]</span>
</p>
<p>For <strong>likelihood</strong>, we have the following distribution:</p>

<p><span class="math display">\[\begin{align}
x|\lambda \sim Pois(\lambda)
\end{align}\]</span>
</p>
<p>For <strong>marginal-density</strong> likelihood:</p>

<p><span class="math display">\[\begin{align}
Lik_X(\lambda|x) \equiv P(X=x|\lambda) = \frac{1}{x!} \lambda^x e^{-\lambda}
\end{align}\]</span>
</p>
<p>For <strong>joint-density</strong> likelihood:</p>

<p><span class="math display">\[\begin{align}
Lik_X(\lambda|x_1,...,x_n) \equiv P_X(x_1,...,x_n|\lambda) = \prod_{i=1}^n \frac{1}{x!} \lambda^x e^{-\lambda}
\end{align}\]</span>
</p>
<p>For <strong>prior</strong>, we choose a <strong>Gamma</strong> distribution for the <span class="math inline">\(\lambda\)</span> parameter:</p>

<p><span class="math display">\[\begin{align}
\lambda \sim Gamma(\alpha_0,\beta_0)\ \ \ \ \ \text{where}\ \alpha_0\ \text{and}\ \beta_0 \text{ are known } \mathbf{hyperparameters}
\end{align}\]</span></p>
<p><span class="math display">\[\begin{align}
\mathcal{\pi}(\lambda) = 
P(\lambda; \alpha_0, \beta_0) = \frac{1}{\beta_0^{\alpha_0} \Gamma(\alpha_0)} \lambda^{\alpha_0-1} e^ {-\frac{\lambda}{\beta_0}} = 
\frac{\beta^{\alpha_0}}{\Gamma(\alpha_0)}\lambda^{\alpha_0-1}e^{-\beta_0 \lambda}
\end{align}\]</span>
</p>
<p>For a <strong>posterior</strong>, we want to arrive at a <strong>Gamma density</strong> given an observed data:</p>

<p><span class="math display">\[\begin{align}
\lambda|x \sim Gamma(\alpha_1, \beta_1) 
\end{align}\]</span>
</p>
<p>However, let us first derive the <strong>posterior density</strong> with respect to <span class="math inline">\(\lambda\)</span> by dropping the constants that do not affect the shape or proportionality of the distribution.</p>
<p>For a <strong>Gamma posterior</strong> with <strong>marginal</strong> (Bernoulli) likelihood:</p>

<p><span class="math display">\[\begin{align}
P(\lambda|x)  {}&amp;\propto  
\underbrace{ \left(\frac{\beta_0^{\alpha_0}}{ \Gamma(\alpha_0)}\right)
\lambda^{\alpha_0-1} e^ {-\beta_0 \lambda} }_\text{gamma prior} \times
\underbrace{ \left(\frac{1}{x!}\right) \lambda^x e^{-\lambda} }_\text{poisson likelihood} \\
\rightarrow  &amp;\text{(drop constants)} \nonumber \\
P(\lambda|x)  &amp;\propto \left( \lambda^{\alpha_0-1} e^ {-\beta_0 \lambda}\right) \times \left( \lambda^x e^{-\lambda} \right) \\
&amp;\propto \left(\lambda^{x + \alpha_0-1} e^ {-\lambda - \beta_0 \lambda} \right) \\
&amp;\propto \left(\lambda^{(x + \alpha_0)-1} e^ {-(1 + \beta_0) \lambda} \right) 
\end{align}\]</span>
</p>
<p>Notice that given a <strong>Gamma posterior</strong> distribution, it becomes apparent that the parameters <span class="math inline">\(\alpha_1\)</span> and <span class="math inline">\(\beta_1\)</span> correspond to the following:</p>
<p><span class="math display">\[\begin{align}
\alpha_1 = x + \alpha_0
\ \ \ \ \ \ \ \ \ \ \ \ \ \
\beta_1 = 1 + \beta_0
\end{align}\]</span></p>
<p>Therefore, we arrive at the following reparameterized <strong>posterior distribution</strong>:</p>

<p><span class="math display">\[\begin{align}
\lambda|x \sim Gamma(\alpha_1, \beta_1)\ \ \ \rightarrow Gamma(x + \alpha_0, 1 + \beta_0)
\end{align}\]</span>
</p>
<p>For a <strong>Gamma posterior</strong> with <strong>joint</strong> (Binomial) likelihood:</p>

<p><span class="math display">\[\begin{align}
P(\lambda|x)  {}&amp;\propto  
\underbrace{ \left(\frac{\beta_0^{\alpha_0}}{ \Gamma(\alpha_0)}\right)
\lambda^{\alpha_0-1} e^ {-\beta_0 \lambda}}_\text{gamma prior}  \times
\underbrace{ \prod_{i=1}^n \left(\frac{1}{x_i!}\right) \lambda^{x_i} e^{-\lambda} }_\text{poisson likelihood}\\
\rightarrow &amp; \text{(drop constants)} \nonumber \\
P(\lambda|x)  &amp;\propto \left( \lambda^{\alpha_0-1} e^ {- \beta_0 \lambda}\right) \times \left( \lambda^{n \bar{x}} e^{-n \lambda} \right),\ \ \ \ \ n \bar{x} = \sum_{i=1}^n x_i \\
&amp;\propto \left( \lambda^{(n \bar{x} +\alpha_0)-1} e^ {-(n + \beta_0) \lambda}\right)
\end{align}\]</span>
</p>
<p>Notice that given a <strong>Gamma posterior</strong> distribution, it becomes apparent that the parameters <span class="math inline">\(\alpha_1\)</span> and <span class="math inline">\(\beta_1\)</span> correspond to the following:</p>
<p><span class="math display">\[\begin{align}
\alpha_1 = n \bar{x} + \alpha_0
\ \ \ \ \ \ \ \ \ \ \ \ \ \
\beta_1 = n + \beta_0
\end{align}\]</span></p>
<p>Therefore, we arrive at the following reparameterized <strong>posterior distribution</strong>:</p>

<p><span class="math display">\[\begin{align}
\lambda|x_1,...,x_n \sim Gamma(\alpha_1, \beta_1)\ \ \ \rightarrow Gamma(n \bar{x} + \alpha_0, n + \beta_0)
\end{align}\]</span>
</p>
</div>
<div id="exponential-gamma-conjugacy" class="section level3 hasAnchor">
<h3><span class="header-section-number">7.4.12</span> Exponential-Gamma Conjugacy <a href="bayesian.html#exponential-gamma-conjugacy" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The idea is to be able to tailor a <strong>Gamma density</strong> distribution for <strong>posterior</strong> given that <strong>Gamma density</strong> is <strong>conjugate prior</strong> for an <strong>Exponential likelihood</strong>. For a notation, let us use the following:</p>

<p><span class="math display">\[\begin{align}
P(\lambda|x) \propto P(\lambda) \times Lik(\lambda|x) 
\end{align}\]</span>
</p>
<p>For <strong>likelihood</strong>, we have the following distribution:</p>

<p><span class="math display">\[\begin{align}
x|\lambda \sim Expo(\lambda)
\end{align}\]</span>
</p>
<p>For <strong>marginal-density</strong> likelihood:</p>

<p><span class="math display">\[\begin{align}
Lik_X(\lambda|x) \equiv P(X=x|\lambda) = \lambda e^{-\lambda x}
\end{align}\]</span>
</p>
<p>For <strong>joint-density</strong> likelihood:</p>

<p><span class="math display">\[\begin{align}
Lik_X(\lambda|x_1,...,x_n) \equiv P_X(x_1,...,x_n|\lambda) = \prod_{i=1}^n \lambda e^{-\lambda x}
\end{align}\]</span>
</p>
<p>For <strong>prior</strong>, we choose a <strong>Gamma</strong> distribution for the <span class="math inline">\(\lambda\)</span> parameter:</p>

<p><span class="math display">\[\begin{align}
\lambda \sim Gamma(\alpha_0,\beta_0)\ \ \ \ \ \text{where}\ \alpha_0\ \text{and}\ \beta_0 \text{ are known } \mathbf{hyperparameters}
\end{align}\]</span></p>
<p><span class="math display">\[\begin{align}
\mathcal{\pi}(\lambda) = P(\lambda; \alpha_0, \beta_0) = \frac{1}{\beta_0^{\alpha_0} \Gamma(\alpha_0)} \lambda^{\alpha_0-1} e^ {-\frac{\lambda}{\beta_0}} = 
\frac{\beta^{\alpha_0}}{\Gamma(\alpha_0)}\lambda^{\alpha_0-1}e^{-\beta_0 \lambda}
\end{align}\]</span>
</p>
<p>For a <strong>posterior</strong>, we want to arrive at a <strong>Gamma density</strong> given an observed data:</p>

<p><span class="math display">\[\begin{align}
\lambda|x \sim Gamma(\alpha_1, \beta_1) 
\end{align}\]</span>
</p>
<p>However, let us first derive the <strong>posterior density</strong> with respect to <span class="math inline">\(\lambda\)</span> by dropping the constants that do not affect the shape or proportionality of the distribution.</p>
<p>For a <strong>Gamma posterior</strong> with <strong>marginal-density</strong> likelihood:</p>

<p><span class="math display">\[\begin{align}
P(\lambda|x)  {}&amp;\propto  
\underbrace{ \left(\frac{\beta_0^{\alpha_0}}{ \Gamma(\alpha_0)}\right)
\lambda^{\alpha_0-1} e^ {-\beta_0 \lambda}}_\text{gamma prior} \times
\underbrace{ \lambda  e^{-\lambda x} }_\text{exponential likelihood}\\
\rightarrow &amp; \text{(drop constants)} \nonumber \\
P(\lambda|x)  &amp;\propto \left( \lambda^{\alpha_0-1} e^ {-\beta_0 \lambda}\right) \times \left( \lambda  e^{-\lambda x} \right) \\
&amp;\propto \left(\lambda^{(1 + \alpha_0) - 1} e^ {-(1 + \beta_0) \lambda} \right) 
\end{align}\]</span>
</p>
<p>Notice that given a <strong>Gamma posterior</strong> distribution, it becomes apparent that the parameters <span class="math inline">\(\alpha_1\)</span> and <span class="math inline">\(\beta_1\)</span> correspond to the following:</p>
<p><span class="math display">\[\begin{align}
\alpha_1 = 1 + \alpha_0
\ \ \ \ \ \ \ \ \ \ \ \ \ \
\beta_1 = 1 + \beta_0
\end{align}\]</span></p>
<p>Therefore, we arrive at the following reparameterized <strong>posterior distribution</strong>:</p>

<p><span class="math display">\[\begin{align}
\lambda|x \sim Gamma(\alpha_1, \beta_1)\ \ \ \rightarrow Gamma(1 + \alpha_0, 1 + \beta_0)
\end{align}\]</span>
</p>
<p>For a <strong>Gamma posterior</strong> with <strong>joint-density</strong> likelihood:</p>

<p><span class="math display">\[\begin{align}
P(\lambda|x)  {}&amp;\propto  
\underbrace{ \left(\frac{\beta_0^{\alpha_0}}{ \Gamma(\alpha_0)}\right)
\lambda^{\alpha_0-1} e^ {-\beta_0 \lambda} }_\text{gamma prior} \times
\underbrace{ \prod_{i=1}^n \lambda e^{-\lambda x_i}}_\text{exponential likelihood} \\
\rightarrow &amp;\text{(drop constants)} \nonumber \\
P(\lambda|x)  &amp;\propto \left( \lambda^{\alpha_0-1} e^ {- \beta_0 \lambda}\right) \times \left( \lambda^{n}  e^{-\lambda n \bar{x}} \right),\ \ \ \ \ n \bar{x} = \sum_{i=1}^n x_i \\
&amp;\propto \left( \lambda^{(n  +\alpha_0)-1} e^ {-(n \bar{x} + \beta_0) \lambda}\right)
\end{align}\]</span>
</p>
<p>Notice that given a <strong>Gamma posterior</strong> distribution, it becomes apparent that the parameters <span class="math inline">\(\alpha_1\)</span> and <span class="math inline">\(\beta_1\)</span> correspond to the following:</p>
<p><span class="math display">\[\begin{align}
\alpha_1 = n  + \alpha_0
\ \ \ \ \ \ \ \ \ \ \ \ \ \
\beta_1 = n \bar{x} + \beta_0
\end{align}\]</span></p>
<p>Therefore, we arrive at the following reparameterized <strong>posterior distribution</strong>:</p>

<p><span class="math display">\[\begin{align}
\lambda|x_1,...,x_n \sim Gamma(\alpha_1, \beta_1)\ \ \ \rightarrow Gamma(n  + \alpha_0, n \bar{x}+ \beta_0)
\end{align}\]</span>
</p>
</div>
<div id="multinomial-dirichlet-conjugacy" class="section level3 hasAnchor">
<h3><span class="header-section-number">7.4.13</span> Multinomial-Dirichlet Conjugacy <a href="bayesian.html#multinomial-dirichlet-conjugacy" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The idea is to be able to tailor a <strong>Dirichlet density</strong> distribution for <strong>posterior</strong> given that <strong>Dirichlet density</strong> is <strong>conjugate prior</strong> for a <strong>Multinomial (or Categorical) likelihood</strong>. For a notation, let us use the following:</p>

<p><span class="math display">\[\begin{align}
P(\rho|x) \propto P(\rho) \times Lik(n, \rho|x) 
\end{align}\]</span>
</p>
<p>For <strong>likelihood</strong>, we have the following distribution:</p>

<p><span class="math display">\[\begin{align}
x|\rho\sim Multi(n,\rho)
\end{align}\]</span></p>
<p><span class="math display">\[\begin{align}
Lik_{X_{1:k}}(n, \rho|x_1,...,x_k)  \equiv P_{X_{1:k}}(x_1,...,x_k|n, \rho) {}&amp;= 
\frac{n!}{x_1! \times ... \times x_k!} 
 \rho_1^{x_1} \times ... \times \rho_k^{x_k}\\
&amp;= \frac{n!}{\prod_{i=1}^k x_i!} \prod_{i=1}^k \rho_i^{x_i}
\end{align}\]</span>
</p>
<p>For <strong>prior</strong>, we choose a <strong>Dirichlet</strong> distribution for the <span class="math inline">\(\lambda\)</span> parameter:</p>

<p><span class="math display">\[\begin{align}
\rho \sim Dir(\alpha_{0_{1:k}})\ \ \ \ \ \text{where}\ \alpha_{0_{1:k}}\ \text{ are known } \mathbf{hyperparameters} 
\end{align}\]</span></p>
<p><span class="math display">\[\begin{align}
\mathcal{\pi}(\rho) = P(\rho; \alpha_{0_{1:k}}) = \frac{1}{\mathcal{B}(\alpha_{0_{1:k}})} \prod_{i=1}^k \rho_i^{\alpha_{0_i}-1},\ \ \ \ \ where\ \alpha_{0_{1:k}} = (\alpha_{0_1},...,\alpha_{0_k})
\end{align}\]</span>
</p>
<p>and where:</p>

<p><span class="math display">\[\begin{align}
\mathcal{B}(\alpha_{0_{1:k}}) = 
\frac{\Gamma(\alpha_{0_1})\times ...\times \Gamma(\alpha_{0_k})}{\Gamma(\alpha_{0_1} + ... + \alpha_{0_k})}
\end{align}\]</span>
</p>
<p>For a <strong>posterior</strong>, we want to arrive at a <strong>Dirichlet density</strong> given an observed data:</p>

<p><span class="math display">\[\begin{align}
\rho|x_1,...,x_k \sim Dir(\alpha_{1_{1:k}}),\ \ \ \ \ where\ \alpha_{1_{1:k}} = (\alpha_{1_1},...,\alpha_{1_k})
\end{align}\]</span>
</p>
<p>However, let us first derive the <strong>posterior density</strong> with respect to <span class="math inline">\(\rho\)</span> by dropping the constants that do not affect the shape or proportionality of the distribution.</p>

<p><span class="math display">\[\begin{align}
P(\rho|x_1,...,x_k)  {}&amp;\propto 
\underbrace { \frac{1}{\mathcal{B}(\alpha_0)} \prod_{i=1}^k \rho_i^{\alpha_{0_i}-1} }_\text{dirichlet prior} \times
\underbrace{ \frac{n!}{\prod_{i=1}^k x_i!} \prod_{i=1}^k \rho_i^{x_i} }_\text{multinomial likelihood}\\
\rightarrow &amp;\text{(drop constants)} \nonumber \\
P(\rho|x_1,...,x_k)  &amp;\propto 
\left( \prod_{i=1}^k \rho_i^{\alpha_{0_i}-1}  \right) \times 
\left( \prod_{i=1}^k \rho_i^{x_i} \right) \\
&amp;\propto \left( \prod_{i=1}^k \rho_i^{(x_i + \alpha_{0_i}) - 1}\right) 
\end{align}\]</span>
</p>
<p>Notice that given a <strong>Dirichlet posterior</strong> distribution, it becomes apparent that the parameters <span class="math inline">\(\rho_1\)</span> corresponds to the following:</p>

<p><span class="math display">\[\begin{align}
\alpha_{1_{1:k}} = \sum_{i=1}^k (x_i + \alpha_{0_i})
\end{align}\]</span>
</p>
<p>Therefore, we arrive at the following reparameterized <strong>posterior distribution</strong>:</p>

<p><span class="math display">\[\begin{align}
\rho|x_1,...,x_k \sim Dir(\alpha_{1_{1:k}})\ \ \ \rightarrow Dir(\sum_{i=1}^k (x_i + \alpha_{0_i}))
\end{align}\]</span>
</p>
<p>Application of this conjugacy becomes apparent in <strong>Variational Bayes</strong> section.</p>
</div>
<div id="hyperparameters" class="section level3 hasAnchor">
<h3><span class="header-section-number">7.4.14</span> Hyperparameters <a href="bayesian.html#hyperparameters" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A <strong>proper prior</strong> is as essentially fitting as the chosen quantities of its <strong>hyperparameters</strong>. Depending on its <strong>hyperparameters</strong>, a <strong>prior</strong> may stretch within the spectrum of being <strong>weakly informed</strong> and <strong>well informed</strong>.</p>
<p>The idea that a <strong>prior</strong> does not have information may be contested because there is always truly information about a <strong>prior</strong>. Therefore, we can say that <strong>non-informative prior</strong> is a misnomer. From that perspective, we also use <strong>weakly informative prior</strong>. Morever, we can use other terms such as <strong>vague prior</strong>, <strong>objective prior</strong>, <strong>imprecise prior</strong>, and <strong>insufficient prior</strong>.</p>
<p>One way to complement and at the same time improve our <strong>weakly informative prior knowledge</strong> is to keep accumulating evidence and to keep seeking prior knowledge from domain experts.</p>
<p>Consequently, our goal is to achieve a <strong>well-behaved proper</strong> posterior. However, with only an initial piece of evidence to use on hand and minimal expert knowledge, we can use a <strong>uniform or flat</strong> prior instead. A <strong>uniform prior</strong> is improper in that it integrates infinitely; however, it leads to a proper posterior when combined with <strong>likelihood</strong>.</p>
<p>An example set of hyperparameter quantities used for <strong>Normal</strong> flat prior is:</p>
<p><span class="math display">\[\begin{align}
\mu \sim U(a = 0, b = 1) = Beta(\alpha_0 = 1, \beta_0  = 1)\ \ \text{(weakly-informed prior)}
\end{align}\]</span></p>
<p>An example set of hyperparameter quantities used for <strong>Beta</strong> flat prior is:</p>
<p><span class="math display">\[\begin{align}
\rho \sim Beta\left(\alpha_0 = \frac{1}{2}, \beta_0 = \frac{1}{2}\right)\ \ \text{(weakly-informed prior)},
\ \ \ \ \alpha_0 &gt; 0,\ \beta_0 &gt; 0 
\end{align}\]</span></p>
<p>An example set of hyperparameter quantities used for <strong>Inverse Gamma</strong> flat prior is:</p>
<p><span class="math display">\[\begin{align}
\sigma^2 \sim Inv. Gamma \left(\alpha_0 =  1, \beta_0 =  1 \right) \ \ \text{(weakly-informed prior)}
\end{align}\]</span></p>
<p>An example set of hyperparameter quantities used for <strong>Gamma</strong> flat prior is:</p>
<p><span class="math display">\[\begin{align}
\lambda \sim Gamma\left(\alpha_0 =  \frac{1}{2}, \beta_0 =  \frac{1}{2}\right)\ \ \text{(weakly-informed prior)}
\end{align}\]</span></p>
<p>Figure <a href="bayesian.html#fig:flatprior">7.8</a> shows graph of the <strong>prior distribution</strong> with corresponding <strong>hyperparameter</strong>.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:flatprior"></span>
<img src="DS_files/figure-html/flatprior-1.png" alt="Flat Prior (Hyperparameter)" width="70%" />
<p class="caption">
Figure 7.8: Flat Prior (Hyperparameter)
</p>
</div>

<p>We leave readers to investigate the topic around <strong>Jeffreyâs prior</strong> for the chosen <strong>hyperparameters</strong> above.</p>
<p>Also, we illustrate the use of <strong>flat prior</strong> and <strong>hyperparameter</strong> in the <strong>Bayesian modeling</strong> section.</p>
<p>In summary, Table <a href="bayesian.html#tab:conjugacy">7.3</a> lists conjugate priors for a few distribution families corresponding to their <strong>likelihood</strong> distributions. That includes the corresponding <strong>hyperparameters</strong>.</p>

<table>
<caption><span id="tab:conjugacy">Table 7.3: </span>Conjugate Prior-Posterior</caption>
<colgroup>
<col width="14%" />
<col width="39%" />
<col width="17%" />
<col width="28%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Conjugacy Family</th>
<th align="left">General Notation</th>
<th align="left">Prior HyperParameter</th>
<th align="left">Likelihood</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Normal</td>
<td align="left"><span class="math inline">\(\mu\mid\sigma^2 \sim N(\mu,\sigma^2)\)</span></td>
<td align="left"><span class="math inline">\(\mu_0, \sigma^2_0\)</span></td>
<td align="left">Normal (unknown <span class="math inline">\(\mu\)</span>)</td>
</tr>
<tr class="even">
<td align="left">Inverse Gamma</td>
<td align="left"><span class="math inline">\(\sigma^2\mid\mu \sim Inv.\Gamma(\alpha,\beta)\)</span></td>
<td align="left"><span class="math inline">\(\alpha_0, \beta_0\)</span></td>
<td align="left">Normal (unknown <span class="math inline">\(\sigma^2\)</span>)</td>
</tr>
<tr class="odd">
<td align="left">Normal</td>
<td align="left"><span class="math inline">\(\mu,\sigma^2 \sim N(\mu,\sigma^2)\)</span></td>
<td align="left"><span class="math inline">\(\mu_0, \sigma^2_0\)</span></td>
<td align="left">Normal (unknown <span class="math inline">\(\mu\)</span>,<span class="math inline">\(\sigma^2\)</span>)</td>
</tr>
<tr class="even">
<td align="left">Gamma</td>
<td align="left"><span class="math inline">\(\mu,\sigma^2 \sim \Gamma(\alpha,\beta)\)</span></td>
<td align="left"><span class="math inline">\(\alpha_0, \beta_0\)</span></td>
<td align="left">Normal (unknown <span class="math inline">\(\mu\)</span>,<span class="math inline">\(\sigma^2\)</span>)</td>
</tr>
<tr class="odd">
<td align="left">Beta</td>
<td align="left"><span class="math inline">\(\rho \sim Beta(\alpha,\beta)\)</span></td>
<td align="left"><span class="math inline">\(\alpha_0, \beta_0\)</span></td>
<td align="left">Binomial</td>
</tr>
<tr class="even">
<td align="left">Beta</td>
<td align="left"><span class="math inline">\(\rho \sim Beta(\alpha,\beta)\)</span></td>
<td align="left"><span class="math inline">\(\alpha_0, \beta_0\)</span></td>
<td align="left">Geometric</td>
</tr>
<tr class="odd">
<td align="left">Gamma</td>
<td align="left"><span class="math inline">\(\lambda \sim \Gamma(\alpha,\beta)\)</span></td>
<td align="left"><span class="math inline">\(\alpha_0, \beta_0\)</span></td>
<td align="left">Poisson</td>
</tr>
<tr class="even">
<td align="left">Gamma</td>
<td align="left"><span class="math inline">\(\lambda \sim \Gamma(\alpha,\beta)\)</span></td>
<td align="left"><span class="math inline">\(\alpha_0, \beta_0\)</span></td>
<td align="left">Exponential</td>
</tr>
<tr class="odd">
<td align="left">Dirichlet</td>
<td align="left"><span class="math inline">\(\rho \sim Dir(\alpha)\)</span></td>
<td align="left"><span class="math inline">\(\alpha_0\)</span></td>
<td align="left">Multinomial</td>
</tr>
</tbody>
</table>

</div>
</div>
<div id="information-theory" class="section level2 hasAnchor">
<h2><span class="header-section-number">7.5</span> Information Theory <a href="bayesian.html#information-theory" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In this section, we introduce <strong>Information Theory</strong>. Some concepts are helpful when we cover <strong>Variational Bayes</strong>, especially around quantifying information. There are cases in which we need to transform our data set, and it is natural for us to compare the original (actual) data set and the transformed data set. To do that, we use measures such as <strong>Entropy</strong>, <strong>Information gain</strong>, <strong>Mutual Information</strong>, <strong>Gini Index</strong>, <strong>Kullback-Leibler divergence</strong>, and many others, which are metrics used to quantify information, mainly optimized by a <strong>cost function</strong> commonly denoted as <span class="math inline">\(\mathcal{J}(\theta)\)</span> in machine learning. Here, we reference the great works of Cover T.M. <span class="citation">(<a href="bibliography.html#ref-ref1039t">2006</a>)</span> and Ebrahimi N. et al. <span class="citation">(<a href="bibliography.html#ref-ref1029n">2010</a>)</span>.</p>
<p>For most of the discussions in this section, we settle only on <strong>Gaussian</strong> and <strong>Binomial</strong> processes; albeit, we do not restrict ourselves to only those distributions. Other familiar distributions should apply. Equivalently, <strong>continuous</strong> random variables do apply as well.</p>
<div id="information" class="section level3 hasAnchor">
<h3><span class="header-section-number">7.5.1</span> Information <a href="bayesian.html#information" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In this section, <strong>information</strong> is based on quantifying the uncertainty of random events. Rare events tend to be more uncertain, and when they happen, they become more <strong>surprising</strong> (more <strong>impure</strong>). Such rare events require additional information.</p>
<p>The amount of information to measure is called <strong>Shannon information</strong> and can be expressed as such:</p>
<p><span class="math display">\[\begin{align}
\mathcal{I}(X) = - \log_e P(X)
\end{align}\]</span></p>
</div>
<div id="entropy" class="section level3 hasAnchor">
<h3><span class="header-section-number">7.5.2</span> Entropy <a href="bayesian.html#entropy" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We describe <strong>Entropy</strong>, also called <strong>Shannon Entropy</strong>, in terms of the degree of randomness, uncertainty, impurity, or disorder based on the amount of information. <strong>Entropy</strong> is also discussed in <strong>Physics</strong> and <strong>Thermodynamics</strong>. It measures the amount of information required to eliminate the degree of randomness or uncertainty (see Figure <a href="bayesian.html#fig:entropy">7.9</a>). </p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:entropy"></span>
<img src="entropy.png" alt="Entropy" width="60%" />
<p class="caption">
Figure 7.9: Entropy
</p>
</div>

<p><strong>Entropy</strong> is denoted by the symbol <span class="math inline">\(\mathcal{H}(X)\)</span> and is expressed as:</p>
<p><span class="math display">\[\begin{align}
\mathcal{H}(X) = 
\begin{cases}
- \sum_x   P_X(x)\ \log_e  P_X(x) &amp; \text{(discrete entropy)}\\
\\
- \int_x   P_X(x)\ \log_e  P_X(x) dx  &amp; \text{(continuous differential entropy)}\\
\end{cases} \label{eqn:eqnnumber313}
\end{align}\]</span></p>
<p>Entropy (<span class="math inline">\(\mathcal{H}\)</span>) measures the level of impurity (or surprise) of the probability of an outcome. If the expected information of a random event is always 100% to the point of perfection (or purity), then it becomes unsurprising. The <strong>entropy</strong> is therefore zero. For example, if we have a coin with a head on both sides, no matter how many times we flip the coin, there is always a 100% probability that it lands on a head. Thus, there are zero surprises right there.</p>
<p><span class="math display">\[\begin{align}
\mathcal{H}(X) = -P(x) log P(x) = -1 \times \log_e (1) = 0,\ \ \ \ \ \ where\ P(x) = 100\%
\end{align}\]</span></p>
<p>Now, let us assume that we have four coins. As strange as it may sound, let us suppose three coins have heads on both sides, and the last coin has tails on both sides. Let us then compute the entropy of the set.</p>
<p><span class="math display">\[\begin{align}
\mathcal{H}(X) &amp;= - P(x_1) \log_e P(x_1) - P(x_2) \log_e P(x_2)  \\
&amp;= - \frac{3}{4} \log_e \left(\frac{3}{4} \right) - \frac{1}{4} \log_e \left( \frac{1}{4} \right)  \nonumber \\
&amp;= - (-0.2157616) - (-0.3465736 ) \nonumber \\
&amp;= 0.5623352 \nonumber
\end{align}\]</span></p>
<p>Notice that the higher the <strong>entropy</strong>, the more we see some information content. This measurement is proper when we split a dataset into corresponding features, similar to the techniques in decision trees in <strong>machine learning</strong>. Another contending measurement is the <strong>Gini Index</strong> which we discuss in the following subsection. </p>
<p>Now, let us consider <strong>Joint Entropy</strong>, which has the following equation: </p>
<p><span class="math display">\[\begin{align}
\mathcal{H}(X, Y) =  - \sum_{x \in X} \sum_{y \in Y} P(x,y) \log_e P(x,y)
\end{align}\]</span></p>
<p><strong>Joint Entropy</strong> computes the entropy of all possible pairs of two events. For example, if <span class="math inline">\(X \in \{A,B\}\)</span> and <span class="math inline">\(Y \in \{C,D\}\)</span>, and we have the following probabilities of each pair of combination: </p>
<p><span class="math display">\[\begin{align*}
P(X=A,Y=C) {}&amp;= 0.30\ \ \ \ \ \ \
P(X=A,Y=D) = 0.30\ \ \ \ \ \ \\
P(X=B,Y=C) &amp;= 0.20\ \ \ \ \ \ \
P(X=B,Y=D) = 0.20
\end{align*}\]</span>
then we can compute for the <strong>Joint Entropy</strong>:</p>
<p><span class="math display">\[\begin{align*}
\mathcal{H}(X, Y) {}&amp;= - \left[\ 0.30 \log_e (0.30) + 0.30 \log_e (0.30) + 0.20 \log_e (0.20) + 0.20 \log_e (0.20)\ \right]\\
&amp;= 1.366159
\end{align*}\]</span></p>
<p><strong>Conditional Entropy</strong> computes the entropy of one possible event given another event which has the following equation: </p>
<p><span class="math display">\[\begin{align}
\mathcal{H}(X|Y) = - \sum_{x \in X} P(x) \sum_{y \in Y} P(y|x) \log_e P(y|x)
\end{align}\]</span></p>
<p><strong>Cross-Entropy</strong> is another concept for measuring the difference between two distributions: one being the actual distribution, namely <span class="math inline">\(P(x)\)</span>, and the other being a training (approximating) distribution, namely <span class="math inline">\(\mathcal{Q}(x)\)</span>. It has the following equation:</p>
<p><span class="math display">\[\begin{align}
\mathcal{H}_Q(P) \equiv \mathcal{H}(P,Q) = 
\begin{cases}
- \sum_x   P_X(x)\ \log_e  \mathcal{Q}_X(x) &amp; \text{(discrete)}\\
\\
- \int_x   P_X(x)\ \log_e  \mathcal{Q}_X(x) dx  &amp; \text{(continuous)}\\
\end{cases} \label{eqn:eqnnumber314}
\end{align}\]</span></p>
<p>A <strong>cross-entropy</strong> value of zero means that the two distributions are almost identical. The higher the value, the farther away the two distributions are alike. In a later section, we discuss <strong>KL divergence</strong>, which is another measurement of <strong>closeness</strong> between two distributions such that we can express the divergence this way (given an actual distribution (<strong>P</strong>) and an estimated distribution (<strong>Q</strong>)):  </p>
<p><span class="math display">\[\begin{align}
\text{KL Divergence} = \underbrace{H(P,Q)}_{\text{cross entropy}} - \underbrace{H(P)}_{\text{entropy}}
\end{align}\]</span></p>
<p>Note that <strong>cross-entropy</strong> is used in <strong>machine learning</strong> as a loss function, generally replacing the common notation <span class="math inline">\(\mathcal{J}(\theta)\)</span> with <span class="math inline">\(\mathcal{H}_Q(P)\)</span>.</p>
<p>Note that the notation can be confused with a <strong>joint entropy</strong> notation. In our case, we use <span class="math inline">\(\mathcal{H}_Q(P)\)</span> to refer to <strong>cross-entropy</strong>.</p>
</div>
<div id="gini-index" class="section level3 hasAnchor">
<h3><span class="header-section-number">7.5.3</span> Gini Index <a href="bayesian.html#gini-index" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Gini Index</strong>, also called <strong>Gini Impurity</strong>, is denoted by the symbol <span class="math inline">\(\mathcal{G}(X)\)</span> and is expressed as:</p>
<p><span class="math display">\[\begin{align}
\mathcal{G}(X)  = \underbrace{1 - \underbrace{\sum_x P_X(x)^2}_{\text{Gini}}}_{\text{Gini Impurity}}
\end{align}\]</span></p>
<p><strong>Gini Index</strong> (<span class="math inline">\(\mathcal{G}\)</span>) can be used to measure the impurity of information similar to <strong>Entropy</strong>. To illustrate, we use the same example we used for <strong>Entropy</strong>. Suppose we have four coins. The three coins have heads on both sides, and the last coin has tails on both sides. Compute for the Gini index of the set.</p>
<p><span class="math display">\[\begin{align}
\mathcal{G} {}&amp;= 1 - ( P(x_1)^2 + P(x_2)^2  \\
&amp;= 1 - \left[ \left(\frac{3}{4}\right)^2 + \left(\frac{1}{4}\right)^2  \right] \nonumber \\
&amp;= 1 - (0.5625 + 0.0625 ) = 1 - 0.625 \nonumber \\
&amp;= 0.375 \nonumber
\end{align}\]</span></p>
<p>Similarly, if we have a coin with one side head and another side also head, no matter how many times we flip the coin, there is always a 100% probability that it lands on the head. Thus, there are zero surprises right there.</p>
<p><span class="math display">\[\begin{align}
\mathcal{G} = 1- P(x)^2  = -1 \times (1)^2 = 0,\ \ \ \ \ \ where\ P(x) = 100\%
\end{align}\]</span></p>
<p>Therefore, similar to <strong>Entropy</strong>, the higher the <strong>Gini index</strong>, the more we see some information content.</p>
</div>
<div id="information-gain" class="section level3 hasAnchor">
<h3><span class="header-section-number">7.5.4</span> Information Gain <a href="bayesian.html#information-gain" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Information Gain</strong> is denoted by the symbol <span class="math inline">\(\mathcal{I}(T,X)\)</span> and is expressed like so:</p>
<p>for <strong>Entropy</strong>:</p>
<p><span class="math display">\[\begin{align}
\mathcal{I}_{entropy}(T, X) {}&amp;= \mathcal{H}(parent) - \binom{weighted}{average} \mathcal{H}(children) \\
&amp;= \mathcal{H}(T) - \mathcal{H}(T,X)\ \ \ \ \ \ where\ \sum_x \mathcal{H}(x)
\end{align}\]</span></p>
<p>for <strong>Gini</strong>:</p>
<p><span class="math display">\[\begin{align}
\mathcal{I}_{gini}(T, X) {}&amp;= \mathcal{G}(parent) - \binom{weighted}{average} \mathcal{G}(children) \\
&amp;= \mathcal{G}(T) - \mathcal{G}(T,X)\ \ \ \ \ \ where\ \sum_x \mathcal{G}(x)
\end{align}\]</span></p>
<p><strong>Information Gain</strong> (<span class="math inline">\(\mathcal{I}\)</span>) measures the quality of <strong>split</strong>. So that if there are 15 red balls and five green balls in an urn and we split those 20 balls into two groups such that the 1st group has eight red balls and three green balls and the 2nd group has seven red balls and two green balls, then the information gain of the split is computed as such:</p>
<p><span class="math display">\[\begin{align*}
\mathcal{H}(T) {}&amp;= -\frac{15}{20}\ \log_e \left( \frac{15}{20} \right) - \frac{5}{20}\ \log_e \left( \frac{5}{20} \right) = 0.5623352 \\
\mathcal{H}(x_1) &amp;= -\frac{8}{11}\ \log_e \left( \frac{8}{11} \right) - \frac{3}{11}\ \log_e \left( \frac{3}{11} \right)=  0.5859526 \\
\mathcal{H}(x_2) &amp;= -\frac{7}{9}\ \log_e \left( \frac{7}{9} \right) - \frac{2}{9}\ \log_e \left( \frac{2}{9} \right) =  0.5297062 \\
\mathcal{H}(T, X) &amp;= \frac{11}{20}\ \times 0.5859526  + \frac{9}{20}\ 0.5297062 = 0.5606417\\
\\
\mathcal{I} &amp;= 0.5623352 - 0.5606417 = 0.0016935
\end{align*}\]</span></p>
<p>Note that the higher the Information Gain, the better the split. An Information Gain of zero means that the split is worst. For Information Gain using Gini, see <strong>Multi-Classification</strong> section in Chapter <strong>10</strong> (<strong>Computation Learning II</strong>).</p>
</div>
<div id="mutual-information" class="section level3 hasAnchor">
<h3><span class="header-section-number">7.5.5</span> Mutual Information <a href="bayesian.html#mutual-information" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Mutual Information</strong> is denoted by the symbol <span class="math inline">\(\mathcal{I}(X; Y)\)</span> and is expressed as:</p>
<p><span class="math display">\[\begin{align}
\mathcal{I}(X; Y) = \sum_{x \in X} \sum_{y \in Y} P(x,y) \log_e \frac{P(x,y)}{P(x)P(y)}
\end{align}\]</span></p>
<p>To illustrate, suppose we have two coins (X and Y), and we toss them five times, choosing any of the two coins randomly so that we end up with the following data: X = (H, H, T), Y = ( T, H ). We then compute for the probabilities:</p>
<p><span class="math display">\[\begin{align}
\begin{array}{rrrr}
P(X) = \frac{3}{5} &amp; P(Y) = \frac{2}{5} &amp; P(H) = \frac{3}{5} &amp; P(T) = \frac{2}{5}\\
P(X,H) = \frac{2}{5} &amp; P(X,T) = \frac{1}{5} &amp; P(Y,H) = \frac{1}{5} &amp; P(Y,T) = \frac{1}{5}\\
\end{array} \label{eqn:eqnnumber315}
\end{align}\]</span></p>
<p>Therefore:</p>
<p><span class="math display">\[\begin{align}
\mathcal{I}(X; Y) {}&amp;= 
P(X, H) \log_e \frac{P(X, H)}{P(X)P(H)} + 
P(X, T) \log_e \frac{P(X, T)}{P(X)P(T)} \nonumber \\ 
&amp;+P(Y, H) \log_e \frac{P(Y, H)}{P(Y)P(H)}  + 
P(Y, T) \log_e \frac{P(Y, T)}{P(Y)P(T)} \\
&amp;= 0.40\ \log_e \frac{0.40}{0.60 \times 0.60} + 0.20\ \log_e \frac{0.20}{0.60 \times 0.40 } \nonumber \\
&amp;+ 0.20\ \log_e \frac{0.20}{0.40 \times 0.60}  + 0.20\ \log_e \frac{0.20}{0.40 \times 0.40}\nonumber \\
&amp;= 0.01384429 \nonumber
\end{align}\]</span></p>
<p>Below is a list of a few important properties of <strong>Mutual Information</strong> in relation to <strong>entropy</strong>.</p>
<p><span class="math display">\[\begin{align}
\mathcal{I}(X; Y) {}&amp;= \mathcal{H}(X) - \mathcal{H}(X|Y)\\
\mathcal{I}(X; Y) &amp;= \mathcal{H}(Y) - \mathcal{H}(Y|X)\\
\mathcal{I}(X; Y) &amp;= \mathcal{H}(X) + \mathcal{H}(Y) - \mathcal{H}(X,Y)
\end{align}\]</span></p>
</div>
<div id="kullback-leibler-divergence" class="section level3 hasAnchor">
<h3><span class="header-section-number">7.5.6</span> Kullback-Leibler Divergence  <a href="bayesian.html#kullback-leibler-divergence" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Kullback-Leibler (KL) Divergence</strong>, also called <strong>Relative Entropy</strong>, measures the <strong>closeness</strong> of an approximating distribution <span class="math inline">\(\mathcal{Q}(X)\)</span> to a true distribution <span class="math inline">\(P(X)\)</span>. <strong>KL divergence</strong> is intimately related to <strong>Cross-Entropy</strong> as we continue to deal with a true distribution <span class="math inline">\(P(X)\)</span> along with a new approximating distribution denoted as <span class="math inline">\(\mathcal{Q}(X)\)</span>. Note that the distribution Q(X) is also called <strong>reference</strong> distribution, <strong>approximate</strong> distribution, <strong>training</strong> distribution, etc.</p>
<p>The <strong>KL divergence</strong> equation comes either in the form of <strong>Forward KL divergence</strong>, also called <strong>mean-seeking</strong>, <strong>zero-avoiding</strong> method; or in the form of <strong>Reverse KL divergence</strong>, also called <strong>mode-seeking</strong>, <strong>zero-forcing</strong> method. See Figure <a href="bayesian.html#fig:kldivergence">7.10</a>.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:kldivergence"></span>
<img src="kldivergence.png" alt="KL Divergence" width="80%" />
<p class="caption">
Figure 7.10: KL Divergence
</p>
</div>

<p>There are two components (factors) of the <strong>KL divergence</strong> equation: the weighting function, namely <span class="math inline">\(w(x)\)</span>, and the penalty function, namely <span class="math inline">\(g(x)\)</span>. The <strong>penalty function</strong> is interpreted as a <strong>log-likelihood ratio</strong>, which measures the ratio of how likely an approximating distribution <span class="math inline">\(Q(X)\)</span> describes a true distribution <span class="math inline">\(P(X)\)</span> and is expressed as:</p>
<p><span class="math display">\[\begin{align}
\log_e \mathcal{LR} \approx \int_x \log_e \left(\frac{P(X)}{\mathcal{Q}(X)}\right)
\end{align}\]</span></p>
<p>The <strong>Forward KL divergence</strong> has the following formula in which the penalty function measures the likelihood ratio of the actual distribution <span class="math inline">\(P(X)\)</span> over <span class="math inline">\(\mathcal{Q}(X)\)</span>. It is written as:</p>
<p><span class="math display">\[\begin{align}
\mathcal{D}_{KL}(P || Q) \equiv \mathcal{KL}(\ P\ ||\ Q\ ) = \sum_{x} 
 \underbrace{P(x)}_\text{weight}\ 
 \underbrace{ \log_e \left[ \frac{P(x)}{\mathcal{Q}(x)}\right] }_\text{penalty} = 
- \sum_{x} 
 \underbrace{P(x)}_\text{weight}\ 
 \underbrace{ \log_e \left[ \frac{\mathcal{Q}(x)}{P(x)}\right] }_\text{penalty}
\end{align}\]</span></p>
<p>For unimodal, the <strong>Forward KL divergence</strong> moves the Q in the direction towards P for measuring the closeness of the approximating distribution to the actual distribution.</p>
<p>For multimodal, the divergence seeks to settle on the average (the mean) of an actual multimodal distribution. The entropy term allows the approximating distribution to control the spread, encouraging it to have broader coverage across the actual multimodal distribution; hence, this divergence is <strong>inclusive</strong>. Below is the <strong>continuous</strong> version of the <strong>forward KL divergence</strong> split into two terms: the relative entropy and the cross-entropy.</p>
<p><span class="math display">\[\begin{align}
\mathcal{KL}(\ P\ ||\ Q\ ) {}&amp;= \int_x P(x)\left(\log_e P(x) - \log_e \mathcal{Q}(x)\right) dx\\
&amp;=\underbrace{\int_x P(x) \log_e P(x) dx}_\text{relative entropy}
\underbrace{ - \int_x P(x) \log_e \mathcal{Q}(x) dx }_\text{cross-entropy}
\end{align}\]</span></p>
<p>On the other hand, the <strong>Reverse KL divergence</strong> has the following formula in which the penalty function measures the likelihood ratio of the approximating distribution <span class="math inline">\(\mathcal{Q}(X)\)</span> over <span class="math inline">\(P(X)\)</span>.</p>
<p><span class="math display">\[\begin{align}
\mathcal{D}_{KL}(Q || P) \equiv \mathcal{KL}(\ Q\ ||\ P\ ) = \sum_{x} 
 \underbrace{\mathcal{Q}(x)}_\text{weight}\ 
 \underbrace{ \log_e \left[ \frac{\mathcal{Q}(x)}{P(x)}\right] }_\text{penalty}
\end{align}\]</span></p>
<p>Here, the <strong>penalty</strong> term has higher influence to the divergence if P(x) &gt; 0.</p>
<p>The divergence seeks to settle on the mode (the most common value) of an actual multimodal distribution. Therefore, in a mixture distribution, it may prefer one with the higher probability - and a mode that has a higher scale (e.g., variance) gets to be one in which the <strong>approximating distribution</strong> may tend to follow; hence, the divergence is <strong>exclusive</strong>.</p>
<p>Also, note that <strong>KL divergence</strong> is non-symmetric; meaning, that <span class="math inline">\(\mathcal{KL}(\ P\ ||\ Q\ ) \ne \mathcal{KL}(\ Q\ ||\ P\ )\)</span>. Additionally, it has the following properties called the <strong>Gibbâs Inequality</strong>:</p>
<p><span class="math display">\[\begin{align}
\mathcal{KL}(P||Q) \ge 0\ \ and\ \ \mathcal{KL}(P||P) = 0
\end{align}\]</span></p>
<p>Below is an example implementation of <strong>Forward KL-divergence</strong> in R code:</p>

<div class="sourceCode" id="cb841"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb841-1" data-line-number="1">KL.divergence &lt;-<span class="st"> </span><span class="cf">function</span>(X, mu1, sd1, mu2, sd2) {</a>
<a class="sourceLine" id="cb841-2" data-line-number="2">  ln &lt;-<span class="st"> </span><span class="cf">function</span>(n) { <span class="kw">log</span>(n, <span class="kw">exp</span>(<span class="dv">1</span>)) } <span class="co"># exp(1) = 2.718282</span></a>
<a class="sourceLine" id="cb841-3" data-line-number="3">  P =<span class="st"> </span><span class="kw">dnorm</span>(<span class="dt">x =</span> X, <span class="dt">mean=</span>mu1, <span class="dt">sd=</span>sd1)</a>
<a class="sourceLine" id="cb841-4" data-line-number="4">  Q =<span class="st"> </span><span class="kw">dnorm</span>(<span class="dt">x =</span> X, <span class="dt">mean=</span>mu2, <span class="dt">sd=</span>sd2)</a>
<a class="sourceLine" id="cb841-5" data-line-number="5">  <span class="kw">sum</span>( P <span class="op">*</span><span class="st"> </span><span class="kw">ln</span>( P <span class="op">/</span><span class="st"> </span>Q) )</a>
<a class="sourceLine" id="cb841-6" data-line-number="6">}</a></code></pre></div>

<p>To illustrate, let us solve for the <strong>KL divergence</strong> by generating two distributions (P and R) whose means <span class="math inline">\(\mu\)</span> are ten apart. Note that we are not explaining mean-seeking and mode-seeking in this illustration; instead, how an approximating distribution estimates the mean parameter of an actual distribution.</p>
<p><span class="math display">\[\begin{align}
P|\mu,\sigma^2 \sim N(0, 1)\ \ \ \ \ \ \ \ \ R|\mu,\sigma^2 \sim N(10, 1.2)
\end{align}\]</span></p>
<p>We simulate the sampling distributions like so:</p>

<div class="sourceCode" id="cb842"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb842-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">2020</span>)</a>
<a class="sourceLine" id="cb842-2" data-line-number="2">P =<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n=</span><span class="dv">10</span>, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd =</span> <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb842-3" data-line-number="3">R =<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n=</span><span class="dv">10</span>, <span class="dt">mean=</span><span class="dv">10</span>, <span class="dt">sd =</span> <span class="fl">1.2</span>)</a></code></pre></div>

<p>Let us show the two true distributions (P, R) in a graph - note that both distributions are independent and are not components of a bimodal mixture distribution. See Figure <a href="bayesian.html#fig:kldivergence1">7.11</a>.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:kldivergence1"></span>
<img src="DS_files/figure-html/kldivergence1-1.png" alt="Model Distribution (P and R)" width="70%" />
<p class="caption">
Figure 7.11: Model Distribution (P and R)
</p>
</div>

<p>The goal is to approximate a distribution given a fixed variance by estimating the mean. In other words, we have an unknown mean, and we need to find the proper values of the corresponding parameters (<span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^2\)</span>) that best characterize one of the distributions in the figure (P or R). Let us call this approximating (moving) distribution as Q.</p>
<p>Let us plot the <strong>KL divergence</strong> between an approximating Q and a true P and between the same Q and another true R.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:kldivergence2"></span>
<img src="DS_files/figure-html/kldivergence2-1.png" alt="Model Distribution (P and R)" width="70%" />
<p class="caption">
Figure 7.12: Model Distribution (P and R)
</p>
</div>

<p>In Figure <a href="bayesian.html#fig:kldivergence2">7.12</a>, as the approximating distribution Q moves in the direction towards P (<span class="math inline">\(\mu\)</span> = 0, <span class="math inline">\(\sigma=1\)</span>), the <strong>KL divergence</strong> becomes zero as it gets a <span class="math inline">\(\mu=0\)</span> which completely matches the P distribution.</p>

<div class="sourceCode" id="cb843"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb843-1" data-line-number="1">P.mu =<span class="st"> </span><span class="dv">0</span>;  P.sd =<span class="st"> </span><span class="dv">1</span>; Q.mu =<span class="st"> </span><span class="dv">1</span>; Q.sd =<span class="st"> </span><span class="dv">1</span></a>
<a class="sourceLine" id="cb843-2" data-line-number="2">Q.sample =<span class="st"> </span><span class="kw">sample</span>(<span class="kw">range</span>(<span class="op">-</span><span class="dv">10</span>,<span class="dv">10</span>), <span class="dt">size=</span><span class="dv">20</span>, <span class="dt">replace=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb843-3" data-line-number="3"><span class="kw">round</span>( <span class="kw">KL.divergence</span>(Q.sample, <span class="dt">mu1=</span>P.mu, <span class="dt">sd1=</span>P.sd, <span class="dt">mu2=</span>Q.mu, <span class="dt">sd2=</span>Q.sd), </a>
<a class="sourceLine" id="cb843-4" data-line-number="4">       <span class="fl">1e-10</span>)</a></code></pre></div>
<pre><code>## [1] 0</code></pre>

<p>Similarly, as Q moves towards R with (<span class="math inline">\(\mu\)</span> = 10, <span class="math inline">\(\sigma=1.2\)</span>), Q settles on <span class="math inline">\(\mu\)</span> with <strong>KL divergence</strong> equating to zero divergence.</p>

<div class="sourceCode" id="cb845"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb845-1" data-line-number="1">R.mu =<span class="st"> </span><span class="dv">10</span>;  R.sd =<span class="st"> </span><span class="fl">1.2</span>; Q.mu =<span class="st"> </span><span class="dv">10</span>; Q.sd =<span class="st"> </span><span class="fl">1.2</span></a>
<a class="sourceLine" id="cb845-2" data-line-number="2">Q.sample =<span class="st"> </span><span class="kw">sample</span>(<span class="kw">range</span>(<span class="op">-</span><span class="dv">10</span>,<span class="dv">10</span>), <span class="dt">size=</span><span class="dv">20</span>, <span class="dt">replace=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb845-3" data-line-number="3"><span class="kw">round</span>( <span class="kw">KL.divergence</span>(Q.sample, <span class="dt">mu1=</span>R.mu, <span class="dt">sd1=</span>R.sd, <span class="dt">mu2=</span>Q.mu, <span class="dt">sd2=</span>Q.sd), </a>
<a class="sourceLine" id="cb845-4" data-line-number="4">       <span class="fl">1e-10</span>)</a></code></pre></div>
<pre><code>## [1] 0</code></pre>

<p>Assume that Q.mu = 5, then we get a high divergence for Q moving away from R:</p>

<div class="sourceCode" id="cb847"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb847-1" data-line-number="1">R.mu =<span class="st"> </span><span class="dv">10</span>;  R.sd =<span class="st"> </span><span class="fl">1.2</span>; Q.mu =<span class="st"> </span><span class="dv">5</span>; Q.sd =<span class="st"> </span><span class="fl">1.2</span></a>
<a class="sourceLine" id="cb847-2" data-line-number="2">Q.sample =<span class="st"> </span><span class="kw">sample</span>(<span class="kw">range</span>(<span class="op">-</span><span class="dv">10</span>,<span class="dv">10</span>), <span class="dt">size=</span><span class="dv">20</span>, <span class="dt">replace=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb847-3" data-line-number="3"><span class="kw">round</span>( <span class="kw">KL.divergence</span>(Q.sample, <span class="dt">mu1=</span>R.mu, <span class="dt">sd1=</span>R.sd, <span class="dt">mu2=</span>Q.mu, <span class="dt">sd2=</span>Q.sd), </a>
<a class="sourceLine" id="cb847-4" data-line-number="4">       <span class="fl">1e-10</span>)</a></code></pre></div>
<pre><code>## [1] 20</code></pre>

<p>For comparison, we leave readers to investigate <strong>Wasserstein distance</strong> as an alternative measurement to <strong>KL divergence</strong>.</p>
<p>Now that we have seen the capability of <strong>KL divergence</strong>, we show how <strong>KL divergence</strong> is minimized for <strong>Variational inference</strong> in a later discussion as a way to solve the computational challenge inherent in <strong>Markov Chain Monte Carlo</strong>.</p>
<p>We leave readers also to investigate <strong>Bregman Divergence</strong>, <strong>Jensen-Bregman Divergence</strong>, and <strong>Jensen-Shannon Divergence</strong>.</p>
</div>
<div id="jensens-inequality" class="section level3 hasAnchor">
<h3><span class="header-section-number">7.5.7</span> Jensenâs Inequality<a href="bayesian.html#jensens-inequality" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Jensenâs Inequality</strong> states that the secant line drawn between any two points on a convex curve is always above the convex curve. Similarly, a secant line drawn between two points on a concave curve is always below the concave curve. See Figure <a href="bayesian.html#fig:jensensinequality">7.13</a>.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:jensensinequality"></span>
<img src="jensensinequality.png" alt="Jensen's Inequality" width="70%" />
<p class="caption">
Figure 7.13: Jensenâs Inequality
</p>
</div>

<p>Mathematically, the average point in a secant line is always greater than a convex function; but lesser than a concave function.</p>
<p><span class="math display">\[\begin{align}
\underbrace{\overbrace{\mathbb{E}(f(x))}^\text{secant line} \ge \overbrace{ f(\mathbb{E}(x))}^\text{curve function}  }_\text{convex}
\ \ \ \ \ \ \ \ \ \ 
\underbrace{   \overbrace{\mathbb{E}(f(x))}^\text{secant line} \le \overbrace{f(\mathbb{E}(x))}^\text{curve function}
}_\text{concave}
\end{align}\]</span></p>
<p>In <strong>variational inference</strong>, we use <strong>Jensenâs inequality</strong> as a trick to be able to derive the upper/lower bound:</p>
<p><span class="math display">\[\begin{align}
\underbrace{\overbrace{\mathbb{E}(f(x))}^\text{secant line} = \overbrace{ f(\mathbb{E}(x))}^\text{curve function}  }_\text{convex (upper bound)}
\ \ \ \ \ \ \ \ \ \ 
\underbrace{   \overbrace{\mathbb{E}(f(x))}^\text{secant line} = \overbrace{f(\mathbb{E}(x))}^\text{curve function}
}_\text{concave (lower bound)}
\end{align}\]</span></p>
</div>
</div>
<div id="bayesianinference" class="section level2 hasAnchor">
<h2><span class="header-section-number">7.6</span> Bayesian Inference<a href="bayesian.html#bayesianinference" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><strong>Bayesian Inference</strong> mostly, if not all cases, operates in the context of <strong>optimization problems</strong> where the object of interest is around the <strong>posterior</strong>.</p>
<p>We begin this section by recalling the discussion around <strong>Linear Regression</strong> in Chapter <strong>3</strong> (<strong>Numerical Linear Algebra II</strong>). See <strong>Linear Regression</strong> Figure under <strong>Approximating Polynomial Functions by Regression</strong> Section in Chapter <strong>3</strong>. A review of <strong>Linear Regression</strong> shows a <strong>deterministic linear model</strong> expressed as such:</p>
<p><span class="math display">\[\begin{align}
\hat{y}_i = \beta_0 + \beta_1 x_i
\end{align}\]</span></p>
<p>However, this model is assumed to be a perfect model that is not mostly and not practically applicable in real-world situations. Most of our observed data are mixed with <strong>random noise</strong> (<span class="math inline">\(\mathbf{\epsilon_i}\)</span>), and thus, we model in a stochastic manner by adding noise into the equation to form a <strong>stochastic linear model</strong>; thus, we have the following:</p>
<p><span class="math display">\[\begin{align}
\hat{y}_i = \beta_0 + \beta_1 x_i + \epsilon_i\ \ \ \ \ \ \ \ \epsilon_i \sim \mathcal{N}(\mu, \sigma^2),\ \ \ \ \ \ \ i = 1,...,n
\end{align}\]</span></p>
<p>There are two notes to mention here.</p>
<p><strong>First</strong>, our response variable - being <span class="math inline">\(\mathbf{\hat{y}_i}\)</span>, given value <span class="math inline">\(\mathbf{x_i}\)</span> - is a <strong>point-estimate</strong>; meaning, our estimate renders one single value.</p>
<p><strong>Second</strong>, <strong>linear regression</strong> is accomplished by optimizing the <span class="math inline">\(\beta\)</span> parameters, namely <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>, by minimizing the <strong>error</strong> (or loss) function, e.g. <strong>least square</strong> based on the residual (<span class="math inline">\(\epsilon_i\)</span>).</p>
<p>In this section, we also deal with two notes corresponding to the response variable and parameter estimation.</p>
<p><strong>First</strong>, instead of dealing with <strong>point-estimates</strong>, we deal with <strong>stochastic estimates</strong> in which our response variable - being <span class="math inline">\(\mathbf{\hat{y}_i}\)</span> - assumes a <strong>random variable</strong>; meaning, our estimate does not render a single value, but rather a random sampling that follows a <strong>normal posterior distribution</strong> and therefore it is expressed as such:</p>
<p><span class="math display">\[\begin{align}
\hat{y}_i|x_i \sim \mathcal{N}(\mu, \sigma^2)
\end{align}\]</span></p>
<p>For every <span class="math inline">\(\mathbf{x_i}\)</span> in the X space, there is a corresponding <span class="math inline">\(\mathbf{\hat{y}_i}\)</span> <strong>normal posterior</strong> distribution.</p>
<p>Another way to get the intuition is to use Figure <a href="bayesian.html#fig:stochasticestimate">7.14</a>.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:stochasticestimate"></span>
<img src="stochasticestimate.png" alt="Point-Estimate vs Stochastic Estimate" width="70%" />
<p class="caption">
Figure 7.14: Point-Estimate vs Stochastic Estimate
</p>
</div>

<p><strong>Second</strong>, recall <span class="math inline">\(\theta\)</span> parameter in the <strong>Likelihood</strong> section. In this case, the theta <span class="math inline">\(\theta\)</span> parameter is a vector that contains <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>. For clear notation, let us use <span class="math inline">\(\alpha\)</span> for <span class="math inline">\(\beta_1\)</span> and use <span class="math inline">\(\beta\)</span> for <span class="math inline">\(\beta_1\)</span>. To optimize theta <span class="math inline">\(\theta\)</span> parameter, we focus on the <strong>likelihood</strong> term in the normalized <strong>Bayes Theorem</strong> and perform <strong>maximum likelihood estimation (MLE)</strong>:</p>
<p><span class="math display">\[\begin{align}
\underbrace{P(\theta|X)}_\text{posterior}\ \propto\ \underbrace{Lik(\theta|X)}_\text{likelihood} \times \underbrace{P(\theta)}_\text{prior}
\end{align}\]</span></p>
<p>Taking Figure <a href="bayesian.html#fig:stochasticestimate">7.14</a> as an example in point, there are four <strong>sampling densities</strong> in the Y <strong>posterior space</strong>: <span class="math inline">\(Y = (\hat{y}_1, \hat{y}_2, \hat{y}_3, \hat{y}_4 )\)</span>. Such list of sampling densities forms the following notation:</p>
<p><span class="math display">\[\begin{align}
\forall y:   \hat{y}_i|x_i;\alpha,\beta,\sigma \sim \overbrace{ \underbrace{ 
   \mathcal{N}(\alpha_i + \beta_i x_i\ , \sigma^2) }_\text{likelihood}}^{sampling\ density}
\end{align}\]</span></p>
<p>Note that each of the <strong>sampling densities</strong> is independent and thus we can form a <strong>joint distribution</strong> like so:</p>
<p><span class="math display">\[\begin{align}
Lik(X; \alpha, \beta, \sigma^2|Y) = Lik(x_1,...,x_n; \alpha, \beta, \sigma^2|y_1,...,y_n) = \prod_{i=1}^n P(y_i|x_i; \alpha_i, \beta_i, \sigma^2) 
\end{align}\]</span></p>
<p>To avoid underflows and overflows, we use log-likelihood:</p>
<p><span class="math display">\[\begin{align}
-\log_e Lik(X; \alpha, \beta, \sigma^2|Y) = - \sum_{i=1}^n ln\ P(y_i|x_i; \alpha_i, \beta_i, \sigma^2) 
\end{align}\]</span></p>
<p>Note that it is common to minimize a <strong>loss</strong> or <strong>cost</strong> function. We minimize the log-likelihood by negating it to conform to the same practice. Therefore, to maximize the likelihood estimate <strong>(MLE)</strong> is also to minimize the <strong>negative log-likelihood (NLL)</strong>. Here is the <strong>minimization</strong> equation:</p>
<p><span class="math display">\[\begin{align}
\hat{y} = \underset{\alpha,\beta,\sigma^2}{argmin}\ -\log_e Lik(X; \alpha, \beta, \sigma^2|Y) = \underset{\alpha,\beta,\sigma^2}{argmin}\ -\sum_{i=1}^n ln\ P(y_i|x_i; \alpha_i, \beta_i, \sigma^2) 
\end{align}\]</span></p>
<p>As for the variance <span class="math inline">\(\sigma^2\)</span> parameter, if we lack assumptions, we can use uniform distribution:</p>
<p><span class="math display">\[\begin{align}
\sigma^2 \sim \mathcal{U}(1,1)
\end{align}\]</span></p>
<div id="maximum-likelihood-mle" class="section level3 hasAnchor">
<h3><span class="header-section-number">7.6.1</span> Maximum Likelihood (MLE)  <a href="bayesian.html#maximum-likelihood-mle" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In <strong>Linear regression</strong>, we look for <strong>a model that fits</strong> our data. The <strong>goodness of fit</strong> is determined using <strong>RMSE</strong> or <span class="math inline">\(\mathbf{R^2}\)</span>. The model is expressed as a <strong>line function</strong> (or a <strong>curve function</strong> for non-linear regression) described by the <span class="math inline">\(\beta\)</span> parameters. Fitting a model depends upon optimizing the <span class="math inline">\(\beta\)</span> parameters.</p>
<p>The same concept applies to <strong>Stochastic regression</strong> in which we also look for a <strong>model that fits</strong> our data. And the <strong>goodness of fit</strong> is determined using <strong>MLE</strong> or <strong>NLL</strong>. The model is expressed as a <strong>likelihood function</strong> and is described by the <span class="math inline">\(\theta\)</span> parameters. Fitting a model depends upon optimizing the <span class="math inline">\(\theta\)</span> parameters.</p>
<p>See Figure <a href="bayesian.html#fig:modeling">7.15</a> for reference.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:modeling"></span>
<img src="modeling.png" alt="Modeling by Parameter Estimation" width="80%" />
<p class="caption">
Figure 7.15: Modeling by Parameter Estimation
</p>
</div>

<p>In this section, the idea here is to optimize the <span class="math inline">\(\theta\)</span> parameters to maximize the likelihood of observing data. That is called <strong>maximum likelihood estimation (MLE)</strong>. An <strong>MLE</strong> takes the following general form:</p>
<p><span class="math display">\[\begin{align}
\hat{\theta} = \underset{\theta}{argmax}\ P(X|\theta) = \underset{\theta}{argmax} \prod_{i=1}^n f( x_i ; \theta)
\end{align}\]</span></p>
<p><strong>MLE</strong> for <strong>Normal Distribution</strong></p>
<p>Let us derive the equation to find the optimal mean <span class="math inline">\(\mu^*\)</span>, given a known <span class="math inline">\(\sigma^{2*}\)</span>. Here, the likelihood function takes multivariates as input and performs a multiplication of the normal <strong>PDF</strong> for each variate.</p>
<p><span class="math display">\[\begin{align}
{}&amp;Lik(\mu, \sigma^2 | x_1,...,x_n) {} \equiv P(x_1,...,x_n\ |\ \mu, \sigma^2)\\
&amp;= \prod_{i=1}^n \frac{1}{\sqrt{2\pi\sigma^2}} exp\left[-\frac{(x_i - \mu)^2}{2\sigma^2}\right]\\
&amp;= \left( \frac{1}{\sqrt{2\pi\sigma^2}} \right)^n
    exp\left[-\frac{\sum_{i=1}^n(x_i - \mu)^2}{2\sigma^2}\right]
\end{align}\]</span></p>
<p>Use log-likelihood and simplify:</p>
<p><span class="math display">\[\begin{align}
{}&amp; \log_e Lik(\mu, \sigma^2 | x_1,...,x_n)  \\
&amp;= ln \left( \frac{1}{\sqrt{2\pi\sigma^2}} \right)^n + ln\ 
    exp\left[-\frac{\sum_{i=1}^n(x_i - \mu)^2}{2\sigma^2}\right]\\
&amp;= \sum_{i=1}^n ln\ \left[\frac{1}{\sqrt{2\pi\sigma^2}} \right] + \left[-\frac{\sum_{i=1}^n(x_i - \mu)^2}{2\sigma^2}\right]
\end{align}\]</span></p>
<p>Now, take the partial derivative with respect to <span class="math inline">\(\mu\)</span>:</p>
<p><span class="math display">\[\begin{align}
{}&amp; \frac{ \partial\ \log_e Lik(\mu, \sigma^2 | x_1,...,x_n) }{\partial \mu}\\
&amp;=  -\frac{1}{2\sigma^2} \frac{\partial}{\partial\mu}  \left[\sum_{i=1}^n(x_i - \mu)^2\right]   &amp; \text{(drop 1st term constant)}\\
&amp;= -\frac{2}{2\sigma^2}  \left[\sum_{i=1}^n x_i - n\mu \right]
\end{align}\]</span></p>
<p>Set left-side of equation to zero and solve for <span class="math inline">\(\mu_{(MLE)}\)</span>:</p>
<p><span class="math display">\[\begin{align}
{}&amp;\rightarrow -\frac{1}{\sigma^2}  \left[\sum_{i=1}^n x_i - n\mu \right] = 0\\
&amp;\rightarrow  \left[\sum_{i=1}^n x_i - n\mu \right] = 0\\
\nonumber \\ 
&amp;\mu_{(MLE)} = \frac{1}{n}\sum_{i=1}^n x_i
\end{align}\]</span></p>
<p>Notice that <strong>MLE</strong> for the mean for a <strong>normal distribution</strong> gets simplified to a simple average computation.</p>
<p>Using the same log-likelihood, let us take the partial derivative with respect to <span class="math inline">\(\sigma^2\)</span>, given <span class="math inline">\(\mu\)</span>. In what follows, we temporarily use placeholder variables:</p>
<p><span class="math display">\[\begin{align}
v = \sigma^2\ \ \ \ \ \ \ \ \ \ \ \ \ \ X_u = \sum_{i=1}^n(x_i - \mu)^2
\end{align}\]</span></p>
<p>Therefore, we get:</p>
<p><span class="math display">\[\begin{align}
\frac{ \partial\ ln\ Lik(\mu, v | x_1,...,x_n) }{\partial v} 
{}&amp;= \frac{\partial}{\partial v}\sum_{i=1}^n ln\ \left[\frac{1}{\sqrt{2\pi v}} \right] + 
   \frac{\partial}{\partial v}\left[-\frac{X_u}{2 v}\right]\\
&amp;= -\frac{n}{2v} + \frac{X_u}{2v^2}
\end{align}\]</span></p>
<p>Set left-side of equation to zero and solve for <span class="math inline">\(\sigma^2_{(MLE)}\)</span>:</p>
<p><span class="math display">\[\begin{align}
{}&amp;\rightarrow -\frac{1}{2}\left[\frac{n}{v} - \frac{X_u}{v^2} \right]= 0\\
{}&amp;\rightarrow v^* = \frac{X_u}{n},\ \ \ \ \ \ \ \ n \ne 0\\
\nonumber \\
\sigma^2_{(MLE)} &amp;= \frac{\sum_{i=1}^n(x_i - \mu)^2}{n} &amp; \text{(substitute placeholders)}
\end{align}\]</span></p>
<p><strong>MLE</strong> for <strong>Binomial Distribution</strong></p>
<p>Let us use <strong>binomial distribution</strong> to illustrate a case. Here, we perform the following:</p>
<p><span class="math display">\[\begin{align}
Lik(n,\rho|x_1,...,x_m) = \prod_{i=1}^m \binom{n}{x_i}  \rho^{x_i}(1-\rho)^{n-x_i}
\ \ \ \ \ \ \ \ \ \ where:\ 
\binom{n}{x_i}\ \text{is a constant}
\end{align}\]</span></p>
<p>Note that the <strong>constant</strong> <span class="math inline">\(\binom{n}{x_i}\)</span> gets dropped in the partial derivatives eventually; therefore, we can drop the constant up-front given data.</p>
<p>We then calculate the log-likelihood:</p>
<p><span class="math display">\[\begin{align}
\log_e  Lik(n,\rho|x_1,...,x_m) {}&amp;=  ln\left( \prod_{i=1}^m \binom{n}{x_i} \rho^{x_i}(1-\rho)^{n-x_i} \right)\\
&amp;= \sum_{i=1}^m  \left( ln\binom{n}{x_i}  + ln(\rho)^{x_i} + ln(1-\rho)^{n-x_i} \right)\\
&amp;=  \sum_{i=1}^m  \left( ln \binom{n}{x_i} + x_i \cdot ln(\rho) + (n-x_i)\cdot ln(1-\rho) \right)
\end{align}\]</span></p>
<p>The <strong>key to optimization</strong> in this respect is based on taking the partial derivatives with respect to the <span class="math inline">\(\rho\)</span> parameter for the log-likelihood:</p>
<p><span class="math display">\[\begin{align}
\frac{\partial}{\partial_\rho} \log_e  Lik(n,\rho|x_1,...,x_m) {}&amp;= \sum_{i=1}^m  \left( ln \binom{n}{x_i} + x_i \cdot \frac{\partial}{\partial_\rho}ln(\rho) + (n-x_i)\cdot \frac{\partial}{\partial_\rho}ln(1-\rho) \right) \\
&amp;= \sum_{i=1}^m  \left( 0 + x_i \cdot \frac{\partial}{\partial_\rho}ln(\rho) + (n-x_i)\cdot \frac{\partial}{\partial_\rho}ln(1-\rho) \right) \\
&amp;= \sum_{i=1}^m \left( \frac{1}{\rho} x_i -  \frac{1}{1 - \rho}(n - x_i) \right) .
\end{align}\]</span></p>
<p>Then we simplify:</p>
<p><span class="math display">\[\begin{align}
\sum_{i=1}^m  \left[ \frac{1}{\rho} x_i - \frac{1}{1 - \rho}(n - x_i) \right] = 0 
\end{align}\]</span></p>
<p>With a few algebraic calculations, we obtain the following optimized parameter (<strong>MLE</strong>):</p>
<p>For <strong>marginal-density (univariate)</strong> likelihood:</p>
<p><span class="math display">\[\begin{align}
\hat{\rho}_{(MLE)} = \underset{\rho}{argmax}\ \log_e Lik(n,\rho|X = x) = \frac{x}{n}
\end{align}\]</span></p>
<p>For <strong>joint-density (multivariate)</strong> likelihood:</p>
<p><span class="math display">\[\begin{align}
\hat{\rho}_{(MLE)} = \underset{\rho}{argmax}\ \log_e Lik(n,\rho|x_1,...,x_m) = \frac{\sum^m x}{mn}
\end{align}\]</span></p>
<p>Below is a family of distributions with their corresponding maximum likelihood estimates. See Table <a href="bayesian.html#tab:familymle">7.4</a>.</p>

<table>
<caption><span id="tab:familymle">Table 7.4: </span>Maximum Likelihood Estimate</caption>
<thead>
<tr class="header">
<th align="left">Family</th>
<th align="left">Parameters (<span class="math inline">\(\hat{\theta}\)</span>)</th>
<th align="left">Derived Function</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Uniform</td>
<td align="left"><span class="math inline">\(\hat{\theta}\)</span></td>
<td align="left"><span class="math inline">\(X_n\)</span></td>
</tr>
<tr class="even">
<td align="left">Normal</td>
<td align="left"><span class="math inline">\(\hat{\theta_1} = \mu\)</span></td>
<td align="left"><span class="math inline">\(\mu\)</span> = <span class="math inline">\(\frac{1}{n} \sum_{i=1}^n x_i\)</span></td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="left"><span class="math inline">\(\hat{\theta_2} = \sigma^2\)</span></td>
<td align="left"><span class="math inline">\(\frac{1}{n} \sum_{i=1}^n(x_i - \hat{\mu})^2\)</span></td>
</tr>
<tr class="even">
<td align="left">Binomial</td>
<td align="left"><span class="math inline">\(\hat{\rho}\)</span></td>
<td align="left"><span class="math inline">\(\frac{\sum^m x}{mn}\)</span></td>
</tr>
<tr class="odd">
<td align="left">Geometric</td>
<td align="left"><span class="math inline">\(\hat{\rho}\)</span></td>
<td align="left"><span class="math inline">\(\frac{1}{X}\)</span> = <span class="math inline">\(\frac{n}{\sum_{i=1}^n x_i}\)</span></td>
</tr>
<tr class="even">
<td align="left">Poisson</td>
<td align="left"><span class="math inline">\(\hat{\lambda}\)</span></td>
<td align="left"><span class="math inline">\(\frac{1}{n} \sum_{i=1}^n x_i\)</span></td>
</tr>
<tr class="odd">
<td align="left">Exponential</td>
<td align="left"><span class="math inline">\(\hat{\lambda}\)</span></td>
<td align="left"><span class="math inline">\(\bar{X}\)</span> = <span class="math inline">\(\frac{1}{n} \sum_{i=1}^n x_i\)</span></td>
</tr>
</tbody>
</table>

<p>In the following two sections, we discuss the <strong>Expectation-Maximization</strong> technique in dealing with multiple latent distributions instead of just one, which we can solve with <strong>MLE</strong>.</p>
<p>Also, in Chapter <strong>9</strong> (<strong>Computational Learning I</strong>), we expand further on the concept of <strong>MLE</strong> (<strong>NLL</strong>) in the context of <strong>Generalized Linear Model (GLM)</strong> and <strong>Logistic Regression</strong>.</p>
<p>For further reading, we encourage readers to investigate MLE in the context of misspecified models <span class="citation">(White H. <a href="bibliography.html#ref-ref1065h">1982</a>)</span>.</p>
</div>
<div id="maximum-a-posteriori-map" class="section level3 hasAnchor">
<h3><span class="header-section-number">7.6.2</span> Maximum A-posteriori (MAP)  <a href="bayesian.html#maximum-a-posteriori-map" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A <strong>Gaussian distribution</strong> can be characterized by its mean (the average) and variance (the spread). In some cases, we may also want to characterize (or estimate) the distribution in terms of mode. For example, in a unimodal Gaussian distribution, we may want to estimate the most common value or the highest peak in the distribution - this is the mode, denoted as <span class="math inline">\(\mu_{(MAP)}\)</span>, with the most number of expected values. Additionally, we also want to identify the variance <span class="math inline">\(\sigma^2_{(MAP)}\)</span> between the mode <span class="math inline">\(\mu_{(MAP)}\)</span> and certain error levels, <span class="math inline">\(\epsilon_0\)</span>, for our confidence level.</p>
<p>In the previous section, we try to optimize <span class="math inline">\(\theta\)</span> parameters for <strong>likelihood</strong>. This section aims to optimize the <span class="math inline">\(\theta\)</span> parameters to maximize the <strong>posterior</strong>. That is called <strong>maximum a-posteriori estimation (MAP)</strong>. The same concept applies in which our goal is to find the closest approximating posterior distribution proportional to the actual posterior distribution.</p>
<p><strong>MAP</strong> takes the following general form:</p>
<p><span class="math display">\[\begin{align}
\theta^* = \underset{\theta}{argmax}\ P(\theta | X) 
\end{align}\]</span></p>
<p>Here, we require a proper <strong>posterior distribution</strong>. Based on the derived closed-form conjugate posterior from the <strong>Conjugacy</strong> section, let us evaluate the posterior from the Normal-Normal conjugacy and Binomial-Beta conjugacy and try to maximize the posterior.</p>
<p><strong>MAP</strong> for <strong>Normal Posterior</strong></p>
<p>To illustrate, let us use the <strong>Normal</strong> family of distribution to compute for <strong>MAP</strong>. However, it helps to review the <strong>Normal-Normal conjugacy</strong> for the posterior equation derived in the <strong>Conjugacy</strong> section.</p>

<p><span class="math display">\[\begin{align}
P(\mu,\sigma^2|x1,...,x_n) {}&amp;\propto Lik_X(\mu, \sigma^2|x_1,...,x_n) \times P(\mu_0,\sigma^2_0)\\
&amp;\propto  \underbrace{\prod_{i=1}^n\frac{1}{\sqrt{2\pi\sigma^2}} exp\left[-\frac{(x_i - \mu)^2}{2\sigma^2}\right] }_\text{normal likelihood} \times 
\underbrace{ \frac{1}{\sqrt{2\pi\sigma^2_0}} exp\left[-\frac{(\mu - \mu_0)^2}{2\sigma^2_0}\right]}_\text{normal prior} \\
&amp;\propto  \left(\frac{1}{\sqrt{2\pi\sigma^2}}\right)^n exp\left[-\frac{\sum_{i=1}^n (x_i - \mu)^2}{2\sigma^2}\right] \times 
 \frac{1}{\sqrt{2\pi\sigma^2_0}} exp\left[-\frac{(\mu - \mu_0)^2}{2\sigma^2_0}\right]
\end{align}\]</span>
</p>
<p>We then calculate for the log a-posteriori (dropping constants up-front):</p>
<p><span class="math display">\[\begin{align}
{}&amp;\log_e P(\mu,\sigma^2|x1,...,x_n) \nonumber \\
&amp;\propto \sum_{i=1}^nln\ \left(\frac{1}{\sqrt{2\pi\sigma^2}}\right) + \left[-\frac{\sum_{i=1}^n (x_i - \mu)^2}{2\sigma^2}\right] + 
 ln\ \frac{1}{\sqrt{2\pi\sigma^2_0}} + \left[-\frac{(\mu - \mu_0)^2}{2\sigma^2_0}\right]
\end{align}\]</span></p>
<p>Next, we take the partial derivative with respect to <span class="math inline">\(\mu\)</span> and simplify:</p>
<p><span class="math display">\[\begin{align}
{}&amp;\frac{\partial\ \log_e P(\mu,\sigma^2|x1,...,x_n)}{\partial \mu} \nonumber \\
&amp;\propto   \frac{\partial}{\partial \mu}\left[-\frac{\sum_{i=1}^n (x_i - \mu)^2}{2\sigma^2}\right]
+  \frac{\partial}{\partial \mu} \left[-\frac{(\mu - \mu_0)^2}{2\sigma^2_0}\right]
&amp; \text{(drop constants)}\\
&amp;\propto  -\frac{2}{2} \left[\frac{n\mu - \sum_{i=1}^n x_i}{\sigma^2}\right]
 -\frac{2}{2} \left[\frac{(\mu - \mu_0)}{\sigma^2_0}\right]\\
&amp;\propto  - \left[\frac{ \sigma^2_0 ( n\mu - \sum_{i=1}^n x_i ) + \sigma^2(\mu - \mu_0)}{\sigma^2 \sigma^2_0}\right]
\end{align}\]</span></p>
<p>Then we set the left-side of equation to zero to solve for <span class="math inline">\(\mu_{(MAP)}\)</span> :</p>
<p><span class="math display">\[\begin{align}
{}&amp;\rightarrow - \left[\frac{ \sigma^2_0 ( n\mu - \sum_{i=1}^n x_i ) + \sigma^2(\mu - \mu_0)}{\sigma^2 \sigma^2_0}\right] = 0\\
&amp;\rightarrow \sigma^2_0 \left( n\mu - \sum_{i=1}^n x_i \right) + \sigma^2(\mu - \mu_0)  = 0 \\
\nonumber \\
\mu_{(MAP)} &amp;= \frac{ \sigma^2_0 \sum_{i=1}^n x_i + \sigma^2 \mu_0  }{n\sigma^2_0 + \sigma^2}
\end{align}\]</span></p>
<p>Let us now take the partial derivative with respect to <span class="math inline">\(\sigma^2\)</span> and simplify. In what follows, we temporarily use placeholder variables:</p>
<p><span class="math display">\[\begin{align}
v = \sigma^2\ \ \ \ \ \ \ \ \ \ \ \ \ Q_x = \sum_{i=1}^n (x_i - \mu)^2
\end{align}\]</span></p>
<p><span class="math display">\[\begin{align}
{}&amp;\frac{\partial\ \log_e P(\mu,v|x1,...,x_n)}{\partial v} \nonumber \\
&amp;\propto  \frac{\partial}{\partial v} \sum_{i=1}^nln\ \left(\frac{1}{\sqrt{2\pi v}}\right) + \frac{\partial}{\partial v}\left[-\frac{Q_x}{2v}\right]
&amp; \text{(drop constants)}\\
&amp;\propto -\frac{n}{2v} +  \frac{Q_x}{2v^2}
\end{align}\]</span></p>
<p>Then we set the left-side of equation to zero to solve for <span class="math inline">\(\sigma^2_{(MAP)}\)</span> :</p>
<p><span class="math display">\[\begin{align}
{}&amp;\rightarrow -\frac{n}{2v} +  \frac{Q_x}{2v^2} = 0\\
&amp;\rightarrow  v = \frac{Q_x}{n}\\
\nonumber \\
\sigma^2_{(MAP)} &amp;= \frac{\sum_{i=1}^n (x_i - \mu)^2}{n} &amp; \text{(substitute placeholders)}
\end{align}\]</span></p>
<p>It is worth mentioning that in a case where we do not have a piece of prior knowledge, we then can use a uniform prior, e.g., <span class="math inline">\(P(\theta) \propto 1\)</span> where <span class="math inline">\(\theta \sim U(1,1)\)</span>. That renders the prior with lesser or no influence on the posterior, so then the maximum posterior (<strong>MAP</strong>) becomes proportional to maximum likelihood (<strong>MLE</strong>). In that regard, we can say that <strong>MAP</strong> is a regularization of <strong>ML</strong> because of the influence of the prior.</p>
<p><strong>MAP</strong> for <strong>Beta Posterior</strong></p>
<p>To illustrate, let us use the <strong>Binomial</strong> family of distribution to compute for <strong>MAP</strong>. For this, it helps to review the <strong>Binomial-Beta conjugacy</strong> for the posterior equation as derived in the <strong>Conjugacy</strong> section.</p>
<p>Here, we calculate using the following equation (where the choice of our <strong>prior</strong> is a <strong>beta prior</strong> - we discuss more of <strong>prior</strong> probability in subsequent sections):</p>
<p><span class="math display">\[\begin{align}
P(n,\rho|x_1,...,x_m) {}&amp;\propto Lik(n,\rho|x_1,...,x_m) \times P(n,\rho) \\
&amp;\propto \underbrace{ \prod_{i=1}^m \binom{n}{x_i}  \rho^{x_i}(1-\rho)^{n-x_i}}_\text{binomial likelihood}  \times \underbrace{ \frac{1}{\mathcal{B}(\alpha_0,\beta_0)}\rho^{\alpha_0 - 1} (1 - \rho)^{\beta_0 - 1} }_\text{beta prior}
\end{align}\]</span></p>
<p>We then calculate for the log a-posteriori (dropping constants up-front):</p>
<p><span class="math display">\[\begin{align}
\log_e  P(n,\rho|x_1,...,x_m)  {}&amp;\propto  ln\left[ \prod_{i=1}^m \binom{n}{x_i}  \rho^{x_i}(1-\rho)^{n-x_i}  \times \frac{1}{\mathcal{B}(\alpha_0,\beta_0)}\rho^{\alpha_0 - 1} (1 - \rho)^{\beta_0 - 1} \right]\\
&amp;\propto   ln\left[ \prod_{i=1}^m \binom{n}{x_i}  \rho^{x_i}(1-\rho)^{n-x_i} \right] +  ln \left[ \frac{1}{\mathcal{B}(\alpha_0,\beta_0)}\rho^{\alpha_0 - 1} (1 - \rho)^{\beta_0 - 1} \right]\\
&amp;\propto   \sum_{i=1}^m ln(\rho)^{x_i} + \sum_{i=1}^mln(1-\rho)^{n-x_i}  + ln(\rho)^{\alpha_0 - 1}+  ln (1 - \rho)^{\beta_0 - 1} 
\end{align}\]</span></p>
<p>Note that we zero-out the constant up-front.</p>
<p>We then take the partial derivative with respect to <span class="math inline">\(\rho\)</span> and simplify:</p>
<p><span class="math display">\[\begin{align}
{}&amp;\frac{\partial}{\partial_\rho}\log_e  P(n,\rho|X = x) \nonumber \\
&amp;\propto  \sum_{i=1}^m \frac{\partial}{\partial_\rho}ln(\rho)^{x_i} + \sum_{i=1}^m \frac{\partial}{\partial_\rho}ln(1-\rho)^{n-x_i} + \frac{\partial}{\partial_\rho} ln(\rho)^{\alpha_0 - 1} + \frac{\partial}{\partial_\rho} ln (1 - \rho)^{\beta_0 - 1}\\
&amp;\propto \sum_{i=1}^m \frac{x_i}{\rho} - \sum_{i=1}^m \frac{n - x_i}{1 - \rho}  + \frac{\alpha_0-1}{\rho} - \frac{\beta_0 - 1}{1 - \rho}\\
&amp;\propto \frac{(1-\rho)(\sum_{i-1}^m x_i + \alpha_0 - 1) - \rho(\sum_{i=1}^m (n-x_i) + \beta_0 - 1)}{\rho(1 - \rho)}
\end{align}\]</span></p>
<p>Then we set the left-side of equation to zero to solve for <span class="math inline">\(\rho_{(MAP)}\)</span>:</p>
<p><span class="math display">\[\begin{align}
{}&amp;\rightarrow (1-\rho)(\sum_{i-1}^m x_i + \alpha_0 - 1) - \rho(\sum_{i=1}^m (n-x_i) + \beta_0 - 1)  = 0\\
{}&amp;\rightarrow (1-\rho)(m\bar{x} + \alpha_0 - 1) - \rho( (mn - m\bar{x}) + \beta_0 - 1)  = 0
\end{align}\]</span></p>
<p>Therefore, for <strong>joint posterior</strong>:</p>
<p><span class="math display">\[\begin{align}
\rho_{(MAP)} = \frac{m \bar{x} + \alpha - 1}{\alpha + \beta + m \bar{x} + (mn - m\bar{x}) - 2}
\end{align}\]</span></p>
<p>For <strong>marginal posterior</strong>:</p>
<p><span class="math display">\[\begin{align}
\rho_{(MAP)} = \frac{x + \alpha - 1}{\alpha + \beta + x + (n- x) - 2}
\end{align}\]</span></p>
<p>We leave readers to investigate the <strong>maximum a-posteriori</strong> for other a-posteriori distributions.</p>
</div>
<div id="laplace-approximation" class="section level3 hasAnchor">
<h3><span class="header-section-number">7.6.3</span> Laplace Approximation <a href="bayesian.html#laplace-approximation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Similar to <strong>Maximum a-posteriori</strong>, the <strong>Laplace Approximation</strong> method is another technique used to approximate an actual <strong>posterior distribution</strong>. As always, we start with the <strong>Bayes theorem</strong>:</p>
<p><span class="math display">\[\begin{align}
P(\theta|X) = \frac{P(X|\theta)P(\theta)}
{P(X)},\ \ \ \ where\ P(X)= \int P(X|\theta)P(\theta) d\theta
\end{align}\]</span></p>
<p>The object of interest is still the true <strong>posterior</strong>, which is rendered with no closed-form solution in cases, for example, where its <strong>marginal likelihood</strong>, namely <span class="math inline">\(P(X)\)</span>, tends to be intractable.</p>
<p><strong>Laplace approximation</strong> uses an <strong>approximating distribution</strong> denoted as <span class="math inline">\(\mathcal{Q}(X)\)</span> for the true <strong>posterior</strong>. To illustrate, let us consider the following steps <span class="citation">(Murphy K. section 8.4.1 <a href="bibliography.html#ref-ref224k">2012</a>; Bishop C.M., section 4.4 <a href="bibliography.html#ref-ref482c">2006</a>)</span>:</p>
<p><strong>First</strong>, to approximate the <strong>posterior distribution</strong>, we replace the equation with the following <strong>approximating distribution</strong>:</p>
<p><span class="math display">\[\begin{align}
\mathcal{Q}(\mu) = \frac{q(u)}{\int q(u)du}\ \ \ \ \ \ \text{let Z = } \int q(u)du
\end{align}\]</span></p>
<p>Here, <strong>Z</strong> takes the role of a <strong>normalizing constant</strong> for <span class="math inline">\(P(X)\)</span> - the denominator. And <span class="math inline">\(q(u)\)</span> assumes the relation between the <strong>likelihood</strong> and the <strong>prior</strong>, namely <span class="math inline">\(P(X|\theta)P(\theta)\)</span>, - the numerator.</p>
<p><strong>Second</strong>, we assume that <span class="math inline">\(\mathcal{Q}(\mu)\)</span> follows a unimodal Gaussian distribution but with a shape based on unknown mean and unknown variance such that <span class="math inline">\(\mathcal{Q} \sim \mathcal{N}(X; \mu, \sigma^2)\)</span>. Naturally, to approximate a <strong>Gaussian distribution</strong> for <span class="math inline">\(\mathcal{Q}(\mu)\)</span>, we need to find the peak instead (or the mode), which we denote as <span class="math inline">\(\mu_0\)</span> for which the slope (first derivative) is zero, e.g., <span class="math inline">\(q&#39;(\mu_0) = 0\)</span>.</p>
<p><span class="math display">\[\begin{align}
\left.\frac{d}{d\mu}q(\mu)\right|_{\mu={\mu_0}}
\end{align}\]</span></p>
<p><strong>Third</strong>, let us derive a gaussian-like equation for <span class="math inline">\(\mathcal{Q}(\mu)\)</span> by using <strong>second-order Taylor series expansion</strong> for the log of <span class="math inline">\(q(u)\)</span>, centered at the mode (<span class="math inline">\(\mu_0\)</span>):</p>
<p><span class="math display">\[\begin{align}
\log_e q(u) {}&amp; = \log_e \left[P(X|\theta = \mu) P(\theta =\mu)\right] \\
\nonumber \\
{}&amp;\approx \sum_{n=0}^{N=2} \left(\frac{q^{(n)}(\mu_0)(\mu - \mu_0)^{(n)}}{n!}\right) &amp; \text{(2nd-order Taylor series)}\\
&amp;= q(\mu_0) + q&#39;(\mu_0)(\mu - \mu_0) + \frac{1}{2}q&#39;&#39;(\mu_0)(\mu - \mu_0)^2 \\
&amp;= q(\mu_0)  + \frac{1}{2}q&#39;&#39;(\mu_0)(\mu - \mu_0)^2 &amp; \text{(1st-order vanishes at slope=0)}\\
&amp;= q(\mu_0)  + \left(-\frac{1}{2}\right)(-q&#39;&#39;(\mu_0))(\mu - \mu_0)^2 &amp; \text{(negate for concave quadratic)}\\
&amp;= q(\mu_0)  + \left(-\frac{1}{2}\right)\frac{(\mu - \mu_0)^2}{\Sigma} &amp; \Sigma=-q&#39;&#39;(\mu_0)^{-1} \leftarrow\ \text{(precision)} \\
q(\mu) &amp;= exp\left[q(\mu_0)  + \left(-\frac{1}{2}\right)\frac{(\mu - \mu_0)^2}{\Sigma}\right] &amp; \text{(exp-log)} \\
&amp;= exp(q(\mu_0))  \times exp \left[-\frac{1}{2}\left(\frac{(\mu - \mu_0)^2}{\Sigma}\right)\right]
\end{align}\]</span></p>
<p><strong>Fourth</strong>, let us also solve for the <strong>normalizing constant</strong>, namely <strong>Z</strong> = <span class="math inline">\(\int q(\mu)d\mu\)</span>.</p>
<p><span class="math display">\[\begin{align}
Z {}&amp;= \int exp(q(\mu_0))  \times exp \left[-\frac{1}{2}\left(\frac{(\mu - \mu_0)^2}{\Sigma}\right)\right] d\mu &amp; \text{(normalizing constant)} \\
&amp;= exp(q(\mu_0))  \int  exp\left[-\frac{1}{2}\left(\frac{(\mu - \mu_0)^2}{\Sigma}\right) \right] d\mu
\end{align}\]</span></p>
<p>Now, recall the equation for <strong>gaussian integral with polar coordinates</strong> used to derive the following sample equation (See Chapter <strong>5</strong> (<strong>Numerical Probability and Distribution</strong>) under <strong>Normal Distribution</strong> Subsection). Similarly, with some integration, we arrive at the following:</p>
<p><span class="math display">\[\begin{align}
\int  exp\left[-\frac{1}{2}\left(\frac{(\mu - \mu_0)^2}{\Sigma}\right) \right] d\mu = \sqrt{2\pi\Sigma}\ \ \ \ \ \ \ \ \ \ \leftarrow\ \ 
\int_{-\infty}^{\infty} e^{-x^2} dx = \sqrt{\pi}
\end{align}\]</span></p>
<p>Therefore:</p>
<p><span class="math display">\[\begin{align}
Z = exp(q(\mu_0)) \times \sqrt{2\pi\Sigma}\ \ \ \ \text{(normalizing constant)}
\end{align}\]</span></p>
<p>That simplifies our <strong>approximating distribution for posterior</strong>, namely <span class="math inline">\(\mathcal{Q}(\mu)\)</span>, by avoiding the use of integration. Therefore, we end up with the following:</p>
<p><span class="math display">\[\begin{align}
\mathcal{Q}(\mu) {}&amp;= \frac{1}{\mathbf{Z}} \times q(u)\  = 
\frac{1}{exp(q(\mu_0)) \times  \sqrt{2\pi\Sigma}}\times
exp(q(\mu_0)) \times exp\left[-\frac{1}{2}\left(\frac{(\mu - \mu_0)^2}{\Sigma}\right) \right]\\
\nonumber \\
&amp;= \frac{1}{\sqrt{2\pi\Sigma}}exp\left[-\frac{1}{2}\left(\frac{(\mu - \mu_0)^2}{\Sigma}\right) \right]
\end{align}\]</span></p>
<p>where:</p>
<p><span class="math display">\[\begin{align}
\mu_0 = \underbrace{q&#39;(\mu_0) = \left.\frac{d}{d\mu}q(\mu)\right|_{\mu={\mu_0}}}_\text{the mode}\ \ 
\ \ \ \  \ \ \ \ \ \ \ \ \ \ \ \ \ 
\Sigma^{-1} = \underbrace{-q&#39;&#39;(\mu_0) = -\left.\frac{d^2}{d\mu^2}q(\mu)\right|_{\mu={\mu_0}}}_\text{the precision}
\end{align}\]</span></p>
<p>In terms of M-dimensional <strong>multivariate gaussian distribution</strong>, we leave the readers to derive the following equation:</p>
<p><span class="math display">\[\begin{align}
\mathcal{Q}_X(\mu)= \frac{1}{\sqrt{(2\pi)^M |H|^{-1}}} exp\left[-\frac{1}{2} (\mu - \mu_0)^T H (\mu - \mu_0)  \right]\ \ \ \leftarrow \text{(H is Hessian Matrix)}
\end{align}\]</span></p>
<p>where:</p>
<p><span class="math display">\[
\mu = 
\left[\begin{array}{r}\mu_0 \\ \mu_1 \\ \vdots \\ \mu_m\end{array}\right],\ \ \ \  \ 
H^{-1} = \left[\begin{array}{rrrr} 
\sigma_{1,1} &amp; \sigma_{1,2} &amp; ... &amp; \sigma_{1,m}\\
\sigma_{2,1} &amp; \sigma_{2,2} &amp;... &amp; \sigma_{2,m}\\
\vdots &amp; \ldots &amp; \ddots &amp; \vdots \\
\sigma_{m,1} &amp; \sigma_{m,2} &amp; \ldots &amp; \sigma_{m,m} \\
\end{array}\right]
\]</span></p>
<p>Depending on the sample size, <strong>Laplace approximation</strong> is adjustable to the <strong>n-order</strong> of a <strong>Taylor series expansion</strong> necessary to improve the estimation. That is called <strong>Bayesian Information Criterion (BIC)</strong>.</p>
<p><strong>Laplace approximation</strong> is an old technique demonstrating approximation of simple unimodal <strong>posterior</strong> distribution, and it performs well if the mean and mode are not far apart. However, for complex models, it may help look at other techniques such as <strong>Expectation-Maximization</strong> and <strong>Variational Bayes</strong>.</p>
</div>
<div id="expectation-maximization-em" class="section level3 hasAnchor">
<h3><span class="header-section-number">7.6.4</span> Expectation-Maximization (EM)  <a href="bayesian.html#expectation-maximization-em" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>There are real-world applications in object recognition such as facial and speech recognition, behavior and gesture recognition, and hand-writing recognition that deal with latent or hidden data. These applications provide solutions for identifying, describing, or recognizing latent data, such as recognizing speech by evaluating speech patterns. There are powerful techniques used, in whole or in part, to solve such problems, and one of them uses the <strong>EM</strong> algorithm.</p>
<p><strong>Expectation-Maximization (EM)</strong> (Dempster, Laird, Rubin 1977) is an iterative and recursive technique that extends <strong>MLE</strong> and <strong>MAP</strong>, optimizing parameter models.</p>
<p>We begin the discussion of the <strong>EM</strong> algorithm by enumerating a few items (Note here that our discussion is driven by the use of the <strong>Gaussian mixture model (GMM)</strong>):</p>
<ul>
<li>A cluster of unknown distributions (or components) that can be classified, e.g. <span class="math inline">\(Y \in \{\ y_1, y_2,...,\ y_k\ \}\)</span>.</li>
<li>A sampling of data from an unknown distribution, e.g. <span class="math inline">\(X \in \{\ x_1,\ x_2,\ ...,\ x_n\ \}\)</span></li>
<li>A set of classification to label cluster components, e.g., <span class="math inline">\(c_j \in \{\ A, B, C\ \}\)</span></li>
<li>A set of proportionality (to serve as weight), e.g. <span class="math inline">\(\omega \in \{\ \omega_1,\ \omega_2,\ ...,\ \omega_k\ \}\)</span>.</li>
<li>An unknown parameter model denoted as theta <span class="math inline">\(\theta\)</span> that models each unknown distribution.</li>
</ul>
<p>Note that in <strong>mixture models</strong>, we also call the <strong>unobserved distributions</strong> as <strong>latent components</strong> (or latent samplings). We may use the first component referring to the first unobserved distribution from time to time.</p>
<p>Now <strong>EM</strong> starts with an initialization step and then iterates between the expectation and maximization steps.</p>
<p><strong>Model initialization (Initialization step)</strong></p>
<p>Unlike our discussion around <strong>MLE</strong> in characterizing a single latent distribution, we illustrate how to characterize latent mixture distributions.</p>
<p>For illustration, assume we have three latent distributions, <span class="math inline">\(k = 3\)</span>, with corresponding parameter models <span class="math inline">\(\theta = \{ \theta_1, \theta_2, \theta_3 \}\)</span> where:</p>
<p><span class="math display">\[
\theta_j = 
\begin{cases}
(\mu, \sigma^2) &amp; \text{(gaussian distribution)}\\
(n, \rho) &amp; \text{(binomial distribution)}\\
... &amp; \text{(other types)}
\end{cases}\ \ \ \ \ \ \ \ \forall j : 1,...,k
\]</span></p>
<p>Suppose that each latent distribution, namely <span class="math inline">\(y_j\)</span>, can be classified accordingly: <span class="math inline">\(c_j \in \{\ A,\ B,\ C\ \}\)</span>.</p>
<p>Here, we characterize each of our <strong>k</strong> models with <strong>gaussian distribution</strong> with corresponding gaussian parameters, namely <span class="math inline">\(\theta_j = (\mu_j, \sigma^2_j)\)</span>.</p>
<p>We start <strong>EM</strong> by initializing our model parameters for each unobserved distribution at time <span class="math inline">\(t=0\)</span>.</p>
<p><span class="math display">\[
\theta_1^0 = (25, 2)\ \ \ \ \ \ \ \ \ \ \ \ 
\theta_2^0 = (30, 2)\ \ \ \ \ \ \ \ \ \ \ \  
\theta_3^0 = (35, 2)
\]</span></p>
<p>As for our observed data, suppose we have <span class="math inline">\(X = \{\ 27,\ 23,\ 18,\ ...,\ x_n\ \}\)</span> where <span class="math inline">\(n = sample\ size\)</span>.</p>
<p>We assume the following proportionality (or <strong>prior</strong> probability) of three samplings from the <strong>mixture</strong> distribution. Here, we arbitrarily assign the proportions like so:</p>
<p><span class="math display">\[
P(\theta_1) = \omega_1 = 33\%\ \ \ \ \ \ \ \ \ 
P(\theta_2) = \omega_2 = 33\%\ \ \ \ \ \ \ \ \ 
P(\theta_3) = \omega_3 = 34\%
\]</span></p>
<p>The <strong>proportionality</strong>, also called <strong>weight</strong>, sums up to 1, for example, <span class="math inline">\(\sum_{j=1}^k \omega_j\)</span> = 1. We can use uniform distribution equally spread across all <strong>prior</strong> probabilities if we do not make any assumptions using the following <strong>proportionality</strong> formula:</p>
<p><span class="math display">\[
w_j = \frac{n_j}{n}\ \ \ \ \ \ \text{where}\ n_j \text{= size of jth component and n = total size of X}
\]</span></p>
<p><strong>Expectation Step (E-STEP)</strong></p>
<p>In this step, we use the initialized (and eventually the optimized) model to calculate the <strong>posterior</strong> probability using the <strong>Bayes Theorem</strong> equation.</p>
<p><span class="math display">\[\begin{align}
P(x_i \in  y_j|x_i) = \frac{P(x_i | x_i \in  y_j) P(y_j)}{P(x_i) }
\end{align}\]</span></p>
<p>The idea is to evaluate every observation, namely (<span class="math inline">\(x_i\)</span>), and estimate the probability that each observation in the sample <strong>belongs to</strong> or <strong>exists</strong> (<span class="math inline">\(\in\)</span>) <strong>in</strong> a particular sampling component, namely (<span class="math inline">\(y_i\)</span>). However, it may help show how the model theta <span class="math inline">\(\theta\)</span> contributes to the equations.</p>
<p>Therefore, we can express the <strong>posterior</strong> term like so:</p>
<p><span class="math display">\[\begin{align}
P(x_i \in  y_j|x_i)
\equiv \underbrace{ P\left(Y = y_j|X = x_i,\ \theta_j^{(t)}\right)  }_\text{posterior}
\end{align}\]</span></p>
<p>where <span class="math inline">\(\theta_j^t\)</span> models (or characterizes) <span class="math inline">\(\mathbf{y_j}\)</span>.</p>
<p>The <strong>likelihood</strong> term can be defined as:</p>
<p><span class="math display">\[\begin{align}
P(x_i | x_i \in  y_j) \equiv \underbrace{P\left(X=x_i|\theta_j^{(t)}\right)}_\text{likelihood} = \frac{1}{\sqrt{2\pi\sigma_j^{2{(t)}}}} exp\left[-\frac{\left(x_i - \mu_j^{(t)}\right)^2}{2\sigma_j^{2{(t)}}}\right]
\end{align}\]</span></p>
<p>Here, we use <strong>gaussian pdf</strong> and is implemented like so:</p>

<div class="sourceCode" id="cb849"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb849-1" data-line-number="1">norm.prob &lt;-<span class="st"> </span><span class="cf">function</span>(x, mean, sd) { <span class="kw">dnorm</span>(x, <span class="dt">mean=</span> mean, <span class="dt">sd =</span> sd) }</a></code></pre></div>

<p>Finally, our normalizer - the marginal likelihood - can be written as:</p>
<p><span class="math display">\[\begin{align}
P(x_i) \equiv \sum_{l=1}^k P\left(X=x_i|\theta_l^{(t)}\right)\times\omega_l
\end{align}\]</span></p>
<p>We use the <strong>log marginal likelihood</strong>, namely <span class="math inline">\(\log_eP(x_i)\)</span>, to evaluate convergence during iteration. Because of the intractable nature of the normalizer for more complex models, we discuss a way to solve the intractability problem in the next section under <strong>variational EM</strong>.</p>
<p>For now, here is the equivalent equation for our <strong>vanilla EM</strong>.</p>
<p><span class="math display">\[\begin{align}
P(Y = y_j|X = x_i,\ \theta_j^{(t)}) = 
\frac{P\left(X=x_i|\theta_j^{(t)}\right)\times\omega_j}{\sum_{l=1}^k P\left(X=x_i|\theta_l^{(t)}\right)\times\omega_l}
,\ \ \ \ \ \ \forall j : 1,...,k
\end{align}\]</span></p>
<p>Now, let us use a placeholder variable for the outcome of the calculation in the above equation which we use in the <strong>maximization</strong> step:</p>
<p><span class="math display">\[\begin{align}
\Upsilon_{j,x_i}^{(t)}\ \ \leftarrow P\left(Y = y_j|X = x_i,\ \theta_j^{(t)}\right)
\end{align}\]</span></p>
<p>Note that this variable represents a posterior proportion of the jth component. Also, it is essential to note further that the proportionality of all components must sum up to one. In the context of <strong>ML</strong> classification, calculating the proportion of every value over the sum of all values in a vector is called <strong>Softmax</strong>. A <strong>Softmax</strong> function performs proportion evaluation (especially in neural networks) to decide the path with the highest proportion. See our simple classification implementation later in this section.</p>
<p><strong>Maximization Step (M-STEP)</strong></p>
<p>In this step, we maximize the parameter model. In the case of <strong>gaussian mixture</strong>, we maximize <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^2\)</span>:</p>
<p><span class="math display">\[\begin{align}
\mu_j^{(t+1)} {}&amp;= \frac{\sum_{i=1}^n x_i \Upsilon_{j,x_i}^{(t)}}{\sum_{i=1}^n  \Upsilon_{j,x_i}^{(t)}} 
\ \ \ \ \ \ \ \ \ \ \ \ \sigma_j^{t+1} = \frac{\sum_{i=1}^n \left(x_i - \mu_j^{(t)}\right)^2 \Upsilon_{j,x_i}^{(t)}}{\sum_{i=1}^n  \Upsilon_{j,x_i}^{(t)}}\\
\theta_j^{(t+1)} &amp;= (\mu_j^{(t+1)}  , \sigma_j^{t+1})
\ \ \ \ \ \ \ \ \ \ \ \ 
\omega_j^{t+1} = \frac{ \sum_{i=1}^n \Upsilon_{j,x_i}^{(t)}}{n}
\end{align}\]</span></p>
<p>We then iterate between <strong>E-step</strong> and <strong>M-step</strong> until convergence. Note that we use the log of the normalizer being computed in <strong>E-STEP</strong> to evaluate convergence, for example:</p>
<p><span class="math display">\[\begin{align}
| \underbrace{\log_e P(x_i)^{(t)}}_\text{new loglik} - \underbrace{\log_e P(x_i)^{(t-1)}}_\text{old loglik}  | &lt; tolerance
\end{align}\]</span></p>
<p>To illustrate, let us perform the <strong>initialization step</strong>:</p>

<div class="sourceCode" id="cb850"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb850-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">2020</span>)</a>
<a class="sourceLine" id="cb850-2" data-line-number="2">k =<span class="st"> </span><span class="dv">3</span></a>
<a class="sourceLine" id="cb850-3" data-line-number="3">sample_size =<span class="st"> </span><span class="dv">5</span></a>
<a class="sourceLine" id="cb850-4" data-line-number="4">n =<span class="st"> </span>k <span class="op">*</span><span class="st"> </span>sample_size</a>
<a class="sourceLine" id="cb850-5" data-line-number="5">theta =<span class="st"> </span><span class="kw">matrix</span>( <span class="kw">c</span>(  <span class="kw">c</span>(<span class="dv">25</span>, <span class="dv">2</span>), <span class="kw">c</span>(<span class="dv">30</span>, <span class="fl">1.5</span>), <span class="kw">c</span>(<span class="dv">35</span>, <span class="fl">1.5</span>) ), <span class="dt">nrow=</span>k, </a>
<a class="sourceLine" id="cb850-6" data-line-number="6">                <span class="dt">byrow=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb850-7" data-line-number="7">x1 =<span class="st"> </span>sample1 =<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n =</span> sample_size, <span class="dt">mean =</span> theta[<span class="dv">1</span>,<span class="dv">1</span>],   </a>
<a class="sourceLine" id="cb850-8" data-line-number="8">                     <span class="dt">sd =</span> theta[<span class="dv">1</span>,<span class="dv">2</span>])</a>
<a class="sourceLine" id="cb850-9" data-line-number="9">x2 =<span class="st"> </span>sample2 =<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n =</span> sample_size, <span class="dt">mean =</span> theta[<span class="dv">2</span>,<span class="dv">1</span>],   </a>
<a class="sourceLine" id="cb850-10" data-line-number="10">                     <span class="dt">sd =</span> theta[<span class="dv">2</span>,<span class="dv">2</span>])</a>
<a class="sourceLine" id="cb850-11" data-line-number="11">x3 =<span class="st"> </span>sample3 =<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n =</span> sample_size, <span class="dt">mean =</span> theta[<span class="dv">3</span>,<span class="dv">1</span>],   </a>
<a class="sourceLine" id="cb850-12" data-line-number="12">                     <span class="dt">sd =</span> theta[<span class="dv">3</span>,<span class="dv">2</span>])</a>
<a class="sourceLine" id="cb850-13" data-line-number="13">w1 =<span class="st"> </span><span class="kw">length</span>(sample1) <span class="op">/</span><span class="st"> </span><span class="kw">length</span>(X)  </a>
<a class="sourceLine" id="cb850-14" data-line-number="14">w2 =<span class="st"> </span><span class="kw">length</span>(sample2) <span class="op">/</span><span class="st"> </span><span class="kw">length</span>(X)  </a>
<a class="sourceLine" id="cb850-15" data-line-number="15">w3 =<span class="st"> </span><span class="kw">length</span>(sample3) <span class="op">/</span><span class="st"> </span><span class="kw">length</span>(X)  </a>
<a class="sourceLine" id="cb850-16" data-line-number="16">W =<span class="st"> </span><span class="kw">c</span>(w1, w2, w3)    <span class="co"># prior probabilities</span></a>
<a class="sourceLine" id="cb850-17" data-line-number="17">X =<span class="st"> </span><span class="kw">c</span>(x1, x2, x3)    <span class="co"># mixture distribution</span></a>
<a class="sourceLine" id="cb850-18" data-line-number="18">Y =<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;A&quot;</span>, <span class="st">&quot;B&quot;</span>, <span class="st">&quot;C&quot;</span>) <span class="co"># components</span></a></code></pre></div>

<p>Albeit we have generated three samples, they are merely used to simulate a <strong>gaussian mixture</strong> for our observed data, namely <strong>X</strong>. For demonstration, the three samples (or three components) become latent but labeled as <strong>A</strong>, <strong>B</strong>, and <strong>C</strong> accordingly. The parameters for each component, namely theta <span class="math inline">\(\theta_j\)</span> and prior weight <span class="math inline">\(\omega_j\)</span>, are kept unknown but arbitrarily initialized. See Figure <a href="bayesian.html#fig:mixturecomponents">7.16</a>.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:mixturecomponents"></span>
<img src="DS_files/figure-html/mixturecomponents-1.png" alt="Gaussian Mixture Model - 3 hidden components" width="70%" />
<p class="caption">
Figure 7.16: Gaussian Mixture Model - 3 hidden components
</p>
</div>

<p>Before we show the implementation of each step, let us first define the <strong>natural log</strong> function.</p>

<div class="sourceCode" id="cb851"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb851-1" data-line-number="1">ln &lt;-<span class="st"> </span><span class="cf">function</span>(n) { <span class="kw">log</span>(n, <span class="kw">exp</span>(<span class="dv">1</span>))} <span class="co"># exp(1) = 2.718282</span></a></code></pre></div>

<p>For the <strong>Expectation Step</strong>, we calculate the <strong>weighted likelihood</strong> of each observation belonging to a component. Notice that each weighted likelihood gets a higher weighting score the more relevant the corresponding data points become to their component.</p>

<div class="sourceCode" id="cb852"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb852-1" data-line-number="1">weight.likelihd1 =<span class="st"> </span><span class="kw">norm.prob</span>(X, <span class="dt">mean=</span>theta[<span class="dv">1</span>,<span class="dv">1</span>], <span class="dt">sd=</span>theta[<span class="dv">1</span>,<span class="dv">2</span>]) <span class="op">*</span><span class="st"> </span>W[<span class="dv">1</span>]</a>
<a class="sourceLine" id="cb852-2" data-line-number="2">weight.likelihd2 =<span class="st"> </span><span class="kw">norm.prob</span>(X, <span class="dt">mean=</span>theta[<span class="dv">2</span>,<span class="dv">1</span>], <span class="dt">sd=</span>theta[<span class="dv">2</span>,<span class="dv">2</span>]) <span class="op">*</span><span class="st"> </span>W[<span class="dv">2</span>]</a>
<a class="sourceLine" id="cb852-3" data-line-number="3">weight.likelihd3 =<span class="st"> </span><span class="kw">norm.prob</span>(X, <span class="dt">mean=</span>theta[<span class="dv">3</span>,<span class="dv">1</span>], <span class="dt">sd=</span>theta[<span class="dv">3</span>,<span class="dv">2</span>]) <span class="op">*</span><span class="st"> </span>W[<span class="dv">3</span>]</a>
<a class="sourceLine" id="cb852-4" data-line-number="4"><span class="kw">round</span>(<span class="kw">matrix</span>( <span class="kw">c</span>(weight.likelihd1, weight.likelihd2, weight.likelihd3),</a>
<a class="sourceLine" id="cb852-5" data-line-number="5">     <span class="dt">nrow=</span><span class="dv">3</span>, <span class="dt">byrow=</span><span class="ot">TRUE</span>),<span class="dv">4</span>)[,<span class="dv">1</span><span class="op">:</span><span class="dv">8</span>] <span class="co"># display 1st 8 columns</span></a></code></pre></div>
<pre><code>##        [,1]   [,2]   [,3]   [,4]  [,5]   [,6]   [,7]   [,8]
## [1,] 0.0464 0.0477 0.0273 0.0263 0.001 0.0005 0.0003 0.0033
## [2,] 0.0012 0.0009 0.0000 0.0000 0.000 0.0513 0.0428 0.0648
## [3,] 0.0000 0.0000 0.0000 0.0000 0.000 0.0022 0.0038 0.0001</code></pre>

<p>Then we calculate for the normalizer - the joint probability of the <strong>Gaussian mixture</strong>.</p>

<div class="sourceCode" id="cb854"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb854-1" data-line-number="1">normalizer =<span class="st"> </span>weight.likelihd1 <span class="op">+</span><span class="st"> </span>weight.likelihd2 <span class="op">+</span><span class="st"> </span>weight.likelihd3</a>
<a class="sourceLine" id="cb854-2" data-line-number="2"><span class="kw">round</span>(normalizer,<span class="dv">3</span>)[<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>] <span class="co"># display 1st 10 columns</span></a></code></pre></div>
<pre><code>##  [1] 0.048 0.049 0.027 0.026 0.001 0.054 0.047 0.068 0.033 0.068</code></pre>

<p>Finally, we calculate the <strong>normalized posterior</strong> of each component. Let us show the posterior result of the 1st component.</p>

<div class="sourceCode" id="cb856"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb856-1" data-line-number="1">posterior1 =<span class="st"> </span>weight.likelihd1 <span class="op">/</span><span class="st"> </span>normalizer </a>
<a class="sourceLine" id="cb856-2" data-line-number="2">posterior2 =<span class="st"> </span>weight.likelihd2 <span class="op">/</span><span class="st"> </span>normalizer </a>
<a class="sourceLine" id="cb856-3" data-line-number="3">posterior3 =<span class="st"> </span>weight.likelihd3 <span class="op">/</span><span class="st"> </span>normalizer </a>
<a class="sourceLine" id="cb856-4" data-line-number="4"><span class="kw">round</span>(posterior1,<span class="dv">2</span>)[<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>] <span class="co"># display 1st 10 columns</span></a></code></pre></div>
<pre><code>##  [1] 0.97 0.98 1.00 1.00 1.00 0.01 0.01 0.05 0.00 0.03</code></pre>

<p>For <strong>Maximization step</strong>:</p>
<p>We first calculate the normalizer for <strong>mean</strong>, <strong>standard deviation</strong>, and <strong>prior weight</strong>.</p>

<div class="sourceCode" id="cb858"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb858-1" data-line-number="1">cnm1 =<span class="st"> </span>comp.normalizer1 =<span class="st"> </span><span class="kw">sum</span>( posterior1 )</a>
<a class="sourceLine" id="cb858-2" data-line-number="2">cnm2 =<span class="st"> </span>comp.normalizer2 =<span class="st"> </span><span class="kw">sum</span>( posterior2 )</a>
<a class="sourceLine" id="cb858-3" data-line-number="3">cnm3 =<span class="st"> </span>comp.normalizer3 =<span class="st"> </span><span class="kw">sum</span>( posterior3 )</a>
<a class="sourceLine" id="cb858-4" data-line-number="4"><span class="kw">c</span>(<span class="st">&quot;comp.norm1&quot;</span> =<span class="st"> </span>cnm1, <span class="st">&quot;comp.norm2&quot;</span> =<span class="st"> </span>cnm2, <span class="st">&quot;comp.norm3&quot;</span> =<span class="st"> </span>cnm3)</a></code></pre></div>
<pre><code>## comp.norm1 comp.norm2 comp.norm3 
##      5.047      4.330      5.623</code></pre>

<p>Then we calculate the parameter <strong>mean</strong> <span class="math inline">\(\mu_j^{(t=1)}\)</span> itself for each component at time=1 (or 1st iteration).</p>

<div class="sourceCode" id="cb860"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb860-1" data-line-number="1">mu1 =<span class="st"> </span><span class="kw">sum</span>( posterior1 <span class="op">*</span><span class="st"> </span>X ) <span class="op">/</span><span class="st"> </span>comp.normalizer1 </a>
<a class="sourceLine" id="cb860-2" data-line-number="2">mu2 =<span class="st"> </span><span class="kw">sum</span>( posterior2 <span class="op">*</span><span class="st"> </span>X ) <span class="op">/</span><span class="st"> </span>comp.normalizer2 </a>
<a class="sourceLine" id="cb860-3" data-line-number="3">mu3 =<span class="st"> </span><span class="kw">sum</span>( posterior3 <span class="op">*</span><span class="st"> </span>X ) <span class="op">/</span><span class="st"> </span>comp.normalizer3 </a>
<a class="sourceLine" id="cb860-4" data-line-number="4"><span class="kw">c</span>(<span class="st">&quot;mean1&quot;</span> =<span class="st"> </span>mu1, <span class="st">&quot;mean2&quot;</span> =<span class="st"> </span>mu2, <span class="st">&quot;mean3&quot;</span> =<span class="st"> </span>mu3)</a></code></pre></div>
<pre><code>## mean1 mean2 mean3 
## 23.36 30.79 34.89</code></pre>

<p>We do the same for standard deviation by calculating for <strong>sd</strong> <span class="math inline">\(\sigma_j^{(t=1)}\)</span>.</p>

<div class="sourceCode" id="cb862"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb862-1" data-line-number="1">sd1 =<span class="st"> </span><span class="kw">sum</span>( posterior1 <span class="op">*</span><span class="st"> </span>(X <span class="op">-</span><span class="st"> </span>mu1)<span class="op">^</span><span class="dv">2</span> ) <span class="op">/</span><span class="st"> </span>comp.normalizer1 </a>
<a class="sourceLine" id="cb862-2" data-line-number="2">sd2 =<span class="st"> </span><span class="kw">sum</span>( posterior2 <span class="op">*</span><span class="st"> </span>(X <span class="op">-</span><span class="st"> </span>mu2)<span class="op">^</span><span class="dv">2</span> ) <span class="op">/</span><span class="st"> </span>comp.normalizer2 </a>
<a class="sourceLine" id="cb862-3" data-line-number="3">sd3 =<span class="st"> </span><span class="kw">sum</span>( posterior3 <span class="op">*</span><span class="st"> </span>(X <span class="op">-</span><span class="st"> </span>mu3)<span class="op">^</span><span class="dv">2</span> ) <span class="op">/</span><span class="st"> </span>comp.normalizer3 </a>
<a class="sourceLine" id="cb862-4" data-line-number="4"><span class="kw">c</span>(<span class="st">&quot;sd1&quot;</span> =<span class="st"> </span>sd1, <span class="st">&quot;sd2&quot;</span> =<span class="st"> </span>sd2, <span class="st">&quot;mean3&quot;</span> =<span class="st"> </span>sd3)</a></code></pre></div>
<pre><code>##   sd1   sd2 mean3 
## 6.145 1.252 2.124</code></pre>

<p>We also re-calculate for the next value of our <strong>prior weights</strong> <span class="math inline">\(\omega_j^{(t=1)}\)</span>:</p>

<div class="sourceCode" id="cb864"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb864-1" data-line-number="1">w1 =<span class="st"> </span>comp.normalizer1 <span class="op">/</span><span class="st"> </span><span class="kw">length</span>(X) </a>
<a class="sourceLine" id="cb864-2" data-line-number="2">w2 =<span class="st"> </span>comp.normalizer2 <span class="op">/</span><span class="st"> </span><span class="kw">length</span>(X) </a>
<a class="sourceLine" id="cb864-3" data-line-number="3">w3 =<span class="st"> </span>comp.normalizer3 <span class="op">/</span><span class="st"> </span><span class="kw">length</span>(X) </a>
<a class="sourceLine" id="cb864-4" data-line-number="4"><span class="kw">c</span>(<span class="st">&quot;prior1&quot;</span> =<span class="st"> </span>w1, <span class="st">&quot;prior2&quot;</span> =<span class="st"> </span>w2, <span class="st">&quot;prior3&quot;</span> =<span class="st"> </span>w3)</a></code></pre></div>
<pre><code>## prior1 prior2 prior3 
## 0.3364 0.2887 0.3749</code></pre>

<p>After computing for <strong>mean</strong>, <strong>sd</strong>, and <strong>prior weight</strong> we continue to iterate until convergence.</p>
<p>Below is an example of <strong>EM</strong> in R code (Here, we change the sample size to 500). Note that the implementation and samples are based on <strong>gaussian distribution</strong>.</p>



<div class="sourceCode" id="cb866"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb866-1" data-line-number="1">expectation &lt;-<span class="st"> </span><span class="cf">function</span>(X, theta, W) {</a>
<a class="sourceLine" id="cb866-2" data-line-number="2">  posterior =<span class="st"> </span><span class="kw">matrix</span>(<span class="dv">0</span>, <span class="dt">nrow=</span>k, <span class="dt">ncol=</span>n, <span class="dt">byrow=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb866-3" data-line-number="3">  normalizer =<span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb866-4" data-line-number="4">  <span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>k) {</a>
<a class="sourceLine" id="cb866-5" data-line-number="5">    posterior[j,] =<span class="st"> </span><span class="kw">norm.prob</span>(X, <span class="dt">mean=</span> theta[j,<span class="dv">1</span>], </a>
<a class="sourceLine" id="cb866-6" data-line-number="6">                              <span class="dt">sd =</span> theta[j,<span class="dv">2</span>]) <span class="op">*</span><span class="st"> </span>W[j]</a>
<a class="sourceLine" id="cb866-7" data-line-number="7">    normalizer =<span class="st"> </span>normalizer <span class="op">+</span><span class="st"> </span>posterior[j,]</a>
<a class="sourceLine" id="cb866-8" data-line-number="8">  }</a>
<a class="sourceLine" id="cb866-9" data-line-number="9">  <span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>k) {</a>
<a class="sourceLine" id="cb866-10" data-line-number="10">    posterior[j,] =<span class="st"> </span>posterior[j,] <span class="op">/</span><span class="st"> </span>normalizer</a>
<a class="sourceLine" id="cb866-11" data-line-number="11">  }</a>
<a class="sourceLine" id="cb866-12" data-line-number="12">  <span class="kw">list</span>(<span class="st">&quot;posterior&quot;</span> =<span class="st"> </span>posterior, <span class="st">&quot;loglik&quot;</span> =<span class="kw">sum</span>(<span class="kw">log</span>(normalizer, <span class="kw">exp</span>(<span class="dv">1</span>))))</a>
<a class="sourceLine" id="cb866-13" data-line-number="13">}</a>
<a class="sourceLine" id="cb866-14" data-line-number="14">maximization &lt;-<span class="st"> </span><span class="cf">function</span>(X, posterior ) { </a>
<a class="sourceLine" id="cb866-15" data-line-number="15">  comp.normalizer =<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, k)</a>
<a class="sourceLine" id="cb866-16" data-line-number="16">  mu =<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, k); var =<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, k); W =<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, k)</a>
<a class="sourceLine" id="cb866-17" data-line-number="17">  <span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>k) { </a>
<a class="sourceLine" id="cb866-18" data-line-number="18">    comp.normalizer[j] =<span class="st"> </span><span class="kw">sum</span>( posterior[j,] )</a>
<a class="sourceLine" id="cb866-19" data-line-number="19">    mu[j] =<span class="st"> </span><span class="kw">sum</span>( posterior[j,] <span class="op">*</span><span class="st"> </span>X ) <span class="op">/</span><span class="st"> </span>comp.normalizer[j] </a>
<a class="sourceLine" id="cb866-20" data-line-number="20">    var[j] =<span class="st"> </span><span class="kw">sum</span>( posterior[j,] <span class="op">*</span><span class="st"> </span></a>
<a class="sourceLine" id="cb866-21" data-line-number="21"><span class="st">                        </span>(X <span class="op">-</span><span class="st"> </span>mu[j])<span class="op">^</span><span class="dv">2</span> ) <span class="op">/</span><span class="st"> </span>comp.normalizer[j] </a>
<a class="sourceLine" id="cb866-22" data-line-number="22">    W[j]  =<span class="st"> </span>comp.normalizer[j] <span class="op">/</span><span class="st"> </span><span class="kw">length</span>(X)</a>
<a class="sourceLine" id="cb866-23" data-line-number="23">  }</a>
<a class="sourceLine" id="cb866-24" data-line-number="24">  theta =<span class="st"> </span><span class="kw">matrix</span>( <span class="kw">c</span>(mu, <span class="kw">sqrt</span>(var)), <span class="dt">nrow=</span>k, <span class="dt">byrow=</span><span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb866-25" data-line-number="25">  <span class="kw">list</span>(<span class="st">&quot;theta&quot;</span>=theta, <span class="st">&quot;W&quot;</span>=<span class="st"> </span>W)</a>
<a class="sourceLine" id="cb866-26" data-line-number="26">}</a>
<a class="sourceLine" id="cb866-27" data-line-number="27">iterate &lt;-<span class="st"> </span><span class="cf">function</span>(x, theta, <span class="dt">limit=</span><span class="dv">1000</span>) {</a>
<a class="sourceLine" id="cb866-28" data-line-number="28">  tol =<span class="st"> </span><span class="fl">1e-10</span>; err =<span class="st"> </span>loglik.old =<span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb866-29" data-line-number="29">  sequence =<span class="st"> </span><span class="kw">matrix</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">2</span><span class="op">*</span>k <span class="op">+</span><span class="st"> </span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb866-30" data-line-number="30">  <span class="cf">for</span> (t <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>limit) {</a>
<a class="sourceLine" id="cb866-31" data-line-number="31">    component &lt;-<span class="st"> </span><span class="kw">expectation</span>(x, theta, W)        <span class="co"># new posterior</span></a>
<a class="sourceLine" id="cb866-32" data-line-number="32">    model =<span class="st"> </span><span class="kw">maximization</span>(X, component<span class="op">$</span>posterior) <span class="co"># new model parameters </span></a>
<a class="sourceLine" id="cb866-33" data-line-number="33">    loglik =<span class="st"> </span>component<span class="op">$</span>loglik</a>
<a class="sourceLine" id="cb866-34" data-line-number="34">    err =<span class="st"> </span><span class="kw">abs</span> ( loglik <span class="op">-</span><span class="st"> </span>loglik.old )</a>
<a class="sourceLine" id="cb866-35" data-line-number="35">    sequence =<span class="st"> </span><span class="kw">rbind</span>(sequence, <span class="kw">c</span>(t, <span class="kw">round</span>(theta[,<span class="dv">1</span>],<span class="dv">2</span>), </a>
<a class="sourceLine" id="cb866-36" data-line-number="36">                                 <span class="kw">round</span>(theta[,<span class="dv">2</span>],<span class="dv">2</span>), err ))</a>
<a class="sourceLine" id="cb866-37" data-line-number="37">    <span class="cf">if</span> ( err <span class="op">&lt;</span><span class="st"> </span>tol ) { <span class="cf">break</span> }</a>
<a class="sourceLine" id="cb866-38" data-line-number="38">    theta =<span class="st"> </span>model<span class="op">$</span>theta  <span class="co"># old model parameter update</span></a>
<a class="sourceLine" id="cb866-39" data-line-number="39">    W =<span class="st"> </span>model<span class="op">$</span>W          <span class="co"># old prior update</span></a>
<a class="sourceLine" id="cb866-40" data-line-number="40">    loglik.old =<span class="st"> </span>loglik  <span class="co"># old likelihood update</span></a>
<a class="sourceLine" id="cb866-41" data-line-number="41">  }</a>
<a class="sourceLine" id="cb866-42" data-line-number="42">  <span class="kw">colnames</span>(sequence) =<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Iteration&quot;</span>, <span class="kw">paste0</span>(<span class="st">&quot;mu&quot;</span>, <span class="kw">seq</span>(<span class="dv">1</span>,k)), </a>
<a class="sourceLine" id="cb866-43" data-line-number="43">                         <span class="kw">paste0</span>(<span class="st">&quot;sd&quot;</span>, <span class="kw">seq</span>(<span class="dv">1</span>,k)), <span class="st">&quot;error&quot;</span> )</a>
<a class="sourceLine" id="cb866-44" data-line-number="44">  iteration =<span class="st"> </span><span class="kw">as.data.frame</span>( <span class="kw">tail</span>( sequence))</a>
<a class="sourceLine" id="cb866-45" data-line-number="45">  <span class="kw">list</span>(<span class="st">&quot;theta&quot;</span>=theta, <span class="st">&quot;iteration&quot;</span>=iteration, </a>
<a class="sourceLine" id="cb866-46" data-line-number="46">       <span class="st">&quot;posterior&quot;</span> =<span class="st"> </span>component<span class="op">$</span>posterior)</a>
<a class="sourceLine" id="cb866-47" data-line-number="47">}</a></code></pre></div>

<p>By executing the <strong>EM steps</strong>, we can iterate and converge with an optimized value for <strong>mean</strong> and <strong>standard deviation</strong> parameters. Note that parameters are more optimized with more observations.</p>

<div class="sourceCode" id="cb867"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb867-1" data-line-number="1">em =<span class="st"> </span><span class="kw">iterate</span>(X, theta, <span class="dt">limit=</span><span class="dv">1000</span>)</a>
<a class="sourceLine" id="cb867-2" data-line-number="2">em<span class="op">$</span>iteration</a></code></pre></div>
<pre><code>##        Iteration   mu1   mu2   mu3  sd1  sd2  sd3     error
## [180,]       180 24.96 29.92 34.95 2.14 1.32 1.57 1.601e-10
## [181,]       181 24.96 29.92 34.95 2.14 1.32 1.57 1.446e-10
## [182,]       182 24.96 29.92 34.95 2.14 1.32 1.57 1.291e-10
## [183,]       183 24.96 29.92 34.95 2.14 1.32 1.57 1.155e-10
## [184,]       184 24.96 29.92 34.95 2.14 1.32 1.57 1.037e-10
## [185,]       185 24.96 29.92 34.95 2.14 1.32 1.57 9.277e-11</code></pre>

<p>Also, we can now perform stratification by classifying each observation according to the component it belongs. The table below shows the number of observations and proportions belonging to each component after the <strong>EM iteration</strong>.</p>

<div class="sourceCode" id="cb869"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb869-1" data-line-number="1">classify &lt;-<span class="st"> </span><span class="cf">function</span>(theta, posterior) {</a>
<a class="sourceLine" id="cb869-2" data-line-number="2">    component =<span class="st"> </span><span class="kw">apply</span>(posterior, <span class="dv">2</span>, which.max)</a>
<a class="sourceLine" id="cb869-3" data-line-number="3">    strata =<span class="st"> </span><span class="kw">table</span> (component) <span class="co"># groupings or classes</span></a>
<a class="sourceLine" id="cb869-4" data-line-number="4">    model =<span class="st"> </span><span class="kw">cbind</span>(theta, strata, strata <span class="op">/</span><span class="st"> </span>n)</a>
<a class="sourceLine" id="cb869-5" data-line-number="5">    <span class="kw">colnames</span>(model) =<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;mean&quot;</span>, <span class="st">&quot;sd&quot;</span>, <span class="st">&quot;count&quot;</span>, <span class="st">&quot;proportion&quot;</span>)</a>
<a class="sourceLine" id="cb869-6" data-line-number="6">    <span class="kw">rownames</span>(model) =<span class="st"> </span>Y <span class="co"># components</span></a>
<a class="sourceLine" id="cb869-7" data-line-number="7">    <span class="kw">round</span>( model, <span class="dv">2</span>)</a>
<a class="sourceLine" id="cb869-8" data-line-number="8">    <span class="kw">list</span>(<span class="st">&quot;model&quot;</span>=model, <span class="st">&quot;component&quot;</span>=component)</a>
<a class="sourceLine" id="cb869-9" data-line-number="9">}</a>
<a class="sourceLine" id="cb869-10" data-line-number="10">classified =<span class="st"> </span><span class="kw">classify</span>(em<span class="op">$</span>theta, em<span class="op">$</span>posterior)</a>
<a class="sourceLine" id="cb869-11" data-line-number="11">classified<span class="op">$</span>model</a></code></pre></div>
<pre><code>##    mean    sd count proportion
## A 24.96 2.142   492     0.3280
## B 29.92 1.320   488     0.3253
## C 34.95 1.570   520     0.3467</code></pre>

<p>Finally, we also can show how the proportions are broken down into their <strong>Gaussian components</strong>. See Figure <a href="bayesian.html#fig:mixturecomponents1">7.17</a>.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:mixturecomponents1"></span>
<img src="DS_files/figure-html/mixturecomponents1-1.png" alt="Four mixture densities" width="70%" />
<p class="caption">
Figure 7.17: Four mixture densities
</p>
</div>

<p>We leave readers to experiment on <strong>EM</strong> by using other parameter models of other familiar distributions.</p>
</div>
<div id="variational-inference" class="section level3 hasAnchor">
<h3><span class="header-section-number">7.6.5</span> Variational Inference <a href="bayesian.html#variational-inference" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In a previous section, we used <strong>Laplace approximation</strong> to estimate our posterior with ease. That is possible only because the problem statement in our case involves a unimodal Gaussian distribution that may be easy to compute. Also, in the last section, we use <strong>Expectation-Maximization</strong> to solve for a more complex distribution; and that is possible only because the problem statement allows for a tractable posterior. However, if our Gaussian mixture distribution consists of a larger number of components with a larger number of observations than as seen in Figure <a href="bayesian.html#fig:mixturecomponents1">7.17</a>, then the <strong>marginal likelihood</strong> - the denominator in the Bayes theorem - becomes intractable. The equation below demonstrates the intractability of the <strong>marginal likelihood</strong> <span class="citation">(Blei D et al., <a href="bibliography.html#ref-ref393d">n.d.</a>)</span>:</p>

<p><span class="math display">\[\begin{align}
P(\mu_{1:k}, y_{1:n}|x_{1:n}) =
\frac{\prod_{j=1}^kP(\mu_j) \prod_{i=1}^n P(y_i)P(x_i|y_i,\mu_{1:k})}
{\int_{\mu_{1:k}}\sum_{y_{1:n}} \prod_{j=1}^k P(\mu_j)\prod_{i=1}^nP(y_i)P(x_i|y_i,\mu_{1:k})}
\end{align}\]</span>
</p>
<p>Consequently, our <strong>posterior distribution</strong> is rendered intractable. That is also true if none of the standard <strong>Conjugacy</strong> methods apply, otherwise allowing us to compute for the <strong>posterior distribution</strong> exactly (in closed-form).</p>
<p>Additionally, the inference techniques discussed in previous sections, such as <strong>MLE</strong> and <strong>MAP</strong>, fail to operate on complex models. Therefore, it behooves us to find other techniques in mitigating the challenge.</p>
<p>Here, we introduce <strong>Variational Bayes</strong>. Note that our discussion references some of the works of Bishop C.M <span class="citation">(<a href="bibliography.html#ref-ref482c">2006</a>)</span>, Blei D. et al. <span class="citation">(<a href="bibliography.html#ref-ref381d">2017</a>)</span>, and C.W., Roberts S.J. <span class="citation">(<a href="bibliography.html#ref-ref1048f">2012</a>)</span>. </p>
<p>The motivation in this section is to find an <strong>approximating distribution</strong> denoted as <span class="math inline">\(\mathcal{Q}(y)\)</span> to eventually take the place of our intractable <strong>posterior distribution</strong> denoted as <span class="math inline">\(P(y|x)\)</span>. In the context of <strong>Bayesian inference</strong>, also referenced as <strong>variational inference (VI)</strong>, this approximating distribution is also called <strong>variational distribution</strong> with parameters optimized based on an approach different from one offered by <strong>Laplace approximation</strong> for reasons that become apparent later.</p>
<p>One essential concept in this section is the <strong>Bayesian Network</strong>, which depicts the dependency between variables. For example, Figure <a href="bayesian.html#fig:bayesnetwork">7.18</a> demonstrates a joint probability that follows the product rule <span class="citation">(Nguyen L. <a href="bibliography.html#ref-ref948l">2013</a>; Horny M. <a href="bibliography.html#ref-ref939m">2014</a>)</span>.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:bayesnetwork"></span>
<img src="bayesnetwork.png" alt="Bayesian Network" width="80%" />
<p class="caption">
Figure 7.18: Bayesian Network
</p>
</div>

<p>Let us now discuss how <strong>variational Bayes</strong> works.</p>
<p><strong>First</strong>, our goal is essentially to develop a model for our inference. This model represents a family of distributions. We define this family of distributions <strong>depending on the problem statement</strong>. In our case, let us scheme to use a model that involves a multivariate Gaussian mixture distribution:</p>

<p><span class="math display">\[\begin{align*}
\underbrace{x_i|y_i \sim \mathcal{N}_p(\mu_k, \Lambda_k)}_\text{observed variable}
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \
\underbrace{y_i  \sim Multi(n,\pi_k)}_\text{latent variable}
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \
\underbrace{\pi_k \sim Dirichlet(\omega_0)}_\text{mixing weight/coefficient}\\
\end{align*}\]</span></p>
<p><span class="math display">\[\begin{align*}
\underbrace{\mu_k\ \sim \mathcal{N}_p(\alpha_0, \beta_0) }_\text{1st latent conjugate prior}
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \
\underbrace{\Lambda_k\ \sim Wishart(\nu_0, \Sigma_0) }_\text{2nd latent conjugate prior}
\end{align*}\]</span>
</p>
<p>where <span class="math inline">\(\beta_0\)</span> is scaling factor, <span class="math inline">\(\pi_k\)</span> is a <strong>mixture coefficient</strong>, and <span class="math inline">\(\Lambda_k\)</span> is a <strong>positive-definite precision matrix</strong>.</p>
<p>The observed variable, namely <strong>x</strong>, has a corresponding latent (classifying) variable, namely <strong>y</strong>, which contains a hot-encoding of a binary vector of K-size, namely <span class="math inline">\(\mathbf{\tau_k}\)</span> (to be further explained), describing which cluster each corresponding observation belongs.</p>
<p>We also can revisit Figure <a href="bayesian.html#fig:bayestheorem">7.1</a> discussed in <strong>Bayes Theorem</strong> section as reference along with Figure <a href="bayesian.html#fig:mixturebayes">7.19</a> for two models. Albeit here, we operate on <strong>p-variate</strong> gaussian mixture models.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:mixturebayes"></span>
<img src="mixturebayes.png" alt="Multivariate Gaussian Mixture Model" width="70%" />
<p class="caption">
Figure 7.19: Multivariate Gaussian Mixture Model
</p>
</div>

<p>From Figure <a href="bayesian.html#fig:mixturebayes">7.19</a>, the <strong>Bayesian model</strong> captures five hyperparameters, namely <span class="math inline">\(\{\ \omega_0, \alpha_0, (\beta_0\Lambda_k), \nu_0, \Sigma_0 \}\)</span>, for which we calculate the corresponding <strong>conjugacy</strong>. Note here that we assume a conjugacy relationship between parameters, hinting at a closed-form solution for our model, which is useful.</p>
<p>In <strong>Bayesian Network</strong> notation, the dependency in the <strong>Bayesian model</strong> (excluding hyperparameters) is written as: </p>

<p><span class="math display">\[\begin{align}
P(x_i, y_i, \pi_k, \mu_k, \Lambda_k) {}&amp;= P(x_i | y_i, \mu_k, \Lambda_k)   &amp; x_i \text{ depends on } \{y_i, \mu_k, \Lambda_k \} \nonumber \\
&amp;\times P(y_i|\pi_k)   &amp; y_i \text{ depends on } \{\pi_k \} \nonumber \\
&amp;\times P(\pi_k) \nonumber \\
&amp;\times P(\mu_k|\Lambda_k)   &amp; \mu_k \text{ depends on } \{\Lambda_k \} \nonumber \\
&amp;\times P(\Lambda_k) 
\end{align}\]</span>
</p>
<p>For posterior distribution with <span class="math inline">\(\mu_k\)</span> and <span class="math inline">\(\Lambda_k\)</span> being both unknown, recall the derivation for a <strong>normal-Wishart</strong> conjugacy we made in the <strong>Conjugacy</strong> section:</p>

<p><span class="math display">\[\begin{align}
\mu_k, \Lambda_k|x\sim \ \mathcal{NW}_p(\alpha_1, \beta_1, \nu_1,\Sigma_1) 
= \mathcal{N}_p(\alpha_1, \beta_1)\times\mathcal{W}_p(\nu_1, \Sigma_1)
\end{align}\]</span>
</p>
<p>obtaining the following parameters:</p>

<p><span class="math display">\[\begin{align}
\alpha_1 &amp;=  \frac{(\alpha_0\beta_0 + n\bar{x})}{(\beta_0 + n)}\\
\beta_1 &amp;= \beta_0 + n \\
\nu_1 {}&amp;= \nu_0 + n \\
\Sigma_1 &amp;=  \frac{ n\beta_0}{(\beta_0 + n)}(\bar{x} - \alpha_0)( \bar{x} - \alpha_0 )^T + S  + \Sigma_0^{-1} 
\end{align}\]</span>
</p>
<p>In the case in which <span class="math inline">\(\mu_k\)</span> is known and <span class="math inline">\(\Lambda_k\)</span> is unknown, we can use the <strong>normal inverse Wishart</strong> conjugacy instead:</p>

<p><span class="math display">\[\begin{align}
\mu_k|x\sim \ \mathcal{N}_p(\alpha_1, \beta_1)\ \ \ \ \ \ 
\Lambda_k|x\sim \ \mathcal{IW}_p(\nu_1, \Sigma_1)
\end{align}\]</span>
</p>
<p>obtaining the following parameters:</p>

<p><span class="math display">\[\begin{align}
\Sigma_1 = (\Sigma_0 + \Sigma)^{-1}\ \ \ \ \ \ \ \ \nu_1 = \nu_0 + n 
\end{align}\]</span>
</p>
<p>For the posterior distribution of our category, <span class="math inline">\(\pi_k\)</span>, let us recall the derivation for a multinomial-Dirichlet conjugacy:</p>

<p><span class="math display">\[\begin{align}
\pi_k \sim \mathcal{Dir}\left(\omega_1\right) = \frac{1}{\mathcal{B}\left(\omega_1\right)}\prod_{k=1}^K x_i^{\omega_1-1}
\end{align}\]</span>
</p>
<p>obtaining the following:</p>

<p><span class="math display">\[\begin{align}
\omega_1 = \sum_{i=1}^k\left(x_i + \omega_0\right)
\end{align}\]</span>
</p>
<p>A natural step to take here is to initialize the hyperparameters and iteratively optimize the model parameters <span class="math inline">\(\{\ \pi_k, \mu_k, \Lambda_k\ \}\)</span>, including the latent variable <strong>y</strong>. We have shown this in the <strong>Expectation-Maximization</strong> section. However, to illustrate <strong>variational inference</strong>, let us skip the <strong>analytical operations</strong> and the dependency to <strong>conjugate</strong> priors. Instead, we move on to the <strong>Mean-Field modeling</strong> for approximation.</p>
<p>For the <strong>Mean-Field model</strong>, the family of distributions above forms our <strong>variational distribution</strong> that approximates our true <strong>posterior</strong> such that <span class="math inline">\(P(y,\pi, \mu, \Lambda |x) \approx \mathcal{Q}(y,\pi, \mu, \Lambda)\)</span>. For mathematical convenience, let us temporarily use <strong>z</strong> as placeholder for <span class="math inline">\(\{\ y, \pi, \mu, \Lambda\ \}\)</span> so that we have the following: </p>

<p><span class="math display">\[\begin{align}
P(z|x) \approx \mathcal{Q}(z)\ \ \ \ \leftarrow\ \ \ \ \ P(y,\pi, \mu, \Lambda |x) \approx \mathcal{Q}(y,\pi, \mu, \Lambda).
\end{align}\]</span>
</p>
<p>Then, to generalize, we factorize into a simpler tractable granular composition (a factor) such that we have the following:</p>

<p><span class="math display">\[\begin{align}
\mathcal{Q}(z) = \prod_{j=1} \mathcal{Q}_i(z_i)
\end{align}\]</span>
</p>
<p>That is called <strong>mean-field variational family</strong> <span class="citation">(Blei D. et al. <a href="bibliography.html#ref-ref381d">2017</a>)</span>. We explain the reason for factorization in a few steps.</p>
<p>It is important to assume that the latent variable and its parameters are independent (by virtue of mean-field variational property), and so we can model a joint distribution - <strong>our variational distribution</strong> - like so:</p>

<p><span class="math display">\[\begin{align}
\mathcal{Q}(z)  = \mathcal{Q}(y,\pi, \mu, \Lambda ) = 
\prod_{i=1}^N \mathcal{Q}_y(y_i) \times \prod_{k=1}^K\left[\mathcal{Q}_\pi(\pi_k) \times \mathcal{Q}_\mu(\mu_k)\times\mathcal{Q}_{\Lambda}\left(\Lambda_k\right)\right] 
\end{align}\]</span>
</p>
<p><strong>Second</strong>, because our objective is to optimize our <strong>variational distribution</strong>, we need to <strong>develop an objective function</strong> that we can maximize. Let us show a couple of derivations that we need later for our inference. We start by deriving a <strong>variational lower bound</strong> equation, also called <strong>evidence lower bound (ELBO)</strong>, and a <strong>KL divergence</strong> equation <span class="citation">(Yang X. <a href="bibliography.html#ref-ref1057x">2017</a>)</span>. Both are derived from the <strong>marginal likelihood</strong> factor in the <strong>Bayes Theorem</strong> - the <strong>evidence</strong>. </p>

<p><span class="math display">\[\begin{align}
P(x) {}&amp;= \int_z P(x, z)\ dz &amp; \text{(marginal/sum rule)}\\
\log_e P(x) &amp;= \log_e \int_z P(x, z)\ dz &amp; \text{(logarithm)}\\
&amp;= \log_e \int_z \frac{\mathcal{Q}(z)}{\mathcal{Q}(z)}  P(x,z)\ dz &amp;  \text{(variational distribution)}\\
&amp;\equiv \log_e\left(\mathbb{E}_{\mathcal{Q}(z)} \frac{P(x,z)}{\mathcal{Q}(z)}\right) &amp; \text{(expectation)}\\
&amp;\ge \mathbb{E}_{\mathcal{Q}(z)} \left( \log_e \frac{P(x,z)}{\mathcal{Q}(z)}\right) &amp; \text{(jensen&#39;s inequality)}
\end{align}\]</span></p>
<p><span class="math display">\[\begin{align}
&amp; \text{(focus on the equal sign of the inequality,} &amp; \nonumber \\
&amp; \text{extract the lower bound)} &amp; \nonumber \\
\nonumber \\
\mathcal{LB}[Q(z)] &amp;= \mathbb{E}_{\mathcal{Q}(z)} \left( \log_e \frac{P(x,z)}{\mathcal{Q}(z)}\right)\ \ \ \ (\text{lower bound - } \mathbf{\text{ELBO}})\\
&amp;\equiv \int_z {\mathcal{Q}(z)} \left( \log_e \frac{P(x,z)}{\mathcal{Q}(z)}\right) dz &amp; \text{(equivalent)}\\
&amp;= \int_z {\mathcal{Q}(z)} \left( \log_e \frac{P(z|x)P(x)}{\mathcal{Q}(z)}\right) dz &amp; \text{(chain rule)}\\
&amp;= \int_z {\mathcal{Q}(z)} \left( \log_e \frac{P(z|x)}{\mathcal{Q}(z)}  +
 \log_e P(x)\right) dz &amp; \text{(simplify)}\\
&amp;= \underbrace{\int_z \mathcal{Q}(z)  \log_e \frac{P(z|x)}{\mathcal{Q}(z)}\ dz }_\text{-KL divergence} +
 \underbrace{\int_z  \mathcal{Q}(z) \log_e P(x)\  dz }_\text{marginal log likelihood} &amp; \text{(logarithm)}\\
\nonumber \\
\mathcal{LB}[Q(z)] &amp;=  -KL(\mathcal{Q}(z) || P(z|x)) + \log_e  P(x) &amp; \text{(ELBO eq. 1)}\\
\nonumber \\
\mathcal{KL}(\mathcal{Q}(z) || P(z|x))  &amp;=   -\mathcal{LB}[Q(z)] + \log_e  P(x) &amp; \text{(KL divergence)}
\end{align}\]</span>
</p>
<p>The second term in the <strong>ELBO</strong> equation can be treated as a constant, and because it is independent of the <strong>approximating distribution</strong>, it can therefore be ignored.</p>
<p>Note that the <strong>lower bound (ELBO)</strong> is a functional expression as it accepts a probability function, namely <span class="math inline">\(Q(z)\)</span>.</p>
<p>We now have an <strong>objective function</strong> we can use in the form of the <strong>ELBO</strong>. Both <strong>ELBO</strong> and <strong>KL divergence</strong> can be used as an objective function. See below.</p>

<p><span class="math display">\[\begin{align}
\mathcal{LB}(\mathcal{Q}(z)) = \int_z {\mathcal{Q}(z)} \left( \log_e \frac{P(x,z)}{\mathcal{Q}(z)}\right) dz
\ \ \ \ \ \ \ \ \
\mathcal{KL}(\mathcal{Q}(z)||\mathcal{Q}(z|x)) = 
- \int_z \mathcal{Q}(z)  \log_e \frac{P(z|x)}{\mathcal{Q}(z)}\ dz
\end{align}\]</span>
</p>
<p>By maximizing <strong>ELBO</strong>, we are effectively minimizing <strong>KL divergence</strong> which means that our <strong>variational distribution</strong> is closer to our <strong>posterior</strong>, e.g. <span class="math inline">\(\mathcal{Q}(z) \approx P(z|x)\)</span>. See Figure <a href="bayesian.html#fig:tightbound">7.20</a> for the balance:</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:tightbound"></span>
<img src="tightbound.png" alt="KL Divergence vs Lower Bound" width="70%" />
<p class="caption">
Figure 7.20: KL Divergence vs Lower Bound
</p>
</div>

<p>However, notice that the <strong>KL divergence</strong> has a conditional distribution that can potentially be intractable. That also effectively renders <strong>ELBO</strong> intractable.</p>
<p>Let us show an alternative <strong>ELBO</strong> measurement. We use <strong>Entropy</strong> over <strong>KL divergence</strong>, which we can also derive from the lower bound. We avoid the use of the chain rule in what follows.</p>

<p><span class="math display">\[\begin{align}
\mathcal{LB}[Q(z)] {}&amp;= \int_z {\mathcal{Q}(z)} \left( \log_e \frac{P(x,z)}{\mathcal{Q}(z)}\right) dz &amp; \text{(lower bound)}\\
&amp;= \int_z \mathcal{Q}(z) \left( \log_e  P(x,z) - \log_e \mathcal{Q}(z)  \right) \ dz &amp; \text{(logarithm rule)}\\
&amp;= \underbrace{\int_z \mathcal{Q}(z)\log_e P(x,z)\ dz}_\text{expected energy}\ 
  \underbrace{-\int_z \mathcal{Q}(z)\log_e \mathcal{Q}(z) \ dz}_\text{Entropy} &amp; \text{(simplify)}\\
\nonumber \\
\mathcal{LB}[Q(z)] &amp;= \mathbb{E}_{Q(z)}\left[\log_e P(x,z)\right] + \mathcal{H}(z) &amp; \text{(ELBO eq. 2)}
\end{align}\]</span>
</p>
<p><strong>Third</strong>, now that we have an objective function in the form of <strong>ELBO eq. 2</strong>, we also need to generate an <strong>update function</strong> to optimize our model parameters. That is where we need to perform more derivation. So let us expand <strong>ELBO eq. 2</strong> <span class="citation">(Yuling Yao et al <a href="bibliography.html#ref-ref457y">2018</a>; Keng B. <a href="bibliography.html#ref-ref443b">2018</a>)</span>.</p>

<p><span class="math display">\[\begin{align}
{}&amp;\mathcal{LB}[Q(z)] = \mathbb{E}_{Q(z)}(P(x,z)) + \mathcal{H}(z) \\
&amp;= \int_z \mathcal{Q}(z)\log_e P(x,z)\ dz -\int_z \mathcal{Q}(z)\log_e \mathcal{Q}(z) \ dz\\
&amp;= \int_z \prod_{i=1} \mathcal{Q_i}(z_i)\log_e P(x,z)\ dz -\int_z \prod_{i=1} \mathcal{Q_i}(z_i)\log_e \prod_{i=1} \mathcal{Q_i}(z_i) \ dz &amp; \text{(mean-field assumption)}\\
&amp;\rightarrow  \prod_{i=1} \mathcal{Q}_i(z_i) = \mathcal{Q}_j(z_j) \times \prod_{i \ne j} \mathcal{Q}_i(z_i) &amp; \text{(extract jth component)}
\end{align}\]</span></p>
<p><span class="math display">\[\begin{align}
&amp;= \int_{z_j}  \mathcal{Q}_j(z_j) \int_{z_{-j}} \left[ \prod_{i \ne j} \mathcal{Q}_i(z_i) \log_e P(x,z)  \right] d_{z_{-j}} d_{z_j} &amp; \text{(notation:} -j \equiv i\ne j ) \nonumber \\
&amp;-  \int_{z_j} \mathcal{Q}_j(z_j) \int_{z_{-j}} \prod_{i \ne j} \mathcal{Q}_i(z_i) \left( \log_e \mathcal{Q}_j(z_j) + \log_e \prod_{i \ne j} \mathcal{Q}_i(z_i)\right)  d_{z_{-j}}d_{z_j}\\
&amp;\rightarrow \int_{z_{-j}} \ \prod_{i \ne j} \mathcal{Q}_i(z_i) d_{z_{-j}} = 1 &amp; \text{(simplify)}\\
&amp;\rightarrow \int_{z_{-j}} \ \prod_{i \ne j} \mathcal{Q}_i(z_i) \log_e \prod_{-j} \mathcal{Q}_i(z_i) d_{z_{i\ne j}} = const &amp; \text{(simplify)}\\
&amp;= \int_{z_j}  \mathcal{Q}_j(z_j) \mathbb{E}_{Q_{z_{i\ne j}}} \left( \log_e P(x,z) \right)  d_{z_j}   &amp; \text{(expectation)} \nonumber \\
&amp;-  \int_{z_j} \mathcal{Q}_j(z_j)  \left( \log_e \mathcal{Q}_j(z_j) + const \right)d_{z_j}\\
\nonumber \\
&amp;= \int_{z_j} \mathcal{Q}_j(z_j) \left(\mathbb{E}_{Q_{z_{i\ne j}}}(\log_e P(x,z)) -  \log_e \mathcal{Q}_j(z_j)\right) dz_j &amp; \text{(factorized ELBO)}
\end{align}\]</span>
</p>
<p>Notice that we have factorized the lower bound. We also can generate the factorized version of the <strong>KL divergence</strong> (which we may not be using in our discussion):</p>

<p><span class="math display">\[\begin{align}
\mathcal{LB}[\mathcal{Q}(z)]
&amp;= \int_{z_j} \mathcal{Q}_j(z_j) \log_e \frac{\mathbb{E}_{Q_{z_{i\ne j}}}(\log_e P(x,z)) } {\mathcal{Q}_j(z_j)} dz_j &amp; \text{(-KL divergence)}\\
&amp;= -KL(\mathcal{Q}_j(z_j)||\mathbb{E}_{Q_{z_{i\ne j}}}(\log_e P( x,z)) )
\end{align}\]</span>
</p>
<p>To get the <strong>update function</strong>, we maximize the factors. We use <strong>Lagrange multiplier</strong> and partial derivative with respect to the function <span class="math inline">\(\mathcal{Q}_j\)</span> to extract (formulate) the equation for any arbitrary jth component - this uses <strong>functional differential</strong>:</p>

<p><span class="math display">\[\begin{align}
\frac{ \partial\ \mathcal{LB}[\mathcal{Q_j}(z_j)]}{\partial\ \mathcal{Q}_j(z_j)} {}&amp;\equiv
\frac{ \partial}{\partial\ \mathcal{Q}_j(z_j)} \left[ \int_{z_j} \mathcal{Q}_j(z_j) \left(\mathbb{E}_{Q_{z_{i \ne j}}}(\log_e P(x,z)) -  \log_e \mathcal{Q}_j(z_j)\right) dz_j  \right] =  0\\
&amp;\equiv \mathbb{E}_{Q_{z_{i \ne j}}}(\log_e P(x,z)) - \log_e \mathcal{Q}_j(z_j) - 1 = 0 
\nonumber\\
&amp;\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \text{(entropy functional derivative)}\\
&amp;\equiv exp\left[\mathbb{E}_{Q_{z_{i \ne j}}}(\log_e P(x,z)) - \log_e \mathcal{Q}_j(z_j)  \right] = const \ \ \  \text{(exp-log)}\\
&amp;\equiv exp\ \mathbb{E}_{Q_{z_{i \ne j}}}(\log_e P(x,z)) -  \mathcal{Q}_j(z_j)  ) = const\ \ \  \text{(exp-log)}\\
\nonumber \\
\mathcal{Q}_j(z_j) &amp;\propto exp\left[\mathbb{E}_{Q_{z_{i \ne j}}}(\log_e P(x,z))\right] + const\\
&amp;\propto exp\left[\mathbb{E}_{Q_{z_{i \ne j}}}(\log_e P(x,z))\right] + const\ \ \ \ \text{(factorized; mean-field property)}
\end{align}\]</span>
</p>
<p>Herein lies a template for our <strong>update function</strong> that we can use to update individual factors.</p>

<p><span class="math display">\[\begin{align}
\mathcal{Q}_j(z_j) \propto exp\left[\mathbb{E}_{Q_{z_{i \ne j}}}(\log_e P(x,z))\right] + const
\end{align}\]</span>
</p>
<p>Equivalently, we have the following expectation equation for the log factor:</p>

<p><span class="math display">\[\begin{align}
\log_e \mathcal{Q}_j(z_j) \propto \mathbb{E}_{Q_{z_{i \ne j}}}\left[\log_e P(x,z)\right] + const
\end{align}\]</span>
</p>
<p>That naturally completes the picture in which we have a <strong>factor-level update function</strong> and an <strong>ELBO eq 2</strong> to use for convergence.</p>
<p><strong>Fourth</strong>, at this point, we still do not have a shape for each factor of our <strong>variational distribution</strong>, namely <span class="math inline">\(\mathcal{Q}(z) = \mathcal{Q}(y, \pi, \mu, \Lambda)\)</span>. Our next goal is to pick or make assumptions on the closest type of distribution to use for each factor. For that, we use Figure <a href="bayesian.html#fig:mixturebayes">7.19</a> around the conditional dependency on the <strong>Bayesian model</strong>.</p>
<p>Notice that both our <strong>ELBO eq. 2</strong> and <strong>update function</strong> rely on <span class="math inline">\(\log_e P(x, z)\)</span>. Let us expand the log probability function:</p>

<p><span class="math display">\[\begin{align}
\log_e P(x, z) {}&amp;= \log_e P(x, y, \pi, \mu, \Lambda)\\ 
&amp;= \log_e \left[ P(x| y, \mu, \Lambda)
           P(y|\pi)P(\pi)P(\mu|\Lambda)P(\Lambda)\right] \\
&amp;= \sum_{k=1}^K \biggl[ 
   \log_e \prod_{i=1}^N P(x_i| y_{ik}, \mu_k, \Lambda_k) + 
   \log_e \prod_{i=1}^N P(y_{ik}|\pi_k) +  \log_e P(\pi_k)
   +\log_e P(\mu_k,\Lambda_k) \biggr]
\end{align}\]</span>
</p>
<p>Equivalently, the approximate joint distribution is shown below.</p>

<p><span class="math display">\[\begin{align}
P(x, y, \pi, \mu, \Lambda) \approx \mathcal{Q}(y, \pi, \mu, \Lambda) = 
\mathcal{Q}_y(y)\mathcal{Q}_\pi(\pi) \prod_{k=1}^K\mathcal{Q}(\mu_k, \Lambda_k) 
\end{align}\]</span>
</p>
<p>Both <span class="math inline">\(\mu_k\)</span> and <span class="math inline">\(\Lambda_k\)</span> are not split apart into their conditional form, e.g.:</p>

<p><span class="math display">\[\begin{align}
\log_e P(\mu_k,\Lambda_k) = \log_e P(\mu_k|\Lambda_k) + \log_e P(\Lambda_k).
\end{align}\]</span>
</p>
<p>Note that the shape of the joint distribution is not the one of interest, but we use the factors above to approximate the shape of the closest distribution we pick.</p>
<p><strong>For</strong> <span class="math inline">\(\mathbf{\mathcal{Q}_y(y)}\)</span>, we absorb terms with respect to <strong>y</strong>:</p>

<p><span class="math display">\[\begin{align}
\log_e \mathcal{Q}^*_y(y) {}&amp;\propto \mathbb{E}_{Q_{-y}}\left[\log_e P(x,z)\right] + const\\
&amp;\propto  \mathbb{E}_{Q_{\mu,\Lambda}}\left[ \log_e P(x| y, \mu, \Lambda)\right] + 
   \mathbb{E}_{Q_{\pi}}\left[\log_e P(y|\pi)\right] + const\\
&amp;\propto \sum_{k=1}^K \sum_{i=1}^N (y_{ik}) \left[ 
    \log_e \mathcal{N}_p(\ x_i\ ;\ \mu_k, {\Lambda_k}^{-1}\ ) + \log_e {\pi_k} \right]  + const
\end{align}\]</span>
</p>
<p>Operate on the first term, recalling that <span class="math inline">\(\Lambda_k\)</span> is a <strong>positive-definite precision matrix</strong>:</p>

<p><span class="math display">\[\begin{align}
\log_e \mathcal{N}_p(\ x_i\ ;\ \mu_k, {\Lambda_k}^{-1}\ ) &amp;= \log_e \left[\frac{|\Lambda_k|^{\frac{1}{2}}}{(2\pi)^{\frac{p}{2}}} exp\left( -\frac{1}{2}(x_i - \mu_k)^T\Lambda_k(x_i - \mu_k)\right)\right] 
\end{align}\]</span>
</p>
<p>Note that <span class="math inline">\((\log_e \pi_k)\)</span> is a <strong>categorical weight or mixture coefficient</strong> and thus should not to be confused with the <strong>gaussian normalizing constant</strong>, namely <span class="math inline">\((2\pi)^{\frac{p}{2}}\)</span>.</p>
<p>Combine the two terms and use a placeholder, namely <span class="math inline">\(\log_e\ \rho_{ik}\)</span>.</p>

<p><span class="math display">\[\begin{align}
\log_e\ \rho_{ik} {}&amp;=  
   \log_e \left[\frac{|\Lambda_k|^{\frac{1}{2}}}{(2\pi)^{\frac{p}{2}}} exp\left( -\frac{1}{2}(x_i - \mu_k)^T\Lambda_k(x_i - \mu_k)\right)\right]      +  \log_e \pi_k\\
&amp;=\frac{1}{2}\log_e |\Lambda_k| - \frac{p}{2}\log_e (2\pi) - \frac{1}{2}(x_i - \mu_k)^T\Lambda_k(x_i - \mu_k) + \log_e \pi_k
\end{align}\]</span>
</p>
<p>Also, take a note of the following expectation and its vector of cluster sizes, namely <span class="math inline">\(\tau_{k}\)</span>, used by other variational factors:</p>

<p><span class="math display">\[\begin{align}
 \mathbb{E}_{Q_{y}}\left[y_{ik} \right]  = \tau_{ik} = \frac{\rho_{ik}}{\sum_{j=1}^K \rho_{ij}}
 \ \ \ \ \ \ \ and \ \ \ \ \ \ \ \
 \tau_k = \sum_{i=1}^N \tau_{ik}
\end{align}\]</span>
</p>
<p>where:</p>

<p><span class="math display">\[\begin{align}
\rho_{ik} = 
   \frac{\pi_k|\Lambda_k|^{\frac{1}{2}}}{(2\pi)^{\frac{p}{2}}} exp\left(-\frac{1}{2}\biggl[ (x_i - \mu_k)^T\Lambda_k(x_i - \mu_k)\biggr]\right)  
\end{align}\]</span>
</p>
<p><strong>Now</strong>, combine the two terms and solve for <span class="math inline">\(\mathcal{Q}^*_y(y)\)</span>:</p>

<p><span class="math display">\[\begin{align}
\log_e \mathcal{Q}^*_y(y) {}&amp;=  \sum_{k=1}^K \sum_{n=1}^N (y_{ik})  \log_e \rho_{ik}
    = \sum_{k=1}^K \sum_{i=1}^N (y_{ik})  \log_e \tau_{ik} \label{eqn:eqnnumber316}
   \\
 \mathcal{Q}^*_y({{y_{ik}}; \tau_{ik}})  &amp;= Multi( {{y_{ik}}; \tau_{ik}})  = \prod_{i=1}^N \prod_{k=1}^K  {\tau_{ik}}^{y_{ik}} &amp;
 \begin{array}{rr}
 \text{(exponentiate)}\\
 \text{(Multinomial PDF)}
 \end{array} \label{eqn:eqnnumber317}
\end{align}\]</span>
</p>
<p><strong>For</strong> <span class="math inline">\(\mathbf{\mathcal{Q}_\pi(\pi)}\)</span>, we absorb terms with respect to <span class="math inline">\(\pi\)</span>:</p>

<p><span class="math display">\[\begin{align}
\log_e \mathcal{Q}_\pi(\pi) {}&amp;\propto \mathbb{E}_{Q_{-\pi}}\left[\log_e P(x,z)\right] + const\\ 
&amp;\propto  \mathbb{E}_{Q_{y}}\left[\log_e P(z|\pi)\right] +  \log_e P(\pi)  + const\\
&amp;\propto  \sum_{k=1}^K \left[\sum_{i=1}^N (y_{ik}) \log_e {\pi_k} +  \log_e \mathcal{Dir}(\pi_{k}; \omega_0)  \right] + const\\
&amp;\propto  \left[\sum_{k=1}^K \sum_{i=1}^N (y_{ik}) \log_e {\pi_k} +  \log_e \mathcal{Dir}(\pi_{1:k}; \omega_0)  \right] + const
\end{align}\]</span>
</p>
<p>Operate on the first term:</p>

<p><span class="math display">\[\begin{align}
\left[\sum_{k=1}^K  \sum_{i=1}^N (y_{ik}) \log_e {\pi_k} \right] =
\sum_{k=1}^K  \sum_{i=1}^N (\tau_{ik}) \log_e {\pi_k} \ \leftarrow \ {\tau}_{ik} &amp; \text{  (normalized)}
\end{align}\]</span>
</p>
<p>Operate on the second term (See Dirichlet distribution in Chapter <strong>5</strong> (<strong>Numerical Probability and Distribution</strong>) for <span class="math inline">\(\mathcal{B}(w_0)\)</span>):</p>

<p><span class="math display">\[\begin{align}
\log_e \mathcal{Dir}(\pi_{1:k}; \omega_0) {}&amp;\rightarrow 
\log_e \left[\frac{1}{\mathcal{B}(\omega_0)}\prod_{k=1}^K {\pi_k}^{\omega_0 - 1}\right]\\
&amp;= \log_e  \frac{1}{\mathcal{B}(\omega_0)} + \log_e \prod_{k=1}^K  {\pi_k}^{\omega_0 - 1} &amp; \text{(logarithm)}\\
&amp;= \log_e \prod_{k=1}^K  {\pi_k}^{\omega_0 - 1} + const   &amp; \text{(constant)}\\
&amp;= (\omega_0 - 1)\sum_{k=1}^K \log_e  {\pi_k}   + const  
\end{align}\]</span>
</p>
<p><strong>Now</strong>, combine the two terms and solve for <span class="math inline">\(\mathcal{Q}^*_\pi(\pi)\)</span>:</p>

<p><span class="math display">\[\begin{align}
\log_e \mathcal{Q}_\pi(\pi) {}&amp;= \sum_{k=1}^K  \sum_{i=1}^N (\tau_{ik}) \log_e {\pi_k}  + (\omega_0 - 1)\sum_{k=1}^K \log_e  {\pi_k}  + const \label{eqn:eqnnumber318}\\ 
&amp;= \sum_{k=1}^K  \left[\sum_{i=1}^N (\tau_{ik})  + (\omega_0 - 1) \right] \log_e  {\pi_k} + const \label{eqn:eqnnumber319}\\ 
\mathcal{Q}_\pi^*(\pi)  &amp;= \sum_{k=1}^K  {\pi_k} \times exp \left[\left( \tau_{k}  + \omega_0 \right) - 1 \right] + const &amp; 
\begin{array}{rr}
\text{(exponentiate)}  \\
\text{(Dirichlet PDF)}  \\
\end{array}    \label{eqn:eqnnumber320}
\\ 
\nonumber \\
\mathcal{Q}_\pi^*(\pi_{1:k}; \omega_1) &amp;=  \text{Dir}\left(\pi_{1:k}| \omega_1 \right) 
      \ \ \ \ \ \ \ \ \ where\ \omega_1 =  \tau_{k} + \omega_0  \label{eqn:eqnnumber321}
\end{align}\]</span>
</p>
<p><strong>For</strong> <span class="math inline">\(\mathbf{\mathcal{Q}(\mu, \Lambda) }\)</span>, we absorb terms with respect to <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\Lambda\)</span>. Here, we choose to compute both parameters via <strong>normal-Wishart distribution</strong>; albeit, one can choose to calculate the two parameters independently.</p>

<p><span class="math display">\[\begin{align}
\log_e {}&amp;\mathcal{Q}^*_{\mu,\Lambda}(\mu, \Lambda) \propto \mathbb{E}_{Q_{-\mu,\Lambda}}\left[\log_e P(x,z)\right] + const\\
&amp;\propto  \mathbb{E}_{Q_{y}}\left[ 
   \log_e P(x| y, \mu, \Lambda) + \log_e P(\mu,\Lambda) \right] + const\\
&amp;\propto  \left[ \sum_{k=1}^K \sum_{i=1}^N 
   (y_{ik})\log_e \mathcal{N}_p(x_i;  \mu_k, {\Lambda_k}^{-1}) \right] + \nonumber  \\
&amp;\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \left[\sum_{k=1}^K \log_e\ \mathcal{NW}_p(\mu_k, \Lambda_k; \alpha_0, (\beta_0\Lambda_k)^{-1}, \nu_0, \Sigma_0) \right] + c\\
\nonumber \\
\rightarrow&amp; \text{Recalling that } \mathbb{E}_{Q_{y}}\left[y_{ik} \right] =  \tau_{ik}. \nonumber \\
&amp;\propto  \left[ \sum_{k=1}^K \sum_{i=1}^N 
   (\tau_{ik})\log_e \mathcal{N}_p(x_i;  \mu_k, {\Lambda_k}^{-1}) \right] + \nonumber \\ 
&amp;\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \left[\sum_{k=1}^K \log_e\ \mathcal{NW}_p(\mu_k, \Lambda_k; \alpha_0, (\beta_0\Lambda_k)^{-1}, \nu_0, \Sigma_0) \right] + c\\
\nonumber \\
\rightarrow &amp;\text{Let } \tau_k = \sum_{i=1}^N  (\tau_{ik}) 
      \text{ and } \bar{x}_k = \frac{1}{\tau_k} \sum_{i=1}^N \left[ (\tau_{ik}) x_i\right]. \\
&amp;\propto  \left[ \sum_{k=1}^K 
   (\tau_{k}) \log_e \mathcal{N}_p(\bar{x}_k;  \mu_k, {\Lambda_k}^{-1}) \right] + \nonumber \\ 
&amp;\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \left[\sum_{k=1}^K \log_e\ \mathcal{NW}_p(\mu_k, \Lambda_k; \alpha_0, (\beta_0\Lambda_k)^{-1}, \nu_0, \Sigma_0) \right] + c
\end{align}\]</span>
</p>
<p>Operate on the first term (dropping constants):</p>

<p><span class="math display">\[\begin{align}
\log_e \mathcal{N}&amp;(\ \bar{x}_k \ ;\ \mu_k, {\Lambda_k}^{-1}\ ) \nonumber \\
 &amp;= \log_e \left[\frac{|\Lambda_k|^{\frac{1}{2}}}{(2\pi)^{\frac{p}{2}}} exp\left( -\frac{1}{2}(\bar{x}_k - \mu_k)^T\Lambda_k(\bar{x}_k - \mu_k)\right)\right] 
\\ 
&amp;=  (\log_e |\Lambda_k|^{ \frac{1}{2}} ) - \frac{p}{2}(\log_e  2\pi )  -\frac{1}{2}(\bar{x} - \mu_k)^T\Lambda_k(\bar{x} - \mu_k)  &amp; \text{(logarithm)}\\
&amp;\propto  (\log_e |\Lambda_k|^{ \frac{1}{2}} )  -\frac{1}{2}\Lambda_k(\bar{x}_k \bar{x}_k^T - \bar{x}_k {\mu_k}^T - 
  \mu_k \bar{x}_k^T + \mu_k {\mu_k}^T)  &amp; \text{(logarithm)}
\end{align}\]</span>
</p>
<p>Operate on the second term (dropping constants).</p>

<p><span class="math display">\[\begin{align}
\log_e &amp;\mathcal{NW}_p{}(\mu_k, \Lambda_k ;\ \alpha_0, (\beta_0 \Lambda_k)^{-1}, \nu_0, \Sigma_0\ ) \nonumber \\ 
&amp;\propto log_e \left( \ \underbrace{ |\beta_0\Lambda_k|^{\frac{1}{2}} 
  exp\left[-\frac{1}{2}(\mu_k - \alpha_0)^T\beta_0\Lambda_k(\mu_k - \alpha_0)\right]}_\text{gaussian}
      \times
       \underbrace{ |\Lambda_k|^{\frac{\nu_0-p-1}{2}}  
  exp\left[-\frac{1}{2}tr(\Sigma_0^{-1}\Lambda_k)\right]  }_\text{wishart } \right) \\
&amp;\propto  log_e \left(  |\beta_0|^\frac{1}{2} |\Lambda_k|^{\frac{1}{2}}  |\Lambda_k|^{\frac{\nu_0-p-1}{2}}  exp\left[-\frac{\beta_0}{2}\Lambda_k(\mu_k - \alpha_0)(\mu_k - \alpha_0)^T + -\frac{1}{2}tr(\Sigma_0^{-1}\Lambda_k) \right] \right) \\
&amp;\propto log_e \left[ |\Lambda_k|^{\frac{\nu_0-p}{2}}  exp\left[-\frac{\beta_0}{2}\Lambda_k(\mu_k\mu_k^T - \mu{\alpha_0}^T - {\alpha_0}\mu^T + \alpha_0{\alpha_0}^T) + -\frac{1}{2}tr(\Sigma_0^{-1}\Lambda_k) \right] \right]
\end{align}\]</span>
</p>
<p>Combine the two terms:</p>

<p><span class="math display">\[\begin{align}
\log_e \mathcal{Q}^*_{\mu,\Lambda}(\mu, \Lambda) {}&amp;\propto \left[ \sum_{k=1}^K  
   \left( \tau_{k}\log_e |\Lambda_k|^{ \frac{1}{2}}  -\frac{\tau_k}{2}\Lambda_k(\bar{x}_k \bar{x}_k^T - \bar{x}_k {\mu_k}^T - \mu_k \bar{x}_k^T  + \mu_k {\mu_k}^T) \right)\right] \nonumber \\
&amp;+  \sum_{k=1}^K \left[log_e  |\Lambda_k|^{\frac{\nu_0 - p}{2}} -\frac{1}{2}\left(\beta_0 \Lambda_k(\mu_k\mu_k^T - \mu_k{\alpha_0}^T - {\alpha_0}\mu_k^T + \alpha_0{\alpha_0}^T)   -tr(\Sigma_0^{-1}\Lambda_k) \right) \right]
\end{align}\]</span>
</p>
<p>Exponentiate:</p>

<p><span class="math display">\[\begin{align}
\mathcal{Q}^*_{\mu,\Lambda}(\mu, \Lambda)  
{}&amp;\propto \left[ \prod_{k=1}^K 
  \left(|\Lambda_k|^{ (\tau_{k})/2} exp \left[ -\frac{\tau_k}{2}\Lambda_k\left(\bar{x}_k \bar{x}_k^T - \bar{x}_k {\mu_k}^T - \mu_k \bar{x}_k^T  + \mu_k {\mu_k}^T\right) \right]\right)\right] \nonumber \\
&amp;\times  \prod_{k=1}^K \left[ |\Lambda_k|^{\frac{\nu_0 - p}{2}} exp \left( -\frac{1}{2}\biggl[\beta_0 \Lambda_k(\mu_k\mu_k^T - \mu_k{\alpha_0}^T - {\alpha_0}\mu_k^T + \alpha_0{\alpha_0}^T)   -tr(\Sigma_0^{-1}\Lambda_k) \biggr] \right)\right]\\
\nonumber \\
&amp;\propto \prod_{k=1}^K 
    |\Lambda_k|^{(\nu_0 +  \tau_{k} - p)/2}  exp \biggl[ -\frac{1}{2}\biggl(\Lambda_k \biggl(\Upsilon \biggr) - tr\biggl(\Sigma_0^{-1}\Lambda_k\biggr) \biggr)  \biggr]
\end{align}\]</span>
</p>
<p><span class="math display">\[
\text{let }\Upsilon = \tau_k(\bar{x}_k \bar{x}_k^T - \bar{x}_k {\mu_k}^T - \mu_k \bar{x}_k^T  + \mu_k {\mu_k}^T) +  \beta_0(\mu_k\mu_k^T - \mu_k{\alpha_0}^T -  {\alpha_0}\mu_k^T + \alpha_0{\alpha_0}^T)
\]</span></p>
<p><strong>Now</strong>, solving for <span class="math inline">\(\mathcal{Q}^*_{\mu,\Lambda}(\mu, \Lambda)\)</span> from here, recall the simplification of the exponent under the <strong>Normal Wishart Conjugacy</strong> Section. That leads to the following:</p>

<p><span class="math display">\[\begin{align}
\mathcal{Q}^*_{\mu,\Lambda}(\mu, \Lambda\ ) {}&amp;\propto   \prod_{k=1}^K  |\Lambda_k|^{(\nu_0+\tau_{k}-p)/2} \nonumber \\
&amp;\underbrace{ exp\biggl[-\frac{(\beta_0 + \tau_{k}) }{2}\biggl( \mu_k - \frac{(\alpha_0\beta_0 + \tau_{k}\bar{x}_k)}{(\beta_0 + \tau_{k})} \biggr)^T\Lambda_k\biggl( \mu_k - \frac{(\alpha_0\beta_0 + \tau_{k}\bar{x}_k)}{(\beta_0 + \tau_{k})} \biggr) \biggr]}_\text{gaussian} \times \nonumber \\
&amp;\underbrace{exp\biggl[-\frac{1}{2}tr\biggl(  \frac{ \tau_k\beta_0}{(\beta_0 + \tau_{k})}(\tau_k\bar{x}_k - \alpha_0)( \tau_k\bar{x}_k - \alpha_0 )^T + (\tau_{k}) S_k  + \Sigma_0^{-1} \biggr) \Lambda_k \biggr]}_\text{wishart}
\end{align}\]</span>
</p>
<p>Reparameterize the prior hyperparameters:</p>

<p><span class="math display">\[\begin{align}
\alpha_1 {}&amp;=  \frac{(\alpha_0\beta_0 + \tau_{k}\bar{x}_k)}{(\beta_0 + \tau_{k})}\\
\beta_1 &amp;= \beta_0 + \tau_{k} \\
\nu_1 {}&amp;= \nu_0 + \tau_{k} \\
\Sigma_1 &amp;=  \frac{ \tau_k \beta_0}{(\beta_0 + \tau_{k})}(\bar{x}_k - \alpha_0)( \bar{x}_k - \alpha_0 )^T + \tau_{k} S_k  + \Sigma_0^{-1} \\
\nonumber \\
&amp;where: S_k = \frac{1}{\tau_{k}} \sum_{i=1}^n (\tau_{ik}) (x_i - \bar{x}_k)(x_i - \bar{x}_k)^T.
\end{align}\]</span>
</p>
<p>We then get the following equation:</p>

<p><span class="math display">\[\begin{align}
\mathcal{Q}^*_{\mu,\Lambda}(\mu, \Lambda) &amp;= \prod_{k=1}^K  \mathcal{N}_p(\mu_k; \alpha_1, (\beta_1\Lambda_k)^{-1})\times \mathcal{W}_p(\Lambda_k; \nu_1, \Sigma_1) &amp; \text{(Normal-Wishart PDF)}
\end{align}\]</span>
</p>
<p><strong>Finally</strong>, our <strong>variational distribution</strong> has the following equation:</p>

<p><span class="math display">\[\begin{align}
\mathcal{Q}(z) {}&amp;=  \mathcal{Q}^*_y(y) \times \mathcal{Q}_\pi^*(\pi) \times  \prod_{k=1}^K  \mathcal{Q}^*_{\mu,\Lambda}(\mu, \Lambda) \\
&amp;= \text{Multi}( {{y_{ik}}; \tau_{ik}}) \times \text{Dir}\left(\pi_{1:k}| \omega_1 \right) \times \prod_{k=1}^K  \mathcal{N}_p(\mu_k; \alpha_1, (\beta_1\Lambda_k)^{-1})\times \mathcal{W}_p(\Lambda_k; \nu_1, \Sigma_1)
\end{align}\]</span>
</p>
<p><strong>Fifth</strong>, we need to use an <strong>iterative</strong> algorithm to optimize our model. We choose to use the <strong>Variational EM</strong> algorithm or a straight-forward <strong>Coordinate Ascent Variational Inference (CAVI)</strong>.</p>
<p>As for <strong>CAVI</strong>, we have the below algorithm <span class="citation">(Bishop C.M <a href="bibliography.html#ref-ref482c">2006</a>; Blei D. et al <a href="bibliography.html#ref-ref381d">2017</a>)</span>:</p>

<p><span class="math display">\[\begin{align*}
\begin{array}{ll}
\mathcal{LB}[Q(z)] = \mathbb{E}_{Q(z)}\left[\log_e P(x,z)\right] + \mathcal{H}(z) &amp; \text{(ELBO eq. 2)}\\
\text{while}\ \mathbf{ELBO}\ \text{has not converged}\\
\ \ \ \ \text{for j in 1,...,m}\\
\ \ \ \ \ \ \ \ \ \text{set } \log_e \mathcal{Q}_j(z_j) \propto \mathbb{E}_{Q_{z_{i \ne j}}}\left[\log_e P(x,z)\right] \\
\ \ \ \ \text{end}\\
\ \ \ \ \text{compute}\ \mathbf{ELBO}\\
\text{end}
\end{array}
\end{align*}\]</span>
</p>
<p>On the other hand, to illustrate the use of <strong>variational EM</strong> (which has a different arrangement), we first initialize the parameters.</p>
<p><strong>Initialization</strong>:</p>
<p>We start <strong>VEM</strong> by initializing the parameters for each variational factor, given the following assumptions:</p>
<ul>
<li><strong>p</strong> is the number of random variables (p-dimensions).</li>
<li><strong>n</strong> is the number of observations for each random variable.</li>
<li><strong>k</strong> is the number of classes or clusters (e.g., tri-modal mixture).</li>
</ul>
<p>For <strong>model parameters</strong>:</p>
<p><span class="math display">\[
\mathbf{x} = \left[
\begin{array}{c}
x_{1n} \\
x_{2n} \\
\end{array}
\right]_{p=2}\ \ \ \ 
\mathbf{\mu} = \left[
\begin{array}{c}
\mu_{1} = \bar{x}_1 \\
\mu_{2} = \bar{x}_2\\
\end{array}
\right]_{p=2}
\]</span></p>
<p><span class="math display">\[
\Lambda = \left(\left[
\begin{array}{cc} \sigma_{11} &amp;  \sigma_{1p}\\ \sigma_{p1} &amp;  \sigma_{pp} \end{array}
\right]_{pxp}^{-1}
\left[
\begin{array}{cc} \sigma_{11} &amp;  \sigma_{1p}\\ \sigma_{p1} &amp;  \sigma_{pp} \end{array}
\right]_{pxp}^{-1}
\left[
\begin{array}{cc} \sigma_{11} &amp;  \sigma_{1p}\\ \sigma_{p1} &amp;  \sigma_{pp} \end{array}
\right]_{pxp}^{-1}
\right)_{k=3}^T
\]</span></p>
<p>Note that <span class="math inline">\(\mu_k\)</span> and <span class="math inline">\(\Lambda_k\)</span> are unknown.</p>
<p>For <strong>hyperparameters</strong>:</p>

<p><span class="math display">\[\begin{align*}
\omega_0 &amp;= \left[\begin{array}{lll}1/K &amp; 1/K &amp; 1/K \end{array}\right] &amp; \text{(hyper-proportionality of } \pi_k \text{)}\\
\alpha_0 &amp;= \left[\begin{array}{ll}0 &amp; 0 \end{array}\right] &amp; \text{(hyper-mean of } \mu_k \text{)} \\
\beta_0 &amp;=  1 &amp; \text{(hyper-variance of } \mu_k \text{)}  \\ 
\nu_0 &amp;= p -1 &amp; \text{(degrees of freedom of } \Lambda_k \text{)} \\
\Sigma_0 &amp;= 
\left[\begin{array}{cc} 1 &amp;  0\\ 0 &amp;  1\\ \end{array}\right]_{pxp}
&amp; \text{(hyper-covariance of } \Lambda_k  \text{)}\\
\end{align*}\]</span>
</p>
<p><strong>Variational Estimation Step (VE-Step)</strong>:</p>
<p>In this step, we use the initialized (and eventually the optimized) parameters to calculate expectations and <span class="math inline">\(\mathcal{Q}^*(y)\)</span>.</p>
<p>For <strong>expectation of log-determinant of Wishart covariance and log of the mixture coefficient</strong>, we can reference the following use of <strong>digamma function</strong> for an estimation. Also, let us use an asterisk to denote estimation for the following parameters, namely <span class="math inline">\(\Lambda_k^*\)</span> and <span class="math inline">\(\pi_k^*\)</span>. We reference Bishop C.M., pp.475-479 <span class="citation">(<a href="bibliography.html#ref-ref482c">2006</a>)</span> for the expectation formulas. The hyperparameters, namely <span class="math inline">\(\omega_1, \alpha_1, \beta_1, \nu_1, \Sigma_1\)</span>, are available after calculating the other factors.</p>

<p><span class="math display">\[\begin{align}
\log_e\ \Lambda_k^* \equiv \mathbb{E}_{\Lambda}[\log_e\ |\Lambda_k|] {}&amp;= p\log_e2 + \log_e|\Sigma_1| + \sum_{i=1}^p\Psi\left(\frac{\nu_1 - i + 1}{2}\right)\\
\log_e\ \pi_k^* \equiv \mathbb{E}_{\pi}[\log_e\ \pi_k] &amp;= 
  \Psi(\omega_1) - \Psi\left( \sum_{k} \omega_1 \right)\\
\mathbb{E}_{\mu,\Lambda}\left[(x_i - \mu_k)^T\Lambda_k(x_i - \mu_k)\right] &amp;= 
  p\beta_1^{-1} + \nu_1(x_i - \alpha_1)^T\Sigma_1(x_i - \alpha_1)\\
\nonumber \\
\text{where } \Psi(.)\text{ is the } &amp;\text{digamma function.} \nonumber
\end{align}\]</span>
</p>
<p>Therefore, given the expectations, we formulate the equation below for the responsibilities:</p>

<p><span class="math display">\[\begin{align}
\log_e\ \rho_{ik} =\frac{1}{2}\log_e \Lambda_k^* - \frac{p}{2}\log_e (2\pi) - \frac{1}{2}\left[p\beta_1^{-1} + \nu_1(x_i - \alpha_1)^T\Sigma_1(x_i - \alpha_1)\right] + \log_e \pi_k^*
\end{align}\]</span></p>
<p><span class="math display">\[\begin{align}
\rho_{ik} \propto 
   \pi_k^*|\Lambda_k^*|^{\frac{1}{2}} exp\left(-\frac{1}{2}\biggl[ p\beta_1^{-1} + \nu_1(x_i - \alpha_1)^T\Sigma_1(x_i - \alpha_1)\biggr]\right)
\end{align}\]</span></p>
<p><span class="math display">\[\begin{align}
 \mathbb{E}_{Q_{y}}\left[y_{ik} \right]  = \tau_{ik} = \frac{\rho_{ik}}{\sum_{j=1}^K \rho_{ij}}
 \ \ \ \ \ \ \ and \ \ \ \ \ \ \ \
 \tau_k = \sum_{i=1}^N \tau_{ik}
\end{align}\]</span></p>
<p><span class="math display">\[\begin{align}
\mathcal{Q}^*_y(y)  &amp;= \text{Multi}( {{y_{ik}}; \tau_{ik}}) = \prod_{i=1}^N \prod_{k=1}^K  {\tau_{ik}}^{y_{ik}}
\end{align}\]</span>
</p>
<p><strong>Update Cluster Statistics</strong>:</p>
<p>The following statistics depend on the <span class="math inline">\(\tau_{ik}\)</span> as <strong>one-hot encoding</strong> for classification (clustering) and are structured as so:</p>
<p><span class="math display">\[
\tau_{ik} = \left[ \begin{array}{cccccccc} 
1 &amp; 1 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; ... &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; ... &amp; 1 \\
0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 1 &amp; ... &amp; 0 \\
\end{array}
\right]_{kxn}^T\ \ \ \ \ \ \ \ where\ k = 3
\]</span></p>

<p><span class="math display">\[\begin{align}
\tau_k  &amp;= \sum_{i=1}^n \tau_{ik}  = 
\left[\begin{array}{c} n_1 \\ n_2 \\ n_3 \end{array}\right]_k^T
\ \ \ \ \ \ \ \ 
\begin{array}{l}
\text{ where } n_i \text{ is number of observations per cluster - }\\
\text{ the responsibilities}\\
\end{array}  \label{eqn:eqnnumber322} \\
\bar{x}_k &amp;= \frac{1}{\tau_k} \sum_{i=1}^N \left[ (\tau_{ik}) x_i\right]  \label{eqn:eqnnumber323}\\
S_k &amp;= \frac{1}{\tau_{k}} \sum_{i=1}^n (\tau_{ik}) (x_i - \bar{x}_k)(x_i - \bar{x}_k)^T. \label{eqn:eqnnumber324}
\end{align}\]</span>
</p>
<p><strong>Variational Maximization Step (VM-Step)</strong>:</p>
<p>In this step, we optimize the parameters and calculate <span class="math inline">\(\mathcal{Q}^*(\pi)\)</span> and <span class="math inline">\(\mathcal{Q}^*(\mu,\Lambda)\)</span>.</p>

<p><span class="math display">\[\begin{align}
\mathcal{Q}_\pi^*(\pi_{1:k}; \omega_1) {}&amp;=  \text{Dir}\left(\pi_{1:k}| \omega_1 \right)\\
\nonumber \\
\omega_1 &amp;=  \tau_{k} + \omega_0\\
\nonumber \\
\mathcal{Q}^*_{\mu,\Lambda}(\mu, \Lambda) &amp;= \prod_{k=1}^K  \mathcal{N}_p(\mu_k; \alpha_1, (\beta_1\Lambda_k)^{-1})\times \mathcal{W}_p(\Lambda_k; \nu_1, \Sigma_1) \\
\nonumber \\
\alpha_1 &amp;=  \frac{(\alpha_0\beta_0 + \tau_{k}\bar{x}_k)}{(\beta_0 + \tau_{k})}\\
\beta_1 &amp;= \beta_0 + \tau_{k} \\
\nu_1 {}&amp;= \nu_0 + \tau_{k} \\
\Sigma_1 &amp;=  \frac{ \tau_k \beta_0}{(\beta_0 + \tau_{k})}(\bar{x}_k - \alpha_0)( \bar{x}_k - \alpha_0 )^T + \tau_{k} S_k  + \Sigma_0^{-1} 
\end{align}\]</span>
</p>
<p>From here, we perform iteration until <strong>ELBO</strong> converges.</p>
<p><strong>Sixth</strong>, we need to calculate <strong>ELBO eq. 2 for convergence</strong>. Recall <strong>log marginal likelihood</strong>, namely <span class="math inline">\(\log_e P(X)\)</span>, which we use for convergence as illustrated in the previous section for <strong>EM</strong>. Here, we use the derived <strong>ELBO eq. 2</strong> to evaluate convergence.</p>

<p><span class="math display">\[\begin{align}
\mathcal{LB}[Q(z)]  {}&amp;= \int_z \mathcal{Q}(z)\log_e P(x,z)\ dz\ 
  -\int_z \mathcal{Q}(z)\log_e \mathcal{Q}(z) \ dz\\
 &amp;= \mathbb{E}_{Q(z)}\left[\log_e P(x,z)\right] + \mathcal{H}(z) 
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \text{(ELBO eq. 2)}\\
 &amp;= \mathbb{E}_{Q(z)}\left[\log_e P(x,z)\right] - \mathbb{E}_{Q(z)}\left[\log_e \mathcal{Q}(z)\right]\\
 &amp;= \mathbb{E}_{Q(z)}\left[\log_e P(x,y,\pi,\mu,\Lambda)\right] - \mathbb{E}_{Q(z)}\left[\log_e \mathcal{Q}(y,\pi,\mu,\Lambda)\right]\\
 &amp;= \mathbb{E}\left[\log_e P(x|y,\mu,\Lambda)\right] +
 \mathbb{E}\left[\log_e P(y,\pi)\right] +
 \mathbb{E}\left[\log_e P(\pi)\right] +
 \mathbb{E}\left[\log_e P(\mu,\Lambda)\right] \nonumber \\
 &amp;\ \ \ \ \ - \mathbb{E}\left[\log_e \mathcal{Q}(y)\right]
      - \mathbb{E}\left[\log_e \mathcal{Q}(\pi)\right]
      - \mathbb{E}\left[\log_e \mathcal{Q}(\mu,\Lambda)\right]
\end{align}\]</span>
</p>
<p>We then have to calculate the individual <strong>expectations</strong>. We leave readers to derive the individual terms of the <strong>lower bound</strong> as exercise. For reference, see Bishop C.M., section 10.2.2 <span class="citation">(<a href="bibliography.html#ref-ref482c">2006</a>)</span>.</p>
<p>Let us go through the process with an example implementation of <strong>Variational Bayes</strong> in R code using the <strong>Variational EM</strong> algorithm.</p>
<p><strong>First</strong>, let us generate our dataset (bivariate trimodal) like so:</p>

<div class="sourceCode" id="cb871"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb871-1" data-line-number="1">K =<span class="st"> </span><span class="dv">3</span>  <span class="co"># number of clusters (tri-modal)</span></a>
<a class="sourceLine" id="cb871-2" data-line-number="2">P =<span class="st"> </span><span class="dv">2</span>  <span class="co"># number of random variables (p-variate)</span></a>
<a class="sourceLine" id="cb871-3" data-line-number="3">N =<span class="st"> </span><span class="dv">60</span> <span class="co"># number of observations per random variable</span></a>
<a class="sourceLine" id="cb871-4" data-line-number="4">ksample &lt;-<span class="st"> </span><span class="cf">function</span>(m, mu, sd, seed) {</a>
<a class="sourceLine" id="cb871-5" data-line-number="5">  <span class="kw">set.seed</span>(seed);  <span class="kw">rnorm</span>(<span class="dt">n=</span>m, <span class="dt">mean=</span>mu, <span class="dt">sd=</span>sd)</a>
<a class="sourceLine" id="cb871-6" data-line-number="6">}</a>
<a class="sourceLine" id="cb871-7" data-line-number="7">dataset &lt;-<span class="st"> </span><span class="cf">function</span>() {</a>
<a class="sourceLine" id="cb871-8" data-line-number="8">  <span class="co"># simulate bivariate tri-modal mixture model (cluster: A, B, C)</span></a>
<a class="sourceLine" id="cb871-9" data-line-number="9">  <span class="co">#set.seed(2020)</span></a>
<a class="sourceLine" id="cb871-10" data-line-number="10">  mu =<span class="st"> </span><span class="kw">c</span>(<span class="dv">10</span>, <span class="dv">20</span>, <span class="dv">30</span>)    <span class="co"># assume true mean of all three clusters</span></a>
<a class="sourceLine" id="cb871-11" data-line-number="11">  sd =<span class="st"> </span><span class="kw">c</span>(<span class="fl">2.0</span>, <span class="fl">1.5</span>, <span class="fl">1.5</span>) <span class="co"># assume true std dev of all three clusters</span></a>
<a class="sourceLine" id="cb871-12" data-line-number="12">  m =<span class="st"> </span><span class="dv">20</span></a>
<a class="sourceLine" id="cb871-13" data-line-number="13">  A.x1  =<span class="st"> </span><span class="kw">ksample</span>(m, mu[<span class="dv">1</span>], sd[<span class="dv">1</span>], <span class="dv">150</span> ) </a>
<a class="sourceLine" id="cb871-14" data-line-number="14">  A.x2  =<span class="st"> </span><span class="kw">ksample</span>(m, mu[<span class="dv">1</span>], sd[<span class="dv">1</span>], <span class="dv">180</span> )</a>
<a class="sourceLine" id="cb871-15" data-line-number="15">  B.x1  =<span class="st"> </span><span class="kw">ksample</span>(m, mu[<span class="dv">2</span>], sd[<span class="dv">2</span>], <span class="dv">160</span> ) </a>
<a class="sourceLine" id="cb871-16" data-line-number="16">  B.x2  =<span class="st"> </span><span class="kw">ksample</span>(m, mu[<span class="dv">2</span>], sd[<span class="dv">2</span>], <span class="dv">190</span> )</a>
<a class="sourceLine" id="cb871-17" data-line-number="17">  C.x1  =<span class="st"> </span><span class="kw">ksample</span>(m, mu[<span class="dv">3</span>], sd[<span class="dv">3</span>], <span class="dv">170</span> ) </a>
<a class="sourceLine" id="cb871-18" data-line-number="18">  C.x2  =<span class="st"> </span><span class="kw">ksample</span>(m, mu[<span class="dv">3</span>], sd[<span class="dv">3</span>], <span class="dv">200</span> )</a>
<a class="sourceLine" id="cb871-19" data-line-number="19">  x1 =<span class="st"> </span><span class="kw">c</span>(A.x1 , B.x1 , C.x1)</a>
<a class="sourceLine" id="cb871-20" data-line-number="20">  x2 =<span class="st"> </span><span class="kw">c</span>(A.x2 , B.x2 , C.x2)</a>
<a class="sourceLine" id="cb871-21" data-line-number="21">  x =<span class="st"> </span><span class="kw">cbind</span>(x1, x2)</a>
<a class="sourceLine" id="cb871-22" data-line-number="22">  <span class="kw">list</span>(<span class="st">&quot;m&quot;</span> =<span class="st"> </span>m, <span class="st">&quot;x&quot;</span> =<span class="st"> </span>x )</a>
<a class="sourceLine" id="cb871-23" data-line-number="23">}</a>
<a class="sourceLine" id="cb871-24" data-line-number="24">data =<span class="st"> </span><span class="kw">dataset</span>()</a>
<a class="sourceLine" id="cb871-25" data-line-number="25"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="dv">40</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="dv">40</span>), </a>
<a class="sourceLine" id="cb871-26" data-line-number="26">     <span class="dt">xlab=</span><span class="st">&quot;x1&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;x2&quot;</span>,</a>
<a class="sourceLine" id="cb871-27" data-line-number="27">     <span class="dt">main=</span><span class="st">&quot;Bivariate tri-modal mixture model&quot;</span>,  <span class="dt">frame=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb871-28" data-line-number="28"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb871-29" data-line-number="29"><span class="kw">points</span>(data<span class="op">$</span>x[,<span class="dv">1</span>], data<span class="op">$</span>x[,<span class="dv">2</span>], <span class="dt">col=</span><span class="kw">c</span>(<span class="st">&quot;black&quot;</span>), <span class="dt">pch=</span><span class="dv">16</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:bivartrimodel1"></span>
<img src="DS_files/figure-html/bivartrimodel1-1.png" alt="Bivariate tri-modal mixture model" width="70%" />
<p class="caption">
Figure 7.21: Bivariate tri-modal mixture model
</p>
</div>

<p>Figure <a href="bayesian.html#fig:bivartrimodel1">7.21</a> shows the data points that are intentionally colored with black and distributed in three clusters with centroid points (10,10), (20,20), and (30,30). The goal is to see if we can correctly identify the cluster that each data point belongs to by assigning colors to each.</p>
<p><strong>Second</strong>, let us perform initialization.</p>

<div class="sourceCode" id="cb872"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb872-1" data-line-number="1">initialize &lt;-<span class="st"> </span><span class="cf">function</span>(data) {</a>
<a class="sourceLine" id="cb872-2" data-line-number="2">  omega =<span class="st"> </span><span class="kw">rep</span>(<span class="dv">1</span><span class="op">/</span>K, K)               <span class="co"># dirichlet hyper-parameter</span></a>
<a class="sourceLine" id="cb872-3" data-line-number="3">  alpha =<span class="st"> </span><span class="kw">kmeans</span>(data<span class="op">$</span>x, K)<span class="op">$</span>centers <span class="co"># mean approximation using k-means</span></a>
<a class="sourceLine" id="cb872-4" data-line-number="4">  beta =<span class="st"> </span><span class="kw">rep</span>(<span class="dv">1</span>, K)                  <span class="co"># variance  hyper-parameter</span></a>
<a class="sourceLine" id="cb872-5" data-line-number="5">  v    =<span class="st"> </span><span class="kw">rep</span>(P,K)                   <span class="co"># degrees of freedom hyperparameter</span></a>
<a class="sourceLine" id="cb872-6" data-line-number="6">  sigma =<span class="st"> </span><span class="kw">array</span>(<span class="dv">0</span>, <span class="kw">c</span>(P,P,K)) </a>
<a class="sourceLine" id="cb872-7" data-line-number="7">  sigma[,,] =<span class="st"> </span><span class="kw">rep</span>(<span class="kw">diag</span>(P),K)        <span class="co"># covariance hyperparameter</span></a>
<a class="sourceLine" id="cb872-8" data-line-number="8"></a>
<a class="sourceLine" id="cb872-9" data-line-number="9">  loge_pi     =<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, K)</a>
<a class="sourceLine" id="cb872-10" data-line-number="10">  loge_lambda =<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, K)</a>
<a class="sourceLine" id="cb872-11" data-line-number="11">  E_mulambda =<span class="st"> </span><span class="kw">matrix</span>(<span class="dv">0</span>, N, K)</a>
<a class="sourceLine" id="cb872-12" data-line-number="12">  </a>
<a class="sourceLine" id="cb872-13" data-line-number="13">  <span class="kw">list</span>( <span class="st">&quot;omega&quot;</span> =<span class="st"> </span>omega, <span class="st">&quot;alpha&quot;</span>=<span class="st"> </span>alpha, <span class="st">&quot;beta&quot;</span> =<span class="st"> </span>beta, </a>
<a class="sourceLine" id="cb872-14" data-line-number="14">        <span class="st">&quot;v&quot;</span> =<span class="st"> </span>v, <span class="st">&quot;sigma&quot;</span> =<span class="st"> </span>sigma, </a>
<a class="sourceLine" id="cb872-15" data-line-number="15">        <span class="st">&quot;loge_pi&quot;</span>=loge_pi, <span class="st">&quot;loge_lambda&quot;</span> =<span class="st"> </span>loge_lambda,</a>
<a class="sourceLine" id="cb872-16" data-line-number="16">        <span class="st">&quot;E_mulambda&quot;</span> =<span class="st"> </span>E_mulambda)  </a>
<a class="sourceLine" id="cb872-17" data-line-number="17">}</a>
<a class="sourceLine" id="cb872-18" data-line-number="18">params =<span class="st"> </span><span class="kw">initialize</span>(data)</a></code></pre></div>

<p><strong>Third</strong>, let us implement <strong>variational EM</strong>. Note that the VEM implementation references an R code published in public by Jean Arreola <span class="citation">(<a href="bibliography.html#ref-ref546j">2018</a>)</span>. We made a few re-arrangement and slight modifications to reflect corresponding notations in the discussion above. Additionally, our implementation is motivated by an R code from Fabian Dablander <span class="citation">(<a href="bibliography.html#ref-ref453b">2018</a>)</span>). As always, our implementation and the referenced implementations are examples only that should be used only to supplement our understanding, and thus they may not be production-proof):</p>

<div class="sourceCode" id="cb873"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb873-1" data-line-number="1">ln &lt;-<span class="st"> </span><span class="cf">function</span>(x) { <span class="kw">log</span>(x, <span class="kw">exp</span>(<span class="dv">1</span>))} <span class="co"># exp(1) = 2.718282</span></a>
<a class="sourceLine" id="cb873-2" data-line-number="2">one_hot_encoding &lt;-<span class="st"> </span><span class="cf">function</span>(n) { <span class="co"># using log-sum-exp</span></a>
<a class="sourceLine" id="cb873-3" data-line-number="3">  <span class="kw">t</span>( <span class="kw">apply</span>(n, <span class="dv">1</span>, <span class="cf">function</span>(x) { offset =<span class="st"> </span><span class="kw">max</span>(x); y =<span class="st"> </span>x <span class="op">-</span><span class="st"> </span>offset</a>
<a class="sourceLine" id="cb873-4" data-line-number="4">    <span class="kw">return</span>  ( <span class="kw">exp</span>(y)<span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(<span class="kw">exp</span>(y) ))</a>
<a class="sourceLine" id="cb873-5" data-line-number="5">  }) )</a>
<a class="sourceLine" id="cb873-6" data-line-number="6">}</a>
<a class="sourceLine" id="cb873-7" data-line-number="7">update_xmean &lt;-<span class="st"> </span><span class="cf">function</span>(x, rik, rk) {</a>
<a class="sourceLine" id="cb873-8" data-line-number="8">  xm =<span class="st"> </span><span class="kw">matrix</span>(<span class="dv">0</span>, K, P)</a>
<a class="sourceLine" id="cb873-9" data-line-number="9">  <span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>K) { xm[k,] =<span class="st"> </span><span class="kw">colSums</span>(rik[,k] <span class="op">*</span><span class="st"> </span>x <span class="op">/</span><span class="st"> </span>rk[k]) }</a>
<a class="sourceLine" id="cb873-10" data-line-number="10">  xm</a>
<a class="sourceLine" id="cb873-11" data-line-number="11">}</a>
<a class="sourceLine" id="cb873-12" data-line-number="12">update_S &lt;-<span class="st"> </span><span class="cf">function</span>(x, rik, rk, xm) {</a>
<a class="sourceLine" id="cb873-13" data-line-number="13">  <span class="co"># Update covariance</span></a>
<a class="sourceLine" id="cb873-14" data-line-number="14">  S =<span class="st"> </span><span class="kw">array</span>(<span class="dv">0</span>, <span class="kw">c</span>(P,P,K))</a>
<a class="sourceLine" id="cb873-15" data-line-number="15">  <span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>K) {</a>
<a class="sourceLine" id="cb873-16" data-line-number="16">    sum_sk =<span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb873-17" data-line-number="17">    <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>N) {</a>
<a class="sourceLine" id="cb873-18" data-line-number="18">      sum_sk =<span class="st"> </span>sum_sk <span class="op">+</span><span class="st"> </span>rik[i,k] <span class="op">*</span><span class="st"> </span>(x[i,] <span class="op">-</span><span class="st"> </span></a>
<a class="sourceLine" id="cb873-19" data-line-number="19"><span class="st">                                  </span>xm[k,]) <span class="op">%*%</span><span class="st"> </span><span class="kw">t</span>(x[i,] <span class="op">-</span><span class="st"> </span>xm[k,])</a>
<a class="sourceLine" id="cb873-20" data-line-number="20">    }</a>
<a class="sourceLine" id="cb873-21" data-line-number="21">    S[,,k] =<span class="st"> </span>sum_sk <span class="op">/</span><span class="st"> </span>rk[k]</a>
<a class="sourceLine" id="cb873-22" data-line-number="22">  }</a>
<a class="sourceLine" id="cb873-23" data-line-number="23">  S</a>
<a class="sourceLine" id="cb873-24" data-line-number="24">}</a>
<a class="sourceLine" id="cb873-25" data-line-number="25">VEM &lt;-<span class="st"> </span><span class="cf">function</span>(x, params) {</a>
<a class="sourceLine" id="cb873-26" data-line-number="26">  <span class="co"># consider k = 3 ( tri-modal )</span></a>
<a class="sourceLine" id="cb873-27" data-line-number="27">  omega<span class="fl">.0</span> =<span class="st"> </span><span class="dv">1</span><span class="op">/</span>K          <span class="co"># mixing weight hyperparameter</span></a>
<a class="sourceLine" id="cb873-28" data-line-number="28">  alpha<span class="fl">.0</span> =<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, P)    <span class="co"># mean hyperparameter</span></a>
<a class="sourceLine" id="cb873-29" data-line-number="29">  beta<span class="fl">.0</span>  =<span class="st"> </span><span class="dv">1</span>            <span class="co"># variance hyperparameter</span></a>
<a class="sourceLine" id="cb873-30" data-line-number="30">  v<span class="fl">.0</span>     =<span class="st"> </span>P            <span class="co"># degrees of freedom hyperparameter</span></a>
<a class="sourceLine" id="cb873-31" data-line-number="31">  sigma<span class="fl">.0</span> =<span class="st"> </span><span class="kw">diag</span>(P)      <span class="co"># lambda - covariance hyperparameter</span></a>
<a class="sourceLine" id="cb873-32" data-line-number="32">  <span class="co"># hyperparameters</span></a>
<a class="sourceLine" id="cb873-33" data-line-number="33">  omega      =<span class="st"> </span>params<span class="op">$</span>omega</a>
<a class="sourceLine" id="cb873-34" data-line-number="34">  alpha      =<span class="st"> </span>params<span class="op">$</span>alpha</a>
<a class="sourceLine" id="cb873-35" data-line-number="35">  beta       =<span class="st"> </span>params<span class="op">$</span>beta  </a>
<a class="sourceLine" id="cb873-36" data-line-number="36">  v          =<span class="st"> </span>params<span class="op">$</span>v     </a>
<a class="sourceLine" id="cb873-37" data-line-number="37">  sigma     =<span class="st"> </span>params<span class="op">$</span>sigma </a>
<a class="sourceLine" id="cb873-38" data-line-number="38">  <span class="co"># expectation estimations</span></a>
<a class="sourceLine" id="cb873-39" data-line-number="39">  loge_pi     =<span class="st"> </span>params<span class="op">$</span>loge_pi</a>
<a class="sourceLine" id="cb873-40" data-line-number="40">  loge_lambda =<span class="st"> </span>params<span class="op">$</span>loge_lambda</a>
<a class="sourceLine" id="cb873-41" data-line-number="41">  E_mulambda  =<span class="st"> </span>params<span class="op">$</span>E_mulambda</a>
<a class="sourceLine" id="cb873-42" data-line-number="42">  pik         =<span class="st"> </span><span class="kw">matrix</span>(<span class="dv">0</span>, N, K)</a>
<a class="sourceLine" id="cb873-43" data-line-number="43">  <span class="co">############### Variational E-Step ###########################</span></a>
<a class="sourceLine" id="cb873-44" data-line-number="44">  <span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>K) {</a>
<a class="sourceLine" id="cb873-45" data-line-number="45">    loge_lambda[k] =<span class="st"> </span><span class="dv">0</span>  </a>
<a class="sourceLine" id="cb873-46" data-line-number="46">    <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>P) {</a>
<a class="sourceLine" id="cb873-47" data-line-number="47">      loge_lambda[k] =<span class="st"> </span>loge_lambda[k] <span class="op">+</span><span class="st"> </span><span class="kw">digamma</span>( (v[k] <span class="op">-</span><span class="st"> </span>i <span class="op">+</span><span class="st"> </span><span class="dv">1</span>) <span class="op">/</span><span class="st"> </span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb873-48" data-line-number="48">    }</a>
<a class="sourceLine" id="cb873-49" data-line-number="49">    loge_lambda[k] =<span class="st"> </span>P <span class="op">*</span><span class="st"> </span><span class="kw">ln</span>(<span class="dv">2</span>) <span class="op">+</span><span class="st"> </span><span class="kw">ln</span>(<span class="kw">det</span>(sigma[,,k])) <span class="op">+</span><span class="st"> </span>loge_lambda[k]</a>
<a class="sourceLine" id="cb873-50" data-line-number="50">    loge_pi[k] =<span class="st"> </span><span class="kw">digamma</span>(omega[k]) <span class="op">-</span><span class="st"> </span><span class="kw">digamma</span>(<span class="kw">sum</span>(omega))</a>
<a class="sourceLine" id="cb873-51" data-line-number="51">    </a>
<a class="sourceLine" id="cb873-52" data-line-number="52">    <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>N) {</a>
<a class="sourceLine" id="cb873-53" data-line-number="53">      E_mulambda[i,k] =<span class="st"> </span>(P <span class="op">/</span><span class="st"> </span>beta[k]) <span class="op">+</span></a>
<a class="sourceLine" id="cb873-54" data-line-number="54"><span class="st">         </span>v[k] <span class="op">*</span><span class="st"> </span><span class="kw">t</span>(x[i,] <span class="op">-</span><span class="st"> </span>alpha[k,]) <span class="op">%*%</span><span class="st"> </span>sigma[,,k] <span class="op">%*%</span></a>
<a class="sourceLine" id="cb873-55" data-line-number="55"><span class="st">                          </span>(x[i,] <span class="op">-</span><span class="st"> </span>alpha[k,])</a>
<a class="sourceLine" id="cb873-56" data-line-number="56">      </a>
<a class="sourceLine" id="cb873-57" data-line-number="57">      pik[i,k] =<span class="st"> </span>loge_pi[k]  <span class="op">+</span><span class="st"> </span><span class="fl">0.5</span> <span class="op">*</span><span class="st"> </span>loge_lambda[k] <span class="op">-</span><span class="st"> </span></a>
<a class="sourceLine" id="cb873-58" data-line-number="58"><span class="st">                 </span><span class="fl">0.5</span> <span class="op">*</span><span class="st"> </span>E_mulambda[i,k] <span class="op">-</span><span class="st"> </span>(P<span class="op">/</span><span class="dv">2</span>) <span class="op">*</span><span class="st"> </span><span class="kw">ln</span>(<span class="dv">2</span><span class="op">*</span>pi)  </a>
<a class="sourceLine" id="cb873-59" data-line-number="59">    }</a>
<a class="sourceLine" id="cb873-60" data-line-number="60">  }</a>
<a class="sourceLine" id="cb873-61" data-line-number="61">  <span class="co">############### Update Cluster Statistics #####################</span></a>
<a class="sourceLine" id="cb873-62" data-line-number="62">  rik =<span class="st"> </span><span class="kw">one_hot_encoding</span>(pik)</a>
<a class="sourceLine" id="cb873-63" data-line-number="63">  rk =<span class="st"> </span><span class="kw">apply</span>(rik, <span class="dv">2</span>, sum) <span class="co"># capture no of obsv per cluster</span></a>
<a class="sourceLine" id="cb873-64" data-line-number="64">  xm =<span class="st"> </span><span class="kw">update_xmean</span>(x, rik, rk)</a>
<a class="sourceLine" id="cb873-65" data-line-number="65">  S  =<span class="st"> </span><span class="kw">update_S</span>(x, rik, rk, xm)</a>
<a class="sourceLine" id="cb873-66" data-line-number="66">  <span class="co">############### Variational M-Step ###########################</span></a>
<a class="sourceLine" id="cb873-67" data-line-number="67">  <span class="co"># Update hyperparameters</span></a>
<a class="sourceLine" id="cb873-68" data-line-number="68">  <span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>K) {</a>
<a class="sourceLine" id="cb873-69" data-line-number="69">    <span class="co"># beta1</span></a>
<a class="sourceLine" id="cb873-70" data-line-number="70">    beta[k] =<span class="st"> </span>beta<span class="fl">.0</span> <span class="op">+</span><span class="st"> </span>rk[k]</a>
<a class="sourceLine" id="cb873-71" data-line-number="71">    <span class="co"># alpha1</span></a>
<a class="sourceLine" id="cb873-72" data-line-number="72">    alpha[k,] =<span class="st">  </span>(alpha<span class="fl">.0</span> <span class="op">*</span><span class="st"> </span>beta<span class="fl">.0</span> <span class="op">+</span><span class="st"> </span>rk[k] <span class="op">*</span><span class="st"> </span>xm[k,]) <span class="op">/</span><span class="st"> </span>beta[k]</a>
<a class="sourceLine" id="cb873-73" data-line-number="73">    <span class="co"># v1</span></a>
<a class="sourceLine" id="cb873-74" data-line-number="74">    v[k] =<span class="st"> </span>v<span class="fl">.0</span> <span class="op">+</span><span class="st"> </span>rk[k]</a>
<a class="sourceLine" id="cb873-75" data-line-number="75">    <span class="co"># sigma1</span></a>
<a class="sourceLine" id="cb873-76" data-line-number="76">    sigma[,,k] =<span class="st">  </span>((beta<span class="fl">.0</span> <span class="op">*</span><span class="st"> </span>rk[k]) <span class="op">/</span><span class="st"> </span>beta[k ]) <span class="op">*</span></a>
<a class="sourceLine" id="cb873-77" data-line-number="77"><span class="st">                   </span>(xm[k,] <span class="op">-</span><span class="st"> </span>alpha<span class="fl">.0</span>) <span class="op">%*%</span><span class="st"> </span><span class="kw">t</span>(xm[k,] <span class="op">-</span><span class="st"> </span>alpha<span class="fl">.0</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb873-78" data-line-number="78"><span class="st">                   </span><span class="op">+</span><span class="st"> </span>rk[k] <span class="op">*</span><span class="st"> </span>S[,,k] <span class="op">+</span><span class="st">  </span><span class="kw">solve</span>(sigma<span class="fl">.0</span>)</a>
<a class="sourceLine" id="cb873-79" data-line-number="79">  }</a>
<a class="sourceLine" id="cb873-80" data-line-number="80">  <span class="co"># hyperparameters</span></a>
<a class="sourceLine" id="cb873-81" data-line-number="81">  params<span class="op">$</span>omega       =<span class="st"> </span>omega</a>
<a class="sourceLine" id="cb873-82" data-line-number="82">  params<span class="op">$</span>alpha        =<span class="st"> </span>alpha</a>
<a class="sourceLine" id="cb873-83" data-line-number="83">  params<span class="op">$</span>beta        =<span class="st"> </span>beta</a>
<a class="sourceLine" id="cb873-84" data-line-number="84">  params<span class="op">$</span>v           =<span class="st"> </span>v</a>
<a class="sourceLine" id="cb873-85" data-line-number="85">  params<span class="op">$</span>sigma    =<span class="st"> </span>sigma</a>
<a class="sourceLine" id="cb873-86" data-line-number="86">  <span class="co"># expectation estimations</span></a>
<a class="sourceLine" id="cb873-87" data-line-number="87">  params<span class="op">$</span>loge_pi     =<span class="st"> </span>loge_pi</a>
<a class="sourceLine" id="cb873-88" data-line-number="88">  params<span class="op">$</span>loge_lambda =<span class="st"> </span>loge_lambda</a>
<a class="sourceLine" id="cb873-89" data-line-number="89">  params<span class="op">$</span>E_mulambda  =<span class="st"> </span>E_mulambda</a>
<a class="sourceLine" id="cb873-90" data-line-number="90">  <span class="kw">list</span>( <span class="st">&quot;params&quot;</span> =<span class="st"> </span>params, <span class="st">&quot;rik&quot;</span>=rik, <span class="st">&quot;rk&quot;</span>=rk,  <span class="st">&quot;S&quot;</span> =<span class="st"> </span>S, <span class="st">&quot;xm&quot;</span> =<span class="st"> </span>xm)</a>
<a class="sourceLine" id="cb873-91" data-line-number="91">}</a></code></pre></div>



<p><strong>Finally</strong>, we step through the iteration until <strong>ELBO</strong> converges.</p>

<div class="sourceCode" id="cb874"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb874-1" data-line-number="1">tol =<span class="st"> </span><span class="fl">1e-5</span></a>
<a class="sourceLine" id="cb874-2" data-line-number="2">limit =<span class="st">  </span><span class="dv">100</span></a>
<a class="sourceLine" id="cb874-3" data-line-number="3">old_elbo =<span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb874-4" data-line-number="4">params =<span class="st"> </span><span class="kw">initialize</span>(data)</a>
<a class="sourceLine" id="cb874-5" data-line-number="5"><span class="cf">for</span> (iterate <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>limit) {</a>
<a class="sourceLine" id="cb874-6" data-line-number="6">  vem =<span class="st"> </span><span class="kw">VEM</span>(data<span class="op">$</span>x, params)</a>
<a class="sourceLine" id="cb874-7" data-line-number="7">  elbo =<span class="st"> </span><span class="kw">with</span>(vem, <span class="kw">ELBO</span>(params, rik, rk, S, xm))</a>
<a class="sourceLine" id="cb874-8" data-line-number="8">  <span class="cf">if</span> (<span class="op">!</span><span class="kw">is.nan</span>(elbo)) {</a>
<a class="sourceLine" id="cb874-9" data-line-number="9">    err =<span class="st"> </span><span class="kw">abs</span>(elbo <span class="op">-</span><span class="st"> </span>old_elbo)</a>
<a class="sourceLine" id="cb874-10" data-line-number="10">    <span class="cf">if</span> (err <span class="op">&lt;</span><span class="st"> </span>tol) <span class="cf">break</span></a>
<a class="sourceLine" id="cb874-11" data-line-number="11">  }</a>
<a class="sourceLine" id="cb874-12" data-line-number="12">  old_elbo =<span class="st"> </span>elbo</a>
<a class="sourceLine" id="cb874-13" data-line-number="13">  params =<span class="st"> </span>vem<span class="op">$</span>params</a>
<a class="sourceLine" id="cb874-14" data-line-number="14">}</a>
<a class="sourceLine" id="cb874-15" data-line-number="15"><span class="kw">print</span>(<span class="kw">paste0</span>(<span class="st">&quot;Number of Iterations : &quot;</span>, iterate))</a></code></pre></div>
<pre><code>## [1] &quot;Number of Iterations : 3&quot;</code></pre>

<p>And now we plot the data points with the assigned colors (see Figure <a href="bayesian.html#fig:bivartrimodel2">7.22</a>).</p>

<div class="sourceCode" id="cb876"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb876-1" data-line-number="1">color =<span class="st"> </span><span class="kw">apply</span>(vem<span class="op">$</span>rik, <span class="dv">1</span>, which.max) <span class="op">+</span><span class="st"> </span><span class="dv">1</span></a>
<a class="sourceLine" id="cb876-2" data-line-number="2"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="dv">40</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="dv">40</span>), </a>
<a class="sourceLine" id="cb876-3" data-line-number="3">     <span class="dt">xlab=</span><span class="st">&quot;x1&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;x2&quot;</span>,</a>
<a class="sourceLine" id="cb876-4" data-line-number="4">     <span class="dt">main=</span><span class="st">&quot;Bivariate tri-modal mixture model&quot;</span>,  <span class="dt">frame=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb876-5" data-line-number="5"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb876-6" data-line-number="6"><span class="kw">points</span>(data<span class="op">$</span>x[,<span class="dv">1</span>], data<span class="op">$</span>x[,<span class="dv">2</span>], <span class="dt">col=</span>color, <span class="dt">pch=</span><span class="dv">16</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:bivartrimodel2"></span>
<img src="DS_files/figure-html/bivartrimodel2-1.png" alt="Approximate Bivariate tri-modal mixture model" width="70%" />
<p class="caption">
Figure 7.22: Approximate Bivariate tri-modal mixture model
</p>
</div>


</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="statistics.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="bayesian2.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "sepia",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["DS.pdf", "DS.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
