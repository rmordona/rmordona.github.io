<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 5 Numerical Probability and Distribution | The Power and Art of Approximation</title>
  <meta name="description" content="Inspired by the vast amount of knowledge across a wide span of fields, this book covers a compendium of both analytical and numerical techniques, conflated into a common idea to showcase the fundamental requirements of Data Science and Machine Learning (ML) Engineering. Our common theme across the book is intuition, contemplating more on fundamental operations than mathematical rigor. This book is written for those who are new to Data Science and have developed some proclivity towards this field but may not know where to begin. The hope is that we can introduce some fundamental aspects of Data Science in a more progressive and possibly structured manner. Depending on interest, this book tries to avoid being specific to a target audience. The premise is that Data Science can be for everybody, whether one is an engineer, a researcher in a specific domain, or, for that matter, an undergraduate student just trying to get into this field. As a starting point and as a supplemental reference for anyone (professional or not alike) wanting to pursue Data Science in conjunction with his or her domain, it is essential to take a refresh of mathematical concepts first which we encourage readers to take this first step. For that reason, we cover a list of mathematical concepts that are no doubt valuable to get us to Machine Learning concepts eventually. Only a certain elementary and introductory portion of each field of mathematics are covered while we put emphasis only on the relevant and essential areas. But while that is the case, admittedly, the first half (or the first volume) of this book talks about Linear Algebra, Numerical Analysis, Statistical Analysis, and Bayesian Analysis. This is founded upon the idea that most of what we do in Data Science is expressed in the language of mathematics, more numerically inclined in fact than analytical - meaning, we live to decide on the basis of close approximation in many situations. And it is just right to have a historical perspective of the mathematical foundations which Machine Learning algorithms may have come about - if not at least what they fundamentally depend upon. The second half of the book covers ML methods such as Linear Regression, Regression and Classification Trees, Random Forest, XGBoost, SVM, and many others. It covers clustering such as KNN, Hierarchical clustering, and DBSCAN. Finally, it covers Deep Neural Networks such as CNN, RNN (LSTM/GRU), ResNet, and Transformers." />
  <meta name="generator" content="bookdown 0.16 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 5 Numerical Probability and Distribution | The Power and Art of Approximation" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Inspired by the vast amount of knowledge across a wide span of fields, this book covers a compendium of both analytical and numerical techniques, conflated into a common idea to showcase the fundamental requirements of Data Science and Machine Learning (ML) Engineering. Our common theme across the book is intuition, contemplating more on fundamental operations than mathematical rigor. This book is written for those who are new to Data Science and have developed some proclivity towards this field but may not know where to begin. The hope is that we can introduce some fundamental aspects of Data Science in a more progressive and possibly structured manner. Depending on interest, this book tries to avoid being specific to a target audience. The premise is that Data Science can be for everybody, whether one is an engineer, a researcher in a specific domain, or, for that matter, an undergraduate student just trying to get into this field. As a starting point and as a supplemental reference for anyone (professional or not alike) wanting to pursue Data Science in conjunction with his or her domain, it is essential to take a refresh of mathematical concepts first which we encourage readers to take this first step. For that reason, we cover a list of mathematical concepts that are no doubt valuable to get us to Machine Learning concepts eventually. Only a certain elementary and introductory portion of each field of mathematics are covered while we put emphasis only on the relevant and essential areas. But while that is the case, admittedly, the first half (or the first volume) of this book talks about Linear Algebra, Numerical Analysis, Statistical Analysis, and Bayesian Analysis. This is founded upon the idea that most of what we do in Data Science is expressed in the language of mathematics, more numerically inclined in fact than analytical - meaning, we live to decide on the basis of close approximation in many situations. And it is just right to have a historical perspective of the mathematical foundations which Machine Learning algorithms may have come about - if not at least what they fundamentally depend upon. The second half of the book covers ML methods such as Linear Regression, Regression and Classification Trees, Random Forest, XGBoost, SVM, and many others. It covers clustering such as KNN, Hierarchical clustering, and DBSCAN. Finally, it covers Deep Neural Networks such as CNN, RNN (LSTM/GRU), ResNet, and Transformers." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 Numerical Probability and Distribution | The Power and Art of Approximation" />
  
  <meta name="twitter:description" content="Inspired by the vast amount of knowledge across a wide span of fields, this book covers a compendium of both analytical and numerical techniques, conflated into a common idea to showcase the fundamental requirements of Data Science and Machine Learning (ML) Engineering. Our common theme across the book is intuition, contemplating more on fundamental operations than mathematical rigor. This book is written for those who are new to Data Science and have developed some proclivity towards this field but may not know where to begin. The hope is that we can introduce some fundamental aspects of Data Science in a more progressive and possibly structured manner. Depending on interest, this book tries to avoid being specific to a target audience. The premise is that Data Science can be for everybody, whether one is an engineer, a researcher in a specific domain, or, for that matter, an undergraduate student just trying to get into this field. As a starting point and as a supplemental reference for anyone (professional or not alike) wanting to pursue Data Science in conjunction with his or her domain, it is essential to take a refresh of mathematical concepts first which we encourage readers to take this first step. For that reason, we cover a list of mathematical concepts that are no doubt valuable to get us to Machine Learning concepts eventually. Only a certain elementary and introductory portion of each field of mathematics are covered while we put emphasis only on the relevant and essential areas. But while that is the case, admittedly, the first half (or the first volume) of this book talks about Linear Algebra, Numerical Analysis, Statistical Analysis, and Bayesian Analysis. This is founded upon the idea that most of what we do in Data Science is expressed in the language of mathematics, more numerically inclined in fact than analytical - meaning, we live to decide on the basis of close approximation in many situations. And it is just right to have a historical perspective of the mathematical foundations which Machine Learning algorithms may have come about - if not at least what they fundamentally depend upon. The second half of the book covers ML methods such as Linear Regression, Regression and Classification Trees, Random Forest, XGBoost, SVM, and many others. It covers clustering such as KNN, Hierarchical clustering, and DBSCAN. Finally, it covers Deep Neural Networks such as CNN, RNN (LSTM/GRU), ResNet, and Transformers." />
  

<meta name="author" content="Raymond Michael Ofiaza OrdoÃ±a" />


<meta name="date" content="2022-02-12" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="numerical-calculus.html"/>
<link rel="next" href="statistics.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">The Power and Art of Approximation</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="0.1" data-path="index.html"><a href="index.html#acknowledgment-and-motivations"><i class="fa fa-check"></i><b>0.1</b> Acknowledgment and Motivations</a></li>
<li class="chapter" data-level="0.2" data-path="index.html"><a href="index.html#about-the-author"><i class="fa fa-check"></i><b>0.2</b> About the Author</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="" data-path="mathematical-notation.html"><a href="mathematical-notation.html"><i class="fa fa-check"></i>Mathematical Notation</a><ul>
<li class="chapter" data-level="0.3" data-path="mathematical-notation.html"><a href="mathematical-notation.html#notation"><i class="fa fa-check"></i><b>0.3</b> Notation</a></li>
<li class="chapter" data-level="0.4" data-path="mathematical-notation.html"><a href="mathematical-notation.html#number-system"><i class="fa fa-check"></i><b>0.4</b> Number System</a></li>
<li class="chapter" data-level="0.5" data-path="mathematical-notation.html"><a href="mathematical-notation.html#implementation"><i class="fa fa-check"></i><b>0.5</b> Implementation</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="numerical-methods.html"><a href="numerical-methods.html"><i class="fa fa-check"></i><b>1</b> Direct and Indirect Methods</a><ul>
<li class="chapter" data-level="1.1" data-path="numerical-methods.html"><a href="numerical-methods.html#closed-form-equation"><i class="fa fa-check"></i><b>1.1</b> Closed-form equation</a></li>
<li class="chapter" data-level="1.2" data-path="numerical-methods.html"><a href="numerical-methods.html#analytical-and-numerical-solutions"><i class="fa fa-check"></i><b>1.2</b> Analytical and Numerical solutions  </a></li>
<li class="chapter" data-level="1.3" data-path="numerical-methods.html"><a href="numerical-methods.html#significant-figures"><i class="fa fa-check"></i><b>1.3</b> Significant figures</a></li>
<li class="chapter" data-level="1.4" data-path="numerical-methods.html"><a href="numerical-methods.html#accuracy"><i class="fa fa-check"></i><b>1.4</b> Accuracy</a></li>
<li class="chapter" data-level="1.5" data-path="numerical-methods.html"><a href="numerical-methods.html#precision"><i class="fa fa-check"></i><b>1.5</b> Precision </a></li>
<li class="chapter" data-level="1.6" data-path="numerical-methods.html"><a href="numerical-methods.html#stability-and-sensitivity"><i class="fa fa-check"></i><b>1.6</b> Stability and Sensitivity  </a></li>
<li class="chapter" data-level="1.7" data-path="numerical-methods.html"><a href="numerical-methods.html#stiffness-and-implicitness"><i class="fa fa-check"></i><b>1.7</b> Stiffness and Implicitness  </a></li>
<li class="chapter" data-level="1.8" data-path="numerical-methods.html"><a href="numerical-methods.html#conditioning-and-posedness"><i class="fa fa-check"></i><b>1.8</b> Conditioning and Posedness  </a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="linear-algebra.html"><a href="linear-algebra.html"><i class="fa fa-check"></i><b>2</b> Numerical Linear Algebra I</a><ul>
<li class="chapter" data-level="2.1" data-path="linear-algebra.html"><a href="linear-algebra.html#system-of-linear-equations"><i class="fa fa-check"></i><b>2.1</b> System of Linear Equations</a></li>
<li class="chapter" data-level="2.2" data-path="linear-algebra.html"><a href="linear-algebra.html#scalar-vector-and-matrix-tensor"><i class="fa fa-check"></i><b>2.2</b> Scalar, Vector, and Matrix, Tensor</a></li>
<li class="chapter" data-level="2.3" data-path="linear-algebra.html"><a href="linear-algebra.html#transposition-and-multiplication"><i class="fa fa-check"></i><b>2.3</b> Transposition and Multiplication</a><ul>
<li class="chapter" data-level="2.3.1" data-path="linear-algebra.html"><a href="linear-algebra.html#transposition"><i class="fa fa-check"></i><b>2.3.1</b> Transposition</a></li>
<li class="chapter" data-level="2.3.2" data-path="linear-algebra.html"><a href="linear-algebra.html#dot-product"><i class="fa fa-check"></i><b>2.3.2</b> Dot Product</a></li>
<li class="chapter" data-level="2.3.3" data-path="linear-algebra.html"><a href="linear-algebra.html#hadamard-product"><i class="fa fa-check"></i><b>2.3.3</b> Hadamard Product</a></li>
<li class="chapter" data-level="2.3.4" data-path="linear-algebra.html"><a href="linear-algebra.html#kronecker-product"><i class="fa fa-check"></i><b>2.3.4</b> Kronecker Product</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="linear-algebra.html"><a href="linear-algebra.html#magnitude-direction-unit-vectors"><i class="fa fa-check"></i><b>2.4</b> Magnitude, Direction, Unit Vectors</a></li>
<li class="chapter" data-level="2.5" data-path="linear-algebra.html"><a href="linear-algebra.html#linear-combination-and-independence"><i class="fa fa-check"></i><b>2.5</b> Linear Combination and Independence</a></li>
<li class="chapter" data-level="2.6" data-path="linear-algebra.html"><a href="linear-algebra.html#space-span-and-basis"><i class="fa fa-check"></i><b>2.6</b> Space, Span and Basis</a></li>
<li class="chapter" data-level="2.7" data-path="linear-algebra.html"><a href="linear-algebra.html#determinants"><i class="fa fa-check"></i><b>2.7</b> Determinants </a></li>
<li class="chapter" data-level="2.8" data-path="linear-algebra.html"><a href="linear-algebra.html#minors-cofactors-and-adjugate-forms"><i class="fa fa-check"></i><b>2.8</b> Minors, Cofactors, and Adjugate Forms</a></li>
<li class="chapter" data-level="2.9" data-path="linear-algebra.html"><a href="linear-algebra.html#inverse-form-and-row-echelon-form"><i class="fa fa-check"></i><b>2.9</b> Inverse Form and Row Echelon Form</a></li>
<li class="chapter" data-level="2.10" data-path="linear-algebra.html"><a href="linear-algebra.html#linear-transformations"><i class="fa fa-check"></i><b>2.10</b> Linear Transformations</a><ul>
<li class="chapter" data-level="2.10.1" data-path="linear-algebra.html"><a href="linear-algebra.html#scaling"><i class="fa fa-check"></i><b>2.10.1</b> Scaling </a></li>
<li class="chapter" data-level="2.10.2" data-path="linear-algebra.html"><a href="linear-algebra.html#transvection-shearing"><i class="fa fa-check"></i><b>2.10.2</b> Transvection (Shearing)  </a></li>
<li class="chapter" data-level="2.10.3" data-path="linear-algebra.html"><a href="linear-algebra.html#rotation"><i class="fa fa-check"></i><b>2.10.3</b> Rotation </a></li>
<li class="chapter" data-level="2.10.4" data-path="linear-algebra.html"><a href="linear-algebra.html#reflection"><i class="fa fa-check"></i><b>2.10.4</b> Reflection </a></li>
<li class="chapter" data-level="2.10.5" data-path="linear-algebra.html"><a href="linear-algebra.html#projection"><i class="fa fa-check"></i><b>2.10.5</b> Projection </a></li>
<li class="chapter" data-level="2.10.6" data-path="linear-algebra.html"><a href="linear-algebra.html#translation"><i class="fa fa-check"></i><b>2.10.6</b> Translation </a></li>
<li class="chapter" data-level="2.10.7" data-path="linear-algebra.html"><a href="linear-algebra.html#dilation-and-composition"><i class="fa fa-check"></i><b>2.10.7</b> Dilation and Composition  </a></li>
</ul></li>
<li class="chapter" data-level="2.11" data-path="linear-algebra.html"><a href="linear-algebra.html#rank-and-nullity"><i class="fa fa-check"></i><b>2.11</b> Rank and Nullity  </a></li>
<li class="chapter" data-level="2.12" data-path="linear-algebra.html"><a href="linear-algebra.html#singularity-and-triviality"><i class="fa fa-check"></i><b>2.12</b> Singularity and Triviality  </a></li>
<li class="chapter" data-level="2.13" data-path="linear-algebra.html"><a href="linear-algebra.html#orthogonality-and-orthonormality"><i class="fa fa-check"></i><b>2.13</b> Orthogonality and Orthonormality  </a></li>
<li class="chapter" data-level="2.14" data-path="linear-algebra.html"><a href="linear-algebra.html#eigenvectors-and-eigenvalues"><i class="fa fa-check"></i><b>2.14</b> Eigenvectors and Eigenvalues  </a></li>
<li class="chapter" data-level="2.15" data-path="linear-algebra.html"><a href="linear-algebra.html#eigen-spectral-decomposition"><i class="fa fa-check"></i><b>2.15</b> Eigen (Spectral) Decomposition</a></li>
<li class="chapter" data-level="2.16" data-path="linear-algebra.html"><a href="linear-algebra.html#diagonalizability-of-a-matrix"><i class="fa fa-check"></i><b>2.16</b> Diagonalizability of a Matrix </a></li>
<li class="chapter" data-level="2.17" data-path="linear-algebra.html"><a href="linear-algebra.html#trace-of-a-square-matrix"><i class="fa fa-check"></i><b>2.17</b> Trace of a Square Matrix </a></li>
<li class="chapter" data-level="2.18" data-path="linear-algebra.html"><a href="linear-algebra.html#algebraic-and-geometric-multiplicity"><i class="fa fa-check"></i><b>2.18</b> Algebraic and Geometric Multiplicity</a></li>
<li class="chapter" data-level="2.19" data-path="linear-algebra.html"><a href="linear-algebra.html#types-of-matrices"><i class="fa fa-check"></i><b>2.19</b> Types of Matrices</a></li>
<li class="chapter" data-level="2.20" data-path="linear-algebra.html"><a href="linear-algebra.html#matrix-factorization"><i class="fa fa-check"></i><b>2.20</b> Matrix Factorization </a><ul>
<li class="chapter" data-level="2.20.1" data-path="linear-algebra.html"><a href="linear-algebra.html#eigen-spectral-decomposition-1"><i class="fa fa-check"></i><b>2.20.1</b> Eigen (Spectral) Decomposition  </a></li>
<li class="chapter" data-level="2.20.2" data-path="linear-algebra.html"><a href="linear-algebra.html#ludecomposition"><i class="fa fa-check"></i><b>2.20.2</b> LU Decomposition (Gauss-Jordan Elimination)</a></li>
<li class="chapter" data-level="2.20.3" data-path="linear-algebra.html"><a href="linear-algebra.html#ldu-factorization"><i class="fa fa-check"></i><b>2.20.3</b> LDU Factorization </a></li>
<li class="chapter" data-level="2.20.4" data-path="linear-algebra.html"><a href="linear-algebra.html#qr-factorization-gram-schmidt-householder-and-givens"><i class="fa fa-check"></i><b>2.20.4</b> QR Factorization (Gram-Schmidt, Householder, and Givens) </a></li>
<li class="chapter" data-level="2.20.5" data-path="linear-algebra.html"><a href="linear-algebra.html#cholesky-factorization"><i class="fa fa-check"></i><b>2.20.5</b> Cholesky Factorization </a></li>
<li class="chapter" data-level="2.20.6" data-path="linear-algebra.html"><a href="linear-algebra.html#svd-factorization"><i class="fa fa-check"></i><b>2.20.6</b> SVD Factorization </a></li>
<li class="chapter" data-level="2.20.7" data-path="linear-algebra.html"><a href="linear-algebra.html#jordan-decomposition"><i class="fa fa-check"></i><b>2.20.7</b> Jordan Decomposition </a></li>
<li class="chapter" data-level="2.20.8" data-path="linear-algebra.html"><a href="linear-algebra.html#other-decomposition"><i class="fa fa-check"></i><b>2.20.8</b> Other Decomposition</a></li>
</ul></li>
<li class="chapter" data-level="2.21" data-path="linear-algebra.html"><a href="linear-algebra.html#software-libraries"><i class="fa fa-check"></i><b>2.21</b> Software libraries    </a></li>
<li class="chapter" data-level="2.22" data-path="linear-algebra.html"><a href="linear-algebra.html#summary"><i class="fa fa-check"></i><b>2.22</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html"><i class="fa fa-check"></i><b>3</b> Numerical Linear Algebra II</a><ul>
<li class="chapter" data-level="3.1" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html#iteration-and-convergence"><i class="fa fa-check"></i><b>3.1</b> Iteration and Convergence </a></li>
<li class="chapter" data-level="3.2" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html#approximating-eigenvalues-and-eigenvectors-by-iteration-a-v-lambda-v"><i class="fa fa-check"></i><b>3.2</b> Approximating Eigenvalues and Eigenvectors by Iteration (<span class="math inline">\(A v = \lambda v\)</span>)</a><ul>
<li class="chapter" data-level="3.2.1" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html#power-method"><i class="fa fa-check"></i><b>3.2.1</b> Power Method </a></li>
<li class="chapter" data-level="3.2.2" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html#inverse-power-method-using-lu-decomposition"><i class="fa fa-check"></i><b>3.2.2</b> Inverse Power Method (using LU Decomposition)</a></li>
<li class="chapter" data-level="3.2.3" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html#rayleigh-quotient-method-using-lu-decomposition"><i class="fa fa-check"></i><b>3.2.3</b> Rayleigh Quotient Method (using LU Decomposition)</a></li>
<li class="chapter" data-level="3.2.4" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html#qr-method-using-qr-decomposition-by-givens"><i class="fa fa-check"></i><b>3.2.4</b> QR Method (using QR Decomposition by Givens)</a></li>
<li class="chapter" data-level="3.2.5" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html#jacobi-eigenvalue-method-using-jacobi-rotation"><i class="fa fa-check"></i><b>3.2.5</b> Jacobi Eigenvalue Method (using Jacobi Rotation)</a></li>
<li class="chapter" data-level="3.2.6" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html#arnoldi-method-using-gram-schmidt-in-krylov-subspace"><i class="fa fa-check"></i><b>3.2.6</b> Arnoldi Method (using Gram-Schmidt in Krylov Subspace) </a></li>
<li class="chapter" data-level="3.2.7" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html#lanczos-method-using-gram-schmidt-in-krylov-subspace"><i class="fa fa-check"></i><b>3.2.7</b> Lanczos Method (using Gram-Schmidt in Krylov Subspace)</a></li>
<li class="chapter" data-level="3.2.8" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html#fine-tuning-of-iteration-and-convergence"><i class="fa fa-check"></i><b>3.2.8</b> Fine-Tuning of Iteration and Convergence</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html#approximating-root-and-fixed-point-by-iteration"><i class="fa fa-check"></i><b>3.3</b> Approximating Root and Fixed-Point by Iteration</a><ul>
<li class="chapter" data-level="3.3.1" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html#root-finding-method-fx-0"><i class="fa fa-check"></i><b>3.3.1</b> Root-Finding Method (<span class="math inline">\(f(x) = 0\)</span>) </a></li>
<li class="chapter" data-level="3.3.2" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html#fixed-point-method-fx-x"><i class="fa fa-check"></i><b>3.3.2</b> Fixed-Point Method (<span class="math inline">\(f(x) = x\)</span>) </a></li>
<li class="chapter" data-level="3.3.3" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html#bisection-method"><i class="fa fa-check"></i><b>3.3.3</b> Bisection Method </a></li>
<li class="chapter" data-level="3.3.4" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html#newton-raphson-method-using-the-tangent-line"><i class="fa fa-check"></i><b>3.3.4</b> Newton-Raphson Method (using the Tangent Line)</a></li>
<li class="chapter" data-level="3.3.5" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html#secant-method-using-the-secant-line"><i class="fa fa-check"></i><b>3.3.5</b> Secant Method (using the Secant Line)</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html#approximating-solutions-to-systems-of-equations-by-iteration-ax-b"><i class="fa fa-check"></i><b>3.4</b> Approximating Solutions to Systems of Equations by Iteration (<span class="math inline">\(Ax = b\)</span>)</a><ul>
<li class="chapter" data-level="3.4.1" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html#krylovmethods"><i class="fa fa-check"></i><b>3.4.1</b> Krylov Methods</a></li>
<li class="chapter" data-level="3.4.2" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html#gmres-generalized-minimal-residual"><i class="fa fa-check"></i><b>3.4.2</b> GMRES (Generalized Minimal Residual)  </a></li>
<li class="chapter" data-level="3.4.3" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html#conjugate-gradient-method-cg"><i class="fa fa-check"></i><b>3.4.3</b> Conjugate Gradient Method (CG)  </a></li>
<li class="chapter" data-level="3.4.4" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html#jacobi-and-gauss-seidel-method"><i class="fa fa-check"></i><b>3.4.4</b> Jacobi and Gauss-Seidel Method </a></li>
<li class="chapter" data-level="3.4.5" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html#successive-over-relaxation-sor-method"><i class="fa fa-check"></i><b>3.4.5</b> Successive Over-Relaxation (SOR) Method  </a></li>
<li class="chapter" data-level="3.4.6" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html#newtons-method"><i class="fa fa-check"></i><b>3.4.6</b> Newtonâs Method </a></li>
<li class="chapter" data-level="3.4.7" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html#broydens-method"><i class="fa fa-check"></i><b>3.4.7</b> Broydenâs Method </a></li>
<li class="chapter" data-level="3.4.8" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html#bfgs-broyden-fletcher-goldfarb-shanno-method"><i class="fa fa-check"></i><b>3.4.8</b> BFGS (Broyden-Fletcher-Goldfarb-Shanno) method </a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html#polynomial_regression"><i class="fa fa-check"></i><b>3.5</b> Approximating Polynomial Functions by Regression</a><ul>
<li class="chapter" data-level="3.5.1" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html#least-squares"><i class="fa fa-check"></i><b>3.5.1</b> Least-Squares </a></li>
<li class="chapter" data-level="3.5.2" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html#linear-regression"><i class="fa fa-check"></i><b>3.5.2</b> Linear Regression </a></li>
<li class="chapter" data-level="3.5.3" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html#higher_degree_polynomials"><i class="fa fa-check"></i><b>3.5.3</b> Higher Degree Polynomials</a></li>
<li class="chapter" data-level="3.5.4" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html#non-linear-regression"><i class="fa fa-check"></i><b>3.5.4</b> Non-Linear Regression </a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html#approximating-polynomial-functions-by-series-expansion"><i class="fa fa-check"></i><b>3.6</b> Approximating Polynomial Functions by Series Expansion </a></li>
<li class="chapter" data-level="3.7" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html#polynomial_interpolation"><i class="fa fa-check"></i><b>3.7</b> Approximating Polynomial Functions by Interpolation</a><ul>
<li class="chapter" data-level="3.7.1" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html#monomial-interpolation"><i class="fa fa-check"></i><b>3.7.1</b> Monomial interpolation </a></li>
<li class="chapter" data-level="3.7.2" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html#lagrange-interpolation"><i class="fa fa-check"></i><b>3.7.2</b> Lagrange interpolation </a></li>
<li class="chapter" data-level="3.7.3" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html#newton-interpolation"><i class="fa fa-check"></i><b>3.7.3</b> Newton interpolation </a></li>
<li class="chapter" data-level="3.7.4" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html#newton-forward-interpolation"><i class="fa fa-check"></i><b>3.7.4</b> Newton Forward interpolation </a></li>
<li class="chapter" data-level="3.7.5" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html#newton-backward-interpolation"><i class="fa fa-check"></i><b>3.7.5</b> Newton Backward interpolation </a></li>
<li class="chapter" data-level="3.7.6" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html#interpolation-considerations"><i class="fa fa-check"></i><b>3.7.6</b> Interpolation Considerations</a></li>
<li class="chapter" data-level="3.7.7" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html#lebesque-constant"><i class="fa fa-check"></i><b>3.7.7</b> Lebesque Constant </a></li>
<li class="chapter" data-level="3.7.8" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html#horners-method"><i class="fa fa-check"></i><b>3.7.8</b> Hornerâs method </a></li>
<li class="chapter" data-level="3.7.9" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html#piecewise-polynomial-interpolation"><i class="fa fa-check"></i><b>3.7.9</b> Piecewise Polynomial Interpolation </a></li>
<li class="chapter" data-level="3.7.10" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html#b-spline-interpolation"><i class="fa fa-check"></i><b>3.7.10</b> B-Spline interpolation </a></li>
<li class="chapter" data-level="3.7.11" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html#bspline"><i class="fa fa-check"></i><b>3.7.11</b> B-Spline Regression</a></li>
<li class="chapter" data-level="3.7.12" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html#p-spline-regression"><i class="fa fa-check"></i><b>3.7.12</b> P-Spline Regression </a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html#polynomial_smoothing"><i class="fa fa-check"></i><b>3.8</b> Approximating Polynomial Functions by Smoothing</a><ul>
<li class="chapter" data-level="3.8.1" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html#bin-smoothing"><i class="fa fa-check"></i><b>3.8.1</b> Bin Smoothing </a></li>
<li class="chapter" data-level="3.8.2" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html#scatterplot-smoothing"><i class="fa fa-check"></i><b>3.8.2</b> Scatterplot Smoothing </a></li>
<li class="chapter" data-level="3.8.3" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html#kernel-smoothing"><i class="fa fa-check"></i><b>3.8.3</b> Kernel Smoothing </a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html#polynomial-optimization"><i class="fa fa-check"></i><b>3.9</b> Polynomial Optimization </a><ul>
<li class="chapter" data-level="3.9.1" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html#simplex_method"><i class="fa fa-check"></i><b>3.9.1</b> Simplex Method</a></li>
<li class="chapter" data-level="3.9.2" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html#dual_simplex"><i class="fa fa-check"></i><b>3.9.2</b> Dual Simplex</a></li>
<li class="chapter" data-level="3.9.3" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html#primal_dual"><i class="fa fa-check"></i><b>3.9.3</b> Primal-Dual Formulation</a></li>
<li class="chapter" data-level="3.9.4" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html#lagrange-multiplier"><i class="fa fa-check"></i><b>3.9.4</b> Lagrange Multiplier </a></li>
<li class="chapter" data-level="3.9.5" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html#karush-khun-tucker-conditions"><i class="fa fa-check"></i><b>3.9.5</b> Karush-Khun-Tucker Conditions </a></li>
</ul></li>
<li class="chapter" data-level="3.10" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html#summary-1"><i class="fa fa-check"></i><b>3.10</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="numerical-calculus.html"><a href="numerical-calculus.html"><i class="fa fa-check"></i><b>4</b> Numerical Calculus</a><ul>
<li class="chapter" data-level="4.1" data-path="numerical-calculus.html"><a href="numerical-calculus.html#calculus"><i class="fa fa-check"></i><b>4.1</b> Calculus</a><ul>
<li class="chapter" data-level="4.1.1" data-path="numerical-calculus.html"><a href="numerical-calculus.html#function"><i class="fa fa-check"></i><b>4.1.1</b> Function</a></li>
<li class="chapter" data-level="4.1.2" data-path="numerical-calculus.html"><a href="numerical-calculus.html#slopes"><i class="fa fa-check"></i><b>4.1.2</b> Slopes</a></li>
<li class="chapter" data-level="4.1.3" data-path="numerical-calculus.html"><a href="numerical-calculus.html#limits"><i class="fa fa-check"></i><b>4.1.3</b> Limits</a></li>
<li class="chapter" data-level="4.1.4" data-path="numerical-calculus.html"><a href="numerical-calculus.html#derivatives"><i class="fa fa-check"></i><b>4.1.4</b> Derivatives</a></li>
<li class="chapter" data-level="4.1.5" data-path="numerical-calculus.html"><a href="numerical-calculus.html#integrals"><i class="fa fa-check"></i><b>4.1.5</b> Integrals </a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="numerical-calculus.html"><a href="numerical-calculus.html#approximation-by-numerical-integration"><i class="fa fa-check"></i><b>4.2</b> Approximation by Numerical Integration </a><ul>
<li class="chapter" data-level="4.2.1" data-path="numerical-calculus.html"><a href="numerical-calculus.html#newton-cotes-quadrature"><i class="fa fa-check"></i><b>4.2.1</b> Newton-Cotes Quadrature </a></li>
<li class="chapter" data-level="4.2.2" data-path="numerical-calculus.html"><a href="numerical-calculus.html#composite-quadrature"><i class="fa fa-check"></i><b>4.2.2</b> Composite Quadrature </a></li>
<li class="chapter" data-level="4.2.3" data-path="numerical-calculus.html"><a href="numerical-calculus.html#adaptive-quadrature"><i class="fa fa-check"></i><b>4.2.3</b> Adaptive Quadrature </a></li>
<li class="chapter" data-level="4.2.4" data-path="numerical-calculus.html"><a href="numerical-calculus.html#gaussianquadrature"><i class="fa fa-check"></i><b>4.2.4</b> Gaussian Quadrature</a></li>
<li class="chapter" data-level="4.2.5" data-path="numerical-calculus.html"><a href="numerical-calculus.html#romberg-integration"><i class="fa fa-check"></i><b>4.2.5</b> Romberg integration </a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="numerical-calculus.html"><a href="numerical-calculus.html#approximation-by-numerical-differentiation"><i class="fa fa-check"></i><b>4.3</b> Approximation by Numerical Differentiation </a><ul>
<li class="chapter" data-level="4.3.1" data-path="numerical-calculus.html"><a href="numerical-calculus.html#order-of-accuracy"><i class="fa fa-check"></i><b>4.3.1</b> Order of Accuracy</a></li>
<li class="chapter" data-level="4.3.2" data-path="numerical-calculus.html"><a href="numerical-calculus.html#finite-difference"><i class="fa fa-check"></i><b>4.3.2</b> Finite Difference </a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="numerical-calculus.html"><a href="numerical-calculus.html#approximation-using-ordinary-differential-equations"><i class="fa fa-check"></i><b>4.4</b> Approximation using Ordinary Differential Equations  </a><ul>
<li class="chapter" data-level="4.4.1" data-path="numerical-calculus.html"><a href="numerical-calculus.html#eulers-method-explicit"><i class="fa fa-check"></i><b>4.4.1</b> Eulerâs Method (Explicit) </a></li>
<li class="chapter" data-level="4.4.2" data-path="numerical-calculus.html"><a href="numerical-calculus.html#eulers-method-implicit"><i class="fa fa-check"></i><b>4.4.2</b> Eulerâs Method (Implicit)</a></li>
<li class="chapter" data-level="4.4.3" data-path="numerical-calculus.html"><a href="numerical-calculus.html#heuns-method"><i class="fa fa-check"></i><b>4.4.3</b> Heunâs Method </a></li>
<li class="chapter" data-level="4.4.4" data-path="numerical-calculus.html"><a href="numerical-calculus.html#runge-kutta-method"><i class="fa fa-check"></i><b>4.4.4</b> Runge-Kutta Method </a></li>
<li class="chapter" data-level="4.4.5" data-path="numerical-calculus.html"><a href="numerical-calculus.html#shooting-method"><i class="fa fa-check"></i><b>4.4.5</b> Shooting Method </a></li>
<li class="chapter" data-level="4.4.6" data-path="numerical-calculus.html"><a href="numerical-calculus.html#finite-difference-method"><i class="fa fa-check"></i><b>4.4.6</b> Finite Difference Method  </a></li>
<li class="chapter" data-level="4.4.7" data-path="numerical-calculus.html"><a href="numerical-calculus.html#finite-element-method-based-on-wrm-and-vm"><i class="fa fa-check"></i><b>4.4.7</b> Finite Element Method (based on WRM and VM) </a></li>
<li class="chapter" data-level="4.4.8" data-path="numerical-calculus.html"><a href="numerical-calculus.html#least-square-method-using-wrm"><i class="fa fa-check"></i><b>4.4.8</b> Least-Square Method (using WRM)</a></li>
<li class="chapter" data-level="4.4.9" data-path="numerical-calculus.html"><a href="numerical-calculus.html#galerkin-method-using-wrm"><i class="fa fa-check"></i><b>4.4.9</b> Galerkin Method (using WRM)</a></li>
<li class="chapter" data-level="4.4.10" data-path="numerical-calculus.html"><a href="numerical-calculus.html#petrov-galerkin-method-using-wrm"><i class="fa fa-check"></i><b>4.4.10</b> Petrov-Galerkin Method (using WRM)</a></li>
<li class="chapter" data-level="4.4.11" data-path="numerical-calculus.html"><a href="numerical-calculus.html#rayleigh-ritz-method-using-wrm"><i class="fa fa-check"></i><b>4.4.11</b> Rayleigh-Ritz Method (using WRM)</a></li>
<li class="chapter" data-level="4.4.12" data-path="numerical-calculus.html"><a href="numerical-calculus.html#subdomain-method-using-subdomains"><i class="fa fa-check"></i><b>4.4.12</b> Subdomain Method (using subdomains)</a></li>
<li class="chapter" data-level="4.4.13" data-path="numerical-calculus.html"><a href="numerical-calculus.html#collocation-method-using-direct-location-points"><i class="fa fa-check"></i><b>4.4.13</b> Collocation Method (using direct location points) </a></li>
<li class="chapter" data-level="4.4.14" data-path="numerical-calculus.html"><a href="numerical-calculus.html#weighted-residual-summary"><i class="fa fa-check"></i><b>4.4.14</b> Weighted Residual Summary </a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="numerical-calculus.html"><a href="numerical-calculus.html#approximation-using-functional-differential-equations"><i class="fa fa-check"></i><b>4.5</b> Approximation using Functional Differential Equations </a><ul>
<li class="chapter" data-level="4.5.1" data-path="numerical-calculus.html"><a href="numerical-calculus.html#variational-functions"><i class="fa fa-check"></i><b>4.5.1</b> Variational Functions </a></li>
<li class="chapter" data-level="4.5.2" data-path="numerical-calculus.html"><a href="numerical-calculus.html#variational-methods"><i class="fa fa-check"></i><b>4.5.2</b> Variational Methods </a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="numerical-calculus.html"><a href="numerical-calculus.html#approximation-using-partial-differential-equations"><i class="fa fa-check"></i><b>4.6</b> Approximation using Partial Differential Equations </a><ul>
<li class="chapter" data-level="4.6.1" data-path="numerical-calculus.html"><a href="numerical-calculus.html#the-poisson-equation"><i class="fa fa-check"></i><b>4.6.1</b> The Poisson Equation </a></li>
<li class="chapter" data-level="4.6.2" data-path="numerical-calculus.html"><a href="numerical-calculus.html#the-laplace-equation-elliptic-pde"><i class="fa fa-check"></i><b>4.6.2</b> The Laplace Equation (Elliptic PDE)  </a></li>
<li class="chapter" data-level="4.6.3" data-path="numerical-calculus.html"><a href="numerical-calculus.html#the-heat-equation-parabolic-pde"><i class="fa fa-check"></i><b>4.6.3</b> The Heat equation (Parabolic PDE)  </a></li>
<li class="chapter" data-level="4.6.4" data-path="numerical-calculus.html"><a href="numerical-calculus.html#the-wave-equation-hyperbolic-pde"><i class="fa fa-check"></i><b>4.6.4</b> The Wave equation (Hyperbolic PDE)  </a></li>
<li class="chapter" data-level="4.6.5" data-path="numerical-calculus.html"><a href="numerical-calculus.html#the-crank-nicolson-equation"><i class="fa fa-check"></i><b>4.6.5</b> The Crank-Nicolson Equation </a></li>
<li class="chapter" data-level="4.6.6" data-path="numerical-calculus.html"><a href="numerical-calculus.html#the-burgers-equation"><i class="fa fa-check"></i><b>4.6.6</b> The Burgerâs Equation </a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="numerical-calculus.html"><a href="numerical-calculus.html#approximation-using-fourier-series-and-transform"><i class="fa fa-check"></i><b>4.7</b> Approximation using Fourier Series And Transform </a></li>
<li class="chapter" data-level="4.8" data-path="numerical-calculus.html"><a href="numerical-calculus.html#discrete-fourier-transform-dft"><i class="fa fa-check"></i><b>4.8</b> Discrete Fourier Transform (DFT)  </a></li>
<li class="chapter" data-level="4.9" data-path="numerical-calculus.html"><a href="numerical-calculus.html#inverse-discrete-fourier-transformation-idft"><i class="fa fa-check"></i><b>4.9</b> Inverse Discrete Fourier Transformation (IDFT)  </a></li>
<li class="chapter" data-level="4.10" data-path="numerical-calculus.html"><a href="numerical-calculus.html#fast-fourier-transform-fft"><i class="fa fa-check"></i><b>4.10</b> Fast Fourier Transform (FFT)  </a></li>
<li class="chapter" data-level="4.11" data-path="numerical-calculus.html"><a href="numerical-calculus.html#summary-2"><i class="fa fa-check"></i><b>4.11</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="numerical-probability.html"><a href="numerical-probability.html"><i class="fa fa-check"></i><b>5</b> Numerical Probability and Distribution</a><ul>
<li class="chapter" data-level="5.1" data-path="numerical-probability.html"><a href="numerical-probability.html#approximation-based-on-random-chances"><i class="fa fa-check"></i><b>5.1</b> Approximation based on Random Chances </a></li>
<li class="chapter" data-level="5.2" data-path="numerical-probability.html"><a href="numerical-probability.html#distribution"><i class="fa fa-check"></i><b>5.2</b> Distribution</a></li>
<li class="chapter" data-level="5.3" data-path="numerical-probability.html"><a href="numerical-probability.html#mass-and-density"><i class="fa fa-check"></i><b>5.3</b> Mass and Density  </a></li>
<li class="chapter" data-level="5.4" data-path="numerical-probability.html"><a href="numerical-probability.html#probability"><i class="fa fa-check"></i><b>5.4</b> Probability </a></li>
<li class="chapter" data-level="5.5" data-path="numerical-probability.html"><a href="numerical-probability.html#probability-density-function-pdf"><i class="fa fa-check"></i><b>5.5</b> Probability Density Function (PDF)  </a></li>
<li class="chapter" data-level="5.6" data-path="numerical-probability.html"><a href="numerical-probability.html#probability-mass-function-pmf"><i class="fa fa-check"></i><b>5.6</b> Probability Mass function (PMF)  </a></li>
<li class="chapter" data-level="5.7" data-path="numerical-probability.html"><a href="numerical-probability.html#cumulative-distribution-function-cdf"><i class="fa fa-check"></i><b>5.7</b> Cumulative Distribution Function (CDF)  </a></li>
<li class="chapter" data-level="5.8" data-path="numerical-probability.html"><a href="numerical-probability.html#special-functions"><i class="fa fa-check"></i><b>5.8</b> Special Functions</a><ul>
<li class="chapter" data-level="5.8.1" data-path="numerical-probability.html"><a href="numerical-probability.html#gamma-function"><i class="fa fa-check"></i><b>5.8.1</b> Gamma function </a></li>
<li class="chapter" data-level="5.8.2" data-path="numerical-probability.html"><a href="numerical-probability.html#incomplete-gamma-function"><i class="fa fa-check"></i><b>5.8.2</b> Incomplete Gamma function </a></li>
<li class="chapter" data-level="5.8.3" data-path="numerical-probability.html"><a href="numerical-probability.html#digamma-function"><i class="fa fa-check"></i><b>5.8.3</b> Digamma Function </a></li>
<li class="chapter" data-level="5.8.4" data-path="numerical-probability.html"><a href="numerical-probability.html#beta-function"><i class="fa fa-check"></i><b>5.8.4</b> Beta function </a></li>
<li class="chapter" data-level="5.8.5" data-path="numerical-probability.html"><a href="numerical-probability.html#incomplete-beta-function"><i class="fa fa-check"></i><b>5.8.5</b> Incomplete Beta function </a></li>
<li class="chapter" data-level="5.8.6" data-path="numerical-probability.html"><a href="numerical-probability.html#regularized-beta-function"><i class="fa fa-check"></i><b>5.8.6</b> Regularized Beta function</a></li>
<li class="chapter" data-level="5.8.7" data-path="numerical-probability.html"><a href="numerical-probability.html#hypergeometric-function"><i class="fa fa-check"></i><b>5.8.7</b> Hypergeometric function </a></li>
<li class="chapter" data-level="5.8.8" data-path="numerical-probability.html"><a href="numerical-probability.html#continued-fraction"><i class="fa fa-check"></i><b>5.8.8</b> Continued Fraction </a></li>
<li class="chapter" data-level="5.8.9" data-path="numerical-probability.html"><a href="numerical-probability.html#dirac-delta-function"><i class="fa fa-check"></i><b>5.8.9</b> Dirac Delta Function </a></li>
<li class="chapter" data-level="5.8.10" data-path="numerical-probability.html"><a href="numerical-probability.html#kronecker-delta-function"><i class="fa fa-check"></i><b>5.8.10</b> Kronecker Delta Function </a></li>
</ul></li>
<li class="chapter" data-level="5.9" data-path="numerical-probability.html"><a href="numerical-probability.html#distribution_types"><i class="fa fa-check"></i><b>5.9</b> Types of Distribution</a><ul>
<li class="chapter" data-level="5.9.1" data-path="numerical-probability.html"><a href="numerical-probability.html#bernoulli-distribution"><i class="fa fa-check"></i><b>5.9.1</b> Bernoulli distribution </a></li>
<li class="chapter" data-level="5.9.2" data-path="numerical-probability.html"><a href="numerical-probability.html#binomial-distribution"><i class="fa fa-check"></i><b>5.9.2</b> Binomial distribution </a></li>
<li class="chapter" data-level="5.9.3" data-path="numerical-probability.html"><a href="numerical-probability.html#multinomial-distribution"><i class="fa fa-check"></i><b>5.9.3</b> Multinomial distribution </a></li>
<li class="chapter" data-level="5.9.4" data-path="numerical-probability.html"><a href="numerical-probability.html#geometric-distribution"><i class="fa fa-check"></i><b>5.9.4</b> Geometric distribution </a></li>
<li class="chapter" data-level="5.9.5" data-path="numerical-probability.html"><a href="numerical-probability.html#beta-distribution"><i class="fa fa-check"></i><b>5.9.5</b> Beta distribution </a></li>
<li class="chapter" data-level="5.9.6" data-path="numerical-probability.html"><a href="numerical-probability.html#dirichlet-distribution"><i class="fa fa-check"></i><b>5.9.6</b> Dirichlet distribution </a></li>
<li class="chapter" data-level="5.9.7" data-path="numerical-probability.html"><a href="numerical-probability.html#exponential-distribution"><i class="fa fa-check"></i><b>5.9.7</b> Exponential distribution </a></li>
<li class="chapter" data-level="5.9.8" data-path="numerical-probability.html"><a href="numerical-probability.html#gamma-distribution"><i class="fa fa-check"></i><b>5.9.8</b> Gamma distribution </a></li>
<li class="chapter" data-level="5.9.9" data-path="numerical-probability.html"><a href="numerical-probability.html#inverse-gamma-distribution"><i class="fa fa-check"></i><b>5.9.9</b> Inverse Gamma distribution </a></li>
<li class="chapter" data-level="5.9.10" data-path="numerical-probability.html"><a href="numerical-probability.html#weibull-distribution"><i class="fa fa-check"></i><b>5.9.10</b> Weibull distribution </a></li>
<li class="chapter" data-level="5.9.11" data-path="numerical-probability.html"><a href="numerical-probability.html#poisson-distribution"><i class="fa fa-check"></i><b>5.9.11</b> Poisson distribution </a></li>
<li class="chapter" data-level="5.9.12" data-path="numerical-probability.html"><a href="numerical-probability.html#pareto-distribution"><i class="fa fa-check"></i><b>5.9.12</b> Pareto distribution </a></li>
<li class="chapter" data-level="5.9.13" data-path="numerical-probability.html"><a href="numerical-probability.html#normal-distribution"><i class="fa fa-check"></i><b>5.9.13</b> Normal distribution </a></li>
<li class="chapter" data-level="5.9.14" data-path="numerical-probability.html"><a href="numerical-probability.html#wald-distribution"><i class="fa fa-check"></i><b>5.9.14</b> Wald Distribution </a></li>
<li class="chapter" data-level="5.9.15" data-path="numerical-probability.html"><a href="numerical-probability.html#log-normal-distribution"><i class="fa fa-check"></i><b>5.9.15</b> Log-normal Distribution </a></li>
<li class="chapter" data-level="5.9.16" data-path="numerical-probability.html"><a href="numerical-probability.html#uniform-distribution"><i class="fa fa-check"></i><b>5.9.16</b> Uniform Distribution </a></li>
<li class="chapter" data-level="5.9.17" data-path="numerical-probability.html"><a href="numerical-probability.html#t-distribution"><i class="fa fa-check"></i><b>5.9.17</b> T-Distribution </a></li>
<li class="chapter" data-level="5.9.18" data-path="numerical-probability.html"><a href="numerical-probability.html#f-distribution"><i class="fa fa-check"></i><b>5.9.18</b> F-Distribution </a></li>
<li class="chapter" data-level="5.9.19" data-path="numerical-probability.html"><a href="numerical-probability.html#chi-square-distribution"><i class="fa fa-check"></i><b>5.9.19</b> Chi-square Distribution </a></li>
<li class="chapter" data-level="5.9.20" data-path="numerical-probability.html"><a href="numerical-probability.html#wishart_distribution"><i class="fa fa-check"></i><b>5.9.20</b> Wishart distribution</a></li>
<li class="chapter" data-level="5.9.21" data-path="numerical-probability.html"><a href="numerical-probability.html#lkj-distribution"><i class="fa fa-check"></i><b>5.9.21</b> LKJ distribution </a></li>
<li class="chapter" data-level="5.9.22" data-path="numerical-probability.html"><a href="numerical-probability.html#mixture-distribution"><i class="fa fa-check"></i><b>5.9.22</b> Mixture distribution </a></li>
<li class="chapter" data-level="5.9.23" data-path="numerical-probability.html"><a href="numerical-probability.html#non-parametric-distribution"><i class="fa fa-check"></i><b>5.9.23</b> Non-parametric distribution </a></li>
<li class="chapter" data-level="5.9.24" data-path="numerical-probability.html"><a href="numerical-probability.html#multi-dimensional-density"><i class="fa fa-check"></i><b>5.9.24</b> Multi-dimensional Density </a></li>
</ul></li>
<li class="chapter" data-level="5.10" data-path="numerical-probability.html"><a href="numerical-probability.html#summary-3"><i class="fa fa-check"></i><b>5.10</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="statistics.html"><a href="statistics.html"><i class="fa fa-check"></i><b>6</b> Statistical Computation</a><ul>
<li class="chapter" data-level="6.1" data-path="statistics.html"><a href="statistics.html#descriptive-statistics"><i class="fa fa-check"></i><b>6.1</b> Descriptive Statistics</a><ul>
<li class="chapter" data-level="6.1.1" data-path="statistics.html"><a href="statistics.html#visual-representation"><i class="fa fa-check"></i><b>6.1.1</b> Visual Representation</a></li>
<li class="chapter" data-level="6.1.2" data-path="statistics.html"><a href="statistics.html#central-tendency"><i class="fa fa-check"></i><b>6.1.2</b> Central Tendency </a></li>
<li class="chapter" data-level="6.1.3" data-path="statistics.html"><a href="statistics.html#variability"><i class="fa fa-check"></i><b>6.1.3</b> Variability </a></li>
<li class="chapter" data-level="6.1.4" data-path="statistics.html"><a href="statistics.html#kurtosis-and-skewness"><i class="fa fa-check"></i><b>6.1.4</b> Kurtosis and Skewness  </a></li>
<li class="chapter" data-level="6.1.5" data-path="statistics.html"><a href="statistics.html#five-number-summary"><i class="fa fa-check"></i><b>6.1.5</b> Five Number Summary </a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="statistics.html"><a href="statistics.html#inferential-statistics"><i class="fa fa-check"></i><b>6.2</b> Inferential Statistics</a></li>
<li class="chapter" data-level="6.3" data-path="statistics.html"><a href="statistics.html#the-significance-of-difference"><i class="fa fa-check"></i><b>6.3</b> The Significance of Difference </a><ul>
<li class="chapter" data-level="6.3.1" data-path="statistics.html"><a href="statistics.html#hypothesis"><i class="fa fa-check"></i><b>6.3.1</b> Hypothesis</a></li>
<li class="chapter" data-level="6.3.2" data-path="statistics.html"><a href="statistics.html#t-test"><i class="fa fa-check"></i><b>6.3.2</b> T-Test </a></li>
<li class="chapter" data-level="6.3.3" data-path="statistics.html"><a href="statistics.html#z-test"><i class="fa fa-check"></i><b>6.3.3</b> Z-Test </a></li>
<li class="chapter" data-level="6.3.4" data-path="statistics.html"><a href="statistics.html#f-test-using-f-ratio"><i class="fa fa-check"></i><b>6.3.4</b> F-Test using F-ratio  </a></li>
<li class="chapter" data-level="6.3.5" data-path="statistics.html"><a href="statistics.html#f-test-with-one-way-anova"><i class="fa fa-check"></i><b>6.3.5</b> F-Test with One-Way ANOVA </a></li>
<li class="chapter" data-level="6.3.6" data-path="statistics.html"><a href="statistics.html#f-test-with-two-way-anova"><i class="fa fa-check"></i><b>6.3.6</b> F-Test with Two-Way ANOVA </a></li>
<li class="chapter" data-level="6.3.7" data-path="statistics.html"><a href="statistics.html#chi-squared-test"><i class="fa fa-check"></i><b>6.3.7</b> Chi-squared Test </a></li>
<li class="chapter" data-level="6.3.8" data-path="statistics.html"><a href="statistics.html#wilcoxon-test"><i class="fa fa-check"></i><b>6.3.8</b> Wilcoxon Test  </a></li>
<li class="chapter" data-level="6.3.9" data-path="statistics.html"><a href="statistics.html#kruskal-wallis-test"><i class="fa fa-check"></i><b>6.3.9</b> Kruskal-Wallis Test </a></li>
<li class="chapter" data-level="6.3.10" data-path="statistics.html"><a href="statistics.html#friedman-test"><i class="fa fa-check"></i><b>6.3.10</b> Friedman Test </a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="statistics.html"><a href="statistics.html#post-hoc-analysis"><i class="fa fa-check"></i><b>6.4</b> Post-HOC Analysis </a><ul>
<li class="chapter" data-level="6.4.1" data-path="statistics.html"><a href="statistics.html#bonferroni-correction"><i class="fa fa-check"></i><b>6.4.1</b> Bonferroni Correction </a></li>
<li class="chapter" data-level="6.4.2" data-path="statistics.html"><a href="statistics.html#benjamini-hochberg-correction"><i class="fa fa-check"></i><b>6.4.2</b> Benjamini-Hochberg Correction </a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="statistics.html"><a href="statistics.html#multiple-comparison-tests"><i class="fa fa-check"></i><b>6.5</b> Multiple Comparison Tests </a><ul>
<li class="chapter" data-level="6.5.1" data-path="statistics.html"><a href="statistics.html#scheffes-test"><i class="fa fa-check"></i><b>6.5.1</b> Scheffeâs Test </a></li>
<li class="chapter" data-level="6.5.2" data-path="statistics.html"><a href="statistics.html#fishers-test"><i class="fa fa-check"></i><b>6.5.2</b> Fisherâs Test </a></li>
<li class="chapter" data-level="6.5.3" data-path="statistics.html"><a href="statistics.html#tukeys-test"><i class="fa fa-check"></i><b>6.5.3</b> Tukeyâs Test </a></li>
<li class="chapter" data-level="6.5.4" data-path="statistics.html"><a href="statistics.html#newman-keul-test"><i class="fa fa-check"></i><b>6.5.4</b> Newman-Keul Test  </a></li>
<li class="chapter" data-level="6.5.5" data-path="statistics.html"><a href="statistics.html#games-howell-test"><i class="fa fa-check"></i><b>6.5.5</b> Games-Howell Test </a></li>
<li class="chapter" data-level="6.5.6" data-path="statistics.html"><a href="statistics.html#dunnetts-test"><i class="fa fa-check"></i><b>6.5.6</b> Dunnettâs Test </a></li>
<li class="chapter" data-level="6.5.7" data-path="statistics.html"><a href="statistics.html#duncans-test"><i class="fa fa-check"></i><b>6.5.7</b> Duncanâs Test </a></li>
<li class="chapter" data-level="6.5.8" data-path="statistics.html"><a href="statistics.html#meta-analysis-test"><i class="fa fa-check"></i><b>6.5.8</b> Meta-Analysis Test </a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="statistics.html"><a href="statistics.html#statistical-modeling"><i class="fa fa-check"></i><b>6.6</b> Statistical Modeling </a><ul>
<li class="chapter" data-level="6.6.1" data-path="statistics.html"><a href="statistics.html#model-specification"><i class="fa fa-check"></i><b>6.6.1</b> Model Specification </a></li>
<li class="chapter" data-level="6.6.2" data-path="statistics.html"><a href="statistics.html#statistical-interaction"><i class="fa fa-check"></i><b>6.6.2</b> Statistical Interaction </a></li>
<li class="chapter" data-level="6.6.3" data-path="statistics.html"><a href="statistics.html#dummy-variables"><i class="fa fa-check"></i><b>6.6.3</b> Dummy Variables </a></li>
<li class="chapter" data-level="6.6.4" data-path="statistics.html"><a href="statistics.html#model-selection"><i class="fa fa-check"></i><b>6.6.4</b> Model Selection </a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="statistics.html"><a href="statistics.html#regression-analysis"><i class="fa fa-check"></i><b>6.7</b> Regression Analysis </a><ul>
<li class="chapter" data-level="6.7.1" data-path="statistics.html"><a href="statistics.html#assumptions"><i class="fa fa-check"></i><b>6.7.1</b> Assumptions</a></li>
<li class="chapter" data-level="6.7.2" data-path="statistics.html"><a href="statistics.html#correlation-coefficients"><i class="fa fa-check"></i><b>6.7.2</b> Correlation Coefficients </a></li>
<li class="chapter" data-level="6.7.3" data-path="statistics.html"><a href="statistics.html#homoscedasticity-and-heteroscedasticity"><i class="fa fa-check"></i><b>6.7.3</b> Homoscedasticity and Heteroscedasticity  </a></li>
<li class="chapter" data-level="6.7.4" data-path="statistics.html"><a href="statistics.html#normality-and-leverage"><i class="fa fa-check"></i><b>6.7.4</b> Normality and Leverage  </a></li>
<li class="chapter" data-level="6.7.5" data-path="statistics.html"><a href="statistics.html#collinearity"><i class="fa fa-check"></i><b>6.7.5</b> Collinearity </a></li>
<li class="chapter" data-level="6.7.6" data-path="statistics.html"><a href="statistics.html#dispersion"><i class="fa fa-check"></i><b>6.7.6</b> Dispersion </a></li>
<li class="chapter" data-level="6.7.7" data-path="statistics.html"><a href="statistics.html#diagnostic-plots"><i class="fa fa-check"></i><b>6.7.7</b> Diagnostic Plots</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="statistics.html"><a href="statistics.html#the-significance-of-regression"><i class="fa fa-check"></i><b>6.8</b> The Significance of Regression </a><ul>
<li class="chapter" data-level="6.8.1" data-path="statistics.html"><a href="statistics.html#simple-linear-regression"><i class="fa fa-check"></i><b>6.8.1</b> Simple Linear Regression</a></li>
<li class="chapter" data-level="6.8.2" data-path="statistics.html"><a href="statistics.html#multilinear-regression"><i class="fa fa-check"></i><b>6.8.2</b> Multilinear Regression </a></li>
<li class="chapter" data-level="6.8.3" data-path="statistics.html"><a href="statistics.html#logistic-regression"><i class="fa fa-check"></i><b>6.8.3</b> Logistic Regression </a></li>
<li class="chapter" data-level="6.8.4" data-path="statistics.html"><a href="statistics.html#poisson-regression"><i class="fa fa-check"></i><b>6.8.4</b> Poisson Regression </a></li>
<li class="chapter" data-level="6.8.5" data-path="statistics.html"><a href="statistics.html#cox-regression"><i class="fa fa-check"></i><b>6.8.5</b> Cox Regression </a></li>
<li class="chapter" data-level="6.8.6" data-path="statistics.html"><a href="statistics.html#polynomial-regression"><i class="fa fa-check"></i><b>6.8.6</b> Polynomial Regression </a></li>
<li class="chapter" data-level="6.8.7" data-path="statistics.html"><a href="statistics.html#b-splines-and-natural-splines"><i class="fa fa-check"></i><b>6.8.7</b> B-Splines and Natural Splines  </a></li>
<li class="chapter" data-level="6.8.8" data-path="statistics.html"><a href="statistics.html#spline-smoothing"><i class="fa fa-check"></i><b>6.8.8</b> Spline Smoothing </a></li>
<li class="chapter" data-level="6.8.9" data-path="statistics.html"><a href="statistics.html#loess-and-lowess"><i class="fa fa-check"></i><b>6.8.9</b> LOESS and LOWESS  </a></li>
</ul></li>
<li class="chapter" data-level="6.9" data-path="statistics.html"><a href="statistics.html#inference-for-regression"><i class="fa fa-check"></i><b>6.9</b> Inference for Regression</a><ul>
<li class="chapter" data-level="6.9.1" data-path="statistics.html"><a href="statistics.html#goodness-of-fit"><i class="fa fa-check"></i><b>6.9.1</b> Goodness of Fit </a></li>
<li class="chapter" data-level="6.9.2" data-path="statistics.html"><a href="statistics.html#confidence-interval"><i class="fa fa-check"></i><b>6.9.2</b> Confidence interval </a></li>
</ul></li>
<li class="chapter" data-level="6.10" data-path="statistics.html"><a href="statistics.html#summary-4"><i class="fa fa-check"></i><b>6.10</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="bayesian.html"><a href="bayesian.html"><i class="fa fa-check"></i><b>7</b> Bayesian Computation</a><ul>
<li class="chapter" data-level="7.1" data-path="bayesian.html"><a href="bayesian.html#probability-1"><i class="fa fa-check"></i><b>7.1</b> Probability </a><ul>
<li class="chapter" data-level="7.1.1" data-path="bayesian.html"><a href="bayesian.html#marginal-probability"><i class="fa fa-check"></i><b>7.1.1</b> Marginal Probability </a></li>
<li class="chapter" data-level="7.1.2" data-path="bayesian.html"><a href="bayesian.html#joint-probability"><i class="fa fa-check"></i><b>7.1.2</b> Joint Probability </a></li>
<li class="chapter" data-level="7.1.3" data-path="bayesian.html"><a href="bayesian.html#conditional-probability"><i class="fa fa-check"></i><b>7.1.3</b> Conditional Probability </a></li>
<li class="chapter" data-level="7.1.4" data-path="bayesian.html"><a href="bayesian.html#negation-probability"><i class="fa fa-check"></i><b>7.1.4</b> Negation Probability </a></li>
<li class="chapter" data-level="7.1.5" data-path="bayesian.html"><a href="bayesian.html#combination-of-probabilities"><i class="fa fa-check"></i><b>7.1.5</b> Combination of Probabilities</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="bayesian.html"><a href="bayesian.html#probability-rules"><i class="fa fa-check"></i><b>7.2</b> Probability Rules</a><ul>
<li class="chapter" data-level="7.2.1" data-path="bayesian.html"><a href="bayesian.html#law-of-total-probability"><i class="fa fa-check"></i><b>7.2.1</b> Law of Total Probability</a></li>
<li class="chapter" data-level="7.2.2" data-path="bayesian.html"><a href="bayesian.html#law-of-total-expectation"><i class="fa fa-check"></i><b>7.2.2</b> Law of Total Expectation </a></li>
<li class="chapter" data-level="7.2.3" data-path="bayesian.html"><a href="bayesian.html#law-of-total-variance"><i class="fa fa-check"></i><b>7.2.3</b> Law of Total Variance </a></li>
<li class="chapter" data-level="7.2.4" data-path="bayesian.html"><a href="bayesian.html#law-of-total-covariance"><i class="fa fa-check"></i><b>7.2.4</b> Law of Total Covariance </a></li>
<li class="chapter" data-level="7.2.5" data-path="bayesian.html"><a href="bayesian.html#law-of-large-numbers"><i class="fa fa-check"></i><b>7.2.5</b> Law of Large Numbers </a></li>
<li class="chapter" data-level="7.2.6" data-path="bayesian.html"><a href="bayesian.html#central-limit-theorem"><i class="fa fa-check"></i><b>7.2.6</b> Central Limit Theorem </a></li>
<li class="chapter" data-level="7.2.7" data-path="bayesian.html"><a href="bayesian.html#rule-of-independence"><i class="fa fa-check"></i><b>7.2.7</b> Rule of Independence </a></li>
<li class="chapter" data-level="7.2.8" data-path="bayesian.html"><a href="bayesian.html#rule-of-exchangeability"><i class="fa fa-check"></i><b>7.2.8</b> Rule of Exchangeability </a></li>
<li class="chapter" data-level="7.2.9" data-path="bayesian.html"><a href="bayesian.html#rule-of-expectation-and-variance"><i class="fa fa-check"></i><b>7.2.9</b> Rule of Expectation and Variance</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="bayesian.html"><a href="bayesian.html#bayes-theorem"><i class="fa fa-check"></i><b>7.3</b> Bayes Theorem </a><ul>
<li class="chapter" data-level="7.3.1" data-path="bayesian.html"><a href="bayesian.html#naive-bayes"><i class="fa fa-check"></i><b>7.3.1</b> Naive Bayes </a></li>
<li class="chapter" data-level="7.3.2" data-path="bayesian.html"><a href="bayesian.html#likelihood"><i class="fa fa-check"></i><b>7.3.2</b> Likelihood</a></li>
<li class="chapter" data-level="7.3.3" data-path="bayesian.html"><a href="bayesian.html#posterior-probability"><i class="fa fa-check"></i><b>7.3.3</b> Posterior Probability  </a></li>
<li class="chapter" data-level="7.3.4" data-path="bayesian.html"><a href="bayesian.html#prior-probability"><i class="fa fa-check"></i><b>7.3.4</b> Prior Probability  </a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="bayesian.html"><a href="bayesian.html#conjugacy"><i class="fa fa-check"></i><b>7.4</b> Conjugacy</a><ul>
<li class="chapter" data-level="7.4.1" data-path="bayesian.html"><a href="bayesian.html#precision-1"><i class="fa fa-check"></i><b>7.4.1</b> Precision </a></li>
<li class="chapter" data-level="7.4.2" data-path="bayesian.html"><a href="bayesian.html#conjugate-prior"><i class="fa fa-check"></i><b>7.4.2</b> Conjugate Prior </a></li>
<li class="chapter" data-level="7.4.3" data-path="bayesian.html"><a href="bayesian.html#normal-normal-conjugacy"><i class="fa fa-check"></i><b>7.4.3</b> Normal-Normal Conjugacy </a></li>
<li class="chapter" data-level="7.4.4" data-path="bayesian.html"><a href="bayesian.html#normal-inverse-gamma-conjugacy"><i class="fa fa-check"></i><b>7.4.4</b> Normal-Inverse Gamma Conjugacy </a></li>
<li class="chapter" data-level="7.4.5" data-path="bayesian.html"><a href="bayesian.html#multivariate-normal-conjugacy"><i class="fa fa-check"></i><b>7.4.5</b> Multivariate Normal Conjugacy </a></li>
<li class="chapter" data-level="7.4.6" data-path="bayesian.html"><a href="bayesian.html#normal-wishart-conjugacy"><i class="fa fa-check"></i><b>7.4.6</b> Normal Wishart Conjugacy </a></li>
<li class="chapter" data-level="7.4.7" data-path="bayesian.html"><a href="bayesian.html#normal-inverse-wishart-conjugacy"><i class="fa fa-check"></i><b>7.4.7</b> Normal-Inverse Wishart Conjugacy </a></li>
<li class="chapter" data-level="7.4.8" data-path="bayesian.html"><a href="bayesian.html#normal-lkj-conjugacy"><i class="fa fa-check"></i><b>7.4.8</b> Normal-LKJ Conjugacy </a></li>
<li class="chapter" data-level="7.4.9" data-path="bayesian.html"><a href="bayesian.html#binomial-beta-conjugacy"><i class="fa fa-check"></i><b>7.4.9</b> Binomial-Beta Conjugacy </a></li>
<li class="chapter" data-level="7.4.10" data-path="bayesian.html"><a href="bayesian.html#geometric-beta-conjugacy"><i class="fa fa-check"></i><b>7.4.10</b> Geometric-Beta Conjugacy </a></li>
<li class="chapter" data-level="7.4.11" data-path="bayesian.html"><a href="bayesian.html#poisson-gamma-conjugacy"><i class="fa fa-check"></i><b>7.4.11</b> Poisson-Gamma Conjugacy </a></li>
<li class="chapter" data-level="7.4.12" data-path="bayesian.html"><a href="bayesian.html#exponential-gamma-conjugacy"><i class="fa fa-check"></i><b>7.4.12</b> Exponential-Gamma Conjugacy </a></li>
<li class="chapter" data-level="7.4.13" data-path="bayesian.html"><a href="bayesian.html#multinomial-dirichlet-conjugacy"><i class="fa fa-check"></i><b>7.4.13</b> Multinomial-Dirichlet Conjugacy </a></li>
<li class="chapter" data-level="7.4.14" data-path="bayesian.html"><a href="bayesian.html#hyperparameters"><i class="fa fa-check"></i><b>7.4.14</b> Hyperparameters </a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="bayesian.html"><a href="bayesian.html#information-theory"><i class="fa fa-check"></i><b>7.5</b> Information Theory </a><ul>
<li class="chapter" data-level="7.5.1" data-path="bayesian.html"><a href="bayesian.html#information"><i class="fa fa-check"></i><b>7.5.1</b> Information </a></li>
<li class="chapter" data-level="7.5.2" data-path="bayesian.html"><a href="bayesian.html#entropy"><i class="fa fa-check"></i><b>7.5.2</b> Entropy </a></li>
<li class="chapter" data-level="7.5.3" data-path="bayesian.html"><a href="bayesian.html#gini-index"><i class="fa fa-check"></i><b>7.5.3</b> Gini Index </a></li>
<li class="chapter" data-level="7.5.4" data-path="bayesian.html"><a href="bayesian.html#information-gain"><i class="fa fa-check"></i><b>7.5.4</b> Information Gain </a></li>
<li class="chapter" data-level="7.5.5" data-path="bayesian.html"><a href="bayesian.html#mutual-information"><i class="fa fa-check"></i><b>7.5.5</b> Mutual Information </a></li>
<li class="chapter" data-level="7.5.6" data-path="bayesian.html"><a href="bayesian.html#kullback-leibler-divergence"><i class="fa fa-check"></i><b>7.5.6</b> Kullback-Leibler Divergence  </a></li>
<li class="chapter" data-level="7.5.7" data-path="bayesian.html"><a href="bayesian.html#jensens-inequality"><i class="fa fa-check"></i><b>7.5.7</b> Jensenâs Inequality</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="bayesian.html"><a href="bayesian.html#bayesian_inference"><i class="fa fa-check"></i><b>7.6</b> Bayesian Inference</a><ul>
<li class="chapter" data-level="7.6.1" data-path="bayesian.html"><a href="bayesian.html#maximum-likelihood-mle"><i class="fa fa-check"></i><b>7.6.1</b> Maximum Likelihood (MLE)  </a></li>
<li class="chapter" data-level="7.6.2" data-path="bayesian.html"><a href="bayesian.html#maximum-a-posteriori-map"><i class="fa fa-check"></i><b>7.6.2</b> Maximum A-posteriori (MAP)  </a></li>
<li class="chapter" data-level="7.6.3" data-path="bayesian.html"><a href="bayesian.html#laplace-approximation"><i class="fa fa-check"></i><b>7.6.3</b> Laplace Approximation </a></li>
<li class="chapter" data-level="7.6.4" data-path="bayesian.html"><a href="bayesian.html#expectation-maximization-em"><i class="fa fa-check"></i><b>7.6.4</b> Expectation-Maximization (EM)  </a></li>
<li class="chapter" data-level="7.6.5" data-path="bayesian.html"><a href="bayesian.html#variational-inference"><i class="fa fa-check"></i><b>7.6.5</b> Variational Inference </a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="bayesian.html"><a href="bayesian.html#bayesian-models"><i class="fa fa-check"></i><b>7.7</b> Bayesian Models </a><ul>
<li class="chapter" data-level="7.7.1" data-path="bayesian.html"><a href="bayesian.html#belief-propagation"><i class="fa fa-check"></i><b>7.7.1</b> Belief Propagation </a></li>
<li class="chapter" data-level="7.7.2" data-path="bayesian.html"><a href="bayesian.html#expectation-propagation"><i class="fa fa-check"></i><b>7.7.2</b> Expectation Propagation </a></li>
<li class="chapter" data-level="7.7.3" data-path="bayesian.html"><a href="bayesian.html#markov-chain"><i class="fa fa-check"></i><b>7.7.3</b> Markov Chain </a></li>
<li class="chapter" data-level="7.7.4" data-path="bayesian.html"><a href="bayesian.html#hidden-markov-model"><i class="fa fa-check"></i><b>7.7.4</b> Hidden Markov Model  </a></li>
<li class="chapter" data-level="7.7.5" data-path="bayesian.html"><a href="bayesian.html#dynamic-system-model"><i class="fa fa-check"></i><b>7.7.5</b> Dynamic System Model</a></li>
<li class="chapter" data-level="7.7.6" data-path="bayesian.html"><a href="bayesian.html#bayes-filter"><i class="fa fa-check"></i><b>7.7.6</b> Bayes Filter </a></li>
<li class="chapter" data-level="7.7.7" data-path="bayesian.html"><a href="bayesian.html#kalman-filter"><i class="fa fa-check"></i><b>7.7.7</b> Kalman Filter </a></li>
<li class="chapter" data-level="7.7.8" data-path="bayesian.html"><a href="bayesian.html#extended-kalman-filter"><i class="fa fa-check"></i><b>7.7.8</b> Extended Kalman Filter </a></li>
<li class="chapter" data-level="7.7.9" data-path="bayesian.html"><a href="bayesian.html#unscented-kalman-filter"><i class="fa fa-check"></i><b>7.7.9</b> Unscented Kalman Filter </a></li>
<li class="chapter" data-level="7.7.10" data-path="bayesian.html"><a href="bayesian.html#particle-filter"><i class="fa fa-check"></i><b>7.7.10</b> Particle Filter </a></li>
<li class="chapter" data-level="7.7.11" data-path="bayesian.html"><a href="bayesian.html#ensemble-kalman-filter"><i class="fa fa-check"></i><b>7.7.11</b> Ensemble Kalman Filter </a></li>
</ul></li>
<li class="chapter" data-level="7.8" data-path="bayesian.html"><a href="bayesian.html#simulation-and-sampling"><i class="fa fa-check"></i><b>7.8</b> Simulation and Sampling</a><ul>
<li class="chapter" data-level="7.8.1" data-path="bayesian.html"><a href="bayesian.html#monte-carlo-estimation"><i class="fa fa-check"></i><b>7.8.1</b> Monte Carlo Estimation </a></li>
<li class="chapter" data-level="7.8.2" data-path="bayesian.html"><a href="bayesian.html#monte-carlo-simulation"><i class="fa fa-check"></i><b>7.8.2</b> Monte Carlo Simulation </a></li>
<li class="chapter" data-level="7.8.3" data-path="bayesian.html"><a href="bayesian.html#markov-chain-monte-carlo"><i class="fa fa-check"></i><b>7.8.3</b> Markov Chain Monte Carlo  </a></li>
<li class="chapter" data-level="7.8.4" data-path="bayesian.html"><a href="bayesian.html#metropolis-hastings-monte-carlo"><i class="fa fa-check"></i><b>7.8.4</b> Metropolis-Hastings Monte Carlo  </a></li>
<li class="chapter" data-level="7.8.5" data-path="bayesian.html"><a href="bayesian.html#hamiltonian-monte-carlo"><i class="fa fa-check"></i><b>7.8.5</b> Hamiltonian Monte Carlo  </a></li>
<li class="chapter" data-level="7.8.6" data-path="bayesian.html"><a href="bayesian.html#gibbs-sampling"><i class="fa fa-check"></i><b>7.8.6</b> Gibbs Sampling </a></li>
<li class="chapter" data-level="7.8.7" data-path="bayesian.html"><a href="bayesian.html#importance-sampling"><i class="fa fa-check"></i><b>7.8.7</b> Importance Sampling </a></li>
<li class="chapter" data-level="7.8.8" data-path="bayesian.html"><a href="bayesian.html#rejection-sampling"><i class="fa fa-check"></i><b>7.8.8</b> Rejection Sampling </a></li>
<li class="chapter" data-level="7.8.9" data-path="bayesian.html"><a href="bayesian.html#jags-modeling"><i class="fa fa-check"></i><b>7.8.9</b> JAGS Modeling </a></li>
</ul></li>
<li class="chapter" data-level="7.9" data-path="bayesian.html"><a href="bayesian.html#bayesian-analysis"><i class="fa fa-check"></i><b>7.9</b> Bayesian Analysis</a><ul>
<li class="chapter" data-level="7.9.1" data-path="bayesian.html"><a href="bayesian.html#autocorrelation"><i class="fa fa-check"></i><b>7.9.1</b> Autocorrelation </a></li>
<li class="chapter" data-level="7.9.2" data-path="bayesian.html"><a href="bayesian.html#predictive-probability"><i class="fa fa-check"></i><b>7.9.2</b> Predictive Probability </a></li>
<li class="chapter" data-level="7.9.3" data-path="bayesian.html"><a href="bayesian.html#posterior-interval"><i class="fa fa-check"></i><b>7.9.3</b> Posterior Interval </a></li>
<li class="chapter" data-level="7.9.4" data-path="bayesian.html"><a href="bayesian.html#bayes-factor"><i class="fa fa-check"></i><b>7.9.4</b> Bayes Factor </a></li>
</ul></li>
<li class="chapter" data-level="7.10" data-path="bayesian.html"><a href="bayesian.html#summary-5"><i class="fa fa-check"></i><b>7.10</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="machinelearning1.html"><a href="machinelearning1.html"><i class="fa fa-check"></i><b>8</b> Computational Learning I</a><ul>
<li class="chapter" data-level="8.1" data-path="machinelearning1.html"><a href="machinelearning1.html#observation-and-measurement"><i class="fa fa-check"></i><b>8.1</b> Observation and Measurement</a><ul>
<li class="chapter" data-level="8.1.1" data-path="machinelearning1.html"><a href="machinelearning1.html#levels-of-measurements"><i class="fa fa-check"></i><b>8.1.1</b> Levels of Measurements</a></li>
<li class="chapter" data-level="8.1.2" data-path="machinelearning1.html"><a href="machinelearning1.html#levels-of-categorical-measurements"><i class="fa fa-check"></i><b>8.1.2</b> Levels of Categorical measurements</a></li>
<li class="chapter" data-level="8.1.3" data-path="machinelearning1.html"><a href="machinelearning1.html#levels-of-continuous-measurements"><i class="fa fa-check"></i><b>8.1.3</b> Levels of Continuous measurements</a></li>
<li class="chapter" data-level="8.1.4" data-path="machinelearning1.html"><a href="machinelearning1.html#discrete-vs-continuous-measurements"><i class="fa fa-check"></i><b>8.1.4</b> Discrete vs Continuous measurements</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="machinelearning1.html"><a href="machinelearning1.html#input-data"><i class="fa fa-check"></i><b>8.2</b> Input Data</a><ul>
<li class="chapter" data-level="8.2.1" data-path="machinelearning1.html"><a href="machinelearning1.html#structured-data"><i class="fa fa-check"></i><b>8.2.1</b> Structured Data</a></li>
<li class="chapter" data-level="8.2.2" data-path="machinelearning1.html"><a href="machinelearning1.html#non-structured-data"><i class="fa fa-check"></i><b>8.2.2</b> Non-Structured Data</a></li>
<li class="chapter" data-level="8.2.3" data-path="machinelearning1.html"><a href="machinelearning1.html#statistical-data"><i class="fa fa-check"></i><b>8.2.3</b> Statistical Data</a></li>
<li class="chapter" data-level="8.2.4" data-path="machinelearning1.html"><a href="machinelearning1.html#real-time-and-near-real-time-data"><i class="fa fa-check"></i><b>8.2.4</b> Real-Time and Near Real-Time Data</a></li>
<li class="chapter" data-level="8.2.5" data-path="machinelearning1.html"><a href="machinelearning1.html#oltp-and-datawarehouse"><i class="fa fa-check"></i><b>8.2.5</b> OLTP and Datawarehouse</a></li>
<li class="chapter" data-level="8.2.6" data-path="machinelearning1.html"><a href="machinelearning1.html#data-lake"><i class="fa fa-check"></i><b>8.2.6</b> Data lake</a></li>
<li class="chapter" data-level="8.2.7" data-path="machinelearning1.html"><a href="machinelearning1.html#natural-language-nl"><i class="fa fa-check"></i><b>8.2.7</b> Natural Language (NL)</a></li>
<li class="chapter" data-level="8.2.8" data-path="machinelearning1.html"><a href="machinelearning1.html#multimedia-md"><i class="fa fa-check"></i><b>8.2.8</b> Multimedia (MD)</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="machinelearning1.html"><a href="machinelearning1.html#primitive-methods"><i class="fa fa-check"></i><b>8.3</b> Primitive Methods</a><ul>
<li class="chapter" data-level="8.3.1" data-path="machinelearning1.html"><a href="machinelearning1.html#weighting"><i class="fa fa-check"></i><b>8.3.1</b> Weighting</a></li>
<li class="chapter" data-level="8.3.2" data-path="machinelearning1.html"><a href="machinelearning1.html#smoothing"><i class="fa fa-check"></i><b>8.3.2</b> Smoothing</a></li>
<li class="chapter" data-level="8.3.3" data-path="machinelearning1.html"><a href="machinelearning1.html#normalizing"><i class="fa fa-check"></i><b>8.3.3</b> Normalizing</a></li>
<li class="chapter" data-level="8.3.4" data-path="machinelearning1.html"><a href="machinelearning1.html#standardizing"><i class="fa fa-check"></i><b>8.3.4</b> Standardizing </a></li>
<li class="chapter" data-level="8.3.5" data-path="machinelearning1.html"><a href="machinelearning1.html#centering"><i class="fa fa-check"></i><b>8.3.5</b> Centering </a></li>
<li class="chapter" data-level="8.3.6" data-path="machinelearning1.html"><a href="machinelearning1.html#scaling-1"><i class="fa fa-check"></i><b>8.3.6</b> Scaling </a></li>
<li class="chapter" data-level="8.3.7" data-path="machinelearning1.html"><a href="machinelearning1.html#transforming"><i class="fa fa-check"></i><b>8.3.7</b> Transforming</a></li>
<li class="chapter" data-level="8.3.8" data-path="machinelearning1.html"><a href="machinelearning1.html#clipping"><i class="fa fa-check"></i><b>8.3.8</b> Clipping </a></li>
<li class="chapter" data-level="8.3.9" data-path="machinelearning1.html"><a href="machinelearning1.html#regularizing"><i class="fa fa-check"></i><b>8.3.9</b> Regularizing</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="machinelearning1.html"><a href="machinelearning1.html#distance-metrics"><i class="fa fa-check"></i><b>8.4</b> Distance Metrics</a><ul>
<li class="chapter" data-level="8.4.1" data-path="machinelearning1.html"><a href="machinelearning1.html#cosine-similarity"><i class="fa fa-check"></i><b>8.4.1</b> Cosine Similarity</a></li>
<li class="chapter" data-level="8.4.2" data-path="machinelearning1.html"><a href="machinelearning1.html#manhattan-and-euclidean-distance"><i class="fa fa-check"></i><b>8.4.2</b> Manhattan and Euclidean Distance  </a></li>
<li class="chapter" data-level="8.4.3" data-path="machinelearning1.html"><a href="machinelearning1.html#minkowski-and-chebyshev-supremum-distance"><i class="fa fa-check"></i><b>8.4.3</b> Minkowski and Chebyshev (Supremum) Distance  </a></li>
<li class="chapter" data-level="8.4.4" data-path="machinelearning1.html"><a href="machinelearning1.html#jaccard-similarity-and-distance"><i class="fa fa-check"></i><b>8.4.4</b> Jaccard (Similarity and Distance) </a></li>
<li class="chapter" data-level="8.4.5" data-path="machinelearning1.html"><a href="machinelearning1.html#hamming-distance"><i class="fa fa-check"></i><b>8.4.5</b> Hamming Distance </a></li>
<li class="chapter" data-level="8.4.6" data-path="machinelearning1.html"><a href="machinelearning1.html#mahalanobis-distance"><i class="fa fa-check"></i><b>8.4.6</b> Mahalanobis Distance </a></li>
<li class="chapter" data-level="8.4.7" data-path="machinelearning1.html"><a href="machinelearning1.html#precision-and-accuracy"><i class="fa fa-check"></i><b>8.4.7</b> Precision and Accuracy  </a></li>
<li class="chapter" data-level="8.4.8" data-path="machinelearning1.html"><a href="machinelearning1.html#auc-on-roc"><i class="fa fa-check"></i><b>8.4.8</b> AUC on ROC </a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="machinelearning1.html"><a href="machinelearning1.html#exploratory-data-analysis"><i class="fa fa-check"></i><b>8.5</b> Exploratory Data Analysis</a><ul>
<li class="chapter" data-level="8.5.1" data-path="machinelearning1.html"><a href="machinelearning1.html#data-cleaning-wrangling"><i class="fa fa-check"></i><b>8.5.1</b> Data Cleaning (Wrangling)</a></li>
<li class="chapter" data-level="8.5.2" data-path="machinelearning1.html"><a href="machinelearning1.html#association"><i class="fa fa-check"></i><b>8.5.2</b> Association</a></li>
<li class="chapter" data-level="8.5.3" data-path="machinelearning1.html"><a href="machinelearning1.html#pattern-discovery"><i class="fa fa-check"></i><b>8.5.3</b> Pattern Discovery</a></li>
<li class="chapter" data-level="8.5.4" data-path="machinelearning1.html"><a href="machinelearning1.html#null-invariance"><i class="fa fa-check"></i><b>8.5.4</b> Null Invariance </a></li>
<li class="chapter" data-level="8.5.5" data-path="machinelearning1.html"><a href="machinelearning1.html#correlation-and-collinearity"><i class="fa fa-check"></i><b>8.5.5</b> Correlation and Collinearity  </a></li>
<li class="chapter" data-level="8.5.6" data-path="machinelearning1.html"><a href="machinelearning1.html#covariance"><i class="fa fa-check"></i><b>8.5.6</b> Covariance </a></li>
<li class="chapter" data-level="8.5.7" data-path="machinelearning1.html"><a href="machinelearning1.html#outliers-leverage-influence"><i class="fa fa-check"></i><b>8.5.7</b> Outliers, Leverage, Influence   </a></li>
<li class="chapter" data-level="8.5.8" data-path="machinelearning1.html"><a href="machinelearning1.html#dominating-factors"><i class="fa fa-check"></i><b>8.5.8</b> Dominating Factors </a></li>
<li class="chapter" data-level="8.5.9" data-path="machinelearning1.html"><a href="machinelearning1.html#missingness-and-imputation"><i class="fa fa-check"></i><b>8.5.9</b> Missingness and Imputation  </a></li>
<li class="chapter" data-level="8.5.10" data-path="machinelearning1.html"><a href="machinelearning1.html#confounding-variable"><i class="fa fa-check"></i><b>8.5.10</b> Confounding Variable </a></li>
<li class="chapter" data-level="8.5.11" data-path="machinelearning1.html"><a href="machinelearning1.html#data-leakage"><i class="fa fa-check"></i><b>8.5.11</b> Data Leakage </a></li>
<li class="chapter" data-level="8.5.12" data-path="machinelearning1.html"><a href="machinelearning1.html#one-hot-encoding"><i class="fa fa-check"></i><b>8.5.12</b> One Hot Encoding </a></li>
<li class="chapter" data-level="8.5.13" data-path="machinelearning1.html"><a href="machinelearning1.html#winsorization-and-trimming"><i class="fa fa-check"></i><b>8.5.13</b> Winsorization and Trimming  </a></li>
<li class="chapter" data-level="8.5.14" data-path="machinelearning1.html"><a href="machinelearning1.html#discretization"><i class="fa fa-check"></i><b>8.5.14</b> Discretization </a></li>
<li class="chapter" data-level="8.5.15" data-path="machinelearning1.html"><a href="machinelearning1.html#stratification"><i class="fa fa-check"></i><b>8.5.15</b> Stratification </a></li>
<li class="chapter" data-level="8.5.16" data-path="machinelearning1.html"><a href="machinelearning1.html#fine-and-coarse-classing"><i class="fa fa-check"></i><b>8.5.16</b> Fine and Coarse Classing</a></li>
<li class="chapter" data-level="8.5.17" data-path="machinelearning1.html"><a href="machinelearning1.html#embedding"><i class="fa fa-check"></i><b>8.5.17</b> Embedding </a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="machinelearning1.html"><a href="machinelearning1.html#feature_engineering"><i class="fa fa-check"></i><b>8.6</b> Feature Engineering</a><ul>
<li class="chapter" data-level="8.6.1" data-path="machinelearning1.html"><a href="machinelearning1.html#machine-learning-features"><i class="fa fa-check"></i><b>8.6.1</b> Machine Learning Features</a></li>
<li class="chapter" data-level="8.6.2" data-path="machinelearning1.html"><a href="machinelearning1.html#dimensionality-reduction"><i class="fa fa-check"></i><b>8.6.2</b> Dimensionality Reduction </a></li>
<li class="chapter" data-level="8.6.3" data-path="machinelearning1.html"><a href="machinelearning1.html#principal-component-analysis"><i class="fa fa-check"></i><b>8.6.3</b> Principal Component Analysis  </a></li>
<li class="chapter" data-level="8.6.4" data-path="machinelearning1.html"><a href="machinelearning1.html#linear-discriminant-analysis-lda"><i class="fa fa-check"></i><b>8.6.4</b> Linear Discriminant Analysis (LDA)  </a></li>
<li class="chapter" data-level="8.6.5" data-path="machinelearning1.html"><a href="machinelearning1.html#feature-construction"><i class="fa fa-check"></i><b>8.6.5</b> Feature Construction </a></li>
<li class="chapter" data-level="8.6.6" data-path="machinelearning1.html"><a href="machinelearning1.html#feature_selection"><i class="fa fa-check"></i><b>8.6.6</b> Feature Selection</a></li>
<li class="chapter" data-level="8.6.7" data-path="machinelearning1.html"><a href="machinelearning1.html#feature-transformation"><i class="fa fa-check"></i><b>8.6.7</b> Feature Transformation </a></li>
<li class="chapter" data-level="8.6.8" data-path="machinelearning1.html"><a href="machinelearning1.html#model-specification-1"><i class="fa fa-check"></i><b>8.6.8</b> Model Specification </a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="machinelearning1.html"><a href="machinelearning1.html#general-modeling"><i class="fa fa-check"></i><b>8.7</b> General Modeling</a><ul>
<li class="chapter" data-level="8.7.1" data-path="machinelearning1.html"><a href="machinelearning1.html#training-learning"><i class="fa fa-check"></i><b>8.7.1</b> Training (Learning)</a></li>
<li class="chapter" data-level="8.7.2" data-path="machinelearning1.html"><a href="machinelearning1.html#validation-tuning"><i class="fa fa-check"></i><b>8.7.2</b> Validation (Tuning) </a></li>
<li class="chapter" data-level="8.7.3" data-path="machinelearning1.html"><a href="machinelearning1.html#testing-assessing"><i class="fa fa-check"></i><b>8.7.3</b> Testing (Assessing) </a></li>
<li class="chapter" data-level="8.7.4" data-path="machinelearning1.html"><a href="machinelearning1.html#cross-validation-cv"><i class="fa fa-check"></i><b>8.7.4</b> Cross-Validation (CV)  </a></li>
<li class="chapter" data-level="8.7.5" data-path="machinelearning1.html"><a href="machinelearning1.html#bias-and-variance"><i class="fa fa-check"></i><b>8.7.5</b> Bias and Variance </a></li>
<li class="chapter" data-level="8.7.6" data-path="machinelearning1.html"><a href="machinelearning1.html#loss-and-cost-functions"><i class="fa fa-check"></i><b>8.7.6</b> Loss and Cost Functions  </a></li>
<li class="chapter" data-level="8.7.7" data-path="machinelearning1.html"><a href="machinelearning1.html#global-and-local-minima"><i class="fa fa-check"></i><b>8.7.7</b> Global and Local Minima  </a></li>
<li class="chapter" data-level="8.7.8" data-path="machinelearning1.html"><a href="machinelearning1.html#regularization"><i class="fa fa-check"></i><b>8.7.8</b> Regularization</a></li>
</ul></li>
<li class="chapter" data-level="8.8" data-path="machinelearning1.html"><a href="machinelearning1.html#supervised-vs-unsupervised-learning"><i class="fa fa-check"></i><b>8.8</b> Supervised vs Unsupervised Learning  </a></li>
<li class="chapter" data-level="8.9" data-path="machinelearning1.html"><a href="machinelearning1.html#regression"><i class="fa fa-check"></i><b>8.9</b> Regression (Supervised)</a><ul>
<li class="chapter" data-level="8.9.1" data-path="machinelearning1.html"><a href="machinelearning1.html#regression-trees"><i class="fa fa-check"></i><b>8.9.1</b> Regression Trees </a></li>
<li class="chapter" data-level="8.9.2" data-path="machinelearning1.html"><a href="machinelearning1.html#ensemble-methods"><i class="fa fa-check"></i><b>8.9.2</b> Ensemble Methods </a></li>
<li class="chapter" data-level="8.9.3" data-path="machinelearning1.html"><a href="machinelearning1.html#random-forest"><i class="fa fa-check"></i><b>8.9.3</b> Random Forest </a></li>
<li class="chapter" data-level="8.9.4" data-path="machinelearning1.html"><a href="machinelearning1.html#Adaoost"><i class="fa fa-check"></i><b>8.9.4</b> AdaBoost</a></li>
<li class="chapter" data-level="8.9.5" data-path="machinelearning1.html"><a href="machinelearning1.html#gradient-boost"><i class="fa fa-check"></i><b>8.9.5</b> Gradient Boost </a></li>
<li class="chapter" data-level="8.9.6" data-path="machinelearning1.html"><a href="machinelearning1.html#xgboost"><i class="fa fa-check"></i><b>8.9.6</b> XGBoost </a></li>
<li class="chapter" data-level="8.9.7" data-path="machinelearning1.html"><a href="machinelearning1.html#generalized-linear-modeling-glm"><i class="fa fa-check"></i><b>8.9.7</b> Generalized Linear Modeling (GLM)  </a></li>
</ul></li>
<li class="chapter" data-level="8.10" data-path="machinelearning1.html"><a href="machinelearning1.html#summary-6"><i class="fa fa-check"></i><b>8.10</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="machinelearning2.html"><a href="machinelearning2.html"><i class="fa fa-check"></i><b>9</b> Computational Learning II</a><ul>
<li class="chapter" data-level="9.1" data-path="machinelearning2.html"><a href="machinelearning2.html#binary-classification-supervised"><i class="fa fa-check"></i><b>9.1</b> Binary Classification (Supervised)</a><ul>
<li class="chapter" data-level="9.1.1" data-path="machinelearning2.html"><a href="machinelearning2.html#logistic_regression"><i class="fa fa-check"></i><b>9.1.1</b> Logistic Regression</a></li>
<li class="chapter" data-level="9.1.2" data-path="machinelearning2.html"><a href="machinelearning2.html#poisson"><i class="fa fa-check"></i><b>9.1.2</b> Poisson Regression</a></li>
<li class="chapter" data-level="9.1.3" data-path="machinelearning2.html"><a href="machinelearning2.html#linear-svm-sgdpegasos"><i class="fa fa-check"></i><b>9.1.3</b> Linear SVM (SGD/PEGASOS)  </a></li>
<li class="chapter" data-level="9.1.4" data-path="machinelearning2.html"><a href="machinelearning2.html#kernel-svm-smo"><i class="fa fa-check"></i><b>9.1.4</b> Kernel SVM (SMO)  </a></li>
<li class="chapter" data-level="9.1.5" data-path="machinelearning2.html"><a href="machinelearning2.html#sdca-based-svm"><i class="fa fa-check"></i><b>9.1.5</b> SDCA-based SVM </a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="machinelearning2.html"><a href="machinelearning2.html#multi-class-classification-supervised"><i class="fa fa-check"></i><b>9.2</b> Multi-class Classification (Supervised) </a><ul>
<li class="chapter" data-level="9.2.1" data-path="machinelearning2.html"><a href="machinelearning2.html#bayesian-classification"><i class="fa fa-check"></i><b>9.2.1</b> Bayesian Classification </a></li>
<li class="chapter" data-level="9.2.2" data-path="machinelearning2.html"><a href="machinelearning2.html#classification-trees"><i class="fa fa-check"></i><b>9.2.2</b> Classification Trees </a></li>
<li class="chapter" data-level="9.2.3" data-path="machinelearning2.html"><a href="machinelearning2.html#ensemble-methods-1"><i class="fa fa-check"></i><b>9.2.3</b> Ensemble Methods </a></li>
<li class="chapter" data-level="9.2.4" data-path="machinelearning2.html"><a href="machinelearning2.html#random-forest-1"><i class="fa fa-check"></i><b>9.2.4</b> Random Forest </a></li>
<li class="chapter" data-level="9.2.5" data-path="machinelearning2.html"><a href="machinelearning2.html#AdaBoost"><i class="fa fa-check"></i><b>9.2.5</b> AdaBoost &amp; SAMME</a></li>
<li class="chapter" data-level="9.2.6" data-path="machinelearning2.html"><a href="machinelearning2.html#logitboost-j-classes"><i class="fa fa-check"></i><b>9.2.6</b> LogitBoost (J Classes)</a></li>
<li class="chapter" data-level="9.2.7" data-path="machinelearning2.html"><a href="machinelearning2.html#gradient-boost-1"><i class="fa fa-check"></i><b>9.2.7</b> Gradient Boost </a></li>
<li class="chapter" data-level="9.2.8" data-path="machinelearning2.html"><a href="machinelearning2.html#k-next-neighbors-knn"><i class="fa fa-check"></i><b>9.2.8</b> K-Next Neighbors (KNN)  </a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="machinelearning2.html"><a href="machinelearning2.html#clustering-unsupervised"><i class="fa fa-check"></i><b>9.3</b> Clustering (Unsupervised) </a><ul>
<li class="chapter" data-level="9.3.1" data-path="machinelearning2.html"><a href="machinelearning2.html#k-means-clustering"><i class="fa fa-check"></i><b>9.3.1</b> K-means (clustering) </a></li>
<li class="chapter" data-level="9.3.2" data-path="machinelearning2.html"><a href="machinelearning2.html#hierarchical-clustering"><i class="fa fa-check"></i><b>9.3.2</b> Hierarchical (clustering) </a></li>
<li class="chapter" data-level="9.3.3" data-path="machinelearning2.html"><a href="machinelearning2.html#dbscan-clustering"><i class="fa fa-check"></i><b>9.3.3</b> DBSCAN (clustering) </a></li>
<li class="chapter" data-level="9.3.4" data-path="machinelearning2.html"><a href="machinelearning2.html#quality-of-clustering"><i class="fa fa-check"></i><b>9.3.4</b> Quality of Clustering</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="machinelearning2.html"><a href="machinelearning2.html#meta-learning"><i class="fa fa-check"></i><b>9.4</b> Meta-Learning </a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="machinelearning3.html"><a href="machinelearning3.html"><i class="fa fa-check"></i><b>10</b> Computational Learning III</a><ul>
<li class="chapter" data-level="10.1" data-path="machinelearning3.html"><a href="machinelearning3.html#natural-language-processing-nlp"><i class="fa fa-check"></i><b>10.1</b> Natural Language Processing (NLP)  </a><ul>
<li class="chapter" data-level="10.1.1" data-path="machinelearning3.html"><a href="machinelearning3.html#pre-processing-texts"><i class="fa fa-check"></i><b>10.1.1</b> Pre-Processing Texts</a></li>
<li class="chapter" data-level="10.1.2" data-path="machinelearning3.html"><a href="machinelearning3.html#ranking-and-scoring"><i class="fa fa-check"></i><b>10.1.2</b> Ranking and Scoring </a></li>
<li class="chapter" data-level="10.1.3" data-path="machinelearning3.html"><a href="machinelearning3.html#document-similarity"><i class="fa fa-check"></i><b>10.1.3</b> Document Similarity </a></li>
<li class="chapter" data-level="10.1.4" data-path="machinelearning3.html"><a href="machinelearning3.html#linguistic-analysis"><i class="fa fa-check"></i><b>10.1.4</b> Linguistic Analysis </a></li>
<li class="chapter" data-level="10.1.5" data-path="machinelearning3.html"><a href="machinelearning3.html#lexical-analysis"><i class="fa fa-check"></i><b>10.1.5</b> Lexical Analysis </a></li>
<li class="chapter" data-level="10.1.6" data-path="machinelearning3.html"><a href="machinelearning3.html#semantic-analysis"><i class="fa fa-check"></i><b>10.1.6</b> Semantic Analysis </a></li>
<li class="chapter" data-level="10.1.7" data-path="machinelearning3.html"><a href="machinelearning3.html#named-entity-recognition-ner"><i class="fa fa-check"></i><b>10.1.7</b> Named Entity Recognition (NER)  </a></li>
<li class="chapter" data-level="10.1.8" data-path="machinelearning3.html"><a href="machinelearning3.html#sentiment-and-opinion-analysis"><i class="fa fa-check"></i><b>10.1.8</b> Sentiment and Opinion Analysis  </a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="machinelearning3.html"><a href="machinelearning3.html#time-series-forecasting"><i class="fa fa-check"></i><b>10.2</b> Time-Series Forecasting </a><ul>
<li class="chapter" data-level="10.2.1" data-path="machinelearning3.html"><a href="machinelearning3.html#seasonal-trend-decomposition-using-loess-stl"><i class="fa fa-check"></i><b>10.2.1</b> Seasonal Trend Decomposition using LOESS (STL)  </a></li>
<li class="chapter" data-level="10.2.2" data-path="machinelearning3.html"><a href="machinelearning3.html#forecasting-models"><i class="fa fa-check"></i><b>10.2.2</b> Forecasting Models </a></li>
<li class="chapter" data-level="10.2.3" data-path="machinelearning3.html"><a href="machinelearning3.html#time-series-linear-model-tslm"><i class="fa fa-check"></i><b>10.2.3</b> Time-Series Linear Model (TSLM)  </a></li>
<li class="chapter" data-level="10.2.4" data-path="machinelearning3.html"><a href="machinelearning3.html#autoregressive-integrated-moving-average-arima"><i class="fa fa-check"></i><b>10.2.4</b> AutoRegressive Integrated Moving Average (ARIMA)  </a></li>
<li class="chapter" data-level="10.2.5" data-path="machinelearning3.html"><a href="machinelearning3.html#multiplicative-seasonal-arima-sarima"><i class="fa fa-check"></i><b>10.2.5</b> Multiplicative Seasonal ARIMA (SARIMA) </a></li>
<li class="chapter" data-level="10.2.6" data-path="machinelearning3.html"><a href="machinelearning3.html#time-series-decomposition"><i class="fa fa-check"></i><b>10.2.6</b> Time-Series Decomposition </a></li>
<li class="chapter" data-level="10.2.7" data-path="machinelearning3.html"><a href="machinelearning3.html#stl-with-aicbic"><i class="fa fa-check"></i><b>10.2.7</b> STL with AIC/BIC</a></li>
<li class="chapter" data-level="10.2.8" data-path="machinelearning3.html"><a href="machinelearning3.html#multivariate-time-series"><i class="fa fa-check"></i><b>10.2.8</b> Multivariate Time-Series</a></li>
<li class="chapter" data-level="10.2.9" data-path="machinelearning3.html"><a href="machinelearning3.html#forecasting-considerations"><i class="fa fa-check"></i><b>10.2.9</b> Forecasting Considerations</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="machinelearning3.html"><a href="machinelearning3.html#recommender-systems"><i class="fa fa-check"></i><b>10.3</b> Recommender Systems </a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="deeplearning1.html"><a href="deeplearning1.html"><i class="fa fa-check"></i><b>11</b> Deep Computational Learning I</a><ul>
<li class="chapter" data-level="11.1" data-path="deeplearning1.html"><a href="deeplearning1.html#simple-perceptron"><i class="fa fa-check"></i><b>11.1</b> Simple Perceptron  </a></li>
<li class="chapter" data-level="11.2" data-path="deeplearning1.html"><a href="deeplearning1.html#adaptive-linear-neuron-adaline"><i class="fa fa-check"></i><b>11.2</b> Adaptive Linear Neuron (ADALINE)  </a></li>
<li class="chapter" data-level="11.3" data-path="deeplearning1.html"><a href="deeplearning1.html#multi-layer-perceptron-mlp"><i class="fa fa-check"></i><b>11.3</b> Multi Layer Perceptron (MLP)  </a><ul>
<li class="chapter" data-level="11.3.1" data-path="deeplearning1.html"><a href="deeplearning1.html#forward-feed"><i class="fa fa-check"></i><b>11.3.1</b> Forward Feed </a></li>
<li class="chapter" data-level="11.3.2" data-path="deeplearning1.html"><a href="deeplearning1.html#backward-feed"><i class="fa fa-check"></i><b>11.3.2</b> Backward Feed </a></li>
<li class="chapter" data-level="11.3.3" data-path="deeplearning1.html"><a href="deeplearning1.html#backpropagation"><i class="fa fa-check"></i><b>11.3.3</b> BackPropagation </a></li>
<li class="chapter" data-level="11.3.4" data-path="deeplearning1.html"><a href="deeplearning1.html#mlp-example"><i class="fa fa-check"></i><b>11.3.4</b> MLP Example</a></li>
<li class="chapter" data-level="11.3.5" data-path="deeplearning1.html"><a href="deeplearning1.html#activation-function"><i class="fa fa-check"></i><b>11.3.5</b> Activation Function </a></li>
<li class="chapter" data-level="11.3.6" data-path="deeplearning1.html"><a href="deeplearning1.html#mlp-implementation"><i class="fa fa-check"></i><b>11.3.6</b> MLP Implementation</a></li>
<li class="chapter" data-level="11.3.7" data-path="deeplearning1.html"><a href="deeplearning1.html#deep-neural-network-dnn"><i class="fa fa-check"></i><b>11.3.7</b> Deep Neural Network (DNN)  </a></li>
<li class="chapter" data-level="11.3.8" data-path="deeplearning1.html"><a href="deeplearning1.html#vanishing-and-exploding-gradient"><i class="fa fa-check"></i><b>11.3.8</b> Vanishing and Exploding Gradient  </a></li>
<li class="chapter" data-level="11.3.9" data-path="deeplearning1.html"><a href="deeplearning1.html#dead-relu"><i class="fa fa-check"></i><b>11.3.9</b> Dead Relu </a></li>
<li class="chapter" data-level="11.3.10" data-path="deeplearning1.html"><a href="deeplearning1.html#gradient-clipping-gc"><i class="fa fa-check"></i><b>11.3.10</b> Gradient Clipping (GC) </a></li>
<li class="chapter" data-level="11.3.11" data-path="deeplearning1.html"><a href="deeplearning1.html#parameter-initialization"><i class="fa fa-check"></i><b>11.3.11</b> Parameter Initialization </a></li>
<li class="chapter" data-level="11.3.12" data-path="deeplearning1.html"><a href="deeplearning1.html#regularization-by-dropouts"><i class="fa fa-check"></i><b>11.3.12</b> Regularization by Dropouts </a></li>
<li class="chapter" data-level="11.3.13" data-path="deeplearning1.html"><a href="deeplearning1.html#batch-normalization"><i class="fa fa-check"></i><b>11.3.13</b> Batch Normalization </a></li>
<li class="chapter" data-level="11.3.14" data-path="deeplearning1.html"><a href="deeplearning1.html#optimization"><i class="fa fa-check"></i><b>11.3.14</b> Optimization </a></li>
<li class="chapter" data-level="11.3.15" data-path="deeplearning1.html"><a href="deeplearning1.html#interpretability"><i class="fa fa-check"></i><b>11.3.15</b> Interpretability</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="deeplearning1.html"><a href="deeplearning1.html#convolutional-neural-network-cnn"><i class="fa fa-check"></i><b>11.4</b> Convolutional Neural Network (CNN)  </a><ul>
<li class="chapter" data-level="11.4.1" data-path="deeplearning1.html"><a href="deeplearning1.html#computer-graphics"><i class="fa fa-check"></i><b>11.4.1</b> Computer Graphics</a></li>
<li class="chapter" data-level="11.4.2" data-path="deeplearning1.html"><a href="deeplearning1.html#convolution"><i class="fa fa-check"></i><b>11.4.2</b> Convolution </a></li>
<li class="chapter" data-level="11.4.3" data-path="deeplearning1.html"><a href="deeplearning1.html#stride-and-padding"><i class="fa fa-check"></i><b>11.4.3</b> Stride and Padding  </a></li>
<li class="chapter" data-level="11.4.4" data-path="deeplearning1.html"><a href="deeplearning1.html#kernels-and-filters"><i class="fa fa-check"></i><b>11.4.4</b> Kernels And Filters</a></li>
<li class="chapter" data-level="11.4.5" data-path="deeplearning1.html"><a href="deeplearning1.html#dilation"><i class="fa fa-check"></i><b>11.4.5</b> Dilation </a></li>
<li class="chapter" data-level="11.4.6" data-path="deeplearning1.html"><a href="deeplearning1.html#pooling"><i class="fa fa-check"></i><b>11.4.6</b> Pooling </a></li>
<li class="chapter" data-level="11.4.7" data-path="deeplearning1.html"><a href="deeplearning1.html#cnn-architectures"><i class="fa fa-check"></i><b>11.4.7</b> CNN Architectures</a></li>
<li class="chapter" data-level="11.4.8" data-path="deeplearning1.html"><a href="deeplearning1.html#forward-feed-1"><i class="fa fa-check"></i><b>11.4.8</b> Forward Feed </a></li>
<li class="chapter" data-level="11.4.9" data-path="deeplearning1.html"><a href="deeplearning1.html#backpropagation-1"><i class="fa fa-check"></i><b>11.4.9</b> BackPropagation </a></li>
<li class="chapter" data-level="11.4.10" data-path="deeplearning1.html"><a href="deeplearning1.html#optimization-1"><i class="fa fa-check"></i><b>11.4.10</b> Optimization</a></li>
<li class="chapter" data-level="11.4.11" data-path="deeplearning1.html"><a href="deeplearning1.html#normalization"><i class="fa fa-check"></i><b>11.4.11</b> Normalization</a></li>
<li class="chapter" data-level="11.4.12" data-path="deeplearning1.html"><a href="deeplearning1.html#step-decay"><i class="fa fa-check"></i><b>11.4.12</b> Step Decay</a></li>
<li class="chapter" data-level="11.4.13" data-path="deeplearning1.html"><a href="deeplearning1.html#gemm-matrix-multiplication"><i class="fa fa-check"></i><b>11.4.13</b> GEMM (Matrix Multiplication) </a></li>
<li class="chapter" data-level="11.4.14" data-path="deeplearning1.html"><a href="deeplearning1.html#depthwise-separable-convolution-dsc"><i class="fa fa-check"></i><b>11.4.14</b> Depthwise Separable Convolution (DSC)  </a></li>
<li class="chapter" data-level="11.4.15" data-path="deeplearning1.html"><a href="deeplearning1.html#cnn-implementation"><i class="fa fa-check"></i><b>11.4.15</b> CNN Implementation</a></li>
<li class="chapter" data-level="11.4.16" data-path="deeplearning1.html"><a href="deeplearning1.html#cnn-application"><i class="fa fa-check"></i><b>11.4.16</b> CNN Application</a></li>
<li class="chapter" data-level="11.4.17" data-path="deeplearning1.html"><a href="deeplearning1.html#summary-7"><i class="fa fa-check"></i><b>11.4.17</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="deeplearning2.html"><a href="deeplearning2.html"><i class="fa fa-check"></i><b>12</b> Deep Computational Learning II</a><ul>
<li class="chapter" data-level="12.1" data-path="deeplearning2.html"><a href="deeplearning2.html#residual-network-resnet"><i class="fa fa-check"></i><b>12.1</b> Residual Network (ResNet)  </a></li>
<li class="chapter" data-level="12.2" data-path="deeplearning2.html"><a href="deeplearning2.html#recurrent-neural-network-rnn"><i class="fa fa-check"></i><b>12.2</b> Recurrent Neural Network (RNN)  </a><ul>
<li class="chapter" data-level="12.2.1" data-path="deeplearning2.html"><a href="deeplearning2.html#vanilla-rnn"><i class="fa fa-check"></i><b>12.2.1</b> Vanilla RNN</a></li>
<li class="chapter" data-level="12.2.2" data-path="deeplearning2.html"><a href="deeplearning2.html#long-short-term-memory-lstm"><i class="fa fa-check"></i><b>12.2.2</b> Long Short-Term Memory (LSTM)  </a></li>
<li class="chapter" data-level="12.2.3" data-path="deeplearning2.html"><a href="deeplearning2.html#gated-recurrent-units-gru"><i class="fa fa-check"></i><b>12.2.3</b> Gated Recurrent Units (GRU)  </a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="deeplearning2.html"><a href="deeplearning2.html#deep-stacked-rnn"><i class="fa fa-check"></i><b>12.3</b> Deep Stacked RNN </a></li>
<li class="chapter" data-level="12.4" data-path="deeplearning2.html"><a href="deeplearning2.html#deep-stacked-bidirectional-rnn"><i class="fa fa-check"></i><b>12.4</b> Deep Stacked Bidirectional RNN </a></li>
<li class="chapter" data-level="12.5" data-path="deeplearning2.html"><a href="deeplearning2.html#transformer-neural-network-tnn"><i class="fa fa-check"></i><b>12.5</b> Transformer Neural Network (TNN)  </a><ul>
<li class="chapter" data-level="12.5.1" data-path="deeplearning2.html"><a href="deeplearning2.html#attention"><i class="fa fa-check"></i><b>12.5.1</b> Attention </a></li>
<li class="chapter" data-level="12.5.2" data-path="deeplearning2.html"><a href="deeplearning2.html#self-attention-and-trainability"><i class="fa fa-check"></i><b>12.5.2</b> Self-Attention and Trainability </a></li>
<li class="chapter" data-level="12.5.3" data-path="deeplearning2.html"><a href="deeplearning2.html#multi-head-attention"><i class="fa fa-check"></i><b>12.5.3</b> Multi-Head Attention </a></li>
<li class="chapter" data-level="12.5.4" data-path="deeplearning2.html"><a href="deeplearning2.html#word-embedding"><i class="fa fa-check"></i><b>12.5.4</b> Word Embedding </a></li>
<li class="chapter" data-level="12.5.5" data-path="deeplearning2.html"><a href="deeplearning2.html#positional-embedding"><i class="fa fa-check"></i><b>12.5.5</b> Positional Embedding </a></li>
<li class="chapter" data-level="12.5.6" data-path="deeplearning2.html"><a href="deeplearning2.html#sequence-alignment"><i class="fa fa-check"></i><b>12.5.6</b> Sequence Alignment</a></li>
<li class="chapter" data-level="12.5.7" data-path="deeplearning2.html"><a href="deeplearning2.html#transformer-architectures"><i class="fa fa-check"></i><b>12.5.7</b> Transformer Architectures </a></li>
</ul></li>
<li class="chapter" data-level="12.6" data-path="deeplearning2.html"><a href="deeplearning2.html#applications-using-tnn-and-rnn"><i class="fa fa-check"></i><b>12.6</b> Applications using TNN (and RNN)</a><ul>
<li class="chapter" data-level="12.6.1" data-path="deeplearning2.html"><a href="deeplearning2.html#speech-recognition"><i class="fa fa-check"></i><b>12.6.1</b> Speech Recognition </a></li>
<li class="chapter" data-level="12.6.2" data-path="deeplearning2.html"><a href="deeplearning2.html#mel-coefficients-feature-extraction"><i class="fa fa-check"></i><b>12.6.2</b> Mel Coefficients (Feature Extraction) </a></li>
<li class="chapter" data-level="12.6.3" data-path="deeplearning2.html"><a href="deeplearning2.html#connectionist-temporal-classification-ctc"><i class="fa fa-check"></i><b>12.6.3</b> Connectionist Temporal Classification (CTC)  </a></li>
<li class="chapter" data-level="12.6.4" data-path="deeplearning2.html"><a href="deeplearning2.html#model-evaluation"><i class="fa fa-check"></i><b>12.6.4</b> Model Evaluation</a></li>
</ul></li>
<li class="chapter" data-level="12.7" data-path="deeplearning2.html"><a href="deeplearning2.html#generative-adversarial-network-gan"><i class="fa fa-check"></i><b>12.7</b> Generative Adversarial Network (GAN)  </a></li>
<li class="chapter" data-level="12.8" data-path="deeplearning2.html"><a href="deeplearning2.html#deep-reinforcement-network-dqn"><i class="fa fa-check"></i><b>12.8</b> Deep Reinforcement Network (DQN)  </a></li>
<li class="chapter" data-level="12.9" data-path="deeplearning2.html"><a href="deeplearning2.html#summary-8"><i class="fa fa-check"></i><b>12.9</b> Summary</a></li>
<li class="chapter" data-level="12.10" data-path="deeplearning2.html"><a href="deeplearning2.html#general-summary"><i class="fa fa-check"></i><b>12.10</b> General Summary</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i><b>13</b> Appendix</a><ul>
<li class="chapter" data-level="13.1" data-path="appendix.html"><a href="appendix.html#appendix-a"><i class="fa fa-check"></i><b>13.1</b> Appendix A</a><ul>
<li class="chapter" data-level="13.1.1" data-path="appendix.html"><a href="appendix.html#trigonometry"><i class="fa fa-check"></i><b>13.1.1</b> Trigonometry</a></li>
<li class="chapter" data-level="13.1.2" data-path="appendix.html"><a href="appendix.html#logarithms"><i class="fa fa-check"></i><b>13.1.2</b> Logarithms</a></li>
<li class="chapter" data-level="13.1.3" data-path="appendix.html"><a href="appendix.html#category-theory"><i class="fa fa-check"></i><b>13.1.3</b> Category Theory</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="appendix.html"><a href="appendix.html#appendix-b"><i class="fa fa-check"></i><b>13.2</b> Appendix B</a><ul>
<li class="chapter" data-level="13.2.1" data-path="appendix.html"><a href="appendix.html#on-random-chances"><i class="fa fa-check"></i><b>13.2.1</b> On Random chances</a></li>
<li class="chapter" data-level="13.2.2" data-path="appendix.html"><a href="appendix.html#on-replacements"><i class="fa fa-check"></i><b>13.2.2</b> On Replacements</a></li>
<li class="chapter" data-level="13.2.3" data-path="appendix.html"><a href="appendix.html#on-factorials"><i class="fa fa-check"></i><b>13.2.3</b> On Factorials</a></li>
<li class="chapter" data-level="13.2.4" data-path="appendix.html"><a href="appendix.html#on-permutations-and-combinations"><i class="fa fa-check"></i><b>13.2.4</b> On Permutations and Combinations</a></li>
<li class="chapter" data-level="13.2.5" data-path="appendix.html"><a href="appendix.html#on-conditional-probabilities"><i class="fa fa-check"></i><b>13.2.5</b> On Conditional Probabilities</a></li>
<li class="chapter" data-level="13.2.6" data-path="appendix.html"><a href="appendix.html#the-arithmetic-of-probabilities"><i class="fa fa-check"></i><b>13.2.6</b> The Arithmetic of Probabilities</a></li>
<li class="chapter" data-level="13.2.7" data-path="appendix.html"><a href="appendix.html#on-dependent-and-independent-events"><i class="fa fa-check"></i><b>13.2.7</b> On Dependent and Independent Events</a></li>
<li class="chapter" data-level="13.2.8" data-path="appendix.html"><a href="appendix.html#on-mutual-exclusivity"><i class="fa fa-check"></i><b>13.2.8</b> On Mutual Exclusivity</a></li>
<li class="chapter" data-level="13.2.9" data-path="appendix.html"><a href="appendix.html#on-expectation-and-variance"><i class="fa fa-check"></i><b>13.2.9</b> On Expectation and Variance</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="appendix.html"><a href="appendix.html#appendix-d"><i class="fa fa-check"></i><b>13.3</b> Appendix D</a><ul>
<li class="chapter" data-level="13.3.1" data-path="appendix.html"><a href="appendix.html#lubridate-library"><i class="fa fa-check"></i><b>13.3.1</b> Lubridate Library</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="appendix.html"><a href="appendix.html#appendix-c"><i class="fa fa-check"></i><b>13.4</b> Appendix C</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>14</b> References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">The Power and Art of Approximation</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="numerical_probability" class="section level1">
<h1><span class="header-section-number">Chapter 5</span> Numerical Probability and Distribution</h1>
<p>We covered many Numerical methods in previous chapters, providing approximations to solutions that otherwise tend to be impractical or impossible to attain.</p>
<p>In the next three chapters, we continue to review approximations based on random chances (or random events). Note that there are cases when we do not necessarily have the complete set of data. Rather, we may only have a sample of the complete set. In this regard, we analyze the sample and produce an estimate or approximate analysis that may closely explain the complete set.</p>
<p>In this chapter, we continue to focus on Numerical Analysis in the context of Probabilities and Distribution as we reference the works of Press W.H et al <span class="citation">(<a href="references.html#ref-ref215w">2007</a>)</span>, Stewart W.J. <span class="citation">(<a href="references.html#ref-ref233w">2009</a>)</span>, Murpy K.P. <span class="citation">(<a href="references.html#ref-ref224k">2012</a>)</span>, Forsyth D. <span class="citation">(<a href="references.html#ref-ref232d">2018</a>)</span>, and Lambert B. <span class="citation">(<a href="references.html#ref-ref240b">2018</a>)</span>, along with other additional references for consistency.</p>
<div id="approximation-based-on-random-chances" class="section level2">
<h2><span class="header-section-number">5.1</span> Approximation based on Random Chances </h2>
<p>In actuality, when we speak of data, we rely upon the value that is being measured (whether in quantity or quality). Given sample data, <span class="math inline">\(\Omega = \{0.11, 0.14, 0.09, 0.11, 0.15, ... \}\)</span>, it can suggest that we are dealing with some kind of a set of random measurements of observations. We have to ask the following questions:</p>
<ul>
<li>How many observations have we sampled? Here, we take the number of observations we are dealing with.</li>
<li>How many of those observations are unique? Here, we take the cardinality of the observation - a measure of uniqueness. The higher the uniqueness, the higher the cardinality.</li>
<li>Can we group non-unique observations? And if so, how many groups would there be?</li>
<li>Do these groups have the same number of observations? Here, we now start to look at central tendencies such as mean, median, mode, etc.</li>
<li>How many groups do we have? What group(s) have the highest number of similar observations and what group(s) have the lowest number of similar observations? Here, we begin to measure the spread or variance.</li>
<li>Finally, can we get a picture of the groupings? Here, we want to plot the groupings - the distribution.</li>
</ul>
<p>In other words, we want to know all about how data is <strong>distributed</strong>. We will show charts of the <strong>distribution of data</strong>. This is also where we introduce <strong>random variables</strong> and a few other concepts in relation to <strong>random variables</strong>.</p>
<p><strong>Random variables</strong> hold numerical values resulting from a random outcome or random chance, e.g.Â tossing a coin five times, what is the chance of getting a tail each time - could it be 0.50 (50% chance)?</p>
<p><strong>Orthogonal random variables</strong> are random variables that are independent. A change in one random variable does not have an effect on the other; hence, each is completely orthogonal to the other.</p>
<p><strong>Covariates or Variates</strong> hold values of random variables (one being for independent variables and the other being for dependent variables). So if we toss a coin and get a tail, the outcome of having a tail is considered a random outcome or to be more specific, it is a <strong>random variate</strong>. On the other hand, a <strong>covariate</strong> is regarded as a random outcome that is statistically dependent on the independent variable.</p>
<p><strong>Factor variables</strong> are categorical variables that hold categorical values called <strong>levels</strong>. So if we are talking about gender as a factor (or categorical) variable, then <strong>male</strong> is a level and <strong>female</strong> is also a level.</p>
<p>As for random variables, because of the absence of concrete and precise measurements, the distribution of values of random variables requires analysis. There are two distributions that are commonly used to explain distribution in other literature: <strong>Uniform</strong> and <strong>Normal</strong> distribution.</p>
<p><strong>Uniform</strong> distribution of random variables tends to follow a rectangular shape as the size of sampled data increases. Figure  shows chart of a uniform distribution. Below is the R code that plots the chart.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">142</span>)</a>
<a class="sourceLine" id="cb1-2" data-line-number="2">x =<span class="st"> </span><span class="kw">runif</span>(<span class="dt">n=</span><span class="dv">5000</span>, <span class="dt">min=</span><span class="op">-</span><span class="fl">1.5</span>, <span class="dt">max=</span><span class="fl">1.5</span>)</a>
<a class="sourceLine" id="cb1-3" data-line-number="3"><span class="kw">hist</span>(x, <span class="dt">breaks=</span><span class="dv">20</span>, <span class="dt">prob=</span><span class="ot">TRUE</span>, <span class="dt">main=</span><span class="st">&#39;Uniform Distribution&#39;</span>, </a>
<a class="sourceLine" id="cb1-4" data-line-number="4">     <span class="dt">xlab=</span><span class="st">&#39;Random Variable&#39;</span>,  <span class="dt">xlim=</span><span class="kw">range</span>(<span class="op">-</span><span class="fl">1.5</span>,<span class="fl">1.5</span>))</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:uniform"></span>
<img src="DS_files/figure-html/uniform-1.png" alt="Uniform Distribution" width="70%" />
<p class="caption">
Figure 5.1: Uniform Distribution
</p>
</div>
<p><strong>Normal</strong> distribution of random variables tends to follow a bell shape as the size of sampled data increases.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">142</span>)</a>
<a class="sourceLine" id="cb2-2" data-line-number="2">x =<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n=</span><span class="dv">5000</span>,<span class="dt">mean=</span><span class="dv">0</span>,<span class="dt">sd=</span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb2-3" data-line-number="3"><span class="kw">hist</span>(x, <span class="dt">breaks=</span><span class="dv">20</span>, <span class="dt">prob=</span><span class="ot">TRUE</span>, <span class="dt">main=</span><span class="st">&#39;Standard Normal Distribution&#39;</span>,</a>
<a class="sourceLine" id="cb2-4" data-line-number="4">     <span class="dt">xlab=</span><span class="st">&#39;Standard Deviation&#39;</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="op">-</span><span class="dv">4</span>,<span class="dv">4</span>))</a>
<a class="sourceLine" id="cb2-5" data-line-number="5"><span class="kw">curve</span>(<span class="kw">dnorm</span>(x, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span><span class="dv">1</span>),<span class="dt">add=</span><span class="ot">TRUE</span>, <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-1"></span>
<img src="DS_files/figure-html/unnamed-chunk-1-1.png" alt="Standard Normal Distribution" width="70%" />
<p class="caption">
Figure 5.2: Standard Normal Distribution
</p>
</div>
<p>One thing to emphasize here is that we will use uniform and normal distribution to simulate most of our data distribution in the rest of this book. In practice, not all data are distributed uniformly or normally. We will encounter different kinds of distribution. As an example, we will cover logistic distribution, Gamma distribution, Beta distribution, Poisson distribution, Power-law distribution, and so on. Some distributions cannot be simulated with uniform or normal distribution; because of that, some clever means are used to simulate the distribution. More on that in the next chapter.</p>
<p>Also, note that there are cases when we need to take multiple samples of a population. These samples can be regarded as <strong>sampling distribution</strong> which we will cover later. So instead of dealing with just one quantity (e.g.Â the average of a distribution), we deal with multiple averages. Granting, we end up with a thousand samples and compute for the average of each sample, then we are dealing with a thousand averages. These quantities (averages) may form some sort of distribution - the sampling distribution.</p>
<p>Also, note that we are being literal when we refer to data distribution as the distribution of data. In fact, as we mostly deal with statistics; as such, data here is assumed (or considered) to be already qualitatively or quantitatively measured data. And as we pointed out about the attribute of data, it is something measured. The âmeasureâ of one attribute such as 30 degrees Fahrenheit for temperature is what we regard as <strong>statistic</strong>.</p>
<p>In terms of the number of variables and number of outcomes per variable, we can categorize them into the following:</p>
<ul>
<li><p><strong>Univariate</strong> - refers to dealing with one variable.</p></li>
<li><p><strong>Multivariate</strong> - refers to dealing with multiple variables.</p></li>
<li><p><strong>Bivariate</strong> - refers to dealing with two variables.</p></li>
<li><p><strong>Binomial</strong> - refers to a response variable with only two possible outcomes (dichotomous), e.g.Â 1 or 0, true or false.</p></li>
<li><p><strong>Multinomial</strong> - refers to a response variable with more than two possible outcomes, e.g.Â nominal values</p></li>
</ul>
</div>
<div id="distribution" class="section level2">
<h2><span class="header-section-number">5.2</span> Distribution</h2>
<p>To understand <strong>data distribution</strong>, we need to be familiar with certain terms. We start with the term <strong>stochastic</strong> which is commonly defined in terms of <strong>randomness of events</strong>. Then, we have <strong>stochastic process</strong> which is the process that generates the <strong>randomness of events</strong>, leading to an observed outcome in the form of distribution, e.g.Â tossing a coin renders a binomial distribution.</p>
<p>Here, we are interested to know how data is distributed such as below:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb3-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">142</span>)</a>
<a class="sourceLine" id="cb3-2" data-line-number="2">h =<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n=</span><span class="dv">5000</span>,<span class="dt">mean=</span><span class="fl">5.5</span>,<span class="dt">sd=</span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb3-3" data-line-number="3"><span class="kw">hist</span>(<span class="dt">x=</span>h, <span class="dt">breaks=</span><span class="dv">20</span>, <span class="dt">prob=</span><span class="ot">FALSE</span>, <span class="dt">main=</span><span class="st">&#39;Normal Distribution&#39;</span>, </a>
<a class="sourceLine" id="cb3-4" data-line-number="4">     <span class="dt">xlab=</span><span class="st">&#39;Spread&#39;</span>, <span class="dt">ylab=</span><span class="st">&quot;Number of Individuals&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:heightdist"></span>
<img src="DS_files/figure-html/heightdist-1.png" alt="Height Distribution" width="70%" />
<p class="caption">
Figure 5.3: Height Distribution
</p>
</div>
<p>Intuitively, in figure , we see a peak (the highest point) in the distribution which is centered in the middle of the chart. We may attempt to take the average of our distribution and confirm that the average is where the highest concentration of data can be found. To put it into perspective, for a range of height measurement between 2 ft and 8 ft, most likely, a population of 5000 individuals with 30-40 years of age would average between 5 and 6 ft. in height. Probably the most number of people would fall right around the average of 5.5 ft. - that could be the peak. The distribution shows an average of 5.5 ft - that is the <strong>mean</strong> denoted as <span class="math inline">\(\mu_{\vec{x}}\)</span>. Note that the <strong>mean</strong> is also often referred to as the <strong>expected value</strong> or <strong>expectation</strong> denoted as <span class="math inline">\(\mathbb{E}(\vec{x})\)</span>. However, <strong>expectation</strong> has another representation especially when random variables are weighted - see <strong>Probability Rules</strong> under <strong>Bayesian Computation</strong> chapter. Now, If we then try to determine what is the next highest peak after the mean, we may see a 5.0 ft and a 6.0 ft. And as we look for the next highest peak after 5.0 ft or 6.0 ft, we then see 2.0 ft and 8.0 ft. The count is much less than the highest peak and the second-highest peak. It gets lesser as we keep counting for the next highest count. The <strong>spread of the distribution</strong> spans between 2ft and 8 ft.- that is the <strong>variance</strong> denoted as <span class="math inline">\(Var(\vec{x}) = \mathbb{E}(\vec{x}^2) - \mathbb{E}(\vec{x})^2\)</span>.</p>
<p>We actually have just shown the characteristic of a normal distribution. We started from a peak - in the center - and then from there, it tapers off, gradually decreasing in height symmetrically on each side.</p>
<p>There are two parameters that characterize our normal distribution: <strong>mean</strong> and <strong>variance</strong>. Here, <strong>mean</strong> is given the symbol <strong><span class="math inline">\(\mu\)</span></strong> and <strong>variance</strong> is given the symbol <strong><span class="math inline">\(\sigma^2\)</span></strong>. The notation for a normal distribution is then written this way:</p>
<p><span class="math display">\[\begin{align}
X \sim N(\mu, \sigma^2 )
\end{align}\]</span></p>
<p>It reads: <strong>X is distributed as a normal distribution with mean and variance</strong> as the parameters.</p>
<p>It also can be read as <strong>The random variable X follows a normal distribution with mean and variance</strong> parameters.</p>
<p>Why do we need the <strong>mean</strong> and the <strong>variance</strong> parameters? We need the <strong>mean</strong> parameter to see the most popular item in the data. We need the <strong>variance</strong> parameter to understand the popularity of items by ranking them according to popularity - in some way, this gives us a picture of how items are ranked. Graphically, if we are to use a bar chart, items that are most popular have âtallerâ ranks (taller bars) compared to low-ranking items.</p>
<div class="figure" style="text-align: center"><span id="fig:spread1"></span>
<img src="DS_files/figure-html/spread1-1.png" alt="Height Distribution" width="70%" />
<p class="caption">
Figure 5.4: Height Distribution
</p>
</div>
<p>Figure  shows four un-normalized distributions. Notice that the un-normalized distribution with <strong><span class="math inline">\(\mu=50\)</span></strong> has a peak around 50 in the chart. Notice that the un-normalized distribution with <strong><span class="math inline">\(\sigma^2=50\)</span></strong> has a wider spread.</p>
<p>In many cases, when we deal with data, we may prefer to normalize the distribution; or even to standardize the normalized distribution.</p>
<div class="figure" style="text-align: center"><span id="fig:spread2"></span>
<img src="DS_files/figure-html/spread2-1.png" alt="Height Distribution" width="70%" />
<p class="caption">
Figure 5.5: Height Distribution
</p>
</div>
<p>As shown in figure , there is one special kind of normal distribution called standard normal distribution.</p>
<p>A <strong>Standard Normal Distribution</strong> is a distribution that is both <strong>scaled down</strong> and <strong>centered</strong> so that its mean is forced to zero, e.g. <span class="math inline">\((x - \mu)/\sigma^2\)</span>.</p>

<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb4-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">142</span>)</a>
<a class="sourceLine" id="cb4-2" data-line-number="2">x =<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n=</span><span class="dv">5000</span>,<span class="dt">mean=</span><span class="dv">0</span>,<span class="dt">sd=</span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb4-3" data-line-number="3"><span class="kw">hist</span>(x, <span class="dt">breaks=</span><span class="dv">20</span>, <span class="dt">prob=</span><span class="ot">TRUE</span>, <span class="dt">main=</span><span class="st">&#39;Standard Normal Distribution&#39;</span>, </a>
<a class="sourceLine" id="cb4-4" data-line-number="4">     <span class="dt">xlab=</span><span class="st">&#39;Standard Deviation&#39;</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="op">-</span><span class="dv">4</span>,<span class="dv">4</span>))</a>
<a class="sourceLine" id="cb4-5" data-line-number="5"><span class="kw">curve</span>(<span class="kw">dnorm</span>(x, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span><span class="dv">1</span>),<span class="dt">add=</span><span class="ot">TRUE</span>, <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:bellshape"></span>
<img src="DS_files/figure-html/bellshape-1.png" alt="Standard Normal Distribution" width="70%" />
<p class="caption">
Figure 5.6: Standard Normal Distribution
</p>
</div>

</div>
<div id="mass-and-density" class="section level2">
<h2><span class="header-section-number">5.3</span> Mass and Density  </h2>
<p>The distribution of data formed by discrete random variables is regarded as <strong>mass</strong>.</p>
<p>The distribution of data formed by continuous random variables is regarded as <strong>density</strong>.</p>
<p>Given those definitions, when we talk about <strong>density</strong> (or <strong>mass</strong>), we are referring to the distribution of continuous random variables or the distribution of discrete random variables.</p>
<p>Geometrically, a <strong>density</strong> represents a curve by way of a density function which we discuss later - e.g.Â the curve that forms the bell shape in a normal distribution. See Figure .</p>
<p>Here, we use the greek symbol (<span class="math inline">\(\rho\)</span>) for density and it reads as ârhoâ:</p>
<p><span class="math display">\[
\rho(x)
\]</span>
although from time to time, we may also use the notation: <span class="math inline">\(f(x)\)</span></p>
<p>Recall that when talking about distribution, mathematically, we use the following notation (e.g.Â for normal distribution):</p>
<p><span class="math display">\[\begin{align}
X \sim \mathcal{N}(\mu, \sigma^2 )
\end{align}\]</span></p>
<p>We can also then refer to this density notation:</p>
<p><span class="math display">\[\begin{align}
\rho(x) \sim \mathcal{N}(\mu, \sigma^2 )
\end{align}\]</span></p>
<p>or this parameterized notation to be more complete:</p>
<p><span class="math display">\[\begin{align}
\rho(x|\mu,\sigma^2) \sim \mathcal{N}(\mu, \sigma^2 )
\end{align}\]</span></p>
<p>which reads: <strong>the density of x is distributed as normal distribution</strong> - the first notation having the parameters for <span class="math inline">\(\mu\ and\ \sigma^2\)</span> which can be implicit; meaning, we do not have to show the parameters in the notation.</p>
</div>
<div id="probability" class="section level2">
<h2><span class="header-section-number">5.4</span> Probability </h2>
<p><strong>Probability</strong> is a measure of the number of occurrences of a random event. That is the non-Bayesian definition. Bayesian definition puts a different perspective and that is to say, that probability is a measure of the degree of uncertainty (the likelihood) of information. After all, when we say that there is a probable chance of some event to occur, we do claim that we are uncertain about the event to occur. The higher the chance an event would occur, the lower our uncertainty of the information gets.</p>
<p>When dealing with all probabilities of a random event occurring, we know that the totality ends up being one whole. In that respect, probability can be expressed in terms of proportionality. For example, in the world population, what is the proportion of vegans vs non-vegans if there are 1 billion vegans out of 7 billion? The proportion is about 14.29% (1/7).</p>
<p>One of the better exercises when working on proportions (and probability) is developing our familiarity across the different distributions (densities) of data. When it comes to data, it is really and simply about how distributed our data can be and then estimating the probability that a given event (or proportion) falls somewhere in the distribution?</p>
<p>To plot this, let us recall the description of a function in Calculus in which we show how a function drives the slope of a line or the curvature of a curve (or shape of hyperplanes in higher dimensional space)</p>
<p>Let us start with a curve using a simple quadratic function: <span class="math inline">\(f(x) = x^2 \text{, where } 0 \leq x \leq 1\)</span>. See figure .</p>

<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb5-1" data-line-number="1"><span class="kw">suppressWarnings</span>(<span class="kw">suppressMessages</span>(<span class="kw">library</span>(scales)))</a>
<a class="sourceLine" id="cb5-2" data-line-number="2">slope =<span class="st"> </span><span class="dv">6</span></a>
<a class="sourceLine" id="cb5-3" data-line-number="3"></a>
<a class="sourceLine" id="cb5-4" data-line-number="4"><span class="co"># Generate X-Axis</span></a>
<a class="sourceLine" id="cb5-5" data-line-number="5">x =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="fl">.01</span>)</a>
<a class="sourceLine" id="cb5-6" data-line-number="6"></a>
<a class="sourceLine" id="cb5-7" data-line-number="7"><span class="co"># Formulate the functions for a curve with 0 intercept so that the </span></a>
<a class="sourceLine" id="cb5-8" data-line-number="8"><span class="co"># curve touches the y-axis at zero.</span></a>
<a class="sourceLine" id="cb5-9" data-line-number="9">intercept =<span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb5-10" data-line-number="10">quadratic_function =<span class="st"> </span>x<span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span>intercept</a>
<a class="sourceLine" id="cb5-11" data-line-number="11"></a>
<a class="sourceLine" id="cb5-12" data-line-number="12"><span class="co"># Plot the curve, the secant, and the tangent</span></a>
<a class="sourceLine" id="cb5-13" data-line-number="13"><span class="kw">plot</span>(x, quadratic_function, <span class="dt">lwd=</span><span class="dv">1</span>, <span class="dt">pch=</span><span class="dv">16</span>, </a>
<a class="sourceLine" id="cb5-14" data-line-number="14">     <span class="dt">col=</span><span class="kw">alpha</span>(<span class="st">&quot;navyblue&quot;</span>, <span class="fl">0.0</span>),</a>
<a class="sourceLine" id="cb5-15" data-line-number="15">     <span class="dt">main=</span><span class="st">&quot;Area bounded by a curve and a line&quot;</span>,</a>
<a class="sourceLine" id="cb5-16" data-line-number="16">     <span class="dt">xlab=</span><span class="st">&quot;X-Axis&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;Y-Axis&quot;</span>)</a>
<a class="sourceLine" id="cb5-17" data-line-number="17"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>)</a>
<a class="sourceLine" id="cb5-18" data-line-number="18"></a>
<a class="sourceLine" id="cb5-19" data-line-number="19"><span class="co"># The Curve</span></a>
<a class="sourceLine" id="cb5-20" data-line-number="20"><span class="kw">lines</span>(x, quadratic_function, <span class="dt">col=</span><span class="kw">alpha</span>(<span class="st">&quot;navyblue&quot;</span>,<span class="dv">1</span>), <span class="dt">lwd=</span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb5-21" data-line-number="21"><span class="kw">text</span>(<span class="dt">x=</span>.<span class="dv">8</span>, <span class="dt">y=</span>.<span class="dv">5</span>, <span class="dt">label=</span><span class="st">&quot;f(x) = x^2&quot;</span>)</a>
<a class="sourceLine" id="cb5-22" data-line-number="22"></a>
<a class="sourceLine" id="cb5-23" data-line-number="23"><span class="co"># The Area Limits</span></a>
<a class="sourceLine" id="cb5-24" data-line-number="24">a=.<span class="dv">2</span>;  b=.<span class="dv">4</span>;  c=.<span class="dv">6</span></a>
<a class="sourceLine" id="cb5-25" data-line-number="25"><span class="kw">abline</span>(<span class="dt">v=</span><span class="kw">c</span>(a,c), <span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>)</a>
<a class="sourceLine" id="cb5-26" data-line-number="26"></a>
<a class="sourceLine" id="cb5-27" data-line-number="27"><span class="co"># The Area for P(a &lt; x &lt; c)</span></a>
<a class="sourceLine" id="cb5-28" data-line-number="28">p =<span class="st"> </span><span class="kw">which</span>(x <span class="op">&gt;</span><span class="st"> </span>a <span class="op">&amp;</span><span class="st"> </span>x <span class="op">&lt;</span><span class="st"> </span>c)</a>
<a class="sourceLine" id="cb5-29" data-line-number="29">y1 =<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, <span class="kw">length</span>(quadratic_function[p]))</a>
<a class="sourceLine" id="cb5-30" data-line-number="30">y2 =<span class="st"> </span>quadratic_function[p]</a>
<a class="sourceLine" id="cb5-31" data-line-number="31"><span class="kw">segments</span>(x[p], y1, x[p], y2, <span class="dt">lwd=</span><span class="dv">1</span>, <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span> )</a>
<a class="sourceLine" id="cb5-32" data-line-number="32"><span class="kw">text</span>(<span class="dt">x=</span>c, <span class="dt">y=</span>.<span class="dv">65</span>, <span class="dt">label=</span><span class="st">&quot;c&quot;</span>)</a>
<a class="sourceLine" id="cb5-33" data-line-number="33"><span class="kw">text</span>(<span class="dt">x=</span>.<span class="dv">4</span>, <span class="dt">y=</span>.<span class="dv">65</span>, <span class="dt">label=</span><span class="kw">expression</span>(<span class="st">&quot;P(a &lt;= X &lt;= c)&quot;</span>), <span class="dt">lty=</span>.<span class="dv">5</span>, <span class="dt">cex=</span>.<span class="dv">9</span>)</a>
<a class="sourceLine" id="cb5-34" data-line-number="34"><span class="kw">segments</span>(a, <span class="dv">0</span>, a, <span class="fl">.6</span>, <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">col=</span><span class="st">&quot;steelblue&quot;</span> )</a>
<a class="sourceLine" id="cb5-35" data-line-number="35"><span class="kw">segments</span>(c, <span class="dv">0</span>, c, <span class="fl">.6</span>, <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">col=</span><span class="st">&quot;steelblue&quot;</span> )</a>
<a class="sourceLine" id="cb5-36" data-line-number="36"></a>
<a class="sourceLine" id="cb5-37" data-line-number="37"><span class="co"># The Area for P(a &lt; x &lt; b)</span></a>
<a class="sourceLine" id="cb5-38" data-line-number="38">p =<span class="st"> </span><span class="kw">which</span>(x <span class="op">&gt;=</span><span class="st"> </span>a <span class="op">&amp;</span><span class="st"> </span>x <span class="op">&lt;</span><span class="st"> </span>b)</a>
<a class="sourceLine" id="cb5-39" data-line-number="39">y1 =<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, <span class="kw">length</span>(quadratic_function[p]))</a>
<a class="sourceLine" id="cb5-40" data-line-number="40">y2 =<span class="st"> </span>quadratic_function[p]</a>
<a class="sourceLine" id="cb5-41" data-line-number="41"><span class="kw">segments</span>(x[p], y1, x[p], y2, <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">col=</span><span class="st">&quot;steelblue&quot;</span> )</a>
<a class="sourceLine" id="cb5-42" data-line-number="42"><span class="kw">text</span>(<span class="dt">x=</span>a, <span class="dt">y=</span>.<span class="dv">65</span>, <span class="dt">label=</span><span class="st">&quot;a&quot;</span>)</a>
<a class="sourceLine" id="cb5-43" data-line-number="43"><span class="kw">text</span>(<span class="dt">x=</span>b, <span class="dt">y=</span>.<span class="dv">45</span>, <span class="dt">label=</span><span class="st">&quot;b&quot;</span>)</a>
<a class="sourceLine" id="cb5-44" data-line-number="44"><span class="kw">segments</span>(b, <span class="dv">0</span>, b, <span class="fl">.4</span>, <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">col=</span><span class="st">&quot;steelblue&quot;</span> )</a>
<a class="sourceLine" id="cb5-45" data-line-number="45"><span class="kw">text</span>(<span class="dt">x=</span>.<span class="dv">3</span>, <span class="dt">y =</span> <span class="fl">.25</span>, <span class="dt">label=</span><span class="st">&quot;P(a &lt;= X &lt;= b)&quot;</span>, <span class="dt">lty=</span>.<span class="dv">5</span>, <span class="dt">cex=</span>.<span class="dv">9</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:probability4"></span>
<img src="DS_files/figure-html/probability4-1.png" alt="Area under Density Curve" width="70%" />
<p class="caption">
Figure 5.7: Area under Density Curve
</p>
</div>

<p>The totality of a continuous density in terms of proportion equates to 1 with the formula below:</p>
<p><span class="math display">\[\begin{align}
\int_{-\infty}^{\infty} f(x) dx = 1
\end{align}\]</span></p>
<p>We also can say that the total proportion or total probability (<strong>all probable outcome</strong>) of a density unites into 1.</p>
<p>Basically, it means there are no other outcomes after accounting for all other probable outcomes; hence, the 1.</p>
<p>Similarly, the probability of a discrete distribution of data equates to 1 with the formula below:</p>
<p><span class="math display">\[\begin{align}
\sum_{i\to0}^{1} \mathcal{P}(x) = 1
\end{align}\]</span></p>
<p>If we say that vegans share a 14.3 proportion to the world population, that is basically 0.143 of the total sum of 1; therefore, 0.857 being non-vegans.</p>
<p>In figure , we are only interested in the proportion between limit a and b. The probability (or area) bounded by a and b is:</p>
<p><span class="math display">\[\begin{align}
\int_{a}^{b} f(x) dx {}&amp;= \int_{0.2}^{0.4} x^2 dx \\
&amp;= F(f&#39;(b)) - F(f&#39;(a))\\
&amp;=\lim_{x\to b} F(x)\ - \lim_{x\to a} F(x)\\
&amp;= \left[\frac{x^3}{3} + c\right]_{0.2}^{0.4} = \left(\frac{0.4^3}{3}\right)\ - \left(\frac{0.2^3}{3}\right) \nonumber \\
&amp;= 0.0187 \nonumber
\end{align}\]</span></p>
<p>In figure  for continuous distribution, we see limits a and c. The probability (or area) bounded by a and c is:</p>
<p><span class="math display">\[\begin{align}
\int_{a}^{c} f(x) dx {}&amp;= \int_{0.2}^{0.6} x^2 dx \\
&amp;= F(f&#39;(c)) - F(f&#39;(a))\\
&amp;=\lim_{x\to c} F(x)\ - \lim_{x\to a} F(x)\\
&amp;= \left[\frac{x^3}{3} + c\right]_{0.2}^{0.6} = \left(\frac{0.6^3}{3}\right)\ - \left(\frac{0.2^3}{3}\right)  \nonumber\\
&amp;= 0.0693 \nonumber
\end{align}\]</span></p>
<p>Note that the plot shows a density quadratic curve that is made up and does not reflect one of the common distributions that we cover in the next chapters. But this is just to demonstrate probability and proportionality.</p>
<p>In summary, a region that is bounded can also be regarded as the proportion (or probable outcome) sliced between boundaries. Therefore, the region or area between boundaries represents the range of probable outcomes. We see more of this topic when we talk about <strong>cumulative distribution</strong>.</p>
</div>
<div id="probability-density-function-pdf" class="section level2">
<h2><span class="header-section-number">5.5</span> Probability Density Function (PDF)  </h2>
<p>Geometrically, the <strong>probability density function</strong> is a continuous function that describes the shape (or curvature) of a distribution. For example, in Figure , we see a bell shape <strong>density</strong> curve. This is generated by our <strong>probability density function</strong>; hereafter, we use the term <strong>density function</strong>.</p>
<p>A <strong>density function</strong> is expressed in the below general form using a lower-case notation <strong>f(x)</strong>:</p>
<p><span class="math display">\[\begin{align}
f_X(x) = \mathcal{P}(X = x)
\end{align}\]</span></p>
<p>An example of a <strong>density function</strong> is the normal (Gaussian) PDF expressed in the below equation:</p>
<p><span class="math display">\[\begin{align}
f(x; \mu, \sigma) = \frac{1}{\sigma \sqrt{2\pi}} exp\left[-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2\right]
\end{align}\]</span></p>
<p>with the following sample R code implementation:</p>

<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb6-1" data-line-number="1">normal.pdf &lt;-<span class="st"> </span><span class="cf">function</span>(x, mean, sd ) {</a>
<a class="sourceLine" id="cb6-2" data-line-number="2">   <span class="co"># Gaussian / Normal Distribution</span></a>
<a class="sourceLine" id="cb6-3" data-line-number="3">   variance =<span class="st"> </span>sd<span class="op">^</span><span class="dv">2</span> </a>
<a class="sourceLine" id="cb6-4" data-line-number="4">   (<span class="dv">1</span> <span class="op">/</span><span class="st"> </span>(<span class="kw">sqrt</span>( <span class="dv">2</span> <span class="op">*</span><span class="st"> </span>pi <span class="op">*</span><span class="st"> </span>variance ))) <span class="op">*</span><span class="st">  </span></a>
<a class="sourceLine" id="cb6-5" data-line-number="5"><span class="st">     </span><span class="kw">exp</span>(<span class="op">-</span>(x <span class="op">-</span><span class="st"> </span>mean)<span class="op">^</span><span class="dv">2</span><span class="op">/</span>(<span class="dv">2</span> <span class="op">*</span><span class="st"> </span>variance))</a>
<a class="sourceLine" id="cb6-6" data-line-number="6">}</a>
<a class="sourceLine" id="cb6-7" data-line-number="7"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="op">-</span><span class="dv">3</span>,<span class="dv">3</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="fl">0.5</span>), </a>
<a class="sourceLine" id="cb6-8" data-line-number="8">     <span class="dt">xlab=</span><span class="st">&quot;spread (variance)&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;probability density&quot;</span>,</a>
<a class="sourceLine" id="cb6-9" data-line-number="9">     <span class="dt">main=</span><span class="st">&quot;Gaussian PDF&quot;</span>, <span class="dt">axes=</span><span class="ot">FALSE</span>, <span class="dt">frame=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb6-10" data-line-number="10"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb6-11" data-line-number="11"><span class="kw">abline</span>(<span class="dt">h=</span><span class="dv">0</span>, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb6-12" data-line-number="12"><span class="kw">curve</span>(<span class="kw">normal.pdf</span>(x, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span><span class="dv">1</span>), <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span>, <span class="dt">lwd=</span><span class="dv">2</span> )</a>
<a class="sourceLine" id="cb6-13" data-line-number="13"><span class="kw">axis</span>(<span class="dv">1</span>, <span class="dv">-3</span><span class="op">:</span><span class="dv">3</span>, <span class="kw">c</span>(<span class="kw">expression</span>(<span class="op">-</span><span class="dv">3</span><span class="op">*</span>sigma), <span class="kw">expression</span>(<span class="op">-</span><span class="dv">2</span><span class="op">*</span>sigma),</a>
<a class="sourceLine" id="cb6-14" data-line-number="14">               <span class="kw">expression</span>(sigma),<span class="dv">0</span>,<span class="kw">expression</span>(sigma),</a>
<a class="sourceLine" id="cb6-15" data-line-number="15">               <span class="kw">expression</span>(<span class="dv">2</span><span class="op">*</span>sigma),<span class="kw">expression</span>(<span class="dv">3</span><span class="op">*</span>sigma)))</a>
<a class="sourceLine" id="cb6-16" data-line-number="16"><span class="kw">axis</span>(<span class="dv">2</span>)</a>
<a class="sourceLine" id="cb6-17" data-line-number="17">y =<span class="st"> </span><span class="kw">normal.pdf</span>(<span class="dt">x=</span><span class="dv">0</span>, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb6-18" data-line-number="18"><span class="kw">segments</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, y, <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>)</a>
<a class="sourceLine" id="cb6-19" data-line-number="19"><span class="kw">text</span>(<span class="dv">0</span>, y<span class="fl">+0.02</span>, <span class="dt">label=</span><span class="kw">paste</span>(<span class="st">&quot;probability density =&quot;</span>, <span class="kw">round</span>(y,<span class="dv">7</span>)) )</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:gaussianpdf"></span>
<img src="DS_files/figure-html/gaussianpdf-1.png" alt="Gaussian PDF" width="70%" />
<p class="caption">
Figure 5.8: Gaussian PDF
</p>
</div>

<p>Figure  helps to visualize the <strong>probability density</strong> of observing data in a normal distribution in which x = 0. Using our implementation of the <strong>density function</strong>, we get the following result:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb7-1" data-line-number="1"><span class="kw">normal.pdf</span>(<span class="dt">x=</span><span class="dv">0</span>, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span><span class="dv">1</span>)</a></code></pre></div>
<pre><code>## [1] 0.3989423</code></pre>
<p>Alternatively, using a built-in R package <strong>dnorm()</strong>, we can obtain the same result:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb9-1" data-line-number="1"><span class="kw">dnorm</span>(<span class="dt">x=</span><span class="dv">0</span>, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span><span class="dv">1</span>)</a></code></pre></div>
<pre><code>## [1] 0.3989423</code></pre>
</div>
<div id="probability-mass-function-pmf" class="section level2">
<h2><span class="header-section-number">5.6</span> Probability Mass function (PMF)  </h2>
<p>Geometrically, the <strong>probability mass function</strong> is a discrete function that describes the height of a distribution with respect to a discrete location (X-value). In an x-y coordinate system, given an <strong>X</strong> value, one is able to identify the corresponding <strong>Y</strong> value using the function similar to <strong>PDF</strong> but only this time, we deal with <strong>discrete</strong> random variable, <strong>X</strong>.</p>
<p>A <strong>probability mass function</strong> is expressed in the below general form using a lower-case notation <strong>f(x)</strong>:</p>
<p><span class="math display">\[\begin{align}
f_X(x) = \mathcal{P}(X = x)
\end{align}\]</span></p>
<p>Hereafter, we use the term <strong>mass function</strong>. A <strong>mass function</strong> is illustrated using a table or a histogram. For example, let us suppose we have the following discrete support, S:</p>
<p><span class="math display">\[
s \in S\ \ \ \rightarrow S = \{\ -3,-2,-1,\ 0,\ 1,\ 2,\ 3\ \}
\]</span>
In R code, we have the following graph:</p>

<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb11-1" data-line-number="1">x =<span class="st"> </span><span class="dv">-3</span><span class="op">:</span><span class="dv">3</span></a>
<a class="sourceLine" id="cb11-2" data-line-number="2">y =<span class="st"> </span><span class="kw">normal.pdf</span>(x, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb11-3" data-line-number="3"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="op">-</span><span class="dv">3</span>,<span class="dv">3</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="fl">0.5</span>), </a>
<a class="sourceLine" id="cb11-4" data-line-number="4">     <span class="dt">xlab=</span><span class="st">&quot;support&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;probability mass&quot;</span>,</a>
<a class="sourceLine" id="cb11-5" data-line-number="5">     <span class="dt">main=</span><span class="st">&quot;Probability Mass Function (Histogram)&quot;</span>,  <span class="dt">frame=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb11-6" data-line-number="6"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb11-7" data-line-number="7"><span class="kw">abline</span>(<span class="dt">h=</span><span class="dv">0</span>, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb11-8" data-line-number="8"><span class="kw">curve</span>(<span class="kw">normal.pdf</span>(x, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span><span class="dv">1</span>), <span class="dt">col=</span><span class="st">&quot;grey&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span>, <span class="dt">lty=</span><span class="dv">2</span> )</a>
<a class="sourceLine" id="cb11-9" data-line-number="9"><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">7</span>) {</a>
<a class="sourceLine" id="cb11-10" data-line-number="10">    <span class="kw">segments</span>(x[i], <span class="dv">0</span>, x[i], y[i], <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>, <span class="dt">lwd=</span><span class="dv">7</span>)</a>
<a class="sourceLine" id="cb11-11" data-line-number="11">}</a>
<a class="sourceLine" id="cb11-12" data-line-number="12">y =<span class="st"> </span><span class="kw">normal.pdf</span>(<span class="dt">x=</span><span class="dv">0</span>, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb11-13" data-line-number="13"><span class="kw">text</span>(<span class="dv">0</span>, y<span class="fl">+0.02</span>, <span class="dt">label=</span><span class="kw">paste</span>(<span class="st">&quot;probability mass =&quot;</span>, <span class="kw">round</span>(y,<span class="dv">7</span>)) )</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:gaussianpmf"></span>
<img src="DS_files/figure-html/gaussianpmf-1.png" alt="Pobability Mass Function" width="70%" />
<p class="caption">
Figure 5.9: Pobability Mass Function
</p>
</div>

<p>To illustrate, let us calculate the <strong>probability mass</strong> of a normal distribution in which x = 0. Note that our x can only be within the range of our support, X.</p>
<p><span class="math display">\[\begin{align}
f_X(x) = \mathcal{P}(X = x),\ \ \ \ \ where\ x \in \{\ -3,-2,-1,\ 0,\ 1,\ 2,\ 3\ \}.
\end{align}\]</span></p>
<p>We get the following result:</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb12-1" data-line-number="1"><span class="kw">normal.pdf</span>(<span class="dt">x=</span><span class="dv">0</span>, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span><span class="dv">1</span>)</a></code></pre></div>
<pre><code>## [1] 0.3989423</code></pre>
<p>Alternatively, using the same built-in R package <strong>dnorm()</strong>, we can obtain the same result:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb14-1" data-line-number="1"><span class="kw">dnorm</span>(<span class="dt">x=</span><span class="dv">0</span>, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span><span class="dv">1</span>)</a></code></pre></div>
<pre><code>## [1] 0.3989423</code></pre>
</div>
<div id="cumulative-distribution-function-cdf" class="section level2">
<h2><span class="header-section-number">5.7</span> Cumulative Distribution Function (CDF)  </h2>
<p>A <strong>cumulative distribution function</strong> computes for the probability that a continuous random variable <strong>X</strong> falls under a value less than or equal to <strong>x</strong>; hereafter, we use the term <strong>distribution function</strong>.</p>
<p>A <strong>distribution function</strong> is expressed in the below general form using an upper-case notation <strong>F(x)</strong>:</p>
<p><span class="math display">\[\begin{align}
\mathcal{F}_X(x) = \mathcal{P}(X \le x)
\end{align}\]</span></p>
<p>The cumulative distribution describes a monotonic <strong>distribution</strong> curve. See figure .</p>

<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb16-1" data-line-number="1">normal.cdf &lt;-<span class="st"> </span><span class="cf">function</span>(x) {</a>
<a class="sourceLine" id="cb16-2" data-line-number="2">  <span class="kw">round</span>( <span class="kw">pnorm</span>(x, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span><span class="dv">1</span>), <span class="dv">2</span>)</a>
<a class="sourceLine" id="cb16-3" data-line-number="3">}</a>
<a class="sourceLine" id="cb16-4" data-line-number="4">q =<span class="st"> </span>x =<span class="st"> </span><span class="dv">1</span>  <span class="co"># one unit of standard deviation</span></a>
<a class="sourceLine" id="cb16-5" data-line-number="5">p =<span class="st"> </span><span class="kw">normal.cdf</span>(q)</a>
<a class="sourceLine" id="cb16-6" data-line-number="6"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="op">-</span><span class="dv">3</span>,<span class="dv">3</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="dv">1</span>), </a>
<a class="sourceLine" id="cb16-7" data-line-number="7">     <span class="dt">xlab=</span><span class="st">&quot;spread/variance (qnorm)&quot;</span>, </a>
<a class="sourceLine" id="cb16-8" data-line-number="8">     <span class="dt">ylab=</span><span class="st">&quot;cumulative probability (pnorm)&quot;</span>,</a>
<a class="sourceLine" id="cb16-9" data-line-number="9">     <span class="dt">main=</span><span class="st">&quot;Gaussian CDF&quot;</span>, <span class="dt">axes=</span><span class="ot">FALSE</span>, <span class="dt">frame=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb16-10" data-line-number="10"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb16-11" data-line-number="11"><span class="kw">curve</span>(<span class="kw">pnorm</span>(x, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span><span class="dv">1</span>), <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span>, <span class="dt">lwd=</span><span class="dv">2</span> )</a>
<a class="sourceLine" id="cb16-12" data-line-number="12"><span class="kw">segments</span>(<span class="kw">c</span>(<span class="dv">0</span>,<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>) , <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>), </a>
<a class="sourceLine" id="cb16-13" data-line-number="13">         <span class="kw">c</span>(<span class="dv">0</span>,<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>), <span class="kw">c</span>(<span class="kw">normal.cdf</span>(<span class="dv">0</span>), <span class="kw">normal.cdf</span>(<span class="op">-</span><span class="dv">1</span>), p), </a>
<a class="sourceLine" id="cb16-14" data-line-number="14">         <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb16-15" data-line-number="15"><span class="kw">abline</span>(<span class="dt">h=</span><span class="dv">0</span>, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb16-16" data-line-number="16"><span class="kw">axis</span>(<span class="dv">1</span>, <span class="dv">-3</span><span class="op">:</span><span class="dv">3</span>, <span class="kw">c</span>(<span class="kw">expression</span>(<span class="op">-</span><span class="dv">3</span><span class="op">*</span>sigma), <span class="kw">expression</span>(<span class="op">-</span><span class="dv">2</span><span class="op">*</span>sigma),</a>
<a class="sourceLine" id="cb16-17" data-line-number="17">               <span class="kw">expression</span>(<span class="op">-</span><span class="dv">1</span><span class="op">*</span>sigma),<span class="dv">0</span>,<span class="kw">expression</span>(<span class="dv">1</span><span class="op">*</span>sigma),</a>
<a class="sourceLine" id="cb16-18" data-line-number="18">               <span class="kw">expression</span>(<span class="dv">2</span><span class="op">*</span>sigma),<span class="kw">expression</span>(<span class="dv">3</span><span class="op">*</span>sigma)))</a>
<a class="sourceLine" id="cb16-19" data-line-number="19"><span class="kw">axis</span>(<span class="dv">2</span>)</a>
<a class="sourceLine" id="cb16-20" data-line-number="20"><span class="kw">text</span>(<span class="fl">2.5</span>, <span class="fl">0.95</span>, <span class="dt">label=</span><span class="st">&quot;cdf curve&quot;</span>, <span class="dt">ce=</span><span class="dv">1</span>, <span class="dt">col=</span><span class="st">&quot;blue&quot;</span>)</a>
<a class="sourceLine" id="cb16-21" data-line-number="21"><span class="kw">text</span>(<span class="dv">0</span> <span class="op">-</span><span class="st"> </span><span class="fl">0.65</span>,  <span class="kw">normal.cdf</span>(<span class="dv">0</span>), <span class="dt">label=</span><span class="kw">paste0</span>(<span class="st">&quot;(pnorm) = &quot;</span>, </a>
<a class="sourceLine" id="cb16-22" data-line-number="22">                <span class="kw">normal.cdf</span>(<span class="dv">0</span>)), <span class="dt">ce=</span><span class="dv">1</span>, <span class="dt">col=</span><span class="st">&quot;black&quot;</span>)</a>
<a class="sourceLine" id="cb16-23" data-line-number="23"><span class="kw">text</span>(<span class="op">-</span><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="fl">0.65</span>, <span class="kw">normal.cdf</span>(<span class="op">-</span><span class="dv">1</span>), <span class="dt">label=</span><span class="kw">paste0</span>(<span class="st">&quot;(pnorm) = &quot;</span>, </a>
<a class="sourceLine" id="cb16-24" data-line-number="24">                <span class="kw">normal.cdf</span>(<span class="op">-</span><span class="dv">1</span>)), <span class="dt">ce=</span><span class="dv">1</span>, <span class="dt">col=</span><span class="st">&quot;black&quot;</span>)</a>
<a class="sourceLine" id="cb16-25" data-line-number="25"><span class="kw">text</span>(q <span class="op">-</span><span class="st"> </span><span class="fl">0.65</span>,  <span class="kw">normal.cdf</span>(q), <span class="dt">label=</span><span class="kw">paste0</span>(<span class="st">&quot;(pnorm) = &quot;</span>, </a>
<a class="sourceLine" id="cb16-26" data-line-number="26">                <span class="kw">normal.cdf</span>(q)), <span class="dt">ce=</span><span class="dv">1</span>, <span class="dt">col=</span><span class="st">&quot;black&quot;</span>)</a>
<a class="sourceLine" id="cb16-27" data-line-number="27"><span class="kw">text</span>(x <span class="op">+</span><span class="st"> </span><span class="fl">0.5</span>, <span class="fl">0.03</span>, <span class="dt">label=</span><span class="kw">paste0</span>(<span class="st">&quot;(qnorm) = &quot;</span>, q), <span class="dt">ce=</span><span class="dv">1</span>, <span class="dt">col=</span><span class="st">&quot;black&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:gaussiancdf"></span>
<img src="DS_files/figure-html/gaussiancdf-1.png" alt="Gaussian CDF" width="70%" />
<p class="caption">
Figure 5.10: Gaussian CDF
</p>
</div>

<p>Base on figure , we notice three characteristics of a <strong>distribution</strong> curve:</p>
<ul>
<li>The curve is monotonically increasing to the right.</li>
<li>If we increase the support infinitely, we see that the curve flattens infinitely towards 1:</li>
</ul>
<p><span class="math display">\[\begin{align}
\underset{x \rightarrow \infty}{\mathrm{lim}}(\text{CDF}) = 1
\end{align}\]</span></p>
<ul>
<li>If we decrease the support, we see that the curve flattens infinitely towards 0:</li>
</ul>
<p><span class="math display">\[\begin{align}
\underset{x \rightarrow -\infty}{\mathrm{lim}}(\text{CDF}) = 0
\end{align}\]</span></p>
<p>Alternatively, a <strong>distribution function</strong> also computes for the area under the <strong>density</strong> curve. See figure .</p>

<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb17-1" data-line-number="1">normal.cdf &lt;-<span class="st"> </span><span class="cf">function</span>(prob) {</a>
<a class="sourceLine" id="cb17-2" data-line-number="2">   <span class="kw">qnorm</span>(prob)</a>
<a class="sourceLine" id="cb17-3" data-line-number="3">}</a>
<a class="sourceLine" id="cb17-4" data-line-number="4">area &lt;-<span class="st"> </span><span class="cf">function</span>(prob) {</a>
<a class="sourceLine" id="cb17-5" data-line-number="5">    <span class="co"># boundaries</span></a>
<a class="sourceLine" id="cb17-6" data-line-number="6">    a =<span class="st"> </span><span class="dv">-3</span>; b =<span class="st"> </span><span class="kw">normal.cdf</span>(prob) <span class="co"># (quantile function)</span></a>
<a class="sourceLine" id="cb17-7" data-line-number="7">    <span class="co"># area</span></a>
<a class="sourceLine" id="cb17-8" data-line-number="8">    area =<span class="st"> </span><span class="kw">seq</span>(a, b, <span class="dt">length.out=</span><span class="dv">50</span>)</a>
<a class="sourceLine" id="cb17-9" data-line-number="9">    x =<span class="st"> </span><span class="kw">c</span>(a, area , b)</a>
<a class="sourceLine" id="cb17-10" data-line-number="10">    y =<span class="st"> </span><span class="kw">c</span>(<span class="dv">0</span>, <span class="kw">normal.pdf</span>(area, <span class="dv">0</span>, <span class="dv">1</span>), <span class="dv">0</span>)</a>
<a class="sourceLine" id="cb17-11" data-line-number="11">    <span class="kw">polygon</span>(x, y, <span class="dt">col=</span><span class="st">&quot;grey&quot;</span>)</a>
<a class="sourceLine" id="cb17-12" data-line-number="12">}</a>
<a class="sourceLine" id="cb17-13" data-line-number="13"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="op">-</span><span class="dv">3</span>,<span class="dv">3</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="fl">0.5</span>), </a>
<a class="sourceLine" id="cb17-14" data-line-number="14">     <span class="dt">xlab=</span><span class="st">&quot;spread/variance (qnorm)&quot;</span>, </a>
<a class="sourceLine" id="cb17-15" data-line-number="15">     <span class="dt">ylab=</span><span class="st">&quot;probability density (dnorm)&quot;</span>,</a>
<a class="sourceLine" id="cb17-16" data-line-number="16">     <span class="dt">main=</span><span class="st">&quot;Gaussian CDF&quot;</span>, <span class="dt">axes=</span><span class="ot">FALSE</span>, <span class="dt">frame=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb17-17" data-line-number="17"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb17-18" data-line-number="18"><span class="kw">abline</span>(<span class="dt">h=</span><span class="dv">0</span>, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb17-19" data-line-number="19"><span class="kw">curve</span>(<span class="kw">normal.pdf</span>(x, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span><span class="dv">1</span>), <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span>, <span class="dt">lwd=</span><span class="dv">2</span> )</a>
<a class="sourceLine" id="cb17-20" data-line-number="20"><span class="kw">axis</span>(<span class="dv">1</span>, <span class="dv">-3</span><span class="op">:</span><span class="dv">3</span>, <span class="kw">c</span>(<span class="kw">expression</span>(<span class="op">-</span><span class="dv">3</span><span class="op">*</span>sigma), <span class="kw">expression</span>(<span class="op">-</span><span class="dv">2</span><span class="op">*</span>sigma),</a>
<a class="sourceLine" id="cb17-21" data-line-number="21">               <span class="kw">expression</span>(<span class="op">-</span><span class="dv">1</span><span class="op">*</span>sigma),<span class="dv">0</span>,<span class="kw">expression</span>(<span class="dv">1</span><span class="op">*</span>sigma),</a>
<a class="sourceLine" id="cb17-22" data-line-number="22">               <span class="kw">expression</span>(<span class="dv">2</span><span class="op">*</span>sigma),<span class="kw">expression</span>(<span class="dv">3</span><span class="op">*</span>sigma)))</a>
<a class="sourceLine" id="cb17-23" data-line-number="23"><span class="kw">axis</span>(<span class="dv">2</span>)</a>
<a class="sourceLine" id="cb17-24" data-line-number="24"><span class="kw">area</span>(<span class="dt">prob=</span><span class="fl">0.5</span>)</a>
<a class="sourceLine" id="cb17-25" data-line-number="25"><span class="kw">text</span>(<span class="dv">0</span>, <span class="fl">0.42</span>, <span class="dt">label=</span><span class="st">&quot;pdf curve&quot;</span>, <span class="dt">ce=</span><span class="dv">1</span>, <span class="dt">col=</span><span class="st">&quot;blue&quot;</span>)</a>
<a class="sourceLine" id="cb17-26" data-line-number="26"><span class="kw">text</span>(<span class="op">-</span><span class="fl">0.6</span>, <span class="fl">0.14</span>, <span class="dt">label=</span><span class="st">&quot;cdf area = 0.5&quot;</span>, <span class="dt">ce=</span><span class="dv">1</span>, <span class="dt">col=</span><span class="st">&quot;black&quot;</span>)</a>
<a class="sourceLine" id="cb17-27" data-line-number="27"><span class="kw">text</span>(<span class="op">-</span><span class="fl">0.6</span>, <span class="fl">0.09</span>, <span class="dt">label=</span><span class="st">&quot;(pnorm)&quot;</span>, <span class="dt">ce=</span><span class="dv">1</span>, <span class="dt">col=</span><span class="st">&quot;black&quot;</span>)</a>
<a class="sourceLine" id="cb17-28" data-line-number="28"><span class="kw">text</span>(<span class="fl">0.50</span>, <span class="fl">0.02</span>, <span class="dt">label=</span><span class="st">&quot;(qnorm) q=0&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:gaussianq"></span>
<img src="DS_files/figure-html/gaussianq-1.png" alt="Gaussian CDF" width="70%" />
<p class="caption">
Figure 5.11: Gaussian CDF
</p>
</div>

<p>To illustrate, let us calculate the <strong>cumulative density</strong> (or <strong>cumulative distribution</strong> or <strong>probability distribution</strong>) of a normal distribution in which <span class="math inline">\(x = 0\)</span>:</p>
<p><span class="math display">\[\begin{align}
\mathcal{F}_X(x) = \mathcal{P}(X \le x) = \mathcal{P}(X \le 0) 
\end{align}\]</span></p>
<p>In R code, cumulative density can be computed using <strong>pnorm</strong>:</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb18-1" data-line-number="1">(<span class="dt">p =</span> <span class="kw">pnorm</span>(<span class="dt">q=</span><span class="dv">0</span>, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span><span class="dv">1</span>)) <span class="co"># area under the curve, given quantile=0</span></a></code></pre></div>
<pre><code>## [1] 0.5</code></pre>
<p>In reverse, get the <strong>quantile value</strong> given the result of <strong>cdf</strong>:</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb20-1" data-line-number="1">(<span class="dt">q =</span> <span class="kw">qnorm</span>(<span class="dt">p=</span><span class="fl">0.5</span>, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span><span class="dv">1</span>)) <span class="co"># inverse of cdf (or pnorm)</span></a></code></pre></div>
<pre><code>## [1] 0</code></pre>
</div>
<div id="special-functions" class="section level2">
<h2><span class="header-section-number">5.8</span> Special Functions</h2>
<p>Before we discuss the different types of distribution, in this section, let us first introduce some <strong>special functions</strong> that are used often in numerically computing for <strong>PDFs</strong> and <strong>CDFs</strong>. Here, we exclude the derivation of the functions. We leave readers to investigate those derivations.</p>
<div id="gamma-function" class="section level3">
<h3><span class="header-section-number">5.8.1</span> Gamma function </h3>
<p><strong>Gamma</strong> function extends the scope of factorial function from non-negative integer to real numbers.</p>
<p><span class="math display">\[\begin{align}
\Gamma(z) = \int_0^\infty  x^{z-1} e^{-x} dx = (z-1)!\ \ \ \ \ \ \ \ \ \ \ \ \ \ \Gamma(z+1) = z\Gamma(z) =  z(z-1)!
\end{align}\]</span></p>
<p>The Gamma function can be split into two regions (see next section).</p>
<p><span class="math display">\[\begin{align}
\Gamma(z) = \gamma(z, \alpha) + \Gamma(z, \alpha) 
\end{align}\]</span></p>
</div>
<div id="incomplete-gamma-function" class="section level3">
<h3><span class="header-section-number">5.8.2</span> Incomplete Gamma function </h3>
<p>The term <strong>Incomplete</strong> refers to the bounded (only partial) region covered by the integration with respect to the parameter, <span class="math inline">\(\alpha\)</span>.</p>
<p>There are two regions:</p>
<p>The <strong>lower region</strong> defined by the following equation (where x &gt;=0):</p>
<p><span class="math display">\[\begin{align}
\gamma(z, \alpha) = \int_0^\alpha x^{z-1}e^{-x} dx,\ \ \ \ \ \ \ where\ z &gt; 0
\end{align}\]</span></p>
<p>The <strong>upper region</strong> defined by the following equation (where x &gt;= 0):</p>
<p><span class="math display">\[\begin{align}
\Gamma(z, \alpha) = \int_\alpha^\infty x^{z-1}e^{-x} dx,\ \ \ \ \ \ \ where\ z &gt; 0
\end{align}\]</span></p>
<p>Here, let us use one of a few numerical variations such as the <strong>power series</strong> to compute for the <strong>lower incomplete gamma function</strong> (Wikipedia - Incomplete Gamma Function):</p>
<p><span class="math display">\[\begin{align}
\gamma(z, \alpha) = \alpha^z e^{-\alpha} \sum_{k=0}^\infty \frac{\alpha^k}{\Gamma(z+k+1)}
\end{align}\]</span></p>
<p>With that, we have the following <strong>regularized Incomplete Gamma functions</strong>:</p>
<p><strong>lower tail</strong> in a distribution:</p>
<p><span class="math display">\[\begin{align}
P(z, \alpha) = \frac{\gamma(z, \alpha)}{\Gamma(z)} 
= \frac{1}{\Gamma(\alpha)}\int_0^\alpha x^{z-1}e^{-x}dx
= \frac{ \alpha^z e^{-\alpha} }{\Gamma(z)}
\sum_{k=0}^\infty \frac{\alpha^k}{\Gamma(z+k+1)},
\end{align}\]</span></p>
<p>and <strong>upper tail</strong> in a distribution:</p>
<p><span class="math display">\[\begin{align}
Q(z,\alpha) = \frac{\Gamma(z,\alpha)}{\Gamma(z)} 
= \frac{1}{\Gamma(\alpha)}\int_\alpha^\infty x^{z-1}e^{-x}dx
= 1 - P(z, \alpha)
\end{align}\]</span></p>
<p>Here is a naive implementation of <strong>Incomplete Gamma functions</strong> in R code:</p>

<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb22-1" data-line-number="1"><span class="kw">library</span>(pracma)</a>
<a class="sourceLine" id="cb22-2" data-line-number="2">Gamma &lt;-<span class="st"> </span><span class="cf">function</span>(n) { <span class="kw">factorial</span>(n<span class="dv">-1</span>)}</a>
<a class="sourceLine" id="cb22-3" data-line-number="3">GammaInc &lt;-<span class="st"> </span><span class="cf">function</span>(alpha, z) {</a>
<a class="sourceLine" id="cb22-4" data-line-number="4">    s =<span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb22-5" data-line-number="5">    limit =<span class="st"> </span><span class="dv">300</span></a>
<a class="sourceLine" id="cb22-6" data-line-number="6">    flimit =<span class="st"> </span><span class="dv">172</span>  <span class="co"># R&#39;s gamma limit</span></a>
<a class="sourceLine" id="cb22-7" data-line-number="7">    <span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">0</span><span class="op">:</span>limit) {</a>
<a class="sourceLine" id="cb22-8" data-line-number="8">      <span class="cf">if</span> (z <span class="op">+</span><span class="st"> </span>k <span class="op">+</span><span class="st"> </span><span class="dv">1</span> <span class="op">&gt;</span><span class="st"> </span><span class="dv">171</span>) { <span class="cf">break</span> }</a>
<a class="sourceLine" id="cb22-9" data-line-number="9">      s =<span class="st"> </span>s <span class="op">+</span><span class="st"> </span>alpha<span class="op">^</span>k <span class="op">/</span><span class="st"> </span><span class="kw">Gamma</span>( z <span class="op">+</span><span class="st"> </span>k <span class="op">+</span><span class="st"> </span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb22-10" data-line-number="10">    }</a>
<a class="sourceLine" id="cb22-11" data-line-number="11">    lower =<span class="st"> </span>alpha<span class="op">^</span>z <span class="op">*</span><span class="st"> </span><span class="kw">Gamma</span>(z) <span class="op">*</span><span class="st"> </span><span class="kw">exp</span>(<span class="op">-</span>alpha) <span class="op">*</span><span class="st"> </span>s</a>
<a class="sourceLine" id="cb22-12" data-line-number="12">    upper =<span class="st"> </span><span class="kw">Gamma</span>(z) <span class="op">-</span><span class="st"> </span>lower</a>
<a class="sourceLine" id="cb22-13" data-line-number="13">    P =<span class="st"> </span>lower <span class="op">/</span><span class="st"> </span><span class="kw">Gamma</span>(z) <span class="co"># regular inc gamma</span></a>
<a class="sourceLine" id="cb22-14" data-line-number="14">    Q =<span class="st"> </span>upper <span class="op">/</span><span class="st"> </span><span class="kw">Gamma</span>(z)</a>
<a class="sourceLine" id="cb22-15" data-line-number="15">    <span class="kw">list</span>(<span class="st">&quot;lower&quot;</span>=<span class="st"> </span>lower, <span class="st">&quot;upper&quot;</span>=upper,  <span class="st">&quot;P&quot;</span>=P, <span class="st">&quot;Q&quot;</span>=Q )</a>
<a class="sourceLine" id="cb22-16" data-line-number="16">}</a>
<a class="sourceLine" id="cb22-17" data-line-number="17"><span class="co"># Naive implementation</span></a>
<a class="sourceLine" id="cb22-18" data-line-number="18"><span class="kw">t</span>(<span class="kw">GammaInc</span>(<span class="dv">2</span>,<span class="dv">1</span>))</a></code></pre></div>
<pre><code>##      lower     upper     P         Q        
## [1,] 0.8646647 0.1353353 0.8646647 0.1353353</code></pre>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb24-1" data-line-number="1"><span class="co"># Built-in R package (pracma)</span></a>
<a class="sourceLine" id="cb24-2" data-line-number="2"><span class="kw">gammainc</span>(<span class="dv">2</span>,<span class="dv">1</span>)</a></code></pre></div>
<pre><code>##    lowinc    uppinc    reginc 
## 0.8646647 0.1353353 0.8646647</code></pre>

<p>Note that in R, the gamma function may not allow numbers over the range limit of 172. A way to work around that is using log gamma (lgamma) with additional adjustments in the expressions.</p>
</div>
<div id="digamma-function" class="section level3">
<h3><span class="header-section-number">5.8.3</span> Digamma Function </h3>
<p>The <strong>Digamma</strong> function is the derivative of the log of Gamma function and is written as:</p>
<p><span class="math display">\[\begin{align}
\Psi(x) = \frac{d}{dx} \log_e \Gamma(x) = \frac{\Gamma&#39;(x)}{\Gamma(x)}
\end{align}\]</span></p>
<p>We also have <strong>Polygamma</strong> function as a general extension of <strong>Digamma</strong> function and written like so:</p>
<p><span class="math display">\[\begin{align}
\Psi(n,x) = \frac{d^n}{dx^n} \log_e \Gamma(x) = \frac{\Gamma^{(n)}(x)}{\Gamma(x)}
\end{align}\]</span></p>
</div>
<div id="beta-function" class="section level3">
<h3><span class="header-section-number">5.8.4</span> Beta function </h3>
<p><strong>Beta</strong> function is named by <strong>Legendre</strong> for <strong>Eulerâs integral of the first kind</strong> which relies on <strong>Gamma</strong> function.</p>
<p><span class="math display">\[\begin{align}
\mathcal{B}(\alpha, \beta) \equiv \mathcal{B}(1; \alpha, \beta)  = \int_0^1 x^{\alpha-1}(1-x)^{\beta-1} dx 
= \frac{\Gamma(\alpha)\Gamma(\beta)}{\Gamma(\alpha + \beta)}
\end{align}\]</span></p>
<p>where <span class="math inline">\(\alpha &gt; 0\ and\ \beta &gt; 0\)</span>.</p>
<p>Note that if <strong>function</strong> is symmetric, then we have:</p>
<p><span class="math display">\[
\mathcal{B}(\alpha, \beta) = \mathcal{B}(\beta, \alpha)
\]</span></p>
</div>
<div id="incomplete-beta-function" class="section level3">
<h3><span class="header-section-number">5.8.5</span> Incomplete Beta function </h3>
<p>Given <strong>support</strong>, <span class="math inline">\(0 \le x \le 1\)</span>:</p>
<p><span class="math display">\[\begin{align}
\mathcal{B}_x(\alpha, \beta) \equiv \mathcal{B}(x; \alpha, \beta)  = \int_0^x x^{\alpha-1}(1-x)^{\beta-1} dx
\end{align}\]</span></p>
</div>
<div id="regularized-beta-function" class="section level3">
<h3><span class="header-section-number">5.8.6</span> Regularized Beta function</h3>
<p>This is also called <strong>normalized incomplete beta function</strong> and is written as.</p>
<p><span class="math display">\[\begin{align}
I_x(\alpha, \beta) \equiv I(x; \alpha, \beta) = 1 - I_{1-x}(\beta, \alpha)  = \frac{\mathcal{B}_x(\alpha, \beta)}{\mathcal{B}(\alpha, \beta)}
\end{align}\]</span></p>
<p>Equivalently, we have:</p>
<p><span class="math display">\[\begin{align}
I_x(\alpha, \beta) +  I_{1-x}(\beta, \alpha)  = 1
\end{align}\]</span></p>
<p>Also, for the derivations, we have:</p>
<p><span class="math display">\[\begin{align}
I_x(\alpha, \beta) \equiv I(x; \alpha, \beta)  = \frac{1}{\mathcal{B}(\alpha, \beta) } \int_0^x x^{\alpha-1}(1-x)^{\beta-1} dx
\end{align}\]</span></p>
<p>and</p>
<p><span class="math display">\[\begin{align}
I_{1-x}(\beta, \alpha) \equiv I(1-x; \beta, \alpha) = \frac{1}{\mathcal{B}(\alpha, \beta) } \int_{x}^1 x^{\alpha-1}(1-x)^{\beta-1} dx
\end{align}\]</span></p>
<p>For further discussion of <strong>Incomplete Beta functions</strong>, see <strong>CDF</strong> for <strong>T distribution</strong> in <strong>Statistical Computation</strong> chapter.</p>
</div>
<div id="hypergeometric-function" class="section level3">
<h3><span class="header-section-number">5.8.7</span> Hypergeometric function </h3>
<p><strong>Hypergeometric function</strong> is a special function that computes for the sum of <strong>hypergeometric series</strong>.</p>
<p><strong>Generalized form</strong>:</p>
<p><span class="math display">\[\begin{align}
{}_pF_q(\alpha_1,...,\alpha_p; \beta_1,...,\beta_q; x) = \sum_{n=0}^\infty \frac{(\alpha_1)_n\cdots(\alpha_p)_n}{\beta_1)_n\cdots(\beta_q)_n}\frac{x^n}{n!}
\end{align}\]</span></p>
<p><strong>Gauss form</strong>:</p>
<p><span class="math display">\[\begin{align}
{}_2F_1(a,b;c; x) = \sum_{n=0}^\infty \frac{(a)_n(b)_n}{(c)_n}\frac{x^n}{n!}
\end{align}\]</span></p>
<p>Note that <span class="math inline">\((x)_n\)</span> is a <strong>Pochhammer symbol</strong> which is expressed as: </p>
<p><strong>Falling Factorial</strong> (where <span class="math inline">\(x \ge 0\)</span> and <span class="math inline">\(x \in \mathbb{R}\)</span>): </p>
<p><span class="math display">\[\begin{align}
(x)_n = \frac{\Gamma(x+n)}{\Gamma(x - n + 1)}  = x(x-1)(x-2) ... (x- n +1) = \prod_{k=0}^{n-1} (x-k)
\end{align}\]</span></p>
<p><strong>Rising Factorial</strong> (where <span class="math inline">\(x \ge 0\)</span> and <span class="math inline">\(x \in \mathbb{R}\)</span>):</p>
<p><span class="math display">\[\begin{align}
(x)^n = \frac{\Gamma(x+n)}{\Gamma(x)}  = x(x+1)(x+2) ... (x+n-1) = \prod_{k=0}^{n-1}(x+k)
\end{align}\]</span></p>
<p>A rather expansion form of <strong>Hypergeometric function</strong> without the <strong>Pochhammer symbol</strong> is the following:</p>
<p><span class="math display">\[\begin{align}
{}_pF_q(\alpha_1,...,\alpha_p; \beta_1,...,\beta_q; x) = 
\sum_{k=0}^\infty 
\prod_{i=1}^p \frac{\Gamma(k+\alpha_i)}{\Gamma(\alpha_i)}
\prod_{j=1}^p  \frac{\Gamma(\beta_j)}{\Gamma(k+\beta_j)}
\frac{x^k}{k!}
\end{align}\]</span></p>
<p>and using that to form our <strong>Gauss Hypergeometric function</strong>:</p>
<p><span class="math display">\[\begin{align}
{}_2F_1(\alpha_1,\alpha_2; \beta_1; x) = 
\sum_{k=0}^\infty 
\prod_{i=1}^2 \frac{\Gamma(k+\alpha_i)}{\Gamma(\alpha_i)}
\prod_{j=1}^1 \frac{\Gamma(\beta_j)}{\Gamma(k+\beta_j)}
\frac{x^k}{k!}
\end{align}\]</span></p>
<p>The <strong>Gauss Hypergeometric function</strong> has other transformation formulas (Abramowitz and Stegun 1972):</p>
<p><span class="math display">\[\begin{align}
{}_2F_1(\alpha,\beta,c; x) &amp;= (1-x)^{-\beta} {}_2F_1\left(c-\alpha,\beta;c; \frac{x}{x-1}\right)\ \ \ \leftarrow\ \ \ Pfaff\\
&amp;= (1-x)^{-\alpha} {}_2F_1\left(\alpha,c-\beta;c; \frac{x}{x-1}\right)\ \ \ \leftarrow\ \ \ Pfaff\\
&amp;= (1-x)^{c-\alpha-\beta} {}_2F_1(c-\alpha,c-\beta;c; x)\ \ \ \leftarrow\ \ \ Euler
\end{align}\]</span></p>
<p>To illustrate the use of <strong>Gamma, Beta, and Hypergeometric functions</strong>, see the discussion of <strong>CDF</strong> in <strong>Statistics Computation</strong> chapter under <strong>t-Distribution</strong>.</p>
</div>
<div id="continued-fraction" class="section level3">
<h3><span class="header-section-number">5.8.8</span> Continued Fraction </h3>
<p><strong>Continued Fraction</strong> is a finite representation of a rational number in the form of a fraction characterized by a repeating quotient. It has the following format (with <span class="math inline">\(\mathcal{K}\)</span> indicating a series of continued fractions):</p>
<p><span class="math display">\[\begin{align}
CF(a,b) = b_0 + \mathcal{K}_{n=1}^\infty \frac{a_n}{b_n} = b_0 + \frac{a_1}{b_1 + \frac{a_2}{b_2 + \frac{a_3}{b_3 + ...}}}
\end{align}\]</span>
There are two notations we can use to represent <strong>Continued Fraction</strong>:</p>
<p><span class="math display">\[\begin{align}
CF(a,b) = ( b_0; b_1, b_2, b_3, ... )\ \ \ \ and\ \ \ \ 
CF(a,b) = \left[ b_0 + \frac{a_1}{b_1 +}\frac{a_2}{b_2 +}\frac{a_3}{b_3 +} ... \right]
\end{align}\]</span></p>
<p>Only for illustration purpose, here is a sample naive (recursive) implementation of <strong>Continued Fraction</strong> in R code:</p>

<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb26-1" data-line-number="1">continued_fraction &lt;-<span class="st"> </span><span class="cf">function</span>(n, a, b) { <span class="co"># recursive</span></a>
<a class="sourceLine" id="cb26-2" data-line-number="2">    <span class="cf">if</span> (n <span class="op">==</span><span class="st"> </span><span class="dv">0</span>) <span class="kw">return</span>(a<span class="op">/</span>b)</a>
<a class="sourceLine" id="cb26-3" data-line-number="3">    b <span class="op">+</span><span class="st"> </span>a <span class="op">/</span><span class="st"> </span><span class="kw">continued_fraction</span>(n<span class="dv">-1</span>, a, b)</a>
<a class="sourceLine" id="cb26-4" data-line-number="4">}</a>
<a class="sourceLine" id="cb26-5" data-line-number="5"><span class="kw">continued_fraction</span>(<span class="dt">n=</span><span class="dv">20</span>,<span class="dt">a=</span><span class="dv">2</span>,<span class="dt">b=</span><span class="dv">1</span>)</a></code></pre></div>
<pre><code>## [1] 2</code></pre>

<p><span class="math display">\[\begin{align*}
CF(a,b) {}&amp;= b_0 + \mathcal{K}_{n=1}^\infty \frac{a_n}{b_n} 
= 1 + \mathcal{K}_{n=1}^{20} \frac{2}{1} 
&amp;= b_0 + \frac{a_1}{b_1 + \frac{a_2}{b_2 + \frac{a_3}{b_3 + ...}}}
&amp;= 1 + \frac{2}{1+ \frac{2}{1 + \frac{2}{1 + ...}}}
= 2
\end{align*}\]</span></p>
<p>We leave readers to investigate <strong>Lentzâs algorithm</strong> used to compute for continued fractions.</p>
<p>The next two functions may not necessarily be used in distribution functions; however, it helps to be familiar with them.</p>
</div>
<div id="dirac-delta-function" class="section level3">
<h3><span class="header-section-number">5.8.9</span> Dirac Delta Function </h3>
<p>The <strong>Dirac Delta</strong> function is also known as the <strong>Impulse</strong> function. It characterizes a behavior such that from a long constant state, it develops into a sudden spike and immediately drops back to a constant state. Such sudden change of <strong>momentum</strong> because of an applied force creates such an <strong>impulse</strong>.</p>
<p><span class="math display">\[\begin{align}
\delta (x) = 
\begin{cases}
0 &amp; x \ne 0\\
\infty &amp; x = 0
\end{cases}
\end{align}\]</span></p>
</div>
<div id="kronecker-delta-function" class="section level3">
<h3><span class="header-section-number">5.8.10</span> Kronecker Delta Function </h3>
<p>The <strong>Kronecker delta</strong> has the likes of an <strong>indicator</strong> function in that it outputs 1 if a variable equals some given value; otherwise, it outputs zero.</p>
<p><span class="math display">\[\begin{align}
\delta (x) = 
\begin{cases}
0 &amp; x \ne 0\\
1 &amp; x = 0
\end{cases}
\ \ \ \ \ \ \ \
\delta (x) = 
\begin{cases}
0 &amp; x \ne m\\
1 &amp; x = m
\end{cases}
\end{align}\]</span></p>
</div>
</div>
<div id="distribution_types" class="section level2">
<h2><span class="header-section-number">5.9</span> Types of Distribution</h2>
<p>Apart from summarizing data based on quantifying its moments (mean, variance, skewness, kurtosis), it helps to characterize the <strong>distribution</strong> of data based on the geometric shape, size, and thickness of its tails. In this section, we show the <strong>PDF</strong> and <strong>CDF</strong> to describe the distribution. Here, we reference the works of Press W.H et al <span class="citation">(<a href="references.html#ref-ref215w">2007</a>)</span>, pp.Â 321-339 and Murpy K.P. <span class="citation">(<a href="references.html#ref-ref224k">2012</a>)</span>, pp.Â 34-43. </p>
<p>Let us start with <strong>Bernoulli distribution</strong> - a single trial <strong>Binomial distribution</strong>.</p>
<div id="bernoulli-distribution" class="section level3">
<h3><span class="header-section-number">5.9.1</span> Bernoulli distribution </h3>
<p>A <strong>Bernoulli distribution</strong>, named after <strong>Jacob Bernoulli</strong>, is a <strong>discrete</strong> probability distribution of a random variable taking a <strong>binary outcome</strong> which can be 0 or 1, true or false, head or tail of a coin, etc. and is written as:</p>
<p><span class="math display">\[\begin{align}
X \sim Bernoulli(\rho)\ \ \ or\ \ \ \ X \sim Ber(\rho)
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(\rho\)</span> is the approximate probability of success</li>
<li><strong>X</strong> is the data (random variable).</li>
</ul>
<p>Here, we continue to emphasize the idea of approximation. We give two cases where we show approximation for random events.</p>
<p>For example, suppose we make a single attempt to toss a coin with an approximate 50% chance that the coin lands on the head. Here, we have a probability outcome denoted as <span class="math inline">\(\rho\)</span>. If <span class="math inline">\(\rho\)</span> is the probable outcome of the head, then <span class="math inline">\(q = 1 - \rho\)</span> is the probable outcome of the tail.</p>
<p>Being a discrete distribution, the <strong>PMF</strong>, probability mass function, where <span class="math inline">\(\rho=0.50\)</span> is written as:</p>
<p><span class="math display">\[\begin{align}
f(x) = 
\begin{cases}
\rho &amp; x = 1 \\
q = 1 - \rho &amp; x = 0
\end{cases}
\end{align}\]</span></p>
<p>which can also be written as:</p>
<p><span class="math display">\[\begin{align}
f(x; \rho) = \mathcal{P}(X=x|\rho) = \rho^xq^{1-x} = \rho^x(1-\rho)^{1-x}
\end{align}\]</span></p>
<p>For another example, suppose we make just one attempt to roll a six-sided dice with a 16% probability that it lands on one side with the number four. Here, let us use <span class="math inline">\(\mathbf{x=1}\)</span> if dice lands on number four, and <span class="math inline">\(\mathbf{x=0}\)</span> if dice lands on other numbers. Also, let us consider the following:</p>
<p><span class="math display">\[
\rho_{\{4\}} = 0.16\ \ \ \ \ \ \ \ q_{\{1,2,3,5,6\}} = 0.84
\]</span>
Using the equation, we get the following:</p>
<p><span class="math display">\[\begin{align*}
f(x; \rho) {}&amp;= P(X=x|\rho) = \rho^xq^{1-x} = \rho^x(1-\rho)^{1-x}\\
f(x=1; \rho=0.16) &amp;= P(X=1|\rho=0.16) = (0.16)^{1}(0.84)^{1-1} = 0.16\\
f(x=0; \rho=0.16) &amp;= P(X=0|\rho=0.16) = (0.16)^{0}(0.84)^{1-0} = 0.84\\
\end{align*}\]</span></p>
</div>
<div id="binomial-distribution" class="section level3">
<h3><span class="header-section-number">5.9.2</span> Binomial distribution </h3>
<p>On the other hand, a <strong>Binomial distribution</strong> is the sum of <strong>Bernoulli</strong> trials and is written as:</p>
<p><span class="math display">\[\begin{align}
X \sim Bin(n, \rho)
\end{align}\]</span></p>
<p>Note that a <strong>Bernoulli distribution</strong> is characterized by a single trial (n=1) and a <strong>Binomial distribution</strong> is characterized by multiple trials (n &gt; 1).</p>
<p>The <strong>PMF</strong> - probability mass function - for a <strong>discrete Binomial distribution</strong> is expressed as:</p>
<p><span class="math display">\[\begin{align}
f(x; n, \rho)  = P(X = x|n,\rho) = \binom{n}{x}  \rho^xq^{n-x} = \binom{n}{x}  \rho^x(1-\rho)^{n-x}
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li><strong>n</strong> is the number of independent trials (independent observations)</li>
<li><span class="math inline">\(\rho\)</span> is the probability of a state, e.g.Â probability of a coin landing as the head.</li>
<li><strong>X</strong> is data (random variable), where X <span class="math inline">\(\in\)</span> {0,1}.</li>
</ul>
<p>and:</p>
<p><span class="math display">\[
\binom{n}{x} = \frac{n!}{(n-x)!x!}\ \ \ \ \text{(this is a constant)}
\]</span></p>
<p>and:</p>
<p><span class="math display">\[
\rho^x(1-\rho)^{n-x}\ \ \ \ \ \text{(this describes the shape of curve)}
\]</span></p>
<p>The <strong>PMF</strong> is read as <strong>a function of random variable x with n and <span class="math inline">\(\rho\)</span> parameters.</strong></p>
<p>The <strong>CMF</strong> - cumulative mass function - for a <strong>discrete Binomial distribution</strong> is expressed as:</p>
<p><span class="math display">\[\begin{align}
\mathcal{F}(x; n, \rho) = \mathcal{P}( X \le x| n, \rho) = \sum_{k=0}^x \binom{n}{k}  \rho^k(1-\rho)^{n-k}
\end{align}\]</span></p>
<p>Because <strong>Binomial distribution</strong> is discrete, we use summation instead of integration.</p>
<p>Note that for the rest of this section, we use the lowercase <strong>f</strong> function to indicate PDF/PMF and we use the uppercase <strong>F</strong> function to indicate CDF/CMF.</p>
<p>Now to illustrate, suppose we toss a coin 10 times. Each time we toss, we record the outcome. In the end, we will be able to record 10 outcomes of mix tails and heads. However, for each outcome, there are two possibilities: either a T or an H. Therefore, if we toss a coin 10 times, the possible outcome would end up 2^10 = 1024 possible outcomes. That is a lot of possibilities.</p>
<p>Let us try to visualize some of the combinations and see what is the possible outcome of flipping an H:</p>
<ul>
<li>Possibility that all 10 flips end up to be Tails = 1 count out of 1024 possibilities</li>
</ul>
<p><span class="math display">\[
T T T T T T T T T T 
\]</span></p>
<ul>
<li>Possibility that all 10 flips end up to be Heads = 1 count out of 1024 possibilities</li>
</ul>
<p><span class="math display">\[
H H H H H H H H H H
\]</span></p>
<ul>
<li>Possibility that all 10 flips end up to be Tails except the first = 1 count / 1024</li>
</ul>
<p><span class="math display">\[
H T T T T T T T T T
\]</span></p>
<ul>
<li>Possibility that all 10 flips end up to be Tails except the second = 1 count / 1024</li>
</ul>
<p><span class="math display">\[
T H T T T T T T T T
\]</span></p>
<p>If we continue this, we will have to do it for all 1024 possibilities. Let us use combination formula:</p>

<p><span class="math display">\[\begin{align*}
P(Outcome = \ \ 0\ H) {}&amp; = nCr / 1024 = {}_{10}C_0 / 1024 = 1 / 1024\\
P(Outcome = \ \ 1\ H) &amp;= nCr / 1024 = {}_{10}C_1 / 1024 = 10 / 1024\\
P(Outcome = \ \ 2\ H) &amp;= nCr / 1024 = {}_{10}C_2 / 1024 = 45 / 1024\\
P(Outcome = \ \ 3\ H) &amp;= nCr / 1024 = {}_{10}C_3 / 1024 = 120 / 1024\\
P(Outcome = \ \ 4\ H) &amp;= nCr / 1024 = {}_{10}C_4 / 1024 = 210 / 1024\\
P(Outcome = \ \ 5\ H) &amp;= nCr / 1024 = {}_{10}C_5 / 1024 = 252 / 1024\\
P(Outcome = \ \ 6\ H) &amp;= nCr / 1024 = {}_{10}C_6 / 1024 = 210 / 1024\\
P(Outcome = \ \ 7\ H) &amp;= nCr / 1024 = {}_{10}C_7 / 1024 = 120 / 1024\\
P(Outcome = \ \ 8\ H) &amp;= nCr / 1024 = {}_{10}C_8 / 1024 = 45 / 1024\\
P(Outcome = \ \ 9\ H) &amp;= nCr / 1024 = {}_{10}C_9 / 1024 = 10 / 1024\\
P(Outcome = 10\ H) &amp;= nCr / 1024 = {}_{10}C_{10} / 1024 = 1 / 1024
\end{align*}\]</span>
</p>
<p>Now let us plot the distribution of these probable outcomes â¦</p>

<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb28-1" data-line-number="1">random_x &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">10</span>,<span class="dv">45</span>,<span class="dv">120</span>,<span class="dv">210</span>,<span class="dv">252</span>,<span class="dv">210</span>,<span class="dv">120</span>,<span class="dv">45</span>,<span class="dv">10</span>,<span class="dv">1</span>) <span class="op">/</span><span class="st"> </span><span class="dv">1024</span></a>
<a class="sourceLine" id="cb28-2" data-line-number="2"><span class="kw">names</span>(random_x) &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">10</span>,<span class="dv">1</span>)</a>
<a class="sourceLine" id="cb28-3" data-line-number="3"><span class="kw">barplot</span>(random_x, <span class="dt">density=</span>T, <span class="dt">col=</span><span class="dv">2</span>, <span class="dt">xlab=</span><span class="st">&quot;H Outcome&quot;</span>,</a>
<a class="sourceLine" id="cb28-4" data-line-number="4">        <span class="dt">ylim=</span><span class="kw">range</span>(<span class="dv">0</span>, <span class="fl">0.25</span>), <span class="dt">xlim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="dv">12</span>),</a>
<a class="sourceLine" id="cb28-5" data-line-number="5">        <span class="dt">ylab=</span><span class="st">&quot;Probability&quot;</span>, <span class="dt">main=</span><span class="st">&quot;Flip A Fair Coin&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:statistics3"></span>
<img src="DS_files/figure-html/statistics3-1.png" alt="Statistics" width="70%" />
<p class="caption">
Figure 5.12: Statistics
</p>
</div>

<p>Using <strong>dbinom(.)</strong> function, we can derive the same probability of a binomial case. For example, the probability that we get 2 heads successfully out of 10 trials given a 0.20 probability threshold is written as:</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb29-1" data-line-number="1"><span class="kw">dbinom</span>(<span class="dt">x =</span> <span class="dv">2</span>, <span class="dt">size=</span><span class="dv">10</span>, <span class="dt">prob=</span><span class="fl">0.20</span>)</a></code></pre></div>
<pre><code>## [1] 0.3019899</code></pre>
<p>For the expected value and variance of <strong>Binomial distribution</strong>, we use the following equations:</p>
<p><strong>Expected value:</strong></p>
<p><span class="math display">\[\begin{align}
\mathbb{E}(X) {}&amp;= \sum_{x=0}^{n} x(fx) = x \binom{n}{x}  p^n(1-p)^{n-x}  = np\\
\mathbb{E}(X^2) &amp;= \sum_{x=0}^{n} x^2(fx) = x^2 \binom{n}{x}  p^n(1-p)^{n-x}  
= n(n-1)p^2 + np
\end{align}\]</span></p>
<p><strong>Variance:</strong></p>
<p><span class="math display">\[\begin{align}
Var(X) = \mathbb{E}(X^2) - \mathbb{E}(X)^2 = 
\left[ n(n-1)p^2 + np \right] - (np)^2 = np(1-p) = npq
\end{align}\]</span></p>
</div>
<div id="multinomial-distribution" class="section level3">
<h3><span class="header-section-number">5.9.3</span> Multinomial distribution </h3>
<p>A <strong>Multinomial distribution</strong>, also called <strong>Categorical distribution</strong>, models a <strong>discrete categorical</strong> probability distribution of a random variable taking an outcome with <strong>multiple categories</strong> which can be 0 to K states, e.g.Â a dice has 6 possible states (or outcomes), and is written as:</p>
<p><span class="math display">\[\begin{align}
X \sim Multi(n,\rho)
\end{align}\]</span></p>
<p>The <strong>PMF</strong> for a <strong>Multinomial distribution</strong> is expressed as:</p>
<p><span class="math display">\[\begin{align}
f(x; n, \rho) = P(X= x|n, \rho) {}&amp;= 
\frac{n!}{x_1! \times ... \times x_k!} 
 \rho_1^{x_1} \times ... \times \rho_k^{x_k}\\
&amp;= \frac{n!}{\prod_{i=1}^k x_i!} \prod_{i=1}^k \rho_i^{x_i}
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li><strong>n</strong> is the number of independent trials (independent observations)</li>
<li><span class="math inline">\(\rho\)</span> is the probability of a state, e.g.Â probability of a dice landing a 4.</li>
<li><span class="math inline">\(k\)</span> is the number of possible states (or outcomes), e.g.Â a dice has 6 sides.</li>
<li><strong>X</strong> is a random variable with list of occurrences, e.g.Â X = ( <span class="math inline">\(x_1, x_2,..., x_k\)</span> )</li>
<li><span class="math inline">\(x_i\)</span> is the number of occurrences of a state (i); e.g. âx_1 = 3â means there are three occurrences of drawing the first marble from an urn (assuming each marble is labeled with a number).</li>
<li><span class="math inline">\(\rho_i\)</span> is the probability of state (i), e.g. <span class="math inline">\(\rho_4 = 0.60\)</span> means 60% probability of drawing the fourth marble from an urn (assuming each marble is labeled with a number).</li>
</ul>
<p>and:</p>
<p><span class="math display">\[
\frac{n!}{\prod_{i=1}^k x_i!}\ \ \ \ \  \ \text{( the number of possible arrangements)}
\]</span></p>
<p>Here are a few examples that allow a stochastic process to generate <strong>multinomial distribution</strong>:</p>
<ul>
<li>Probability of getting number 6 after rolling a 6-sided dice.</li>
<li>Probability of drawing a red marble out of 6 marbles from an urn.</li>
<li>Probability of drawing a blood type of âABâ out of four blood types (e.g.Â O, A, B, AB) from a list of patients.</li>
</ul>
<p>To illustrate, let us use a common example. Suppose we draw 5 marbles - with replacement - from an urn that has 4 marbles - 1 red marble, 2 green marbles, 1 blue marble. Let us calculate the probability of selecting 2 red marbles and 3 green marbles.</p>
<p>We have the following:</p>
<ul>
<li><strong>n</strong> = 5 draws (trials)</li>
<li><strong>k</strong> = 3 states (red, green, blue)</li>
<li><strong>X</strong> = (2 red marbles, 3 green marbles, 0 blue marbles); <span class="math inline">\(x_1\)</span> = 2, <span class="math inline">\(x_2\)</span> = 3, <span class="math inline">\(x_3\)</span> = 0</li>
<li><span class="math inline">\(\rho\)</span> = probabilities: (<span class="math inline">\(1/4\)</span> red, <span class="math inline">\(2/4\)</span> green, <span class="math inline">\(1/4\)</span> blue); <span class="math inline">\(\rho_1\)</span> = 0.25, <span class="math inline">\(\rho_2\)</span> = 0.50, <span class="math inline">\(\rho_3\)</span> = 0.25</li>
</ul>
<p>Using the <strong>Multinomial distribution</strong> formula:</p>
<p><span class="math display">\[
f(x; n,p) = \mathcal{P}(X= x|n,\rho) = \frac{5!}{2! \times 3! \times 0!} \times \left( 0.25^2 \times 0.50^3 \times 0.25^0  \right) 
\]</span>
let us implement in R code:</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb31-1" data-line-number="1">multinomial.pdf &lt;-<span class="st"> </span><span class="cf">function</span>(x, n, p) {</a>
<a class="sourceLine" id="cb31-2" data-line-number="2">  ( <span class="kw">factorial</span>(n) <span class="op">/</span><span class="st"> </span><span class="kw">prod</span>(<span class="kw">factorial</span>(x)) ) <span class="op">*</span><span class="st"> </span><span class="kw">prod</span> ( p<span class="op">^</span>x )</a>
<a class="sourceLine" id="cb31-3" data-line-number="3">}</a>
<a class="sourceLine" id="cb31-4" data-line-number="4">n =<span class="st"> </span><span class="dv">5</span></a>
<a class="sourceLine" id="cb31-5" data-line-number="5">x =<span class="st"> </span><span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">0</span>)</a>
<a class="sourceLine" id="cb31-6" data-line-number="6">p =<span class="st"> </span><span class="kw">c</span>(<span class="fl">0.25</span>, <span class="fl">0.50</span>, <span class="fl">0.25</span>)</a>
<a class="sourceLine" id="cb31-7" data-line-number="7"><span class="kw">c</span>(<span class="st">&quot;probability&quot;</span>=<span class="kw">multinomial.pdf</span>(x, n, p))</a></code></pre></div>
<pre><code>## probability 
##    0.078125</code></pre>
<p>We can validate using a built-in R function called <strong>dmultinom()</strong>.</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb33-1" data-line-number="1"><span class="kw">dmultinom</span>(x, <span class="dt">size=</span>n, <span class="dt">prob=</span>p)</a></code></pre></div>
<pre><code>## [1] 0.078125</code></pre>
</div>
<div id="geometric-distribution" class="section level3">
<h3><span class="header-section-number">5.9.4</span> Geometric distribution </h3>
<p><strong>Geometric distribution</strong> models a <strong>discrete distribution</strong> of a random variable <strong>X</strong> taking into account the number of failed <strong>Bernoulli</strong> attempts prior to a successful one. It is written as:</p>
<p><span class="math display">\[\begin{align}
X \sim Geo(\rho)
\end{align}\]</span></p>
<p>The <strong>PMF</strong> for a <strong>Geometric distribution</strong> is expressed as:</p>
<p><span class="math display">\[\begin{align}
f(x; \rho) = P(X=x|\rho) = q^{(x-1)}\rho = \rho(1-\rho)^{x-1}
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(\rho\)</span> is the probability of success</li>
<li>q is the probability of failure (1-p)</li>
</ul>
<p>The <strong>CMF</strong> for a <strong>Geometric distribution</strong> is expressed as:</p>
<p><span class="math display">\[\begin{align}
\mathcal{F}(x; \rho) = \mathcal{P}(X \le x|\rho) = 
\begin{cases}
1 - (1-\rho)^{x} &amp; x \ge 0\\
0 &amp; x &lt; 0
\end{cases}
\end{align}\]</span></p>
<p>Note that other literature may have the following equations for geometric <strong>PDF</strong> and <strong>CDF</strong> respectively instead:</p>
<p><span class="math display">\[\begin{align}
f(x; \rho)  = \rho(1-\rho)^{x}\ \ \ \ \ \ \ \ \
\mathcal{F}(x; \rho) = 1 - (1-\rho)^{x+1}
\end{align}\]</span></p>
<p>To illustrate, in tossing a coin, compute for the probability that we miss the first four attempts before a successful fifth attempt, granting the probability of a successful attempt is 0.60.</p>
<p><span class="math display">\[
\mathcal{P}(X = 5) = \mathcal{P}(X \le 5)^{4}P(X=5) = (0.40)^3(0.60) = 0.01536
\]</span></p>
<p>where:</p>
<p><span class="math display">\[\begin{align*}
{}&amp;P(X \le 5)^4 \ \ \ \leftarrow\ \text{first four failed attempts}\\
&amp;P(X = 5) \ \ \ \leftarrow\ \text{fifth successful attempt}\\
\end{align*}\]</span></p>
<p>The <strong>expected value</strong> and <strong>variance</strong> is written respectively as:</p>
<p><span class="math display">\[\begin{align}
\mathbb{E}(X) = 1/\rho\ \ \ \ \ \ \ \ \ \ \ Var(X) = \frac{q}{\rho^2}
\end{align}\]</span></p>
</div>
<div id="beta-distribution" class="section level3">
<h3><span class="header-section-number">5.9.5</span> Beta distribution </h3>
<p><strong>Beta distribution</strong> models a <strong>continuous distribution</strong> which is a special kind of <strong>Binomial distribution</strong> written as:</p>
<p><span class="math display">\[\begin{align}
X \sim Beta(\alpha, \beta)
\end{align}\]</span></p>
<p>with the following <strong>Beta PDF</strong> where <strong>support</strong> is <span class="math inline">\(0 \le x \le 1\)</span>:</p>
<p><span class="math display">\[\begin{align}
f(x;\alpha,\beta) = \mathcal{P}(X = x|\alpha,\beta)  = \frac{1}{\mathcal{B}(\alpha,\beta)} 
x ^{\alpha-1}(1-x)^{\beta - 1} 
\end{align}\]</span></p>
<p>where <strong>Beta function</strong> has the following:</p>
<p><span class="math display">\[\begin{align}
\mathcal{B}(\alpha,\beta) {}&amp;= \int_0^1 x^{\alpha-1}(1-x)^{\beta-1}dx \\
\mathcal{B}(\alpha,\beta) &amp;= \frac{\Gamma(\alpha)\Gamma(\beta)  }{\Gamma(\alpha + \beta) } 
\end{align}\]</span></p>
<p>and where the <strong>Gamma function</strong> is as follows:</p>
<p><span class="math display">\[\begin{align}
\Gamma(n) = (n-1)!\ \ \ \ \ \ \ \ \Gamma(n+1) = n\Gamma(n) = n(n-1)!
\end{align}\]</span></p>
<p>On the other hand, the <strong>CDF</strong> of <strong>Beta distribution</strong> is expressed as:</p>
<p><span class="math display">\[\begin{align}
f(x;\alpha,\beta) {}&amp;= P(X \le x|\alpha,\beta) = \frac{1}{\mathcal{B}(\alpha,\beta)} 
\int_0^x x^{\alpha-1}(1-x)^{\beta - 1} dx\\
\nonumber \\
&amp;= I_x(\alpha,\beta) = \frac{B_x(x; \alpha, \beta)}{\mathcal{B}(\alpha,\beta)}.
\end{align}\]</span></p>
<p>Note that the <strong>CDF</strong> is a <strong>regularized beta function</strong> as introduced in the <strong>Helpful function</strong> section.</p>
<p>Because <strong>Beta distribution</strong> is continuous, we use integration instead of summation (such as <strong>CMF</strong> for <strong>Binomial distribution</strong>).</p>
<p>Here is a naive implementation of <strong>PDF</strong> and <strong>CDF</strong> for <strong>Beta distribution</strong> with the different shapes, <span class="math inline">\(\{\alpha, \beta\}\)</span> (See also <strong>T-distribution</strong> in <strong>Statistics Computation</strong> chapter for an alternative implementation of <span class="math inline">\(\mathbf{Ix(\alpha,\beta)}\)</span>):</p>

<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb35-1" data-line-number="1">Gamma &lt;-<span class="st"> </span><span class="cf">function</span>(n) { <span class="kw">factorial</span>(n<span class="dv">-1</span>)}</a>
<a class="sourceLine" id="cb35-2" data-line-number="2">B &lt;-<span class="st"> </span><span class="cf">function</span>(alpha, beta) { </a>
<a class="sourceLine" id="cb35-3" data-line-number="3">    <span class="co"># also can use built-in, beta(a,b)</span></a>
<a class="sourceLine" id="cb35-4" data-line-number="4">    (<span class="kw">Gamma</span>(alpha) <span class="op">*</span><span class="st"> </span><span class="kw">Gamma</span>(beta)) <span class="op">/</span><span class="st">  </span><span class="kw">Gamma</span>(alpha <span class="op">+</span><span class="st"> </span>beta )</a>
<a class="sourceLine" id="cb35-5" data-line-number="5">}</a>
<a class="sourceLine" id="cb35-6" data-line-number="6">incomplete_beta &lt;-<span class="st"> </span><span class="cf">function</span>(x,a,b) { </a>
<a class="sourceLine" id="cb35-7" data-line-number="7">    <span class="kw">pbeta</span>(x,a,b) <span class="op">*</span><span class="st"> </span><span class="kw">B</span>(a,b) </a>
<a class="sourceLine" id="cb35-8" data-line-number="8">}</a>
<a class="sourceLine" id="cb35-9" data-line-number="9">Ix &lt;-<span class="cf">function</span>(x, a, b) { <span class="co">#regulrized beta function, Ix(x; a, b)</span></a>
<a class="sourceLine" id="cb35-10" data-line-number="10">   <span class="kw">incomplete_beta</span>(x,a,b) <span class="op">/</span><span class="st"> </span><span class="kw">B</span>(a,b)</a>
<a class="sourceLine" id="cb35-11" data-line-number="11">}</a>
<a class="sourceLine" id="cb35-12" data-line-number="12">beta_pdf &lt;-<span class="st"> </span><span class="cf">function</span>(x, alpha, beta ) {</a>
<a class="sourceLine" id="cb35-13" data-line-number="13">   <span class="dv">1</span><span class="op">/</span><span class="kw">B</span>(alpha,beta) <span class="op">*</span><span class="st"> </span>( x<span class="op">^</span>(alpha<span class="dv">-1</span>) <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span><span class="op">-</span>x)<span class="op">^</span>(beta<span class="dv">-1</span>) )</a>
<a class="sourceLine" id="cb35-14" data-line-number="14">}</a>
<a class="sourceLine" id="cb35-15" data-line-number="15">beta_cdf &lt;-<span class="st"> </span><span class="cf">function</span>(x, alpha, beta ) {</a>
<a class="sourceLine" id="cb35-16" data-line-number="16">   <span class="kw">Ix</span>(x, alpha, beta)</a>
<a class="sourceLine" id="cb35-17" data-line-number="17">}</a>
<a class="sourceLine" id="cb35-18" data-line-number="18"></a>
<a class="sourceLine" id="cb35-19" data-line-number="19"><span class="co"># probability density</span></a>
<a class="sourceLine" id="cb35-20" data-line-number="20"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">1</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="dv">3</span>), </a>
<a class="sourceLine" id="cb35-21" data-line-number="21">     <span class="dt">xlab=</span><span class="st">&quot;support&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;probability density&quot;</span>,</a>
<a class="sourceLine" id="cb35-22" data-line-number="22">     <span class="dt">main=</span><span class="st">&quot;PDF (Beta Distribution)&quot;</span>,  <span class="dt">frame=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb35-23" data-line-number="23"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb35-24" data-line-number="24"><span class="kw">abline</span>(<span class="dt">h=</span><span class="dv">0</span>, <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb35-25" data-line-number="25">x =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>, <span class="dt">length.out=</span><span class="dv">20</span>)</a>
<a class="sourceLine" id="cb35-26" data-line-number="26"><span class="kw">curve</span>(<span class="kw">beta_pdf</span>(x, <span class="dt">alpha=</span><span class="dv">1</span>, <span class="dt">beta=</span><span class="dv">4</span>), <span class="dt">col=</span><span class="st">&quot;purple&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb35-27" data-line-number="27"><span class="kw">curve</span>(<span class="kw">beta_pdf</span>(x, <span class="dt">alpha=</span><span class="dv">2</span>, <span class="dt">beta=</span><span class="dv">2</span>), <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb35-28" data-line-number="28"><span class="kw">curve</span>(<span class="kw">beta_pdf</span>(x, <span class="dt">alpha=</span><span class="dv">2</span>, <span class="dt">beta=</span><span class="dv">4</span>), <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb35-29" data-line-number="29"><span class="kw">curve</span>(<span class="kw">beta_pdf</span>(x, <span class="dt">alpha=</span><span class="dv">5</span>, <span class="dt">beta=</span><span class="dv">1</span>), <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb35-30" data-line-number="30"><span class="kw">curve</span>(<span class="kw">beta_pdf</span>(x, <span class="dt">alpha=</span><span class="dv">5</span>, <span class="dt">beta=</span><span class="dv">3</span>), <span class="dt">col=</span><span class="st">&quot;brown&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:betadist1"></span>
<img src="DS_files/figure-html/betadist1-1.png" alt="Beta Distribution (Probability Density)" width="70%" />
<p class="caption">
Figure 5.13: Beta Distribution (Probability Density)
</p>
</div>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb36-1" data-line-number="1"><span class="co"># cumulative density</span></a>
<a class="sourceLine" id="cb36-2" data-line-number="2"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">1</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="dv">1</span>), </a>
<a class="sourceLine" id="cb36-3" data-line-number="3">     <span class="dt">xlab=</span><span class="st">&quot;support&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;cumulative probability&quot;</span>,</a>
<a class="sourceLine" id="cb36-4" data-line-number="4">     <span class="dt">main=</span><span class="st">&quot;CDF (Beta Distribution)&quot;</span>,  <span class="dt">frame=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb36-5" data-line-number="5"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb36-6" data-line-number="6"><span class="kw">abline</span>(<span class="dt">h=</span><span class="dv">0</span>, <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb36-7" data-line-number="7">x =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>, <span class="dt">length.out=</span><span class="dv">20</span>)</a>
<a class="sourceLine" id="cb36-8" data-line-number="8"><span class="kw">curve</span>(<span class="kw">beta_cdf</span>(x, <span class="dt">alpha=</span><span class="dv">1</span>, <span class="dt">beta=</span><span class="dv">4</span>), <span class="dt">col=</span><span class="st">&quot;purple&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb36-9" data-line-number="9"><span class="kw">curve</span>(<span class="kw">beta_cdf</span>(x, <span class="dt">alpha=</span><span class="dv">2</span>, <span class="dt">beta=</span><span class="dv">2</span>), <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb36-10" data-line-number="10"><span class="kw">curve</span>(<span class="kw">beta_cdf</span>(x, <span class="dt">alpha=</span><span class="dv">2</span>, <span class="dt">beta=</span><span class="dv">4</span>), <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb36-11" data-line-number="11"><span class="kw">curve</span>(<span class="kw">beta_cdf</span>(x, <span class="dt">alpha=</span><span class="dv">5</span>, <span class="dt">beta=</span><span class="dv">1</span>), <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb36-12" data-line-number="12"><span class="kw">curve</span>(<span class="kw">beta_cdf</span>(x, <span class="dt">alpha=</span><span class="dv">5</span>, <span class="dt">beta=</span><span class="dv">3</span>), <span class="dt">col=</span><span class="st">&quot;brown&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:betadist2"></span>
<img src="DS_files/figure-html/betadist2-1.png" alt="Beta Distribution (Cumulative Density)" width="70%" />
<p class="caption">
Figure 5.14: Beta Distribution (Cumulative Density)
</p>
</div>

<p>Let us save further discussion of <strong>Beta distribution</strong> until we get to the <strong>Bayesian Computation</strong> to cover <strong>Conjugate and Joint distributions</strong> in which one distribution is chained to another.</p>
<p><span class="math display">\[\begin{align}
X_{Pr} \sim Beta(\alpha, \beta)\ \ \ \rightarrow \ \ \ \ \ X \sim Bin(n, X_{Pr})
\end{align}\]</span></p>
<p>Also, we leave readers to investigate on <strong>Pert</strong> distribution which requires a minimum and a maximum parameter for <strong>Beta distribution</strong>:</p>
<p><span class="math display">\[\begin{align}
X \sim Beta(min, max, \alpha, \beta) \equiv Pert(min, max, \alpha, \beta)
\end{align}\]</span></p>
</div>
<div id="dirichlet-distribution" class="section level3">
<h3><span class="header-section-number">5.9.6</span> Dirichlet distribution </h3>
<p><strong>Dirichlet distribution</strong> models a <strong>continuous distribution</strong> and is a special kind of <strong>Multinomial distribution</strong> written as:</p>
<p><span class="math display">\[\begin{align}
X_{Pr} \sim Dir(\alpha)
\end{align}\]</span></p>
<p>Just like dealing with <strong>Beta distribution</strong> which is related to <strong>Binomial distribution</strong>, the <strong>Dirichlet distribution</strong> is related to <strong>Multinomial distribution</strong>.</p>
<p>The <strong>PDF</strong> for <strong>Dirichlet distribution</strong> with <strong>support</strong> <span class="math inline">\(\{x_1,..., x_k\}\)</span> and <span class="math inline">\(0 \le x_i \le 1\)</span> and <span class="math inline">\(\sum(X) = 1\)</span> is expressed as:</p>
<p><span class="math display">\[\begin{align}
f(X_k;\alpha_k) = \mathcal{P}(x_1,...,x_k|\alpha_1, ... \alpha_k)  = \frac{1}{\mathcal{B}(\alpha)}
\prod_{i=1}^k {x_i}^{\alpha_i-1} 
\end{align}\]</span></p>
<p>where the <strong>Beta function</strong>, <span class="math inline">\(\mathbf{\mathcal{B}(\vec{\alpha})}\)</span>, is equivalent to that of <strong>Beta distribution</strong> :</p>
<p><span class="math display">\[\begin{align}
\mathcal{B}(\alpha) &amp;= \frac{\prod_{i=1}^k \Gamma(\alpha_i)} {\Gamma(\sum_{i=1}^k \alpha_i)}
\ \ \ \ \ \ \leftarrow\ \ \ \ \ \ \ \ 
\mathcal{B}(\alpha_1, \alpha_2) = \frac{\Gamma(\alpha_1)\Gamma(\alpha_2)}{\Gamma(\alpha_1 + \alpha_2)}
\ \ \ \ \text{if k=2}
\end{align}\]</span></p>
<p>and where the <strong>Gamma function</strong> is as follows:</p>
<p><span class="math display">\[\begin{align}
\Gamma(n) = (n-1)!\ \ \ \ \ \ \ \ \Gamma(n+1) = n\Gamma(n) = n(n-1)!
\end{align}\]</span></p>
<p>Note that <strong>Dirichlet distribution</strong> is a generalization of <strong>Beta distribution</strong>.</p>
<p>To illustrate, we can continue to use <strong>Dirichlet PDF</strong> against <strong>Binomial distribution</strong> where <span class="math inline">\(\{\alpha,\beta\} = \{ \alpha, \alpha \} = \{\vec{ \alpha} \}\)</span></p>
<p>Figure  illustrates graphs of the different shapes, <span class="math inline">\(\{\vec{ \alpha} \}\)</span>, of <strong>Dirichlet distribution</strong>.</p>

<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb37-1" data-line-number="1">Gamma &lt;-<span class="st"> </span><span class="cf">function</span>(n) { <span class="kw">factorial</span>(n<span class="dv">-1</span>)}</a>
<a class="sourceLine" id="cb37-2" data-line-number="2">dirichlet_B &lt;-<span class="st"> </span><span class="cf">function</span>(alpha) { </a>
<a class="sourceLine" id="cb37-3" data-line-number="3">    <span class="kw">prod</span>(<span class="kw">Gamma</span>(alpha)) <span class="op">/</span><span class="st"> </span><span class="kw">Gamma</span>( <span class="kw">sum</span> (alpha))  </a>
<a class="sourceLine" id="cb37-4" data-line-number="4">}</a>
<a class="sourceLine" id="cb37-5" data-line-number="5">dirichlet_pdf &lt;-<span class="st"> </span><span class="cf">function</span>(x, alpha) { <span class="co"># naive implementation</span></a>
<a class="sourceLine" id="cb37-6" data-line-number="6">  <span class="co"># using binomial distribution, e.g. x (%success), 1-x (%fail)</span></a>
<a class="sourceLine" id="cb37-7" data-line-number="7">   <span class="dv">1</span><span class="op">/</span><span class="kw">dirichlet_B</span>(alpha) <span class="op">*</span><span class="st"> </span>( x<span class="op">^</span>(alpha[<span class="dv">1</span>]<span class="op">-</span><span class="dv">1</span>) <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span><span class="op">-</span>x)<span class="op">^</span>(alpha[<span class="dv">2</span>]<span class="op">-</span><span class="dv">1</span>) )</a>
<a class="sourceLine" id="cb37-8" data-line-number="8">}</a>
<a class="sourceLine" id="cb37-9" data-line-number="9"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">1</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="dv">3</span>), </a>
<a class="sourceLine" id="cb37-10" data-line-number="10">     <span class="dt">xlab=</span><span class="st">&quot;support&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;probability density&quot;</span>,</a>
<a class="sourceLine" id="cb37-11" data-line-number="11">     <span class="dt">main=</span><span class="st">&quot;PDF (Dirichlet Distribution)&quot;</span>,  <span class="dt">frame=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb37-12" data-line-number="12"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb37-13" data-line-number="13"><span class="kw">abline</span>(<span class="dt">h=</span><span class="dv">0</span>, <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb37-14" data-line-number="14">x =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>, <span class="dt">length.out=</span><span class="dv">20</span>)</a>
<a class="sourceLine" id="cb37-15" data-line-number="15"><span class="kw">curve</span>(<span class="kw">dirichlet_pdf</span>(x, <span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">4</span>)), <span class="dt">col=</span><span class="st">&quot;purple&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb37-16" data-line-number="16"><span class="kw">curve</span>(<span class="kw">dirichlet_pdf</span>(x, <span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>)), <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb37-17" data-line-number="17"><span class="kw">curve</span>(<span class="kw">dirichlet_pdf</span>(x, <span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">4</span>)), <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb37-18" data-line-number="18"><span class="kw">curve</span>(<span class="kw">dirichlet_pdf</span>(x, <span class="kw">c</span>(<span class="dv">5</span>,<span class="dv">1</span>)), <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb37-19" data-line-number="19"><span class="kw">curve</span>(<span class="kw">dirichlet_pdf</span>(x, <span class="kw">c</span>(<span class="dv">5</span>,<span class="dv">3</span>)), <span class="dt">col=</span><span class="st">&quot;brown&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:dirichletdist"></span>
<img src="DS_files/figure-html/dirichletdist-1.png" alt="Dirichlet Distribution" width="70%" />
<p class="caption">
Figure 5.15: Dirichlet Distribution
</p>
</div>

<p>Similarly, we also further cover <strong>Dirichlet distribution</strong> in the <strong>Bayesian Computation</strong> chapter when we discuss <strong>Conjugate distribution</strong>. The idea is about one distribution in which the parameters are based on the outcome of another distribution.</p>
<p><span class="math display">\[\begin{align}
X \sim Mult(n, \rho)\ \ \ \leftarrow \ \ \ \  \  \rho \sim Dir(\alpha)
\end{align}\]</span></p>
</div>
<div id="exponential-distribution" class="section level3">
<h3><span class="header-section-number">5.9.7</span> Exponential distribution </h3>
<p><strong>Exponential distribution</strong> models a <strong>continuous distribution</strong> of a random variable <strong>X</strong> taking into account the <strong>waiting (or elapsed) time</strong> between events. It is written as:</p>
<p><span class="math display">\[\begin{align}
X \sim Expo(\lambda)
\end{align}\]</span></p>
<p>The <strong>PDF</strong> of an <strong>Exponential distribution</strong> has the <strong>support</strong> condition:</p>
<p><span class="math display">\[\begin{align}
f(x;\lambda) = \begin{cases} \lambda e^{-\lambda x} &amp; x \ge 0\\ 0 &amp; x &lt; 0 \end{cases}.
\end{align}\]</span></p>
<p>Therefore, with <strong>support</strong> <span class="math inline">\(0 \le x \le \infty\)</span>, we get:</p>
<p><span class="math display">\[\begin{align}
 \mathcal{P}(X = x|\lambda) =  \lambda e^{-\lambda x}
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(\lambda\)</span> is a shape parameter describing event rate, <span class="math inline">\(\lambda = 1/t\)</span>, e.g.Â 1 event per avg. time.</li>
<li>t is the average wait time (or average elapsed time prior to an event occurring)</li>
</ul>
<p>and the <strong>CDF</strong> of an <strong>Exponential distribution</strong> is expressed as:</p>
<p><span class="math display">\[\begin{align}
\mathcal{F}(x; \lambda) = \mathcal{P}(X \le x|\lambda) =  1 - e^{-\lambda x}
\end{align}\]</span></p>
<p>Exponential growth and decay are two common events in which we can use <strong>Exponential distribution</strong> to measure the expected time. To illustrate, here are three examples of events in which we can form an <strong>Exponential distribution</strong>:</p>
<ul>
<li>Suppose we plant a pumpkin seed about an inch into fertile soil. We compute for the time it takes for the seed to germinate. Hint: does a pumpkin seed germinate in a week?</li>
<li>Suppose we procure a piece of enterprise-grade computer equipment. We compute for the time it takes before the equipment starts to fail. Hint: does it take between three years to five years for equipment support to expire?</li>
<li>Suppose we arrive at a gas station but have to wait for our turn to fill gas. We compute for the time it takes to wait our turn.</li>
</ul>
<p>Here, <span class="math inline">\(\lambda\)</span> (lambda) is the expected time for events to occur. It answers the question, âHow long?â.</p>
<p>Below is a naive implementation of <strong>PDF</strong> and <strong>CDF</strong> of <strong>Exponential distribution</strong> in R code. Here we use <span class="math inline">\(\lambda = 0.5\)</span> and <span class="math inline">\(x = 4\)</span> to show a larger area. See Figure .</p>

<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb38-1" data-line-number="1">exp_pdf &lt;-<span class="st"> </span><span class="cf">function</span>(x, lambda ) {</a>
<a class="sourceLine" id="cb38-2" data-line-number="2">    lambda <span class="op">*</span><span class="st"> </span><span class="kw">exp</span>(<span class="op">-</span>lambda <span class="op">*</span><span class="st"> </span>x)</a>
<a class="sourceLine" id="cb38-3" data-line-number="3">}</a>
<a class="sourceLine" id="cb38-4" data-line-number="4">exp_cdf &lt;-<span class="st"> </span><span class="cf">function</span>(x, lambda) {</a>
<a class="sourceLine" id="cb38-5" data-line-number="5">    <span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">exp</span>(<span class="op">-</span>lambda <span class="op">*</span><span class="st"> </span>x)</a>
<a class="sourceLine" id="cb38-6" data-line-number="6">}</a>
<a class="sourceLine" id="cb38-7" data-line-number="7">exp_area &lt;-<span class="st"> </span><span class="cf">function</span>(x, lambda) {</a>
<a class="sourceLine" id="cb38-8" data-line-number="8">    a =<span class="st"> </span><span class="dv">0</span>; b =<span class="st"> </span>x  <span class="co"># boundaries</span></a>
<a class="sourceLine" id="cb38-9" data-line-number="9">    area =<span class="st"> </span><span class="kw">seq</span>(a, b, <span class="dt">length.out=</span><span class="dv">50</span>) <span class="co"># area</span></a>
<a class="sourceLine" id="cb38-10" data-line-number="10">    x =<span class="st"> </span><span class="kw">c</span>(a, area , b)</a>
<a class="sourceLine" id="cb38-11" data-line-number="11">    y =<span class="st"> </span><span class="kw">c</span>(<span class="dv">0</span>, <span class="kw">exp_pdf</span>(area, lambda), <span class="dv">0</span>)</a>
<a class="sourceLine" id="cb38-12" data-line-number="12">    <span class="kw">polygon</span>(x, y, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>)    </a>
<a class="sourceLine" id="cb38-13" data-line-number="13">}</a>
<a class="sourceLine" id="cb38-14" data-line-number="14"><span class="co">#Plotting PDF and CDF (Area for lambda=0.5)</span></a>
<a class="sourceLine" id="cb38-15" data-line-number="15"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">5</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="fl">2.0</span>), </a>
<a class="sourceLine" id="cb38-16" data-line-number="16">     <span class="dt">xlab=</span><span class="st">&quot;support&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;probability density&quot;</span>,</a>
<a class="sourceLine" id="cb38-17" data-line-number="17">     <span class="dt">main=</span><span class="st">&quot;PDF (Exponential Distribution)&quot;</span>,  <span class="dt">frame=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb38-18" data-line-number="18"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb38-19" data-line-number="19"><span class="kw">abline</span>(<span class="dt">h=</span><span class="dv">0</span>, <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb38-20" data-line-number="20">p =<span class="st"> </span><span class="kw">exp_cdf</span>(<span class="dt">x=</span><span class="dv">4</span>, <span class="dt">lambda=</span><span class="fl">0.5</span>)</a>
<a class="sourceLine" id="cb38-21" data-line-number="21"><span class="kw">exp_area</span>(<span class="dt">x=</span><span class="dv">4</span>, <span class="dt">lambda=</span><span class="fl">0.5</span>)</a>
<a class="sourceLine" id="cb38-22" data-line-number="22"><span class="kw">curve</span>(<span class="kw">exp_pdf</span>(x, <span class="dt">lambda=</span><span class="fl">0.5</span>), <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb38-23" data-line-number="23"><span class="kw">curve</span>(<span class="kw">exp_pdf</span>(x, <span class="dt">lambda=</span><span class="fl">1.0</span>), <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb38-24" data-line-number="24"><span class="kw">curve</span>(<span class="kw">exp_pdf</span>(x, <span class="dt">lambda=</span><span class="fl">1.5</span>), <span class="dt">col=</span><span class="st">&quot;brown&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb38-25" data-line-number="25"><span class="kw">curve</span>(<span class="kw">exp_pdf</span>(x, <span class="dt">lambda=</span><span class="fl">2.0</span>), <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb38-26" data-line-number="26"><span class="kw">text</span>(<span class="dv">3</span>,<span class="fl">0.3</span>, <span class="dt">label=</span><span class="kw">expression</span>(<span class="kw">paste</span>(<span class="st">&quot;pdf=&quot;</span>, lambda <span class="op">*</span><span class="st"> </span>e<span class="op">^</span>(<span class="op">-</span>lambda <span class="op">*</span><span class="st"> </span>x))))</a>
<a class="sourceLine" id="cb38-27" data-line-number="27"><span class="kw">text</span>(<span class="fl">0.6</span>, <span class="fl">0.2</span>, <span class="dt">label=</span><span class="st">&quot;(cdf)&quot;</span>, <span class="dt">col=</span><span class="st">&quot;black&quot;</span>)</a>
<a class="sourceLine" id="cb38-28" data-line-number="28"><span class="kw">text</span>(<span class="fl">0.7</span>, <span class="fl">0.1</span>, <span class="dt">label=</span><span class="kw">paste</span>(<span class="st">&quot;Area = &quot;</span>, <span class="kw">round</span>(p,<span class="dv">5</span>), <span class="dt">sep=</span><span class="st">&quot;&quot;</span>), </a>
<a class="sourceLine" id="cb38-29" data-line-number="29">     <span class="dt">ce=</span><span class="dv">1</span>, <span class="dt">col=</span><span class="st">&quot;black&quot;</span>)</a>
<a class="sourceLine" id="cb38-30" data-line-number="30"><span class="kw">text</span>(<span class="fl">4.2</span>, <span class="fl">0.12</span>, <span class="dt">label=</span><span class="st">&quot;x=4&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:expdist1"></span>
<img src="DS_files/figure-html/expdist1-1.png" alt="Exponential Distribution (PDF)" width="70%" />
<p class="caption">
Figure 5.16: Exponential Distribution (PDF)
</p>
</div>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb39-1" data-line-number="1"><span class="co">#Plotting CDF </span></a>
<a class="sourceLine" id="cb39-2" data-line-number="2"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">5</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="fl">1.0</span>), </a>
<a class="sourceLine" id="cb39-3" data-line-number="3">     <span class="dt">xlab=</span><span class="st">&quot;support&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;cumulative density&quot;</span>,</a>
<a class="sourceLine" id="cb39-4" data-line-number="4">     <span class="dt">main=</span><span class="st">&quot;CDF (Exponential Distribution)&quot;</span>,  <span class="dt">frame=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb39-5" data-line-number="5"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb39-6" data-line-number="6"><span class="kw">abline</span>(<span class="dt">h=</span><span class="dv">0</span>, <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb39-7" data-line-number="7">x =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">5</span>, <span class="dt">length.out=</span><span class="dv">500</span>)</a>
<a class="sourceLine" id="cb39-8" data-line-number="8"><span class="kw">curve</span>(<span class="kw">exp_cdf</span>(x, <span class="dt">lambda=</span><span class="fl">0.5</span>), <span class="dt">col=</span><span class="st">&quot;brown&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb39-9" data-line-number="9"><span class="kw">curve</span>(<span class="kw">exp_cdf</span>(x, <span class="dt">lambda=</span><span class="fl">1.0</span>), <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb39-10" data-line-number="10"><span class="kw">curve</span>(<span class="kw">exp_cdf</span>(x, <span class="dt">lambda=</span><span class="fl">1.5</span>), <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb39-11" data-line-number="11"><span class="kw">curve</span>(<span class="kw">exp_cdf</span>(x, <span class="dt">lambda=</span><span class="fl">2.0</span>), <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:expdist2"></span>
<img src="DS_files/figure-html/expdist2-1.png" alt="Exponential Distribution (CDF)" width="70%" />
<p class="caption">
Figure 5.17: Exponential Distribution (CDF)
</p>
</div>

<p>To illustrate further, let us use one of the examples given. Suppose we wait to fill up gas at a gas station. Let us compute the probability that we wait for less than 5 minutes given that <span class="math inline">\(\lambda = 1/2\)</span>. This gives us the following problem statement:</p>
<p><span class="math display">\[\begin{align}
\mathcal{P}(X \le x) = \mathcal{P}(X \le 5) = 1 - e^{-\lambda x}
\end{align}\]</span></p>
<p>were average time to wait = 2 minutes.</p>
<p>Here is the implementation of <strong>CDF</strong> in R code:</p>

<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb40-1" data-line-number="1"><span class="kw">sum</span> ( <span class="kw">exp_cdf</span>(<span class="dt">x=</span><span class="kw">c</span>(<span class="dv">4</span>),<span class="dt">lambda=</span><span class="fl">0.5</span>) )  <span class="co"># our code</span></a></code></pre></div>
<pre><code>## [1] 0.8646647</code></pre>
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb42-1" data-line-number="1">(<span class="dt">p =</span> <span class="kw">sum</span>(<span class="kw">pexp</span>(<span class="dt">q=</span><span class="kw">c</span>(<span class="dv">4</span>), <span class="dt">rate=</span><span class="fl">0.5</span>))) <span class="co"># R&#39;s built-in package</span></a></code></pre></div>
<pre><code>## [1] 0.8646647</code></pre>

<p>Both outcomes give a 86.47% probability for us to wait for 4 minutes only.</p>
<p>On the other hand, if the average wait time is 10 minutes instead. Then we get:</p>

<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb44-1" data-line-number="1"><span class="kw">sum</span> ( <span class="kw">exp_cdf</span>(<span class="dt">x=</span><span class="kw">c</span>(<span class="dv">4</span>),<span class="dt">lambda=</span><span class="fl">0.2</span>) )  <span class="co"># our code</span></a></code></pre></div>
<pre><code>## [1] 0.550671</code></pre>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb46-1" data-line-number="1">(<span class="dt">p =</span> <span class="kw">sum</span>(<span class="kw">pexp</span>(<span class="dt">q=</span><span class="kw">c</span>(<span class="dv">4</span>), <span class="dt">rate=</span><span class="fl">0.2</span>))) <span class="co"># R&#39;s built-in package</span></a></code></pre></div>
<pre><code>## [1] 0.550671</code></pre>

<p>Both outcomes give a 55.07% probability for us to wait for 4 minutes only.</p>
<p>In terms of expected value and variance, we have the following expression:</p>
<p><strong>Expected value</strong>:</p>
<p><span class="math display">\[\begin{align}
\mathbb{E}(X) = \int_0^\infty x\lambda e^{-\lambda x} dx = 
\left[\frac{e^{-\lambda x}}{\lambda}\right]_0^\infty =
\frac{1}{\lambda}
\end{align}\]</span></p>
<p><strong>Variance:</strong></p>
<p><span class="math display">\[\begin{align}
Var(X) = \mathbb{E}({X}^2) - \mathbb{E}(X)^2 
= \frac{2}{\lambda^2} - \frac{1}{\lambda^2} = \frac{1}{\lambda^2}
\end{align}\]</span></p>
<p>We now discuss the next type of distribution - the <strong>Gamma distribution</strong>. It is notable to mention that <strong>Exponential distribution</strong> and <strong>Gamma distribution</strong> are somewhat related. While <strong>Exponential distribution</strong> is about <strong>waiting time</strong> between events of interest, <strong>Gamma distribution</strong> is <strong>waiting time</strong> taken for <strong>number of events</strong>.</p>
</div>
<div id="gamma-distribution" class="section level3">
<h3><span class="header-section-number">5.9.8</span> Gamma distribution </h3>
<p><strong>Gamma distribution</strong> models a <strong>continuous distribution</strong> of a random variable <strong>X</strong> taking into account the number of events that occurred after <strong>wait (or elapse) time</strong> and is written as:</p>
<p><span class="math display">\[\begin{align}
X \sim Gamma(\alpha, \beta)\ \ \ \ or\ \ \ \ \ X \sim \Gamma(\alpha, \beta) 
\end{align}\]</span></p>
<p>Any queueing system involving wait times or any events that can be measured in terms of elapsed time are two common examples in which the use of <strong>Gamma distribution</strong> is helpful.</p>
<p>The <strong>PDF</strong> of a <strong>Gamma distribution</strong> with <strong>support</strong> <span class="math inline">\(x \ge 0\)</span> is expressed as:</p>
<p><span class="math display">\[\begin{align}
f(x; \alpha,\beta) = \mathcal{P}(X = x|\alpha, \beta) =  \frac{1}{\beta^{\alpha}\Gamma(\alpha)}x^{\alpha-1}e^{-\frac{x}{\beta}} =
\frac{\beta^{\alpha}}{\Gamma(\alpha)}x^{\alpha-1}e^{-\beta x}
\end{align}\]</span></p>
<p>where the <strong>Gamma function</strong> is expressed as:</p>
<p><span class="math display">\[\begin{align}
\Gamma(\alpha) {}&amp;= \int_0^\infty x^{\alpha-1} e^{-x} dx \\
\Gamma(n) &amp;= (n-1)! \\
\Gamma(n+1) &amp;= n\Gamma(n) = n(n-1)!
\end{align}\]</span></p>
<p>also where:</p>
<ul>
<li><span class="math inline">\(\alpha\)</span> is the number of events that occurred</li>
<li><span class="math inline">\(\beta\)</span> is the average number of events per time. It is equivalent to <span class="math inline">\(1/\lambda\)</span> in which <span class="math inline">\(\lambda\)</span> denotes the average time between events.</li>
</ul>
<p>The inverse of <strong>Gamma distribution</strong> is expressed as:</p>
<p><span class="math display">\[\begin{align}
g(x; \alpha,\beta) = \mathcal{P}(X = x|\alpha, \beta) = 
\frac{\beta^{\alpha}}{\Gamma(\alpha)}x^{-(\alpha+1)}e^{-\frac{\beta}{ x}}\ \ \text{(inverse)}
\end{align}\]</span></p>
<p>Note that if the average time between events (e.g.Â bathroom breaks) is two hours <span class="math inline">\(\rightarrow \lambda = 2\ hrs\)</span>, then <span class="math inline">\(\beta = 1/2 = 0.5\)</span>.</p>
<p>The <strong>CDF</strong> of a <strong>Gamma distribution</strong> where <span class="math inline">\(x \ge 0\)</span> is expressed as:</p>
<p><span class="math display">\[\begin{align}
\mathcal{F}(x; \alpha, \beta) = \mathcal{P}(X \le x|\alpha, \beta) = 1 - \sum_{i=0}^{\alpha-1} \frac{(\lambda x)^i}{i!}e^{-\lambda x} 
\end{align}\]</span></p>
<p>Below is a naive implementation of <strong>Gamma Distribution</strong> in R code:</p>

<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb48-1" data-line-number="1">Gamma &lt;-<span class="st"> </span><span class="cf">function</span>(n) { <span class="kw">factorial</span>(n<span class="dv">-1</span>)}</a>
<a class="sourceLine" id="cb48-2" data-line-number="2">gamma_pdf &lt;-<span class="st"> </span><span class="cf">function</span>(x, alpha, beta ) {</a>
<a class="sourceLine" id="cb48-3" data-line-number="3">    <span class="dv">1</span> <span class="op">/</span><span class="st"> </span>(beta <span class="op">^</span>alpha <span class="op">*</span><span class="st"> </span><span class="kw">Gamma</span>(alpha)) <span class="op">*</span><span class="st"> </span>x<span class="op">^</span>(alpha <span class="op">-</span><span class="st"> </span><span class="dv">1</span>) <span class="op">*</span><span class="st"> </span><span class="kw">exp</span>(<span class="op">-</span>x<span class="op">/</span>beta)</a>
<a class="sourceLine" id="cb48-4" data-line-number="4">}</a>
<a class="sourceLine" id="cb48-5" data-line-number="5">gamma_cdf &lt;-<span class="st"> </span><span class="cf">function</span>(x, alpha, beta) {</a>
<a class="sourceLine" id="cb48-6" data-line-number="6">    constant =<span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb48-7" data-line-number="7">    lambda =<span class="st"> </span><span class="dv">1</span><span class="op">/</span>beta</a>
<a class="sourceLine" id="cb48-8" data-line-number="8">    <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">0</span><span class="op">:</span>(alpha<span class="dv">-1</span>)) { </a>
<a class="sourceLine" id="cb48-9" data-line-number="9">      constant =<span class="st"> </span>constant <span class="op">+</span><span class="st"> </span>((lambda<span class="op">*</span>x)<span class="op">^</span>i)<span class="op">/</span><span class="kw">factorial</span>(i)<span class="op">*</span><span class="kw">exp</span>(<span class="op">-</span>lambda<span class="op">*</span>x)</a>
<a class="sourceLine" id="cb48-10" data-line-number="10">    }</a>
<a class="sourceLine" id="cb48-11" data-line-number="11">    <span class="dv">1</span> <span class="op">-</span><span class="st"> </span>constant</a>
<a class="sourceLine" id="cb48-12" data-line-number="12">}</a>
<a class="sourceLine" id="cb48-13" data-line-number="13">gamma_area &lt;-<span class="st"> </span><span class="cf">function</span>(x, alpha, beta) {</a>
<a class="sourceLine" id="cb48-14" data-line-number="14">    a =<span class="st"> </span><span class="dv">0</span>; b =<span class="st"> </span>x     <span class="co"># boundaries</span></a>
<a class="sourceLine" id="cb48-15" data-line-number="15">    area =<span class="st"> </span><span class="kw">seq</span>(a, b, <span class="dt">length.out=</span><span class="dv">50</span>)     <span class="co"># area</span></a>
<a class="sourceLine" id="cb48-16" data-line-number="16">    x =<span class="st"> </span><span class="kw">c</span>(a, area , b)</a>
<a class="sourceLine" id="cb48-17" data-line-number="17">    y =<span class="st"> </span><span class="kw">c</span>(<span class="dv">0</span>, <span class="kw">gamma_pdf</span>(area, alpha, beta), <span class="dv">0</span>)</a>
<a class="sourceLine" id="cb48-18" data-line-number="18">    <span class="kw">polygon</span>(x, y, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>)    </a>
<a class="sourceLine" id="cb48-19" data-line-number="19">}</a>
<a class="sourceLine" id="cb48-20" data-line-number="20"></a>
<a class="sourceLine" id="cb48-21" data-line-number="21"><span class="co">#Plotting PDF and CDF(Area for alpha=5, beta=1)</span></a>
<a class="sourceLine" id="cb48-22" data-line-number="22"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">15</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="fl">0.5</span>), </a>
<a class="sourceLine" id="cb48-23" data-line-number="23">     <span class="dt">xlab=</span><span class="st">&quot;support&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;probability density&quot;</span>,</a>
<a class="sourceLine" id="cb48-24" data-line-number="24">     <span class="dt">main=</span><span class="st">&quot;PDF and CDF (Gamma Distribution)&quot;</span>,  <span class="dt">frame=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb48-25" data-line-number="25"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb48-26" data-line-number="26"><span class="kw">abline</span>(<span class="dt">h=</span><span class="dv">0</span>, <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb48-27" data-line-number="27">p =<span class="st"> </span><span class="kw">gamma_cdf</span>(<span class="dt">x=</span><span class="dv">6</span>, <span class="dt">alpha=</span><span class="dv">5</span>, <span class="dt">beta=</span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb48-28" data-line-number="28"><span class="kw">gamma_area</span>(<span class="dt">x=</span><span class="dv">6</span>, <span class="dt">alpha=</span><span class="dv">5</span>, <span class="dt">beta=</span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb48-29" data-line-number="29"><span class="kw">curve</span>(<span class="kw">gamma_pdf</span>(x, <span class="dt">alpha=</span><span class="dv">1</span>, <span class="dt">beta=</span><span class="dv">2</span>), <span class="dt">col=</span><span class="st">&quot;brown&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb48-30" data-line-number="30"><span class="kw">curve</span>(<span class="kw">gamma_pdf</span>(x, <span class="dt">alpha=</span><span class="dv">2</span>, <span class="dt">beta=</span><span class="dv">2</span>), <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb48-31" data-line-number="31"><span class="kw">curve</span>(<span class="kw">gamma_pdf</span>(x, <span class="dt">alpha=</span><span class="dv">5</span>, <span class="dt">beta=</span><span class="dv">1</span>), <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb48-32" data-line-number="32"><span class="kw">curve</span>(<span class="kw">gamma_pdf</span>(x, <span class="dt">alpha=</span><span class="dv">10</span>, <span class="dt">beta=</span><span class="fl">0.5</span>), <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb48-33" data-line-number="33"><span class="kw">text</span>(<span class="dv">4</span>,<span class="fl">0.06</span>, <span class="dt">label=</span><span class="st">&quot;(cdf)&quot;</span>, <span class="dt">col=</span><span class="st">&quot;black&quot;</span>)</a>
<a class="sourceLine" id="cb48-34" data-line-number="34"><span class="kw">text</span>(<span class="dv">4</span>, <span class="fl">0.02</span>, <span class="dt">label=</span><span class="kw">paste</span>(<span class="st">&quot;Area = &quot;</span>, <span class="kw">round</span>(p,<span class="dv">5</span>), <span class="dt">sep=</span><span class="st">&quot;&quot;</span>), </a>
<a class="sourceLine" id="cb48-35" data-line-number="35">     <span class="dt">ce=</span><span class="fl">0.80</span>, <span class="dt">col=</span><span class="st">&quot;black&quot;</span>)</a>
<a class="sourceLine" id="cb48-36" data-line-number="36"><span class="kw">text</span>(<span class="fl">6.5</span>, <span class="fl">0.04</span>, <span class="dt">label=</span><span class="st">&quot;x=6&quot;</span>)</a>
<a class="sourceLine" id="cb48-37" data-line-number="37"></a>
<a class="sourceLine" id="cb48-38" data-line-number="38"><span class="co">#Plotting CDF</span></a>
<a class="sourceLine" id="cb48-39" data-line-number="39"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">15</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="dv">1</span>), </a>
<a class="sourceLine" id="cb48-40" data-line-number="40">     <span class="dt">xlab=</span><span class="st">&quot;support&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;cumulative density&quot;</span>,</a>
<a class="sourceLine" id="cb48-41" data-line-number="41">     <span class="dt">main=</span><span class="st">&quot;CDF (Gamma Distribution)&quot;</span>,  <span class="dt">frame=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb48-42" data-line-number="42"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb48-43" data-line-number="43"><span class="kw">abline</span>(<span class="dt">h=</span><span class="dv">0</span>, <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb48-44" data-line-number="44">x =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">15</span>, <span class="dt">length.out=</span><span class="dv">500</span>)</a>
<a class="sourceLine" id="cb48-45" data-line-number="45"><span class="kw">curve</span>(<span class="kw">gamma_cdf</span>(x, <span class="dt">alpha=</span><span class="dv">1</span>, <span class="dt">beta=</span><span class="dv">2</span>), <span class="dt">col=</span><span class="st">&quot;brown&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb48-46" data-line-number="46"><span class="kw">curve</span>(<span class="kw">gamma_cdf</span>(x, <span class="dt">alpha=</span><span class="dv">2</span>, <span class="dt">beta=</span><span class="dv">2</span>), <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb48-47" data-line-number="47"><span class="kw">curve</span>(<span class="kw">gamma_cdf</span>(x, <span class="dt">alpha=</span><span class="dv">5</span>, <span class="dt">beta=</span><span class="dv">1</span>), <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb48-48" data-line-number="48"><span class="kw">curve</span>(<span class="kw">gamma_cdf</span>(x, <span class="dt">alpha=</span><span class="dv">10</span>, <span class="dt">beta=</span><span class="fl">0.5</span>), <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:gammapdf1"></span>
<img src="DS_files/figure-html/gammapdf-1.png" alt="Gamma Distribution" width="70%" />
<p class="caption">
Figure 5.18: Gamma Distribution
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:gammapdf2"></span>
<img src="DS_files/figure-html/gammapdf-2.png" alt="Gamma Distribution" width="70%" />
<p class="caption">
Figure 5.19: Gamma Distribution
</p>
</div>

<p>Note that if <span class="math inline">\(\alpha = 1\)</span>, the inverse of <span class="math inline">\(\beta\)</span> makes the <strong>Gamma distribution</strong> equivalent to <strong>Exponential distribution</strong>. Meaning, use <span class="math inline">\(\alpha=1, \beta=1/\lambda\)</span> to mimic <strong>Exponential distribution</strong> using <strong>Gamma PDF</strong>.</p>
<p>One way to illustrate the relation between <strong>Gamma and Exponential distribution</strong> is shown in figure .</p>
<div class="figure" style="text-align: center"><span id="fig:gammadist"></span>
<img src="gamma.png" alt="Gamma and Exponential Distribution" width="80%" />
<p class="caption">
Figure 5.20: Gamma and Exponential Distribution
</p>
</div>
<p>In figure , there are four events, <span class="math inline">\(\{ e1, e2, e3, e4\}\)</span>. Event <strong>e1</strong> happens between times 0 and 1. The time taken is one second, <strong>x1</strong>. Event <strong>e2</strong> happens between times 1 and 2. The time taken is also one second, <strong>x2</strong>. Event <strong>e3</strong> happens between times 2 and 4. The time taken is two seconds, <strong>x3</strong>. And event <strong>e4</strong> happens between times 4 and 7. The time taken is three seconds, <strong>x4</strong>. Here, <strong>Exponential distribution</strong> focuses on the time taken between events.</p>
<p>On the other hand, at time 1, event <strong>e1</strong> happens after waiting for one second, <strong>G1</strong>. There is only one event that happens after one second. At time 2, events <strong>e1, e2</strong> happen after two seconds elapsed, <strong>G2</strong>. There are two events that happen after two seconds. At time 4, after four seconds ,<strong>G3</strong>, events <strong>e1, e2, e3</strong> happen. There are three events that happen after four seconds. Finally, at time 7, seven seconds, <strong>G4</strong>, events <strong>e1, e2, e3, e4</strong> happen. There are four events that happen after seven seconds. Here, <strong>Gamma distribution</strong> focuses on the number of events that happen after some <strong>elapsed time</strong>.</p>
<p>To illustrate in a practical manner, suppose a shuttle bus in an airport long-term parking lot arrives every 30 minutes at the airport to pick up travelers. Let us compute the probability of expecting three buses to arrive after waiting between 1 hour and 2 hours.</p>
<p>A shuttle bus arriving every 30 minutes means we expect to see <span class="math inline">\(\beta = 1/0.5= 2\)</span> buses arriving every hour on average.</p>
<p>Using <span class="math inline">\(\alpha = 3\)</span> and <span class="math inline">\(\beta = 2\)</span>, we can compute this as follows:</p>
<p><span class="math display">\[\begin{align}
\mathcal{P}(1 \le X \le 2) = \sum_{x=1}^{\alpha-1} \frac {1}{\beta^\alpha\Gamma(\alpha)}x^{(\alpha-1)}e^{-\frac{x}{\beta}}
= \sum_{x=1}^{3-1} \frac {1}{\Gamma(3)2^3}x^{(3-1)}e^{-\frac{x}{2}}
= 0.129878
\end{align}\]</span></p>
<p>Here is the implementation of <strong>PDF</strong> in R code:</p>

<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb49-1" data-line-number="1">gamma_pdf &lt;-<span class="st"> </span><span class="cf">function</span>(x, alpha, beta) { </a>
<a class="sourceLine" id="cb49-2" data-line-number="2">  <span class="dv">1</span><span class="op">/</span>( <span class="kw">factorial</span>(alpha<span class="dv">-1</span>)<span class="op">*</span><span class="st"> </span>beta<span class="op">^</span>alpha ) <span class="op">*</span><span class="st"> </span>x<span class="op">^</span>(alpha<span class="dv">-1</span>) <span class="op">*</span><span class="st"> </span><span class="kw">exp</span>(<span class="op">-</span>x<span class="op">/</span>beta)</a>
<a class="sourceLine" id="cb49-3" data-line-number="3">}</a>
<a class="sourceLine" id="cb49-4" data-line-number="4"><span class="kw">sum</span> ( <span class="kw">gamma_pdf</span>(<span class="dt">x=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>), <span class="dt">alpha=</span><span class="dv">3</span>, <span class="dt">beta=</span><span class="dv">2</span>) )  <span class="co"># our code</span></a></code></pre></div>
<pre><code>## [1] 0.129878</code></pre>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb51-1" data-line-number="1"><span class="kw">sum</span>(<span class="kw">dgamma</span>(<span class="dt">x=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>), <span class="dt">shape=</span><span class="dv">3</span>, <span class="dt">rate=</span><span class="fl">0.5</span>)) <span class="co"># R&#39;s built-in package</span></a></code></pre></div>
<pre><code>## [1] 0.129878</code></pre>

<p>Note that <span class="math inline">\(\alpha = shape\)</span> and <span class="math inline">\(\beta = 1 / rate\)</span>.</p>
<p>In terms of expected value and variance, we have the following formulas:</p>
<p><strong>Expected value</strong>:</p>
<p><span class="math display">\[\begin{align}
\mathbb{E}(X) = \alpha \beta
\end{align}\]</span></p>
<p><strong>Variance:</strong></p>
<p><span class="math display">\[\begin{align}
Var(X) = \mathbb{E}({X}^2) - \mathbb{E}(X)^2   =  \alpha \beta^2
\end{align}\]</span></p>
</div>
<div id="inverse-gamma-distribution" class="section level3">
<h3><span class="header-section-number">5.9.9</span> Inverse Gamma distribution </h3>
<p><strong>Inverse Gamma distribution</strong> models a <strong>continuous distribution</strong> whose <strong>PDF</strong> is inverse of <strong>Gamma distribution</strong> where <strong>support</strong> <span class="math inline">\(x \ge 0\)</span> and is written as:</p>
<p><span class="math display">\[\begin{align}
f(x; \alpha,\beta) = P(X = x|\alpha, \beta) = \frac{1}{\beta^{\alpha}\Gamma(\alpha)}x^{-(\alpha+1)}e^{-\frac{1}{x\beta}}
\end{align}\]</span></p>
<p>and its <strong>CDF</strong> is:</p>
<p><span class="math display">\[\begin{align}
\mathcal{F}(x; \alpha,\beta) = \mathcal{P}(X &lt;= x|\alpha, \beta) = \frac{\Gamma(\alpha, \frac{\beta}{x})}{\Gamma(\alpha)} 
\end{align}\]</span></p>
<p>where the upper <strong>incomplete Gamma function</strong> is written as:</p>
<p><span class="math display">\[\begin{align}
\Gamma(\alpha, \frac{\beta}{x}) = \int_0^x t^{\alpha - 1}e^{-t}dt
\end{align}\]</span></p>
<p><strong>Expected value</strong>:</p>
<p><span class="math display">\[\begin{align}
\mathbb{E}(X) = \frac{\beta}{(\alpha - 1 )}
\end{align}\]</span></p>
<p><strong>Variance:</strong></p>
<p><span class="math display">\[\begin{align}
Var(X) = \mathbb{E}({X}^2) - \mathbb{E}(X)^2   =  \frac{\beta^2}{(\alpha-1)^2(\alpha - 2)}
\end{align}\]</span></p>
</div>
<div id="weibull-distribution" class="section level3">
<h3><span class="header-section-number">5.9.10</span> Weibull distribution </h3>
<p>For an alternative to <strong>Gamma distribution</strong>, we leave readers to investigate <strong>Weibull distribution</strong> which offers simplicity and reliability and is written as:</p>
<p><span class="math display">\[\begin{align}
X \sim Weib(\alpha, \beta)
\end{align}\]</span></p>
<p>with the following 2-parameter <strong>PDF</strong> for <strong>Weibull distribution</strong>, where <strong>support</strong> <span class="math inline">\(x \ge 0\)</span> :</p>
<p><span class="math display">\[\begin{align}
f(x; \tau, \lambda) = \mathcal{P}(X = x|\tau, \lambda) =  \frac{\tau}{\lambda}\left(\frac{x}{\lambda}\right)^{\tau - 1} e^{ -\left(\frac{x}{\lambda}\right)^{\tau}}
\end{align}\]</span></p>
<p>and with the 2-parameter <strong>CDF</strong> for <strong>Weibull distribution</strong>:</p>
<p><span class="math display">\[\begin{align}
\mathcal{F}(x; \tau, \lambda) = \mathcal{P}(X \le x| \tau, \lambda) = 1 - e^{ -\left(\frac{x}{\lambda}\right)^{\tau}}
\end{align}\]</span></p>
<p>We note also to investigate the 3-parameter <strong>Weibull PDF</strong> and the 1-parameter <strong>Weibull PDF</strong>.</p>
<p>We now discuss the next type of distribution - the <strong>Poisson distribution</strong>. It is notable to mention that <strong>Gamma distribution</strong> and <strong>Poisson distribution</strong> are also somewhat interrelated. While <strong>Gamma distribution</strong> is about the number of events <strong>after wait time</strong>, <strong>Poisson distribution</strong> is about the number of events <strong>between fixed times</strong>.</p>
</div>
<div id="poisson-distribution" class="section level3">
<h3><span class="header-section-number">5.9.11</span> Poisson distribution </h3>
<p><strong>Poisson distribution</strong> describes a <strong>discrete distribution</strong> of data based on multiple events occurring in some given fixed time-intervals and is expressed as:</p>
<p><span class="math display">\[\begin{align}
X \sim Pois(\lambda )\ \ \ \ \ or \ \ \ \ \  \ X \sim Po(\lambda )
\end{align}\]</span></p>
<p>As examples:</p>
<ul>
<li>How many words are typed every minute?</li>
<li>How many drops of rainfall on a basin every second?</li>
<li>How many cars pass by the highway every minute?</li>
</ul>
<p>Here, <span class="math inline">\(\lambda\)</span> (lambda) is the expected number of occurrences. It answers the question, <strong>How many?</strong>.</p>
<p>The <strong>PMF</strong> of a <strong>discrete Poisson distribution</strong> is expressed as:</p>
<p><span class="math display">\[\begin{align}
f(x; \lambda) = \mathcal{P}(X = x|\lambda) = \frac{\lambda^xe^{-\lambda}}{x!}
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li>k is the number of events occurring successfully</li>
<li><span class="math inline">\(\lambda\)</span> is a shape parameter describing event rate, <span class="math inline">\(\lambda = rt\)</span>, e.g.Â no of events per fix interval of time.</li>
<li>r is the number of occurrences.</li>
<li>t is the fixed interval time.</li>
</ul>
<p>The <strong>CMF</strong> of a <strong>discrete Poisson distribution</strong> is expressed as:</p>
<p><span class="math display">\[\begin{align}
\mathcal{F}(x; \lambda) = \mathcal{P}(X \le x|\lambda) = \sum_{k=0}^{x} \frac{\lambda^k}{k!}e^{-\lambda}
\end{align}\]</span></p>
<p>Below is a naive implementation of <strong>Poisson Distribution</strong> in R code:</p>

<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb53-1" data-line-number="1">poisson_pmf &lt;-<span class="st"> </span><span class="cf">function</span>(x, lambda ) {</a>
<a class="sourceLine" id="cb53-2" data-line-number="2">    lambda<span class="op">^</span>x <span class="op">*</span><span class="st"> </span><span class="kw">exp</span>(<span class="op">-</span>lambda) <span class="op">/</span><span class="st"> </span><span class="kw">factorial</span>(x)</a>
<a class="sourceLine" id="cb53-3" data-line-number="3">}</a>
<a class="sourceLine" id="cb53-4" data-line-number="4">poisson_cmf &lt;-<span class="st"> </span><span class="cf">function</span>(x, lambda) {</a>
<a class="sourceLine" id="cb53-5" data-line-number="5">    poisson =<span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb53-6" data-line-number="6">    <span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">0</span><span class="op">:</span>x) { </a>
<a class="sourceLine" id="cb53-7" data-line-number="7">      poisson =<span class="st"> </span>poisson <span class="op">+</span><span class="st"> </span>(lambda<span class="op">^</span>k)<span class="op">/</span><span class="kw">factorial</span>(k) <span class="op">*</span><span class="st"> </span><span class="kw">exp</span>(<span class="op">-</span>lambda)</a>
<a class="sourceLine" id="cb53-8" data-line-number="8">    }</a>
<a class="sourceLine" id="cb53-9" data-line-number="9">    poisson</a>
<a class="sourceLine" id="cb53-10" data-line-number="10">}</a>
<a class="sourceLine" id="cb53-11" data-line-number="11">poisson_area &lt;-<span class="st"> </span><span class="cf">function</span>(x, lambda) {</a>
<a class="sourceLine" id="cb53-12" data-line-number="12">    a =<span class="st"> </span><span class="dv">0</span>; b =<span class="st"> </span>x     <span class="co"># boundaries</span></a>
<a class="sourceLine" id="cb53-13" data-line-number="13">    area =<span class="st"> </span><span class="kw">seq</span>(a, b, <span class="dt">length.out=</span><span class="dv">50</span>) <span class="co"># area</span></a>
<a class="sourceLine" id="cb53-14" data-line-number="14">    x =<span class="st"> </span><span class="kw">c</span>(a, area , b)</a>
<a class="sourceLine" id="cb53-15" data-line-number="15">    y =<span class="st"> </span><span class="kw">c</span>(<span class="dv">0</span>, <span class="kw">poisson_pmf</span>(area, lambda), <span class="dv">0</span>)</a>
<a class="sourceLine" id="cb53-16" data-line-number="16">    <span class="kw">polygon</span>(x, y, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>)</a>
<a class="sourceLine" id="cb53-17" data-line-number="17">    bars =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">20</span>, <span class="dt">length.out=</span><span class="dv">21</span>)</a>
<a class="sourceLine" id="cb53-18" data-line-number="18">    y =<span class="st"> </span><span class="kw">poisson_pmf</span>(bars, lambda) </a>
<a class="sourceLine" id="cb53-19" data-line-number="19">}</a>
<a class="sourceLine" id="cb53-20" data-line-number="20"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">20</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="op">-</span><span class="fl">0.01</span>,<span class="fl">0.6</span>), </a>
<a class="sourceLine" id="cb53-21" data-line-number="21">     <span class="dt">xlab=</span><span class="st">&quot;support&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;probability mass&quot;</span>,</a>
<a class="sourceLine" id="cb53-22" data-line-number="22">     <span class="dt">main=</span><span class="st">&quot;PMF and CMF (Poisson Distribution)&quot;</span>,  <span class="dt">frame=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb53-23" data-line-number="23"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb53-24" data-line-number="24"><span class="kw">abline</span>(<span class="dt">h=</span><span class="dv">0</span>, <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb53-25" data-line-number="25">p =<span class="st"> </span><span class="kw">poisson_cmf</span>(<span class="dt">x=</span><span class="dv">10</span>, <span class="dt">lambda=</span><span class="dv">9</span>)</a>
<a class="sourceLine" id="cb53-26" data-line-number="26"><span class="kw">poisson_area</span>(<span class="dt">x=</span><span class="dv">10</span>, <span class="dt">lambda=</span><span class="dv">9</span>)</a>
<a class="sourceLine" id="cb53-27" data-line-number="27"><span class="co"># use n=550 to smoothen curves</span></a>
<a class="sourceLine" id="cb53-28" data-line-number="28"><span class="kw">curve</span>(<span class="kw">poisson_pmf</span>(x, <span class="dt">lambda=</span><span class="fl">0.5</span>), <span class="dt">n=</span><span class="dv">550</span>, <span class="dt">col=</span><span class="st">&quot;brown&quot;</span>, </a>
<a class="sourceLine" id="cb53-29" data-line-number="29">      <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb53-30" data-line-number="30"><span class="kw">curve</span>(<span class="kw">poisson_pmf</span>(x, <span class="dt">lambda=</span><span class="dv">1</span>), <span class="dt">n=</span><span class="dv">550</span>, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, </a>
<a class="sourceLine" id="cb53-31" data-line-number="31">      <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb53-32" data-line-number="32"><span class="kw">curve</span>(<span class="kw">poisson_pmf</span>(x, <span class="dt">lambda=</span><span class="dv">5</span>), <span class="dt">n=</span><span class="dv">550</span>, <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, </a>
<a class="sourceLine" id="cb53-33" data-line-number="33">      <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb53-34" data-line-number="34"><span class="kw">curve</span>(<span class="kw">poisson_pmf</span>(x, <span class="dt">lambda=</span><span class="dv">9</span>), <span class="dt">n=</span><span class="dv">550</span>, <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb53-35" data-line-number="35">x =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">20</span>, <span class="dt">length=</span><span class="dv">21</span>)</a>
<a class="sourceLine" id="cb53-36" data-line-number="36">y =<span class="st"> </span><span class="kw">poisson_pmf</span>(x, <span class="dt">lambda=</span><span class="dv">9</span>)</a>
<a class="sourceLine" id="cb53-37" data-line-number="37"><span class="kw">points</span>(x,y, <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>, <span class="dt">pch=</span><span class="dv">16</span>, <span class="dt">cex=</span><span class="fl">0.8</span>)</a>
<a class="sourceLine" id="cb53-38" data-line-number="38"><span class="kw">text</span>(<span class="dv">7</span>,<span class="fl">0.06</span>, <span class="dt">label=</span><span class="st">&quot;(cmf)&quot;</span>, <span class="dt">col=</span><span class="st">&quot;black&quot;</span>)</a>
<a class="sourceLine" id="cb53-39" data-line-number="39"><span class="kw">text</span>(<span class="dv">7</span>, <span class="fl">0.02</span>, <span class="dt">label=</span><span class="kw">paste</span>(<span class="st">&quot;Area = &quot;</span>, <span class="kw">round</span>(p,<span class="dv">5</span>), <span class="dt">sep=</span><span class="st">&quot;&quot;</span>), </a>
<a class="sourceLine" id="cb53-40" data-line-number="40">     <span class="dt">ce=</span><span class="fl">0.80</span>, <span class="dt">col=</span><span class="st">&quot;black&quot;</span>)</a>
<a class="sourceLine" id="cb53-41" data-line-number="41"><span class="kw">text</span>(<span class="dv">10</span>, <span class="fl">-0.01</span>, <span class="dt">label=</span><span class="st">&quot;x=10&quot;</span>, <span class="dt">cex=</span><span class="fl">0.8</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:poissonpdf"></span>
<img src="DS_files/figure-html/poissonpdf-1.png" alt="Poisson (PMF and CMF)" width="70%" />
<p class="caption">
Figure 5.21: Poisson (PMF and CMF)
</p>
</div>

<p>Our <strong>CMF</strong> for the <strong>Poisson distribution</strong> in figure  is 0.70599.</p>
<p>Note that the <strong>PMF</strong> and <strong>CMF</strong> may appear continuous in figure . However, imagine that the curves in <strong>PMF</strong> generate discrete points along the curves instead and that <strong>CMF</strong> generates a set of discrete bars up to <span class="math inline">\(x\)</span> instead of a continuously filled region.</p>
<p>To illustrate further, suppose that a software developer types on a computer keyboard an average of 40 words per minute. Calculate the probability of k = (0,1,2,3,..6) in an interval of 1-minute.</p>
<p><span class="math display">\[
\mathcal{P}(X\ \in\ \{0,1,2,3,4,5,6\}) = \frac{\lambda^x e^{-\lambda}}{x!}
\]</span></p>
<p>where:</p>
<ul>
<li><strong>r</strong> is 40 words typed on the average.</li>
<li><strong>t</strong> is 1 minute interval.</li>
<li><span class="math inline">\(\lambda\)</span> is 40 words / minute</li>
</ul>
<p>Here is the implementation of <strong>PMF</strong> in R code:</p>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb54-1" data-line-number="1">k =<span class="st"> </span><span class="kw">c</span>(<span class="dv">30</span>,<span class="dv">35</span>,<span class="dv">40</span>,<span class="dv">45</span>,<span class="dv">50</span>)</a>
<a class="sourceLine" id="cb54-2" data-line-number="2"><span class="kw">round</span>(<span class="kw">poisson_pmf</span>(<span class="dt">x=</span>k,<span class="dt">lambda=</span><span class="dv">40</span>), <span class="dv">5</span>)   <span class="co"># our code</span></a></code></pre></div>
<pre><code>## [1] 0.01847 0.04854 0.06295 0.04397 0.01771</code></pre>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb56-1" data-line-number="1">(<span class="dt">p =</span> <span class="kw">round</span>(<span class="kw">dpois</span>(<span class="dt">x=</span>k, <span class="dt">lambda=</span><span class="dv">40</span>), <span class="dv">5</span>)) <span class="co"># R&#39;s built-in package</span></a></code></pre></div>
<pre><code>## [1] 0.01847 0.04854 0.06295 0.04397 0.01771</code></pre>
<div class="sourceCode" id="cb58"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb58-1" data-line-number="1"><span class="kw">names</span>(p) &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">4</span>,<span class="dv">1</span>)</a>
<a class="sourceLine" id="cb58-2" data-line-number="2"><span class="kw">barplot</span>(p, <span class="dt">density=</span>T, <span class="dt">col=</span><span class="dv">2</span>, <span class="dt">xlab=</span><span class="st">&quot;Events&quot;</span>,</a>
<a class="sourceLine" id="cb58-3" data-line-number="3">        <span class="dt">ylab=</span><span class="st">&quot;Probability&quot;</span>, <span class="dt">main=</span><span class="st">&quot;Rate of Typed Words&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:rpoipmf1"></span>
<img src="DS_files/figure-html/rpoipmf1-1.png" alt="(PMF) Poisson Distribution" width="60%" />
<p class="caption">
Figure 5.22: (PMF) Poisson Distribution
</p>
</div>
<p>Here, the probability of typing 30 words per minute with an average of 40 words per minute is 1.85%. The probability of typing 40 words per minute is 6.30% if average is 40 words per minute.</p>
<p>For the <strong>expected value</strong> and <strong>variance</strong> respectively, we have:</p>
<p><span class="math display">\[\begin{align}
\mathbb{E}(X) = Var(X) = \lambda = rt
\end{align}\]</span></p>
</div>
<div id="pareto-distribution" class="section level3">
<h3><span class="header-section-number">5.9.12</span> Pareto distribution </h3>
<p><strong>Pareto distribution</strong> models a skewed and heavy-tailed <strong>continouus distribution</strong> written as:</p>
<p><span class="math display">\[\begin{align}
X \sim Pareto(\lambda, \alpha)
\end{align}\]</span></p>
<p>This distribution is commonly known to model the distribution of incomes.</p>
<p>The <strong>Pareto PDF</strong> of a <strong>Pareto distribution</strong> with <strong>support</strong>, <span class="math inline">\(x &gt; \lambda\)</span>, is expressed as:</p>
<p><span class="math display">\[\begin{align}
f(x; \lambda, \alpha) = \mathcal{P}(X = x) = \frac{\alpha \cdot \lambda^\alpha}{X^{\alpha+1}}
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(\lambda\)</span> represents the minimum wage</li>
<li><span class="math inline">\(\alpha\)</span> is the <strong>shape parameter</strong> modeling an income distribution</li>
</ul>
<p>The <strong>Pareto CDF</strong> is expressed in the below equation, where <span class="math inline">\(x &gt; \lambda\)</span>:</p>
<p><span class="math display">\[\begin{align}
f(x; \lambda, \alpha) = \mathcal{P}(X \le x) = 1 - \left(\frac{\lambda}{x}^\alpha\right)
\end{align}\]</span></p>
<p>The mean and variance are expressed as such:</p>
<p><span class="math display">\[\begin{align}
\mathbb{E}(X) = \frac{\alpha\lambda}{\alpha - 1}, \alpha &gt; 1
\ \ \ \ \ \ \ \ \ \ \ \
VAR(X) = \frac{\alpha\lambda^2}{(\alpha - 1)^2(\alpha - 2)}, \alpha &gt; 2
\end{align}\]</span></p>
<p>Below is a naive implementation of <strong>Pareto Distribution</strong> in R code:</p>

<div class="sourceCode" id="cb59"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb59-1" data-line-number="1">pareto_pdf &lt;-<span class="st"> </span><span class="cf">function</span>(x, lambda,  alpha ) {</a>
<a class="sourceLine" id="cb59-2" data-line-number="2">    (alpha <span class="op">*</span><span class="st"> </span>lambda<span class="op">^</span>alpha) <span class="op">/</span><span class="st"> </span>(x<span class="op">^</span>(alpha <span class="op">+</span><span class="st"> </span><span class="dv">1</span>))</a>
<a class="sourceLine" id="cb59-3" data-line-number="3">}</a>
<a class="sourceLine" id="cb59-4" data-line-number="4">pareto_cdf &lt;-<span class="st"> </span><span class="cf">function</span>(x, lambda, alpha) {</a>
<a class="sourceLine" id="cb59-5" data-line-number="5">    <span class="dv">1</span> <span class="op">-</span><span class="st"> </span>(lambda<span class="op">^</span>alpha <span class="op">/</span><span class="st"> </span>x)</a>
<a class="sourceLine" id="cb59-6" data-line-number="6">}</a>
<a class="sourceLine" id="cb59-7" data-line-number="7">pareto_area &lt;-<span class="st"> </span><span class="cf">function</span>(x, lambda, alpha) {</a>
<a class="sourceLine" id="cb59-8" data-line-number="8">    a =<span class="st"> </span><span class="dv">1</span>; b =<span class="st"> </span>x     <span class="co"># boundaries</span></a>
<a class="sourceLine" id="cb59-9" data-line-number="9">    area =<span class="st"> </span><span class="kw">seq</span>(a, b, <span class="dt">length.out=</span><span class="dv">50</span>)     <span class="co"># area</span></a>
<a class="sourceLine" id="cb59-10" data-line-number="10">    x =<span class="st"> </span><span class="kw">c</span>(a, area , b)</a>
<a class="sourceLine" id="cb59-11" data-line-number="11">    y =<span class="st"> </span><span class="kw">c</span>(<span class="dv">0</span>, <span class="kw">pareto_pdf</span>(area, lambda, alpha), <span class="dv">0</span>)</a>
<a class="sourceLine" id="cb59-12" data-line-number="12">    <span class="kw">polygon</span>(x, y, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>)    </a>
<a class="sourceLine" id="cb59-13" data-line-number="13">}</a>
<a class="sourceLine" id="cb59-14" data-line-number="14"><span class="co">#Plotting PDF and CDF (Area for alpha=1, beta=1)</span></a>
<a class="sourceLine" id="cb59-15" data-line-number="15"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">8</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="dv">2</span>), </a>
<a class="sourceLine" id="cb59-16" data-line-number="16">     <span class="dt">xlab=</span><span class="st">&quot;support&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;probability density&quot;</span>,</a>
<a class="sourceLine" id="cb59-17" data-line-number="17">     <span class="dt">main=</span><span class="st">&quot;PDF (Pareto Distribution)&quot;</span>,  <span class="dt">frame=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb59-18" data-line-number="18"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb59-19" data-line-number="19"><span class="kw">abline</span>(<span class="dt">h=</span><span class="dv">0</span>, <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb59-20" data-line-number="20">p =<span class="st"> </span><span class="kw">pareto_cdf</span>(<span class="dt">x=</span><span class="dv">2</span>, <span class="dt">lambda=</span><span class="fl">0.5</span>, <span class="dt">alpha=</span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb59-21" data-line-number="21"><span class="kw">pareto_area</span>(<span class="dt">x=</span><span class="dv">2</span>, <span class="dt">lambda=</span><span class="fl">0.5</span>, <span class="dt">alpha=</span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb59-22" data-line-number="22"><span class="kw">curve</span>(<span class="kw">pareto_pdf</span>(x, <span class="dt">lambda=</span><span class="fl">0.5</span>, <span class="dt">alpha=</span><span class="dv">1</span>), <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb59-23" data-line-number="23"><span class="kw">curve</span>(<span class="kw">pareto_pdf</span>(x, <span class="dt">lambda=</span><span class="dv">1</span>, <span class="dt">alpha=</span><span class="dv">1</span>),   <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, </a>
<a class="sourceLine" id="cb59-24" data-line-number="24">      <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb59-25" data-line-number="25"><span class="kw">curve</span>(<span class="kw">pareto_pdf</span>(x, <span class="dt">lambda=</span><span class="fl">1.5</span>, <span class="dt">alpha=</span><span class="dv">1</span>), <span class="dt">col=</span><span class="st">&quot;brown&quot;</span>, </a>
<a class="sourceLine" id="cb59-26" data-line-number="26">      <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb59-27" data-line-number="27"><span class="kw">curve</span>(<span class="kw">pareto_pdf</span>(x, <span class="dt">lambda=</span><span class="dv">2</span>, <span class="dt">alpha=</span><span class="dv">1</span>),   <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb59-28" data-line-number="28"></a>
<a class="sourceLine" id="cb59-29" data-line-number="29"><span class="kw">text</span>(<span class="fl">1.2</span>,<span class="fl">0.2</span>, <span class="dt">label=</span><span class="st">&quot;(cdf)&quot;</span>, <span class="dt">col=</span><span class="st">&quot;black&quot;</span>)</a>
<a class="sourceLine" id="cb59-30" data-line-number="30"><span class="kw">text</span>(<span class="fl">1.5</span>, <span class="fl">0.1</span>, <span class="dt">label=</span><span class="kw">paste</span>(<span class="st">&quot;Area = &quot;</span>, <span class="kw">round</span>(p,<span class="dv">5</span>), <span class="dt">sep=</span><span class="st">&quot;&quot;</span>), </a>
<a class="sourceLine" id="cb59-31" data-line-number="31">     <span class="dt">ce=</span><span class="fl">0.80</span>, <span class="dt">col=</span><span class="st">&quot;black&quot;</span>)</a>
<a class="sourceLine" id="cb59-32" data-line-number="32"></a>
<a class="sourceLine" id="cb59-33" data-line-number="33"><span class="co">#Plotting CDF</span></a>
<a class="sourceLine" id="cb59-34" data-line-number="34"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="dv">2</span><span class="op">:</span><span class="dv">30</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="dv">1</span>), </a>
<a class="sourceLine" id="cb59-35" data-line-number="35">     <span class="dt">xlab=</span><span class="st">&quot;support&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;cumulative density&quot;</span>,</a>
<a class="sourceLine" id="cb59-36" data-line-number="36">     <span class="dt">main=</span><span class="st">&quot;CDF (Pareto Distribution)&quot;</span>,  <span class="dt">frame=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb59-37" data-line-number="37"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb59-38" data-line-number="38"><span class="kw">abline</span>(<span class="dt">h=</span><span class="dv">0</span>, <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb59-39" data-line-number="39">x =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">15</span>, <span class="dt">length.out=</span><span class="dv">500</span>)</a>
<a class="sourceLine" id="cb59-40" data-line-number="40"><span class="kw">curve</span>(<span class="kw">pareto_cdf</span>(x, <span class="dt">lambda=</span><span class="fl">0.5</span>, <span class="dt">alpha=</span><span class="dv">1</span>), <span class="dt">col=</span><span class="st">&quot;brown&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb59-41" data-line-number="41"><span class="kw">curve</span>(<span class="kw">pareto_cdf</span>(x, <span class="dt">lambda=</span><span class="dv">1</span>, <span class="dt">alpha=</span><span class="dv">1</span>), <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>,   <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb59-42" data-line-number="42"><span class="kw">curve</span>(<span class="kw">pareto_cdf</span>(x, <span class="dt">lambda=</span><span class="fl">1.5</span>, <span class="dt">alpha=</span><span class="dv">1</span>), <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb59-43" data-line-number="43"><span class="kw">curve</span>(<span class="kw">pareto_cdf</span>(x, <span class="dt">lambda=</span><span class="dv">2</span>, <span class="dt">alpha=</span><span class="dv">1</span>), <span class="dt">col=</span><span class="st">&quot;red&quot;</span>,   <span class="dt">add=</span><span class="ot">TRUE</span> )</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:paretopdf1"></span>
<img src="DS_files/figure-html/paretopdf-1.png" alt="Pareto Distribution" width="70%" />
<p class="caption">
Figure 5.23: Pareto Distribution
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:paretopdf2"></span>
<img src="DS_files/figure-html/paretopdf-2.png" alt="Pareto Distribution" width="70%" />
<p class="caption">
Figure 5.24: Pareto Distribution
</p>
</div>

</div>
<div id="normal-distribution" class="section level3">
<h3><span class="header-section-number">5.9.13</span> Normal distribution </h3>
<p><strong>Normal distribution</strong>, also called <strong>Gaussian distribution</strong>, models a <strong>continuous distribution</strong> written as:</p>
<p><span class="math display">\[\begin{align}
X \sim \mathcal{N}(\mu, \sigma^2)
\end{align}\]</span></p>
<p>The <strong>Normal PDF</strong> of a <strong>Normal distribution</strong> with <strong>support</strong> <span class="math inline">\(x \in \mathbb{R}\)</span> is expressed as:</p>
<p><span class="math display">\[\begin{align}
f(x; \mu, \sigma) = \mathcal{P}(X =  x) = \frac{1}{\sigma \sqrt{2\pi}} exp\left[-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2\right]
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(\mu\)</span> is the average or mean of the distribution, where <span class="math inline">\(-\infty &lt; \mu &lt; \infty\)</span></li>
<li><span class="math inline">\(\sigma^2\)</span> is the variance</li>
<li><span class="math inline">\(\sigma\)</span> is the standard deviation.</li>
</ul>
<p>Note that, geometrically, <span class="math inline">\(\mu\)</span> controls the location of the <strong>bell-shaped</strong> curve and <span class="math inline">\(\sigma\)</span> controls the shape or scale of the curve. We discuss this further in Chapter  under <strong>Likelihood</strong>.</p>
<p>See Figure  for the bell-shaped curve of standard normal distribution.</p>
<p>The <span class="math inline">\(\frac{1}{\sqrt{2\pi}}\)</span> is a normalizing constant that helps bring the probability equal to one. This is because if the normalizing constant is removed, then the <strong>probability area</strong> will not integrate into one; instead, we get (<span class="math inline">\(\sqrt{2\pi}\)</span>):</p>
<p><span class="math display">\[\begin{align}
\int_{-\infty}^\infty  exp\left[-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2\right] dx = \sqrt{2\pi}
\end{align}\]</span></p>
<p>For an understanding of the derivation, investigate <strong>Gaussian integrals with polar coordinates</strong>.</p>
<p>Now, if we add the normalizing constant based on the following integration (for continuous distribution), we get:</p>
<p><span class="math display">\[\begin{align}
\frac{1}{\sqrt{2\pi}} \int_{-\infty}^\infty exp\left[-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2\right] dx =
\frac{1}{\sqrt{2\pi}} \left(\sqrt{2\pi}\right) = 1
\end{align}\]</span></p>
<p>On the other hand, the fraction <span class="math inline">\(\frac{1}{2}\)</span> in the exponent exists to transform the variance into a unit variance (and effectively into a unit standard deviation).</p>
<p>Additionally, the negative sign in the exponent exists to flip the quadratic parabola so that its vertex points upwards geometrically, making the shape a bell shape.</p>
<p>Finally, the exponent expression describes the shape of the curve (e.g.Â bell shape). If we drop the constant, this does not affect the shape or proportionality described by the exponent.</p>
<p>The <strong>Normal CDF</strong> is expressed in the below equation (wikipedia 2020), where <span class="math inline">\(x \ge 0\)</span> and <span class="math inline">\(\sigma &gt; 0\)</span>:</p>
<p><span class="math display">\[\begin{align}
\mathcal{F}(x; \mu, \sigma^2) = \mathcal{P}(X \le x) = \frac{1}{2} + \frac{1}{2} 
erf\left(  \frac{( x-\mu)}{2\sqrt{\sigma}} \right)
\end{align}\]</span></p>
<p>where <strong>erf</strong>, <strong>error function</strong>, is written as:</p>
<p><span class="math display">\[\begin{align}
erf(x) = \frac{2}{\sqrt{\pi}}\int_0^x e^{-t^2} dt
\end{align}\]</span></p>
<p>here we can use an approximation for <strong>erf</strong>:</p>
<p><span class="math display">\[\begin{align}
erf(x) \approx tanh\left(\frac{x\pi}{\sqrt{6}}\right)
\end{align}\]</span></p>
<p>See Figure  for <strong>Gauss error function</strong>.</p>
<p>The R code below draws a scattered plot and normal distribution. See Figure .</p>

<div class="sourceCode" id="cb60"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb60-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">142</span>)</a>
<a class="sourceLine" id="cb60-2" data-line-number="2"><span class="co"># Generate random values for random variable x </span></a>
<a class="sourceLine" id="cb60-3" data-line-number="3"><span class="co"># using standard normal distribution.</span></a>
<a class="sourceLine" id="cb60-4" data-line-number="4">size=<span class="dv">500</span></a>
<a class="sourceLine" id="cb60-5" data-line-number="5">x =<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n=</span>size, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb60-6" data-line-number="6"><span class="co"># Draw the scattered plot.</span></a>
<a class="sourceLine" id="cb60-7" data-line-number="7"><span class="kw">plot</span>(x, <span class="dt">lwd=</span><span class="dv">1</span>, <span class="dt">pch=</span><span class="dv">16</span>, <span class="dt">col=</span><span class="st">&quot;black&quot;</span>, <span class="dt">main=</span><span class="st">&quot;Scattered Plot&quot;</span>,</a>
<a class="sourceLine" id="cb60-8" data-line-number="8"><span class="dt">ylab=</span><span class="st">&quot;Response (Y)&quot;</span>, <span class="dt">xlab=</span><span class="st">&quot;Predictor (X)&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:statistics1"></span>
<img src="DS_files/figure-html/statistics1-1.png" alt="Normal Distribution" width="60%" />
<p class="caption">
Figure 5.25: Normal Distribution
</p>
</div>
<div class="sourceCode" id="cb61"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb61-1" data-line-number="1">breaks=<span class="dv">20</span></a>
<a class="sourceLine" id="cb61-2" data-line-number="2"><span class="co"># Draw the standard normal distribution.</span></a>
<a class="sourceLine" id="cb61-3" data-line-number="3"><span class="kw">hist</span>(x, <span class="dt">breaks=</span>breaks, <span class="dt">prob=</span><span class="ot">TRUE</span>,   <span class="dt">xlim=</span><span class="kw">range</span>(<span class="op">-</span><span class="dv">4</span>,<span class="dv">4</span>),</a>
<a class="sourceLine" id="cb61-4" data-line-number="4">       <span class="dt">main=</span><span class="st">&#39;Standard Normal Distribution&#39;</span>, <span class="dt">xlab=</span><span class="st">&#39;Standard Deviation&#39;</span>)</a>
<a class="sourceLine" id="cb61-5" data-line-number="5"><span class="kw">curve</span>(<span class="kw">dnorm</span>(x, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span><span class="dv">1</span>), <span class="dt">add=</span><span class="ot">TRUE</span>, <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:statistics2"></span>
<img src="DS_files/figure-html/statistics2-1.png" alt="Normal Distribution" width="60%" />
<p class="caption">
Figure 5.26: Normal Distribution
</p>
</div>

<p>Note that a normal distribution with mean = 0 and standard deviation = 1 is also called a <strong>unit normal</strong>.</p>
<p>For <strong>multivariate normal distribution (MVN)</strong>, we can use the following similar notation but with vectorized parameters:</p>
<p><span class="math display">\[\begin{align}
X_{(p)} \sim \mathcal{N}\left(\mu_{(p)}, \Sigma_{(pxp)}\right)
\end{align}\]</span></p>
<p><span class="math display">\[\begin{align*}
\mu_{(p)} = \left(\begin{array}{cc}\mu_1 \\ \mu_2 \\ \vdots \\ \mu_p \end{array}\right)
\ \ \ \ \ \ \
\Sigma_{(pxp)} = 
\left(\begin{array}{cccc}
\sigma^2_{11} &amp; \sigma^2_{12} &amp; \cdots &amp;\sigma^2_{1p} \\ 
\sigma^2_{21} &amp; \sigma^2_{22} &amp; \cdots &amp;\sigma^2_{2p} \\ 
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ 
\sigma^2_{p1} &amp; \sigma^2_{p2} &amp; \cdots &amp;\sigma^2_{pp} \\ 
\end{array}\right)_{pxp}
\end{align*}\]</span></p>
<p>where: <span class="math inline">\(\Sigma_{(pxp)}\)</span> is <strong>symmetric positive-definite</strong>.</p>
<p>An <strong>MVN PDF</strong> is written as:</p>
<p><span class="math display">\[
f(x_{(p)}; \mu_{(p)}, \Sigma_{(pxp)}) = \mathcal{P}(X = x_{(p)}) =  \frac{1}{|\Sigma_{(pxp)}|^\frac{1}{2} (2\pi)^{\frac{p}{2}}} exp\left[-\frac{1}{2}(x-\mu)^T\Sigma^{-1}_{(pxp)}( x - \mu)\right]
\]</span></p>
<p>For example, given a bivariate normal distribution:</p>
<p><span class="math display">\[\begin{align}
f(x_{(p)}; \mu_{(p)}, \Sigma_{(pxp)}) &amp;= 
\frac{1}{2\pi \left[\begin{array}{llll} \sigma_{11}^2 &amp; \sigma_{12}^2 \\ \sigma_{21}^2 &amp; \sigma_{22}^2 \end{array}\right]_{(2x1)}^{\frac{1}{2}}} \times \\
&amp;\exp\left[-\frac{1}{2}
 \left[\begin{array}{l} x_1 - \mu_1 \\ x_2 - \mu_2 \end{array}\right]^T_{(2x1)}
 \left[\begin{array}{ll} \sigma_{11}^2 &amp; \sigma_{12}^2 \\ \sigma_{21}^2 &amp; \sigma_{22}^2 \end{array}\right]^{-1}_{(2x2)}
 \left[\begin{array}{l} x_1 - \mu_1 \\ x_2 - \mu_2 \end{array}\right]_{(2x1)}
\right]  \nonumber
\end{align}\]</span></p>
<p>Note that a vector <strong>x</strong> may follow a set of independent gaussian normal distributions. Thus, we also can write this way:</p>
<p><span class="math display">\[\begin{align}
f(x_{(p)}; \mu_{(p)}, \Sigma_{(pxp)}) = 
\prod_{i=1}^n
\frac{1}{ \sqrt{2\pi\sigma_i}} exp\left[-\frac{1}{2}\frac{(x_1-\mu_1)^2}{\sigma_i^2}\right]
\end{align}\]</span></p>
<p>Here is a sample simple implementation of multivariate normal (MVN) distribution (specifically, bivariate):</p>

<div class="sourceCode" id="cb62"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb62-1" data-line-number="1"><span class="kw">library</span>(mvtnorm)</a>
<a class="sourceLine" id="cb62-2" data-line-number="2"><span class="kw">set.seed</span>(<span class="dv">142</span>)</a>
<a class="sourceLine" id="cb62-3" data-line-number="3">sample_size =<span class="st"> </span>n =<span class="st"> </span><span class="dv">40</span></a>
<a class="sourceLine" id="cb62-4" data-line-number="4">x =<span class="st"> </span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">5</span>,<span class="dv">5</span>, <span class="dt">length.out =</span> <span class="dv">40</span>)</a>
<a class="sourceLine" id="cb62-5" data-line-number="5">y =<span class="st"> </span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">5</span>,<span class="dv">5</span>, <span class="dt">length.out =</span> <span class="dv">40</span>)</a>
<a class="sourceLine" id="cb62-6" data-line-number="6">mu =<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>,<span class="dv">2</span>); sigma =<span class="st"> </span><span class="kw">diag</span>(<span class="dv">1</span>,<span class="dv">2</span>)</a>
<a class="sourceLine" id="cb62-7" data-line-number="7">g =<span class="st"> </span><span class="kw">expand.grid</span>(x, y)</a>
<a class="sourceLine" id="cb62-8" data-line-number="8">z &lt;-<span class="st"> </span><span class="kw">matrix</span> ( <span class="kw">dmvnorm</span>(<span class="kw">as.matrix</span>(g), <span class="dt">mean=</span>mu, <span class="dt">sigma=</span>sigma), <span class="dt">nrow =</span> n )</a>
<a class="sourceLine" id="cb62-9" data-line-number="9"><span class="kw">persp</span>(x,y,z, <span class="dt">phi=</span><span class="dv">30</span>, <span class="dt">theta=</span><span class="dv">25</span>,</a>
<a class="sourceLine" id="cb62-10" data-line-number="10">      <span class="dt">expand =</span> <span class="fl">0.5</span>, <span class="dt">shade =</span> <span class="fl">0.1</span>,</a>
<a class="sourceLine" id="cb62-11" data-line-number="11">      <span class="dt">main=</span><span class="st">&quot;Bivariate Normal Distribution&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:multinormal"></span>
<img src="DS_files/figure-html/multinormal-1.png" alt="Bivariate Normal Distribution" width="90%" />
<p class="caption">
Figure 5.27: Bivariate Normal Distribution
</p>
</div>

</div>
<div id="wald-distribution" class="section level3">
<h3><span class="header-section-number">5.9.14</span> Wald Distribution </h3>
<p><strong>Wald Distribution</strong> is also known as <strong>Inverse Gaussian Distribution</strong> and is written as:</p>
<p><span class="math display">\[\begin{align}
X \sim  \mathcal{IG}(\mu, \lambda)
\end{align}\]</span></p>
<p>The <strong>Wald PDF</strong> of a <strong>Normal distribution</strong> with <strong>support</strong> <span class="math inline">\((0, \infty)\)</span> is expressed as:</p>
<p><span class="math display">\[\begin{align}
f(x; \mu, \lambda) = \mathcal{P}(X =  x) = \sqrt{\frac{\lambda}{2\pi x^3}} exp\left(-\frac{\lambda(x-\mu)^2}{2\mu^2 x}\right)
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(\mu\)</span> is the average or mean of the distribution (location),</li>
<li><span class="math inline">\(\lambda\)</span> is the standard deviation (shape).</li>
</ul>
<p>The <strong>Wald CDF</strong> is expressed in the below equation:</p>
<p><span class="math display">\[\begin{align}
\mathcal{F}(x; \mu, \lambda) = 
\Phi \left(\sqrt{\frac{\lambda}{x}}\left(\frac{x}{\mu} - 1\right) \right)
+ exp\left(\frac{2\lambda}{\mu}\right)\Phi \left(
\sqrt{\frac{\lambda}{x}}\left(\frac{x}{\mu} + 1\right)
\right)
\end{align}\]</span></p>
<p><strong>Wald distribution</strong> tends to be a skewed <strong>Gaussian</strong> distribution; such that if <span class="math inline">\(\lambda\)</span> increases to infinity, the <strong>Wald</strong> distribution eventually becomes a <strong>Gaussian</strong> distribution.</p>
</div>
<div id="log-normal-distribution" class="section level3">
<h3><span class="header-section-number">5.9.15</span> Log-normal Distribution </h3>
<p>A <strong>Log-normal distribution</strong> models a <strong>continuous distribution</strong> in which the logarithm of its random variable models a <strong>Normal (Gaussian) distribution</strong> and is written as:</p>
<p><span class="math display">\[\begin{align}
X \sim ln\ \mathcal{N}(\mu, \sigma^2)
\end{align}\]</span></p>
<p>The <strong>Log-normal PDF</strong> is expressed in the below equation, where <span class="math inline">\(x \ge 0\)</span>:</p>
<p><span class="math display">\[\begin{align}
f(x; \mu, \sigma^2) = \frac{1}{x\sqrt{2\pi\sigma^2}} e^{-\frac{(ln\ x-\mu)^2}{2\sigma^2}}
\end{align}\]</span></p>
<p>The <strong>Log-normal CDF</strong> is expressed in the below equation:</p>
<p><span class="math display">\[\begin{align}
\mathcal{F}(x; \mu, \sigma^2) = \mathcal{P}(X \le x) = \frac{1}{2} + \frac{1}{2} erf\left(  \frac{ln\ x-\mu}{\sigma\sqrt{2}} \right)
\end{align}\]</span></p>
<p>where <strong>erf</strong>, <strong>error function</strong>, is written as:</p>
<p><span class="math display">\[\begin{align}
erf(x) {}&amp;= \frac{2}{\sqrt{\pi}}\int_0^x e^{-t^2} dt \\
&amp;\approx tanh\left(\frac{x\pi}{\sqrt{6}}\right)
\end{align}\]</span></p>
<p><strong>ERF</strong> is a sigmoid function as shown in Figure . Note that we are using <strong>tanh</strong> as an approximation only to the integral equation.</p>

<div class="sourceCode" id="cb63"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb63-1" data-line-number="1">erf &lt;-<span class="st"> </span><span class="cf">function</span>(x) {</a>
<a class="sourceLine" id="cb63-2" data-line-number="2">    <span class="kw">tanh</span>(x<span class="op">*</span>pi<span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">6</span>))</a>
<a class="sourceLine" id="cb63-3" data-line-number="3">}</a>
<a class="sourceLine" id="cb63-4" data-line-number="4">x =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">length.out=</span><span class="dv">100</span>)</a>
<a class="sourceLine" id="cb63-5" data-line-number="5"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="op">-</span><span class="dv">2</span>,<span class="dv">2</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>), </a>
<a class="sourceLine" id="cb63-6" data-line-number="6">     <span class="dt">xlab=</span><span class="st">&quot;x&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;y&quot;</span>,</a>
<a class="sourceLine" id="cb63-7" data-line-number="7">     <span class="dt">main=</span><span class="st">&quot;Gauss Error Function&quot;</span>)</a>
<a class="sourceLine" id="cb63-8" data-line-number="8"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb63-9" data-line-number="9"><span class="kw">curve</span>(<span class="kw">erf</span>(x), <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>, <span class="dt">lwd=</span><span class="dv">2</span>,<span class="dt">add=</span><span class="ot">TRUE</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:erf"></span>
<img src="DS_files/figure-html/erf-1.png" alt="Gauss Error Function" width="70%" />
<p class="caption">
Figure 5.28: Gauss Error Function
</p>
</div>

<p>Note that <strong>Log-normal distribution</strong> is more useful over <strong>Normal distribution</strong> for situations where the distribution cannot take a negative value.</p>
<p>Below is a naive implementation of <strong>Log-normal distribution</strong> in R code:</p>

<div class="sourceCode" id="cb64"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb64-1" data-line-number="1">erf &lt;-<span class="st"> </span><span class="cf">function</span>(x, a, b ) { </a>
<a class="sourceLine" id="cb64-2" data-line-number="2">    <span class="kw">tanh</span>(x<span class="op">*</span>pi<span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">6</span>)) <span class="co"># an approximation.</span></a>
<a class="sourceLine" id="cb64-3" data-line-number="3">}</a>
<a class="sourceLine" id="cb64-4" data-line-number="4">logpdf &lt;-<span class="st"> </span><span class="cf">function</span>(x, mean, sd ) {</a>
<a class="sourceLine" id="cb64-5" data-line-number="5">    <span class="co"># Log-normal Distribution</span></a>
<a class="sourceLine" id="cb64-6" data-line-number="6">    ( <span class="dv">1</span> <span class="op">/</span><span class="st"> </span>(x<span class="op">*</span><span class="kw">sqrt</span>(<span class="dv">2</span><span class="op">*</span>pi<span class="op">*</span>sd))) <span class="op">*</span><span class="st"> </span><span class="kw">exp</span>( <span class="op">-</span><span class="st"> </span>(<span class="kw">log</span>(x)<span class="op">-</span>mean)<span class="op">^</span><span class="dv">2</span><span class="op">/</span>(<span class="dv">2</span><span class="op">*</span>sd))</a>
<a class="sourceLine" id="cb64-7" data-line-number="7">}</a>
<a class="sourceLine" id="cb64-8" data-line-number="8">logcdf &lt;-<span class="st"> </span><span class="cf">function</span>(x, mean, sd) {</a>
<a class="sourceLine" id="cb64-9" data-line-number="9">    <span class="dv">1</span><span class="op">/</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span><span class="dv">1</span><span class="op">/</span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="kw">erf</span>((<span class="kw">log</span>(x) <span class="op">-</span><span class="st"> </span>mean)<span class="op">/</span>(<span class="kw">sqrt</span>(<span class="dv">2</span><span class="op">*</span>sd)))</a>
<a class="sourceLine" id="cb64-10" data-line-number="10">}</a>
<a class="sourceLine" id="cb64-11" data-line-number="11">logarea &lt;-<span class="st"> </span><span class="cf">function</span>(x, mean, sd) {</a>
<a class="sourceLine" id="cb64-12" data-line-number="12">    a =<span class="st"> </span><span class="fl">0.01</span>; b =<span class="st"> </span>x <span class="co"># boundaries</span></a>
<a class="sourceLine" id="cb64-13" data-line-number="13">    area =<span class="st"> </span><span class="kw">seq</span>(a, b, <span class="dt">length.out=</span><span class="dv">50</span>) <span class="co"># area</span></a>
<a class="sourceLine" id="cb64-14" data-line-number="14">    x =<span class="st"> </span><span class="kw">c</span>(a, area , b)</a>
<a class="sourceLine" id="cb64-15" data-line-number="15">    y =<span class="st"> </span><span class="kw">c</span>(<span class="dv">0</span>, <span class="kw">logpdf</span>(area, <span class="dv">0</span>, <span class="dv">1</span>), <span class="dv">0</span>)</a>
<a class="sourceLine" id="cb64-16" data-line-number="16">    <span class="kw">polygon</span>(x, y, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>)</a>
<a class="sourceLine" id="cb64-17" data-line-number="17">}</a>
<a class="sourceLine" id="cb64-18" data-line-number="18"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="dv">10</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="op">-</span><span class="fl">0.01</span>,<span class="fl">0.8</span>), </a>
<a class="sourceLine" id="cb64-19" data-line-number="19">     <span class="dt">xlab=</span><span class="st">&quot;spread (variance)&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;probability density&quot;</span>,</a>
<a class="sourceLine" id="cb64-20" data-line-number="20">     <span class="dt">main=</span><span class="st">&quot;Log-normal Distribution&quot;</span> )</a>
<a class="sourceLine" id="cb64-21" data-line-number="21"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb64-22" data-line-number="22"><span class="kw">abline</span>(<span class="dt">h=</span><span class="dv">0</span>, <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>)</a>
<a class="sourceLine" id="cb64-23" data-line-number="23">p =<span class="st"> </span><span class="kw">logcdf</span>(<span class="dt">x=</span><span class="dv">4</span>, <span class="dv">0</span>, <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb64-24" data-line-number="24"><span class="kw">logarea</span>(<span class="dt">x=</span><span class="dv">4</span>, <span class="dv">0</span>, <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb64-25" data-line-number="25"><span class="kw">curve</span>(<span class="kw">logpdf</span>(x, <span class="dv">0</span>, <span class="fl">1.0</span>), <span class="dt">n=</span><span class="dv">500</span>, <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb64-26" data-line-number="26"><span class="kw">curve</span>(<span class="kw">logpdf</span>(x, <span class="dv">1</span>, <span class="fl">0.7</span>), <span class="dt">n=</span><span class="dv">500</span>, <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb64-27" data-line-number="27"><span class="kw">curve</span>(<span class="kw">logpdf</span>(x, <span class="dv">2</span>, <span class="fl">0.5</span>), <span class="dt">n=</span><span class="dv">500</span>, <span class="dt">col=</span><span class="st">&quot;brown&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb64-28" data-line-number="28"><span class="kw">text</span>(<span class="fl">1.5</span>,<span class="fl">0.09</span>, <span class="dt">label=</span><span class="st">&quot;(cdf)&quot;</span>, <span class="dt">col=</span><span class="st">&quot;black&quot;</span>)</a>
<a class="sourceLine" id="cb64-29" data-line-number="29"><span class="kw">text</span>(<span class="fl">1.5</span>, <span class="fl">0.05</span>, <span class="dt">label=</span><span class="kw">paste</span>(<span class="st">&quot;Area = &quot;</span>, <span class="kw">round</span>(p, <span class="dv">5</span>), <span class="dt">sep=</span><span class="st">&quot;&quot;</span>), </a>
<a class="sourceLine" id="cb64-30" data-line-number="30">     <span class="dt">ce=</span><span class="dv">1</span>, <span class="dt">col=</span><span class="st">&quot;black&quot;</span>)</a>
<a class="sourceLine" id="cb64-31" data-line-number="31"><span class="kw">text</span>(<span class="dv">4</span>, <span class="fl">-0.01</span>, <span class="dt">label=</span><span class="st">&quot;q=2&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:lognormal"></span>
<img src="DS_files/figure-html/lognormal-1.png" alt="Log-normal Distribution" width="70%" />
<p class="caption">
Figure 5.29: Log-normal Distribution
</p>
</div>

</div>
<div id="uniform-distribution" class="section level3">
<h3><span class="header-section-number">5.9.16</span> Uniform Distribution </h3>
<p>A <strong>Uniform distribution</strong> models a <strong>continuous distribution</strong> and is written as:</p>
<p><span class="math display">\[\begin{align}
X \sim U(a,b)
\end{align}\]</span></p>
<p>The <strong>PDF</strong> for a <strong>Uniform distribution</strong> with <strong>support</strong> <span class="math inline">\(\{a,b\} \in \mathbb{R}\)</span> and <span class="math inline">\(a &lt; b\)</span> is expressed as:</p>
<p><span class="math display">\[\begin{align}
f(x) = \begin{cases}
\frac{1}{b - a} &amp; a \le x \le b \\
0 &amp; otherwise
\end{cases}
\end{align}\]</span></p>
<p>The <strong>CDF</strong> for a <strong>Uniform distribution</strong> is expressed as:</p>
<p><span class="math display">\[\begin{align}
F(x) = \begin{cases}
0 &amp; x &lt; a \\
1 &amp; x &gt; b \\
\frac{x-a}{b - a} &amp; otherwise
\end{cases}
\end{align}\]</span></p>
<p>For the <strong>expected value</strong> and <strong>variance</strong> respectively, we have:</p>
<p><span class="math display">\[\begin{align}
\mu = \frac{a+b}{2}\ \ \ \ \ \ \ \ \ \ \ \ \ \sigma = \sqrt{\frac{(b-a)^2}{12}}
\end{align}\]</span></p>
<p>Given the simple formula above, the <strong>PDF</strong> and <strong>CDF</strong> for <strong>Uniform distribution</strong> should be simple to implement in R code (we skip the implementation).</p>
<p>The next few sections cover <strong>T-distribution</strong>, <strong>F-distribution</strong>, <strong>Chi-Square distribution</strong>, <strong>Wishart distribution</strong>, and <strong>Mixture distribution</strong> among a few others. We introduce the <strong>CDF</strong> of the subsequent distributions which come with complexity because of the use of special functions such as <strong>Gamma, Beta, Continued Fraction, and HyperGeometric functions</strong>. While these complex <strong>CDFs</strong> are known or used in practice, continued efforts may still be ongoing to explore better alternatives.</p>
</div>
<div id="t-distribution" class="section level3">
<h3><span class="header-section-number">5.9.17</span> T-Distribution </h3>
<p>A <strong>T-distribution</strong>, also called <strong>Studentâs distribution</strong>, models a <strong>continuous distribution</strong> sampled from a <strong>Normal distribution</strong> and is written as:</p>
<p><span class="math display">\[\begin{align}
X_s \sim T(\nu)\ \ \ \ \leftarrow\ \ \ \ \ X_p \sim iid\ N(\mu, \sigma^2)
\end{align}\]</span></p>
<p>The <strong>T-distribution</strong> is used for <strong>T-statistic tests</strong> to analyze samples of data with sample size equal or less than 30. We discuss the <strong>T-Test</strong> in later sections.  </p>
<p>It can be said that a <strong>T-distribution</strong> is independently and identically distributed as a <strong>normal distribution</strong> whose <strong>PDF</strong> follows a much shorter and fatter curve. And it is used only if the sample is smaller (e.g.Â perhaps 30).</p>
<p>The <strong>PDF</strong> for a <strong>T-distribution</strong> with <strong>support</strong> <span class="math inline">\(x \in \mathbb{R}\)</span> is expressed as:</p>
<p><span class="math display">\[\begin{align}
f(x; \nu) = \frac{1} {\Gamma(\frac{\nu}{2})\sqrt{\nu\pi}} 
\Gamma\left(\frac{\nu+1}{2}\right) \left(1 + \frac{x^2}{\nu}\right)^{-\frac{\nu+1}{2}}
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(\nu\)</span> is the degrees of freedom.</li>
</ul>
<p>Here is a naive implementation of <strong>PDF</strong> for a symmetric (central) <strong>T-Distribution</strong> in R code:</p>

<div class="sourceCode" id="cb65"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb65-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">1</span>)</a>
<a class="sourceLine" id="cb65-2" data-line-number="2">Gamma &lt;-<span class="st"> </span><span class="cf">function</span>(n) { <span class="kw">factorial</span>(n<span class="dv">-1</span>) }</a>
<a class="sourceLine" id="cb65-3" data-line-number="3">t_pdf &lt;-<span class="st"> </span><span class="cf">function</span>(x, df) {</a>
<a class="sourceLine" id="cb65-4" data-line-number="4">    <span class="kw">Gamma</span>((df<span class="op">+</span><span class="dv">1</span>)<span class="op">/</span><span class="dv">2</span>) <span class="op">/</span><span class="st"> </span>( <span class="kw">Gamma</span>(df<span class="op">/</span><span class="dv">2</span>) <span class="op">*</span><span class="st"> </span><span class="kw">sqrt</span>(df <span class="op">*</span><span class="st"> </span>pi) ) <span class="op">*</span><span class="st"> </span></a>
<a class="sourceLine" id="cb65-5" data-line-number="5"><span class="st">    </span>( <span class="dv">1</span> <span class="op">+</span><span class="st"> </span>x<span class="op">^</span><span class="dv">2</span><span class="op">/</span>df )<span class="op">^</span>(<span class="op">-</span>(df<span class="op">+</span><span class="dv">1</span>)<span class="op">/</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb65-6" data-line-number="6">}</a>
<a class="sourceLine" id="cb65-7" data-line-number="7">population =<span class="st"> </span><span class="kw">round</span>(<span class="kw">seq</span>(<span class="dv">4</span>,<span class="dv">7</span>, <span class="dt">length.out=</span><span class="dv">10</span>),<span class="dv">1</span>)</a>
<a class="sourceLine" id="cb65-8" data-line-number="8">x =<span class="st"> </span><span class="kw">sample</span>(population, <span class="dt">size=</span><span class="dv">20</span>, <span class="dt">replace=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb65-9" data-line-number="9"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="op">-</span><span class="dv">4</span>,<span class="dv">4</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="fl">0.5</span>), </a>
<a class="sourceLine" id="cb65-10" data-line-number="10">     <span class="dt">xlab=</span><span class="st">&quot;T value&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;probability density&quot;</span>,</a>
<a class="sourceLine" id="cb65-11" data-line-number="11">     <span class="dt">main=</span><span class="st">&quot;T Distribution (PDF)&quot;</span>)</a>
<a class="sourceLine" id="cb65-12" data-line-number="12"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb65-13" data-line-number="13"><span class="kw">curve</span>(<span class="kw">dnorm</span>(x, <span class="dv">0</span>, <span class="dv">1</span>), <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb65-14" data-line-number="14"><span class="kw">curve</span>(<span class="kw">t_pdf</span>(x, <span class="dv">10</span>), <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb65-15" data-line-number="15"><span class="kw">curve</span>(<span class="kw">t_pdf</span>(x, <span class="dv">2</span>), <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb65-16" data-line-number="16"><span class="kw">curve</span>(<span class="kw">t_pdf</span>(x, <span class="dv">1</span>), <span class="dt">col=</span><span class="st">&quot;brown&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">add=</span><span class="ot">TRUE</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:tdist"></span>
<img src="DS_files/figure-html/tdist-1.png" alt="T-Distribution (PDF)" width="70%" />
<p class="caption">
Figure 5.30: T-Distribution (PDF)
</p>
</div>

<p>It can be noticed that as the degree of freedom, <span class="math inline">\(\mathbf{\nu}\)</span>, gets larger, the <strong>T-distribution</strong> gets closer to that of a <strong>Normal distribution</strong> based on <strong>PDF</strong>.</p>
<p>The <strong>CDF</strong> for a symmetric (central) <strong>T-distribution</strong> is expressed as:</p>
<p><span class="math display">\[\begin{align}
F(x; \nu) = \frac{1}{2} + \frac{1}{2} sign(x) \left[
I\left(1; \frac{\nu}{2},\frac{1}{2}\right) -  
I\left(\frac{\nu}{\nu + x^2}; \frac{\nu}{2},\frac{1}{2}\right) \right]
\end{align}\]</span></p>
<p>where:</p>
<p><span class="math display">\[\begin{align}
I_x(\alpha,\beta) = \frac{\mathcal{B}_x(\alpha,\beta)}{\mathcal{B}(\alpha,\beta)}\ \ \leftarrow\ \ \text{regularized beta function}
\end{align}\]</span></p>
<p>And as complementary, we can explore the use of <strong>continued fraction</strong> for <strong>regularized beta function</strong> instead of <strong>hypergeometric function</strong>.</p>
<p>Example, if x &lt; (a+1) / (a+b+2):</p>
<p><span class="math display">\[\begin{align}
Bx(\alpha,\beta) = \frac{ Kx(\alpha,\beta) }{a} \left[1+\frac{d_1}{1+}\frac{d_2}{1+}\frac{d_3}{1+}...\right]
\end{align}\]</span></p>
<p>where:</p>
<p><span class="math display">\[\begin{align}
Kx(\alpha,\beta) = \frac{1}{\mathcal{B}(\alpha,\beta)}x^\alpha(1-x)^\beta 
\end{align}\]</span></p>
<p>and</p>
<p><span class="math display">\[\begin{align}
d_{2m} = \frac{m(\beta-m)x}{(\alpha+2m - 1)(\alpha+2m)}\ \ \ \ \ \ \ \ \
d_{2m+1} =  -\frac{(\alpha+m)(\alpha+\beta+m)x}{(\alpha+2m)(\alpha+2m+1)}
\end{align}\]</span></p>
<p>Let us first show an implementation of <strong>continued fraction</strong> in R code (see Numerical Recipes (W.H. Press et al, 1992) in C code): </p>

<div class="sourceCode" id="cb66"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb66-1" data-line-number="1">Gamma &lt;-<span class="st"> </span><span class="cf">function</span>(n) { <span class="kw">factorial</span>(n<span class="dv">-1</span>) }</a>
<a class="sourceLine" id="cb66-2" data-line-number="2">Beta &lt;-<span class="st"> </span><span class="cf">function</span>(a,b) { <span class="kw">Gamma</span>(a)<span class="op">*</span><span class="kw">Gamma</span>(b) <span class="op">/</span><span class="st"> </span><span class="kw">Gamma</span>(a<span class="op">+</span>b)}</a>
<a class="sourceLine" id="cb66-3" data-line-number="3">even &lt;-<span class="st"> </span><span class="cf">function</span>(x, a, b, m) {</a>
<a class="sourceLine" id="cb66-4" data-line-number="4">  (m<span class="op">*</span>(b<span class="op">-</span>m)<span class="op">*</span>x) <span class="op">/</span><span class="st"> </span>((a <span class="op">+</span><span class="st"> </span><span class="dv">2</span><span class="op">*</span>m <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)<span class="op">*</span>(a<span class="op">+</span><span class="dv">2</span><span class="op">*</span>m))</a>
<a class="sourceLine" id="cb66-5" data-line-number="5">}</a>
<a class="sourceLine" id="cb66-6" data-line-number="6">odd &lt;-<span class="st"> </span><span class="cf">function</span>(x, a, b, m) {</a>
<a class="sourceLine" id="cb66-7" data-line-number="7">  <span class="op">-</span>((a<span class="op">+</span>m)<span class="op">*</span>(a<span class="op">+</span>b<span class="op">+</span>m)<span class="op">*</span>x) <span class="op">/</span><span class="st"> </span>((a<span class="op">+</span><span class="dv">2</span><span class="op">*</span>m)<span class="op">*</span>(a<span class="op">+</span><span class="dv">2</span><span class="op">*</span>m<span class="op">+</span><span class="dv">1</span>))</a>
<a class="sourceLine" id="cb66-8" data-line-number="8">}</a>
<a class="sourceLine" id="cb66-9" data-line-number="9">tiny &lt;-<span class="st"> </span><span class="cf">function</span>(z) {</a>
<a class="sourceLine" id="cb66-10" data-line-number="10">    eps =<span class="st"> </span><span class="fl">1e-30</span></a>
<a class="sourceLine" id="cb66-11" data-line-number="11">    <span class="cf">if</span> (z <span class="op">&lt;</span><span class="st"> </span>eps) { <span class="kw">return</span>(eps) }</a>
<a class="sourceLine" id="cb66-12" data-line-number="12">    z</a>
<a class="sourceLine" id="cb66-13" data-line-number="13">}</a>
<a class="sourceLine" id="cb66-14" data-line-number="14">betacf &lt;-<span class="st"> </span><span class="cf">function</span>(x, a, b, m) {</a>
<a class="sourceLine" id="cb66-15" data-line-number="15">    limit =<span class="st"> </span><span class="dv">200</span></a>
<a class="sourceLine" id="cb66-16" data-line-number="16">    epsilon =<span class="st"> </span><span class="fl">3e-14</span></a>
<a class="sourceLine" id="cb66-17" data-line-number="17">    c =<span class="st"> </span><span class="dv">1</span></a>
<a class="sourceLine" id="cb66-18" data-line-number="18">    d =<span class="st"> </span><span class="dv">1</span> <span class="op">/</span><span class="st"> </span><span class="kw">tiny</span>(<span class="dv">1</span><span class="op">-</span>(a<span class="op">+</span>b)<span class="op">*</span>x<span class="op">/</span>(a<span class="op">+</span><span class="dv">1</span>)) </a>
<a class="sourceLine" id="cb66-19" data-line-number="19">    cf =<span class="st"> </span>d</a>
<a class="sourceLine" id="cb66-20" data-line-number="20">    <span class="cf">for</span> (m <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>limit) {</a>
<a class="sourceLine" id="cb66-21" data-line-number="21">       num =<span class="st"> </span><span class="kw">even</span>(x, a, b, m)</a>
<a class="sourceLine" id="cb66-22" data-line-number="22">       d =<span class="st"> </span><span class="dv">1</span> <span class="op">/</span><span class="st"> </span><span class="kw">tiny</span>(<span class="dv">1</span><span class="op">+</span>num <span class="op">*</span><span class="st"> </span>d ) </a>
<a class="sourceLine" id="cb66-23" data-line-number="23">       c =<span class="st"> </span><span class="kw">tiny</span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>num <span class="op">/</span><span class="st"> </span>c)</a>
<a class="sourceLine" id="cb66-24" data-line-number="24">       cf =<span class="st"> </span>cf <span class="op">*</span><span class="st"> </span>d<span class="op">*</span>c</a>
<a class="sourceLine" id="cb66-25" data-line-number="25">       num =<span class="st"> </span><span class="kw">odd</span>(x, a, b, m)</a>
<a class="sourceLine" id="cb66-26" data-line-number="26">       d =<span class="st"> </span><span class="dv">1</span> <span class="op">/</span><span class="st"> </span><span class="kw">tiny</span>(<span class="dv">1</span><span class="op">+</span>num <span class="op">*</span><span class="st"> </span>d ) </a>
<a class="sourceLine" id="cb66-27" data-line-number="27">       c =<span class="st"> </span><span class="kw">tiny</span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>num<span class="op">/</span>c)</a>
<a class="sourceLine" id="cb66-28" data-line-number="28">       cf =<span class="st"> </span>cf <span class="op">*</span><span class="st"> </span>d<span class="op">*</span>c</a>
<a class="sourceLine" id="cb66-29" data-line-number="29">       <span class="cf">if</span> (<span class="kw">abs</span>(d<span class="op">*</span>c<span class="dv">-1</span>) <span class="op">&lt;</span><span class="st"> </span>epsilon) {</a>
<a class="sourceLine" id="cb66-30" data-line-number="30">           <span class="kw">return</span>(cf)</a>
<a class="sourceLine" id="cb66-31" data-line-number="31">       }</a>
<a class="sourceLine" id="cb66-32" data-line-number="32">    }</a>
<a class="sourceLine" id="cb66-33" data-line-number="33">    <span class="kw">return</span> (<span class="ot">Inf</span>)</a>
<a class="sourceLine" id="cb66-34" data-line-number="34">}</a>
<a class="sourceLine" id="cb66-35" data-line-number="35">Bx &lt;-<span class="st"> </span><span class="cf">function</span>(x, a, b) {</a>
<a class="sourceLine" id="cb66-36" data-line-number="36">   n =<span class="st"> </span><span class="kw">length</span>(x)</a>
<a class="sourceLine" id="cb66-37" data-line-number="37">   bx =<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, n)</a>
<a class="sourceLine" id="cb66-38" data-line-number="38">   <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n) {</a>
<a class="sourceLine" id="cb66-39" data-line-number="39">     <span class="cf">if</span> (x[i] <span class="op">&lt;</span><span class="st"> </span><span class="dv">0</span> <span class="op">||</span><span class="st"> </span>x[i] <span class="op">&gt;</span><span class="st"> </span><span class="dv">1</span>) {bx[i] =<span class="st"> </span><span class="dv">0</span>; <span class="cf">next</span>  }</a>
<a class="sourceLine" id="cb66-40" data-line-number="40">     k =<span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb66-41" data-line-number="41">     <span class="cf">if</span> ( <span class="dv">0</span> <span class="op">&lt;</span><span class="st"> </span>x[i] <span class="op">&amp;&amp;</span><span class="st"> </span>x[i] <span class="op">&lt;</span><span class="st"> </span><span class="dv">1</span> ) {</a>
<a class="sourceLine" id="cb66-42" data-line-number="42">        k =<span class="st"> </span><span class="dv">1</span> <span class="op">/</span><span class="st"> </span><span class="kw">Beta</span>(a,b) <span class="op">*</span><span class="st"> </span>(x[i]<span class="op">^</span>a <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span><span class="op">-</span>x[i])<span class="op">^</span>(b) )</a>
<a class="sourceLine" id="cb66-43" data-line-number="43">     }</a>
<a class="sourceLine" id="cb66-44" data-line-number="44">     <span class="cf">if</span> (x[i] <span class="op">&lt;</span><span class="st"> </span>(a<span class="op">+</span><span class="dv">1</span>) <span class="op">/</span><span class="st"> </span>(a<span class="op">+</span>b<span class="op">+</span><span class="dv">2</span>)) {</a>
<a class="sourceLine" id="cb66-45" data-line-number="45">        <span class="co"># For I(x, a, b)</span></a>
<a class="sourceLine" id="cb66-46" data-line-number="46">        bx[i] =<span class="st"> </span>(k <span class="op">/</span><span class="st"> </span>a <span class="op">*</span><span class="st"> </span><span class="kw">betacf</span>( x[i], a, b, <span class="dv">1</span>))<span class="op">*</span><span class="kw">Beta</span>(a,b)</a>
<a class="sourceLine" id="cb66-47" data-line-number="47">     } <span class="cf">else</span> {</a>
<a class="sourceLine" id="cb66-48" data-line-number="48">        <span class="co"># For I(1-x, b, a)</span></a>
<a class="sourceLine" id="cb66-49" data-line-number="49">        bx[i] =<span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>k <span class="op">/</span><span class="st"> </span>b <span class="op">*</span><span class="st"> </span><span class="kw">betacf</span>( <span class="dv">1</span><span class="op">-</span>x[i], b, a, <span class="dv">1</span>))<span class="op">*</span><span class="kw">Beta</span>(a,b)</a>
<a class="sourceLine" id="cb66-50" data-line-number="50">     }</a>
<a class="sourceLine" id="cb66-51" data-line-number="51">   }</a>
<a class="sourceLine" id="cb66-52" data-line-number="52">   <span class="kw">return</span>(bx)</a>
<a class="sourceLine" id="cb66-53" data-line-number="53">}</a>
<a class="sourceLine" id="cb66-54" data-line-number="54"><span class="co"># replaces original implementation from beta distribution section</span></a>
<a class="sourceLine" id="cb66-55" data-line-number="55">Ix &lt;-<span class="st"> </span><span class="cf">function</span>(x, a, b) { </a>
<a class="sourceLine" id="cb66-56" data-line-number="56">   <span class="kw">Bx</span>(x, a, b) <span class="op">/</span><span class="st"> </span><span class="kw">Beta</span>(a, b)</a>
<a class="sourceLine" id="cb66-57" data-line-number="57">}</a>
<a class="sourceLine" id="cb66-58" data-line-number="58">incomplete_beta &lt;-<span class="st"> </span><span class="cf">function</span>(x,a,b) { </a>
<a class="sourceLine" id="cb66-59" data-line-number="59">    <span class="kw">pbeta</span>(x,a,b) <span class="op">*</span><span class="st"> </span><span class="kw">beta</span>(a,b) <span class="co"># using built-in R package &quot;pbeta&quot;.</span></a>
<a class="sourceLine" id="cb66-60" data-line-number="60">}</a>
<a class="sourceLine" id="cb66-61" data-line-number="61">Ix_alt &lt;-<span class="cf">function</span>(x, a, b) { <span class="co"># see beta distribution chapter</span></a>
<a class="sourceLine" id="cb66-62" data-line-number="62">   <span class="kw">incomplete_beta</span>(x,a,b) <span class="op">/</span><span class="st"> </span><span class="kw">Beta</span>(a,b)</a>
<a class="sourceLine" id="cb66-63" data-line-number="63">}</a>
<a class="sourceLine" id="cb66-64" data-line-number="64">x =<span class="st"> </span><span class="kw">c</span>(<span class="fl">0.50</span>, <span class="fl">-0.50</span>)</a>
<a class="sourceLine" id="cb66-65" data-line-number="65"><span class="kw">list</span>(<span class="st">&quot;Ix&quot;</span>=<span class="kw">Ix</span>(x, <span class="dv">3</span>, <span class="dv">2</span>), <span class="st">&quot;pbeta&quot;</span>=<span class="kw">pbeta</span>(x, <span class="dv">3</span>, <span class="dv">2</span>))</a></code></pre></div>
<pre><code>## $Ix
## [1] 0.3125 0.0000
## 
## $pbeta
## [1] 0.3125 0.0000</code></pre>
<div class="sourceCode" id="cb68"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb68-1" data-line-number="1"><span class="kw">list</span>(<span class="st">&quot;Ix&quot;</span>=<span class="kw">Ix</span>(x, <span class="dv">2</span>, <span class="dv">3</span>), <span class="st">&quot;pbeta&quot;</span>=<span class="kw">pbeta</span>(x, <span class="dv">2</span>, <span class="dv">3</span>))</a></code></pre></div>
<pre><code>## $Ix
## [1] 0.6875 0.0000
## 
## $pbeta
## [1] 0.6875 0.0000</code></pre>

<p>Note that to avoid overflows or underflows, or to avoid using multiplication and division, we use exponential and logarithmic functions (as shown in the original C code from Numerical Recipes). So that for the constant, K, we have:</p>
<p><span class="math display">\[\begin{align}
Kx(\alpha,\beta) {}&amp;= exp( log(\Gamma(\alpha)) -  log(\Gamma(\beta)) 
- log(\Gamma(\alpha +\beta)) \nonumber \\
&amp;+ a \times log(x) + b \times log(1-x))
\end{align}\]</span></p>
<p>However, in our R code, we intentionally use the original beta function instead of the exponential and logarithmic function to keep focused on the notation.</p>
<p><span class="math display">\[\begin{align}
\mathcal{K}x(\alpha,\beta) = \frac{1}{\mathcal{B}(\alpha,\beta)}x^\alpha(1-x)^\beta 
\end{align}\]</span></p>
<p>Also, the <strong>regular beta function</strong> keeps the common notation in the R code:</p>
<p><span class="math display">\[\begin{align}
\mathcal{I}_x(\alpha,\beta) = \frac{ \mathcal{B}_x(\alpha,\beta) }{ \mathcal{B}(\alpha, \beta)}
\end{align}\]</span></p>
<p>Given all that, here is a naive implementation of <strong>CDF</strong> for <strong>T-Distribution</strong> in R code:</p>

<div class="sourceCode" id="cb70"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb70-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">1</span>)</a>
<a class="sourceLine" id="cb70-2" data-line-number="2">t_cdf  &lt;-<span class="st"> </span><span class="cf">function</span>(x, df) {</a>
<a class="sourceLine" id="cb70-3" data-line-number="3">  <span class="dv">1</span><span class="op">/</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span><span class="dv">1</span><span class="op">/</span><span class="dv">2</span> <span class="op">*</span><span class="st">  </span><span class="kw">sign</span>(x) <span class="op">*</span><span class="st"> </span></a>
<a class="sourceLine" id="cb70-4" data-line-number="4"><span class="st">               </span>( <span class="kw">Ix</span>(<span class="dv">1</span>,df<span class="op">/</span><span class="dv">2</span>, <span class="dv">1</span><span class="op">/</span><span class="dv">2</span>) <span class="op">-</span><span class="st"> </span><span class="kw">Ix</span>(df<span class="op">/</span>(df<span class="op">+</span>x<span class="op">^</span><span class="dv">2</span>), df<span class="op">/</span><span class="dv">2</span>, <span class="dv">1</span><span class="op">/</span><span class="dv">2</span>) ) </a>
<a class="sourceLine" id="cb70-5" data-line-number="5">}</a>
<a class="sourceLine" id="cb70-6" data-line-number="6">population =<span class="st"> </span><span class="kw">round</span>(<span class="kw">seq</span>(<span class="dv">4</span>,<span class="dv">7</span>, <span class="dt">length.out=</span><span class="dv">10</span>),<span class="dv">1</span>)</a>
<a class="sourceLine" id="cb70-7" data-line-number="7">x =<span class="st"> </span><span class="kw">sample</span>(population, <span class="dt">size=</span><span class="dv">20</span>, <span class="dt">replace=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb70-8" data-line-number="8"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="op">-</span><span class="dv">5</span>,<span class="dv">5</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="dv">1</span>), </a>
<a class="sourceLine" id="cb70-9" data-line-number="9">     <span class="dt">xlab=</span><span class="st">&quot;T value&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;cumulative probability&quot;</span>,</a>
<a class="sourceLine" id="cb70-10" data-line-number="10">     <span class="dt">main=</span><span class="st">&quot;T Distribution (CDF)&quot;</span>)</a>
<a class="sourceLine" id="cb70-11" data-line-number="11"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb70-12" data-line-number="12"><span class="kw">curve</span>(<span class="kw">pnorm</span>(x, <span class="dv">0</span>, <span class="dv">1</span>), <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb70-13" data-line-number="13"><span class="kw">curve</span>(<span class="kw">t_cdf</span>(x, <span class="dv">10</span>), <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb70-14" data-line-number="14"><span class="kw">curve</span>(<span class="kw">t_cdf</span>(x, <span class="dv">2</span>), <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb70-15" data-line-number="15"><span class="kw">curve</span>(<span class="kw">t_cdf</span>(x, <span class="dv">1</span>), <span class="dt">col=</span><span class="st">&quot;brown&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">add=</span><span class="ot">TRUE</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:ptdist"></span>
<img src="DS_files/figure-html/ptdist-1.png" alt="T-Distribution (CDF)" width="70%" />
<p class="caption">
Figure 5.31: T-Distribution (CDF)
</p>
</div>

<p>An alternative solution to the <strong>CDF</strong> for the <strong>T-distribution</strong> uses the <strong>Hypergeometric function</strong> as follows:</p>
<p><span class="math display">\[\begin{align}
{}_2F_1(a,b;c; x) {}&amp;= (1-x)^{-b} {}_2F_1\left(c-a,b;c; z\right)
\ \ \ \ \ where\ \ \ z = \frac{x}{x-1}\\
&amp;= 
\frac{1}{(1-x)^{b}}\sum_{n=0}^\infty\frac{(c-a)_n (b)_n}{(c)_n} \frac{z^n}{n!}
\end{align}\]</span></p>
<p>Note that we use the first transformation form of the <strong>Hypergeometric function</strong> as listed in the <strong>Helper function</strong> section of the <strong>Numerical Probability</strong> chapter:</p>
<p>Also, note that we use the <strong>rising factorial</strong> for the symbol <span class="math inline">\((...)_n\)</span>.</p>
<p>Here is a naive implementation of the <strong>Hypergeometric function</strong> for our t-distribution <strong>CDF</strong> (Note that in this implementation, the alternative function, <strong>t_cdf_alt</strong>, is limited to the t-distribution support range, <span class="math inline">\(-4 \le x \le 4\)</span>):</p>

<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb71-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">1</span>)</a>
<a class="sourceLine" id="cb71-2" data-line-number="2">Gamma &lt;-<span class="st"> </span><span class="cf">function</span>(n) { <span class="kw">factorial</span>(n<span class="dv">-1</span>) }</a>
<a class="sourceLine" id="cb71-3" data-line-number="3">rise_factorial &lt;-<span class="st"> </span><span class="cf">function</span>(x, n) {</a>
<a class="sourceLine" id="cb71-4" data-line-number="4">    <span class="cf">if</span> (n<span class="op">==</span><span class="dv">0</span>) <span class="kw">return</span>(<span class="dv">1</span>)</a>
<a class="sourceLine" id="cb71-5" data-line-number="5">    prod =<span class="st"> </span><span class="dv">1</span></a>
<a class="sourceLine" id="cb71-6" data-line-number="6">    <span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">0</span><span class="op">:</span>(n<span class="dv">-1</span>)) {</a>
<a class="sourceLine" id="cb71-7" data-line-number="7">        prod =<span class="st"> </span>prod <span class="op">*</span><span class="st"> </span>(x <span class="op">+</span><span class="st"> </span>k)</a>
<a class="sourceLine" id="cb71-8" data-line-number="8">    }</a>
<a class="sourceLine" id="cb71-9" data-line-number="9">    prod</a>
<a class="sourceLine" id="cb71-10" data-line-number="10">}</a>
<a class="sourceLine" id="cb71-11" data-line-number="11">hypergeometric  &lt;-<span class="st"> </span><span class="cf">function</span>(a, b, c, x) { <span class="co"># only for 2F1(a,b;c;x)</span></a>
<a class="sourceLine" id="cb71-12" data-line-number="12">    hyperG_1st_form =<span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb71-13" data-line-number="13">    limit =<span class="st"> </span><span class="dv">50</span></a>
<a class="sourceLine" id="cb71-14" data-line-number="14">    z =<span class="st"> </span>x <span class="op">/</span><span class="st"> </span>( x <span class="op">-</span><span class="st"> </span><span class="dv">1</span>) </a>
<a class="sourceLine" id="cb71-15" data-line-number="15">    <span class="cf">for</span> (n <span class="cf">in</span>  <span class="dv">0</span><span class="op">:</span>limit) {</a>
<a class="sourceLine" id="cb71-16" data-line-number="16">        hyperG_1st_form =<span class="st"> </span>hyperG_1st_form <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb71-17" data-line-number="17"><span class="st">        </span>(( <span class="kw">rise_factorial</span>(c<span class="op">-</span>a , n) <span class="op">*</span><span class="st"> </span><span class="kw">rise_factorial</span>(b, n) ) <span class="op">/</span><span class="st"> </span></a>
<a class="sourceLine" id="cb71-18" data-line-number="18"><span class="st">           </span><span class="kw">rise_factorial</span>(c, n)) <span class="op">*</span><span class="st"> </span>( z<span class="op">^</span>n <span class="op">/</span><span class="st"> </span><span class="kw">factorial</span>(n))</a>
<a class="sourceLine" id="cb71-19" data-line-number="19">    }</a>
<a class="sourceLine" id="cb71-20" data-line-number="20">    hyperG_1st_form <span class="op">/</span><span class="st"> </span>(<span class="dv">1</span><span class="op">-</span>x)<span class="op">^</span>b</a>
<a class="sourceLine" id="cb71-21" data-line-number="21">}</a>
<a class="sourceLine" id="cb71-22" data-line-number="22">t_cdf_alt &lt;-<span class="st"> </span><span class="cf">function</span>(x, df) {</a>
<a class="sourceLine" id="cb71-23" data-line-number="23">   <span class="dv">1</span><span class="op">/</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span>x <span class="op">*</span><span class="st"> </span><span class="kw">Gamma</span>((df<span class="op">+</span><span class="dv">1</span>)<span class="op">/</span><span class="dv">2</span>) <span class="op">/</span><span class="st"> </span>( <span class="kw">Gamma</span>(df<span class="op">/</span><span class="dv">2</span>) <span class="op">*</span><span class="st"> </span><span class="kw">sqrt</span>(df <span class="op">*</span><span class="st"> </span>pi) ) <span class="op">*</span><span class="st"> </span></a>
<a class="sourceLine" id="cb71-24" data-line-number="24"><span class="st">   </span><span class="kw">hypergeometric</span>(<span class="dv">1</span><span class="op">/</span><span class="dv">2</span>, (df<span class="op">+</span><span class="dv">1</span>)<span class="op">/</span><span class="dv">2</span>, <span class="dv">3</span><span class="op">/</span><span class="dv">2</span>, <span class="op">-</span>(x<span class="op">^</span><span class="dv">2</span><span class="op">/</span>df)) </a>
<a class="sourceLine" id="cb71-25" data-line-number="25">}</a></code></pre></div>

<p>Now in terms of the <strong>expected value</strong> and <strong>variance</strong> respectively, we have:</p>
<p><span class="math display">\[\begin{align}
\mu = 0\ \ \ \ \ \ \ \ \ \ \ \ \ \sigma = \frac{v}{v-2}
\end{align}\]</span></p>
<p>We leave readers to investigate the non-central (asymmetric) <strong>T-distribution</strong>.</p>
</div>
<div id="f-distribution" class="section level3">
<h3><span class="header-section-number">5.9.18</span> F-Distribution </h3>
<p>An <strong>F-distribution</strong>, also known as <strong>Fisher-Snedecor distribution</strong>, models a <strong>continuous distribution</strong> and is written as:</p>
<p><span class="math display">\[\begin{align}
X \sim F(\nu_1, \nu_2)
\end{align}\]</span></p>
<p>The distribution is used for <strong>F-statistic test</strong> by comparing two populations which we discuss in later section.  </p>
<p>The <strong>PDF</strong> for an <strong>F-distribution</strong> with <strong>support</strong> <span class="math inline">\(x \ge 0\)</span> is expressed as:</p>
<p><span class="math display">\[\begin{align}
f(x; \nu_1, \nu_2) {}&amp;= 
\left[
\Gamma\left(\frac{\nu_1 + \nu_2}{2}\right)
\nu_1^{\frac{\nu_1}{2}}  \nu_2^{\frac{\nu_2}{2}}  x^{\frac{\nu_1}{2} - 1}
 \right]
\left[
\Gamma\left(\frac{\nu_1}{2}\right) \Gamma\left(\frac{\nu_2}{2}\right) 
( \nu_1  x + \nu_2)^{\frac{\nu1 + \nu_2}{2}}
\right]^{-1} \\
&amp;=\left[
\nu_1^{\frac{\nu_1}{2}}  \nu_2^{\frac{\nu_2}{2}}  x^{\frac{\nu_1}{2} - 1}
 \right]
\left[
B\left(\frac{\nu_1}{2},  \frac{\nu_2}{2} \right) 
( \nu_1  x + \nu_2)^{\frac{\nu1 + \nu_2}{2}}
\right]^{-1} 
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(\nu_1\ and\ \nu_2\)</span> are the degrees of freedom.</li>
</ul>
<p>The <strong>CDF</strong> for an <strong>F-distribution</strong> with <strong>support</strong> <span class="math inline">\(x \ge 0\)</span> is expressed as:</p>
<p><span class="math display">\[\begin{align}
F(x; \nu_1, \nu_2)  = I_z(\alpha, \beta) = I(z; \alpha, \beta)\ \ \rightarrow\ \ \text{regularized beta function}
\end{align}\]</span></p>
<p>where:</p>
<p><span class="math display">\[\begin{align}
z = \left(\frac{\nu_1 x}{\nu_1 x + \nu_2}\right)
\end{align}\]</span></p>
<p>Here is a naive implementation of <strong>PDF</strong> and <strong>CDF</strong> for <strong>F-distribution</strong> in R code (Note that we use the built-in R package <strong>pbeta()</strong> for the regularized beta function):</p>

<div class="sourceCode" id="cb72"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb72-1" data-line-number="1">Gamma &lt;-<span class="st"> </span><span class="cf">function</span>(n) {<span class="kw">factorial</span>(n<span class="dv">-1</span>)}</a>
<a class="sourceLine" id="cb72-2" data-line-number="2">Beta &lt;-<span class="st"> </span><span class="cf">function</span>(a, b) {</a>
<a class="sourceLine" id="cb72-3" data-line-number="3">    ( <span class="kw">Gamma</span>(a) <span class="op">*</span><span class="st"> </span><span class="kw">Gamma</span>(b)) <span class="op">/</span><span class="st"> </span><span class="kw">Gamma</span>(a<span class="op">+</span>b)</a>
<a class="sourceLine" id="cb72-4" data-line-number="4">}</a>
<a class="sourceLine" id="cb72-5" data-line-number="5">f_pdf &lt;-<span class="st"> </span><span class="cf">function</span>(x, df1, df2) {</a>
<a class="sourceLine" id="cb72-6" data-line-number="6">   n =<span class="st">  </span>df1<span class="op">^</span>(df1<span class="op">/</span><span class="dv">2</span>) <span class="op">*</span><span class="st"> </span>df2<span class="op">^</span>(df2<span class="op">/</span><span class="dv">2</span>) <span class="op">*</span><span class="st"> </span>x<span class="op">^</span>((df1<span class="op">/</span><span class="dv">2</span>) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb72-7" data-line-number="7">   d =<span class="st">  </span>(df1<span class="op">*</span>x <span class="op">+</span><span class="st"> </span>df2)<span class="op">^</span>((df1<span class="op">+</span>df2)<span class="op">/</span><span class="dv">2</span>)  </a>
<a class="sourceLine" id="cb72-8" data-line-number="8">   n <span class="op">/</span><span class="st"> </span>( <span class="kw">Beta</span>(df1<span class="op">/</span><span class="dv">2</span>, df2<span class="op">/</span><span class="dv">2</span>) <span class="op">*</span><span class="st"> </span>d )</a>
<a class="sourceLine" id="cb72-9" data-line-number="9">}</a>
<a class="sourceLine" id="cb72-10" data-line-number="10">f_cdf &lt;-<span class="st"> </span><span class="cf">function</span>(x, df1, df2) {</a>
<a class="sourceLine" id="cb72-11" data-line-number="11">   z =<span class="st"> </span>(df1 <span class="op">*</span><span class="st"> </span>x) <span class="op">/</span><span class="st"> </span>( df1 <span class="op">*</span><span class="st"> </span>x <span class="op">+</span><span class="st"> </span>df2)</a>
<a class="sourceLine" id="cb72-12" data-line-number="12">   <span class="kw">pbeta</span> ( z, df1<span class="op">/</span><span class="dv">2</span>, df2<span class="op">/</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb72-13" data-line-number="13">}</a>
<a class="sourceLine" id="cb72-14" data-line-number="14"><span class="co"># Probability Density</span></a>
<a class="sourceLine" id="cb72-15" data-line-number="15">x =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">6</span>)</a>
<a class="sourceLine" id="cb72-16" data-line-number="16"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="dv">6</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="dv">1</span>), </a>
<a class="sourceLine" id="cb72-17" data-line-number="17">     <span class="dt">xlab=</span><span class="st">&quot;F value&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;probability density&quot;</span>,</a>
<a class="sourceLine" id="cb72-18" data-line-number="18">     <span class="dt">main=</span><span class="st">&quot;F Distribution (PDF)&quot;</span>)</a>
<a class="sourceLine" id="cb72-19" data-line-number="19"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb72-20" data-line-number="20"><span class="kw">curve</span>(<span class="kw">f_pdf</span>(x, <span class="dv">2</span>, <span class="dv">5</span>), <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>,  <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb72-21" data-line-number="21"><span class="kw">curve</span>(<span class="kw">f_pdf</span>(x, <span class="dv">10</span>, <span class="dv">5</span>), <span class="dt">col=</span><span class="st">&quot;brown&quot;</span>,  <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb72-22" data-line-number="22"><span class="kw">curve</span>(<span class="kw">f_pdf</span>(x, <span class="dv">50</span>, <span class="dv">10</span>), <span class="dt">col=</span><span class="st">&quot;red&quot;</span>,  <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb72-23" data-line-number="23"></a>
<a class="sourceLine" id="cb72-24" data-line-number="24"><span class="co"># Cumulative Density</span></a>
<a class="sourceLine" id="cb72-25" data-line-number="25">x =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">6</span>)</a>
<a class="sourceLine" id="cb72-26" data-line-number="26"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="dv">6</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="dv">1</span>), </a>
<a class="sourceLine" id="cb72-27" data-line-number="27">     <span class="dt">xlab=</span><span class="st">&quot;F value&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;cumulative probability&quot;</span>,</a>
<a class="sourceLine" id="cb72-28" data-line-number="28">     <span class="dt">main=</span><span class="st">&quot;F Distribution (CDF)&quot;</span>)</a>
<a class="sourceLine" id="cb72-29" data-line-number="29"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb72-30" data-line-number="30"><span class="kw">curve</span>(<span class="kw">f_cdf</span>(x, <span class="dv">2</span>, <span class="dv">5</span>), <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>,  <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb72-31" data-line-number="31"><span class="kw">curve</span>(<span class="kw">f_cdf</span>(x, <span class="dv">10</span>, <span class="dv">5</span>), <span class="dt">col=</span><span class="st">&quot;brown&quot;</span>,  <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb72-32" data-line-number="32"><span class="kw">curve</span>(<span class="kw">f_cdf</span>(x, <span class="dv">50</span>, <span class="dv">10</span>), <span class="dt">col=</span><span class="st">&quot;red&quot;</span>,  <span class="dt">add=</span><span class="ot">TRUE</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:pfdist1"></span>
<img src="DS_files/figure-html/pfdist-1.png" alt="F-Distribution (PDF and CDF)" width="70%" />
<p class="caption">
Figure 5.32: F-Distribution (PDF and CDF)
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:pfdist2"></span>
<img src="DS_files/figure-html/pfdist-2.png" alt="F-Distribution (PDF and CDF)" width="70%" />
<p class="caption">
Figure 5.33: F-Distribution (PDF and CDF)
</p>
</div>

</div>
<div id="chi-square-distribution" class="section level3">
<h3><span class="header-section-number">5.9.19</span> Chi-square Distribution </h3>
<p>A <strong>Chi-square distribution</strong>, also called <span class="math inline">\(X^2\)</span><strong>-distribution</strong>, models a <strong>continuous distribution</strong> formed by squaring and summing the <strong>standard normal deviation</strong> of <span class="math inline">\(\mathbf{\nu}\)</span> independent variables that follow a standard normal distribution. The distribution can be expressed as:</p>
<p><span class="math display">\[\begin{align}
Q \sim X^2(\nu)\ \ \ \ \ \ \ where\ \mathbf{\nu}\ = \text{degrees of freedom}
\end{align}\]</span></p>
<p>The <strong>PDF</strong> for a <strong>Chi-squared distribution</strong> with <strong>support</strong> <span class="math inline">\(x \ge 0\)</span> is expressed as:</p>
<p><span class="math display">\[\begin{align}
f(x; \nu) = \frac{1}{2^{\frac{\nu}{2}}\Gamma\left(\frac{\nu}{2}\right)} 
x^{\frac{\nu}{2}-1} e^{-\frac{x}{2}}
\end{align}\]</span></p>
<p>The <strong>CDF</strong> for a <strong>Chi-square distribution</strong> with <strong>support</strong> <span class="math inline">\(x \ge 0\)</span> is expressed as:</p>
<p><span class="math display">\[\begin{align}
F(x; \nu) = \frac{1}{\Gamma\left(\frac{\nu}{2}\right)} \gamma \left(\frac{\nu}{2},\frac{x}{2}\right) = P(\frac{\nu}{2},\frac{x}{2})
\end{align}\]</span></p>
<p>where <span class="math inline">\(\gamma(\nu, x)\)</span> is the <strong>lower incomplete gamma function</strong> and <span class="math inline">\(P(\nu, x)\)</span> is the <strong>lower regularized gamma function</strong>.</p>
<p>Here is a naive implementation of <strong>PDF and CDF</strong> for <strong>Chi-square distribution</strong> in R code:</p>

<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb73-1" data-line-number="1">Gamma &lt;-<span class="st"> </span><span class="cf">function</span>(n) {<span class="kw">factorial</span>(n<span class="dv">-1</span>)}</a>
<a class="sourceLine" id="cb73-2" data-line-number="2">Beta &lt;-<span class="st"> </span><span class="cf">function</span>(a, b) {</a>
<a class="sourceLine" id="cb73-3" data-line-number="3">    ( <span class="kw">Gamma</span>(a) <span class="op">*</span><span class="st"> </span><span class="kw">Gamma</span>(b)) <span class="op">/</span><span class="st"> </span><span class="kw">Gamma</span>(a<span class="op">+</span>b)</a>
<a class="sourceLine" id="cb73-4" data-line-number="4">}</a>
<a class="sourceLine" id="cb73-5" data-line-number="5">chi_pdf &lt;-<span class="st"> </span><span class="cf">function</span>(x, df) {</a>
<a class="sourceLine" id="cb73-6" data-line-number="6">   <span class="dv">1</span> <span class="op">/</span><span class="st"> </span>( <span class="dv">2</span><span class="op">^</span>(df<span class="op">/</span><span class="dv">2</span>) <span class="op">*</span><span class="st"> </span><span class="kw">Gamma</span>(df<span class="op">/</span><span class="dv">2</span>)) <span class="op">*</span><span class="st"> </span>x<span class="op">^</span>(df<span class="op">/</span><span class="dv">2-1</span>) <span class="op">*</span><span class="st"> </span><span class="kw">exp</span>(<span class="op">-</span>x<span class="op">/</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb73-7" data-line-number="7">}</a>
<a class="sourceLine" id="cb73-8" data-line-number="8"><span class="co"># Probability Density</span></a>
<a class="sourceLine" id="cb73-9" data-line-number="9">x =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">10</span>)</a>
<a class="sourceLine" id="cb73-10" data-line-number="10"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="dv">10</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="dv">1</span>), </a>
<a class="sourceLine" id="cb73-11" data-line-number="11">     <span class="dt">xlab=</span><span class="st">&quot;Chi-square value&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;probability density&quot;</span>,</a>
<a class="sourceLine" id="cb73-12" data-line-number="12">     <span class="dt">main=</span><span class="st">&quot;Chi-squared Distribution (PDF)&quot;</span>)</a>
<a class="sourceLine" id="cb73-13" data-line-number="13"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb73-14" data-line-number="14"><span class="kw">curve</span>(<span class="kw">chi_pdf</span>(x, <span class="dv">1</span>), <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>,  <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb73-15" data-line-number="15"><span class="kw">curve</span>(<span class="kw">chi_pdf</span>(x, <span class="dv">2</span>), <span class="dt">col=</span><span class="st">&quot;brown&quot;</span>,  <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb73-16" data-line-number="16"><span class="kw">curve</span>(<span class="kw">chi_pdf</span>(x, <span class="dv">4</span>), <span class="dt">col=</span><span class="st">&quot;red&quot;</span>,  <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb73-17" data-line-number="17"><span class="kw">curve</span>(<span class="kw">chi_pdf</span>(x, <span class="dv">6</span>), <span class="dt">col=</span><span class="st">&quot;purple&quot;</span>,  <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb73-18" data-line-number="18"><span class="kw">curve</span>(<span class="kw">chi_pdf</span>(x, <span class="dv">9</span>), <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>,  <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb73-19" data-line-number="19"></a>
<a class="sourceLine" id="cb73-20" data-line-number="20">GammaInc &lt;-<span class="st"> </span><span class="cf">function</span>(alpha, z) {</a>
<a class="sourceLine" id="cb73-21" data-line-number="21">    s =<span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb73-22" data-line-number="22">    limit =<span class="st"> </span><span class="dv">300</span></a>
<a class="sourceLine" id="cb73-23" data-line-number="23">    flimit =<span class="st"> </span><span class="dv">172</span>  <span class="co"># R&#39;s gamma limit</span></a>
<a class="sourceLine" id="cb73-24" data-line-number="24">    <span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">0</span><span class="op">:</span>limit) {</a>
<a class="sourceLine" id="cb73-25" data-line-number="25">      <span class="cf">if</span> (z <span class="op">+</span><span class="st"> </span>k <span class="op">+</span><span class="st"> </span><span class="dv">1</span> <span class="op">&gt;</span><span class="st"> </span><span class="dv">171</span>) { <span class="cf">break</span> }</a>
<a class="sourceLine" id="cb73-26" data-line-number="26">      s =<span class="st"> </span>s <span class="op">+</span><span class="st"> </span>alpha<span class="op">^</span>k <span class="op">/</span><span class="st"> </span><span class="kw">Gamma</span>( z <span class="op">+</span><span class="st"> </span>k <span class="op">+</span><span class="st"> </span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb73-27" data-line-number="27">    }</a>
<a class="sourceLine" id="cb73-28" data-line-number="28">    lower =<span class="st"> </span>alpha<span class="op">^</span>z <span class="op">*</span><span class="st"> </span><span class="kw">Gamma</span>(z) <span class="op">*</span><span class="st"> </span><span class="kw">exp</span>(<span class="op">-</span>alpha) <span class="op">*</span><span class="st"> </span>s</a>
<a class="sourceLine" id="cb73-29" data-line-number="29">    upper =<span class="st"> </span><span class="kw">Gamma</span>(z) <span class="op">-</span><span class="st"> </span>lower</a>
<a class="sourceLine" id="cb73-30" data-line-number="30">    P =<span class="st"> </span>lower <span class="op">/</span><span class="st"> </span><span class="kw">Gamma</span>(z) <span class="co"># regular inc gamma</span></a>
<a class="sourceLine" id="cb73-31" data-line-number="31">    Q =<span class="st"> </span>upper <span class="op">/</span><span class="st"> </span><span class="kw">Gamma</span>(z)</a>
<a class="sourceLine" id="cb73-32" data-line-number="32">    <span class="kw">list</span>(<span class="st">&quot;lower&quot;</span>=<span class="st"> </span>lower, <span class="st">&quot;upper&quot;</span>=upper,  <span class="st">&quot;P&quot;</span>=P, <span class="st">&quot;Q&quot;</span>=Q )</a>
<a class="sourceLine" id="cb73-33" data-line-number="33">}</a>
<a class="sourceLine" id="cb73-34" data-line-number="34">chi_cdf &lt;-<span class="st"> </span><span class="cf">function</span>(x, v) {</a>
<a class="sourceLine" id="cb73-35" data-line-number="35">  <span class="dv">1</span> <span class="op">/</span><span class="st"> </span><span class="kw">Gamma</span>(v<span class="op">/</span><span class="dv">2</span>) <span class="op">*</span><span class="st"> </span><span class="kw">GammaInc</span>(x<span class="op">/</span><span class="dv">2</span>, v<span class="op">/</span><span class="dv">2</span>)<span class="op">$</span>lower</a>
<a class="sourceLine" id="cb73-36" data-line-number="36">}</a>
<a class="sourceLine" id="cb73-37" data-line-number="37"><span class="co"># Cumulative Density</span></a>
<a class="sourceLine" id="cb73-38" data-line-number="38">x =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">10</span>)</a>
<a class="sourceLine" id="cb73-39" data-line-number="39"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="dv">20</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="dv">1</span>), </a>
<a class="sourceLine" id="cb73-40" data-line-number="40">     <span class="dt">xlab=</span><span class="st">&quot;Chi-square value&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;cumulative probability&quot;</span>,</a>
<a class="sourceLine" id="cb73-41" data-line-number="41">     <span class="dt">main=</span><span class="st">&quot;Chi-squared Distribution (CDF)&quot;</span>)</a>
<a class="sourceLine" id="cb73-42" data-line-number="42"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb73-43" data-line-number="43"><span class="kw">curve</span>(<span class="kw">chi_cdf</span>(x, <span class="dv">1</span>), <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>,  <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb73-44" data-line-number="44"><span class="kw">curve</span>(<span class="kw">chi_cdf</span>(x, <span class="dv">2</span>), <span class="dt">col=</span><span class="st">&quot;brown&quot;</span>,  <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb73-45" data-line-number="45"><span class="kw">curve</span>(<span class="kw">chi_cdf</span>(x, <span class="dv">4</span>), <span class="dt">col=</span><span class="st">&quot;red&quot;</span>,  <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb73-46" data-line-number="46"><span class="kw">curve</span>(<span class="kw">chi_cdf</span>(x, <span class="dv">6</span>), <span class="dt">col=</span><span class="st">&quot;purple&quot;</span>,  <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb73-47" data-line-number="47"><span class="kw">curve</span>(<span class="kw">chi_cdf</span>(x, <span class="dv">9</span>), <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>,  <span class="dt">add=</span><span class="ot">TRUE</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:pchidist1"></span>
<img src="DS_files/figure-html/pchidist-1.png" alt="Chi-square Distribution (PDF and CDF)" width="70%" />
<p class="caption">
Figure 5.34: Chi-square Distribution (PDF and CDF)
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:pchidist2"></span>
<img src="DS_files/figure-html/pchidist-2.png" alt="Chi-square Distribution (PDF and CDF)" width="70%" />
<p class="caption">
Figure 5.35: Chi-square Distribution (PDF and CDF)
</p>
</div>

<p>It helps to also reference the <strong>Chi-square table</strong> in the appendix section.</p>
<p><span class="math display">\[
\underbrace{\mathcal{P}(x &gt; 2.7055, 1) = 0.100}_\text{df=1}\ \ \ \ \ \ \ \ \ \ \ \ \
\underbrace{\mathcal{P}(x &gt; 4.6052, 2) = 0.100}_\text{df=2}
\]</span></p>
<div class="sourceCode" id="cb74"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb74-1" data-line-number="1"><span class="kw">c</span>(<span class="st">&quot;df=1&quot;</span>=<span class="kw">round</span>( <span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">pchisq</span>(<span class="fl">2.7055</span>,<span class="dv">1</span>),<span class="dv">3</span>), </a>
<a class="sourceLine" id="cb74-2" data-line-number="2">  <span class="st">&quot;df=2&quot;</span>=<span class="kw">round</span>( <span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">pchisq</span>(<span class="fl">4.6052</span>,<span class="dv">2</span>),<span class="dv">3</span>))</a></code></pre></div>
<pre><code>## df=1 df=2 
##  0.1  0.1</code></pre>
<p>Now in terms of the <strong>expected value</strong> and <strong>variance</strong> respectively, we have:</p>
<p><span class="math display">\[\begin{align}
\mathbb{E}(X) = n\ \ \ \ \ \ \ \ \ \ \ \ \ Var(X) = 2n
\end{align}\]</span></p>
<p>See <strong>Chi-square Test</strong> section for sample application of the distribution.</p>
</div>
<div id="wishart_distribution" class="section level3">
<h3><span class="header-section-number">5.9.20</span> Wishart distribution</h3>
<p><strong>Wishart distribution</strong> models a covariance <strong>continuous</strong> distribution drawn or sampled (as a <strong>precision</strong> or <strong>inverse covariance</strong> matrix, namely <strong>V</strong> ) from a <strong>multivariate normal distribution (MVN)</strong>. It is both an extension of gamma distribution and a generalization of the Chi-Square <span class="math inline">\(\mathcal{X}^2\)</span> distribution. To compare Chi-Square and Wishart structure, see below (M.L. Eaton 2007): </p>
<p><span class="math display">\[\begin{align}
\underbrace{V = \sum_{i=1}^n X_i^2}_{
   \begin{array}{c}\text{chi-square}\ (V \in \mathbb{R}^n)\ dist\\ \ V\sim\ \mathcal{X}^2(\ \nu\ )\\ from \\ \text{univariate dist}\\ X \sim\  \mathcal{N}(\mu, \sigma^2)\end{array}
  }\ \ \ \ \ \ \ \ \ \ \
\underbrace{V = \sum_{i=1}^n X_i X_i^T}_{
   \begin{array}{c}\text{wishart} (V \in \mathbb{R}^{pxp})\ dist\\ \ \Sigma\ \sim\ \mathcal{W}(\ \nu, V)\\ from \\\text{multivariate dist}\\ X \sim\  \mathcal{N}_p(\mu, \Sigma)\end{array}
  }
\end{align}\]</span></p>
<p>Below is the structure of a <strong>multivariate distribution</strong>, namely <strong>X</strong>, with corresponding <strong>covariance</strong> matrix, namely <span class="math inline">\(\Sigma\)</span>:</p>
<p><span class="math display">\[
X = \left[\begin{array}{rrrr}
    x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1p}\\ 
    x_{21} &amp; x_{22} &amp; \cdots &amp; x_{2p} \\ 
    \vdots &amp;  \vdots &amp; \ddots &amp;  \vdots \\ 
    x_{n1} &amp; x_{n2} &amp; \cdots &amp; x_{np} 
    \end{array}\right]_\text{(nxp)}
 \ \ \ 
\mu = \left[\begin{array}{c}\bar{x}_1 \\ \bar{x}_2 \\ \vdots \\ \bar{x}_p \end{array}\right]
= \left[\begin{array}{c}\mu_1 \\ \mu_2 \\ \vdots \\ \mu_p \end{array}\right]_\text{(1xp)}
\]</span></p>
<p><span class="math display">\[
\Sigma_{(pxp)} = \left[\begin{array}{rrrr}
   \sigma^2_{1} &amp; \sigma_{12} &amp; \cdots &amp; \sigma_{1p}\\
   \sigma_{21} &amp; \sigma^2_{2} &amp; \cdots &amp; \sigma_{2p} \\ 
   \vdots &amp;  \vdots &amp;  \ddots &amp;  \vdots \\ 
   \sigma_{p1} &amp; \sigma_{p2} &amp; \cdots &amp; \sigma^2_{p} 
   \end{array}\right]_\text{(pxp)} 
\]</span></p>
<p>Here, we cover three types of <strong>Wishart distributions</strong> using the following illustration:</p>
<p>The first distribution type is the <strong>Central Wishart distribution</strong> which is written as:</p>
<p><span class="math display">\[\begin{align}
V \sim W_p \left(\nu, \Sigma_{(pxp)}\right) \equiv Wishart_p \left(\nu, \Sigma_{(pxp)} \right) 
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li><strong>V</strong> is a <strong>precision</strong> or <strong>inverse</strong> covariance <strong>positive-definite</strong> matrix.</li>
<li><span class="math inline">\(\Sigma_{(pxp)}\)</span> is upper sigma describing a pxp <strong>non-inverse</strong> covariance <strong>positive-definite scale</strong> matrix</li>
<li><strong>p</strong> is number of random variables, e.g.Â p-variate distribution.</li>
<li><span class="math inline">\(\mathbf{\nu}\)</span> is degrees of freedom, where <span class="math inline">\(\nu\)</span> &gt; <strong>p</strong> - 1. Also, <span class="math inline">\(\nu = n\)</span>.</li>
</ul>
<p>The <strong>X</strong> is drawn from a multivariate normal distribution of which its covariance matrix is a positive-definite scale matrix with <strong>p</strong> random variables. For a shorter illustration, we use bivariate normal distribution where <strong>p</strong> = 2.</p>
<p><span class="math display">\[\begin{align}
X \sim \mathcal{N}_2(\mu_{(2)}, \Sigma_{(2x2)}),\ \ \ \ \ \ 
\mu_{(2)} = \left[\begin{array}{cc}\mu_1 \\ \mu_2  \end{array}\right],\ \ \ \ \ \ 
\Sigma_{(2x2)} = 
\underbrace{\left[\begin{array}{cc}
\sigma^2_{11} &amp; \sigma^2_{12} \\ 
\sigma^2_{21} &amp; \sigma^2_{22}  \\ 
\end{array}\right]_{2x2}}_\text{scale matrix}
\end{align}\]</span></p>
<p>Given <strong>X</strong>, we generate a sum square covariance <strong>V</strong> distribution written as:</p>
<p><span class="math display">\[\begin{align}
V = \sum_{i=1}^n\left(x_i -\mu)(x_i - \mu\right)^T \ \ \ \ \ where\ \mu = \bar{x}
\end{align}\]</span></p>
<p>The <strong>PDF</strong> for a <strong>Central Wishart distribution</strong> is expressed as:</p>
<p><span class="math display">\[\begin{align}
f_p(V; \nu, \Sigma_{(pxp)}) = 
    \frac{|V|^{\frac{\nu-p-1}{2}} exp\left[-\frac{1}{2}tr(\Sigma^{-1}V)\right]}
    {2^{\frac{\nu p}{2}}|\Sigma|^{\frac{\nu}{2}}\ \Gamma_p\left(\frac{\nu}{2}\right)}\ \ \ 
\begin{array}{ll}
\text{(see matrix trace in Linear}\\
\text{ Algebra chapter)}\\
\end{array}
\end{align}\]</span></p>
<p>where <strong>multivariate Gamma function</strong> is:</p>
<p><span class="math display">\[\begin{align}
\Gamma_p\left(\frac{\nu}{2}\right) = \pi^{\frac{p(p-1)}{4}} \prod_{i=1}^p \Gamma\left[\frac{\nu - (i - 1)}{2}\right]
\end{align}\]</span></p>
<p>and</p>
<p><span class="math display">\[\begin{align}
mean =  n \times \Sigma_{(pxp)}\ \ \ \ \ \ \ |V| = \text{det}(V)
\end{align}\]</span></p>
<p>The second distribution type is the <strong>Non-Central Wishart distribution</strong> which is written as:</p>
<p><span class="math display">\[\begin{align}
U \sim W_p(\nu, \Sigma_{(pxp)}, \Upsilon) \equiv Wishart_p(\nu, \Sigma_{(pxp)}, \Upsilon) 
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li><strong>U</strong> is a <strong>precision</strong> or <strong>inverse</strong> covariance <strong>positive-definite</strong> matrix.</li>
<li><span class="math inline">\(\Sigma_{(pxp)}\)</span> is a pxp <strong>non-inverse</strong> covariance <strong>positive-definite scale</strong> matrix</li>
<li><strong>p</strong> is the number of random variables, e.g.Â p-variate distribution.</li>
<li><span class="math inline">\(\mathbf{\nu}\)</span> is degrees of freedom, where <span class="math inline">\(\nu\)</span> &gt; <strong>p</strong> - 1.</li>
</ul>
<p>The <strong>X</strong> is drawn from a multivariate normal distribution of which its covariance matrix is a positive-definite scale matrix with <strong>p</strong> random variables. For illustration, we use bivariate normal distribution where <strong>p</strong> = 2.</p>
<p><span class="math display">\[\begin{align}
X \sim \mathcal{N}(\mu_{(2)}, \Sigma_{(2x2)}),\ \ \ \ \ \ 
\mu_{(2)} = \left(\begin{array}{cc}\mu_1 \\ \mu_2  \end{array}\right),\ \ \ \ \ \ 
\Sigma_{(2x2)} = 
\underbrace{\left(\begin{array}{cc}
\sigma^2_{11} &amp; \sigma^2_{12} \\  
\sigma^2_{21} &amp; \sigma^2_{22}  \\ 
\end{array}\right)_{2x2}}_\text{scale matrix}
\end{align}\]</span></p>
<p>Here we extend the <strong>Central Wishart</strong> equation with two other factors:</p>
<p><span class="math display">\[\begin{align}
U = \sum_{i=1}^n X_i X_k^T\ \ \ \ \ \ \ \ \ \ \ \ \ \Upsilon = N\Sigma^{-1}\mu\mu^T
\end{align}\]</span></p>
<p>The <strong>PDF</strong> for a <strong>Non-Central Wishart distribution</strong> is expressed as:</p>
<p><span class="math display">\[\begin{align}
f_p(U; \nu, \Sigma_{(pxp)}, \Upsilon) = 
    \frac{|U|^{\frac{\nu-p-1}{2}} exp\left[-\frac{1}{2}tr(\Sigma^{-1}U)\right]}
    {2^{\frac{\nu p}{2}}|\Sigma|^{\frac{\nu}{2}}\ \Gamma_p\left(\frac{\nu}{2}\right)}exp\left[-\frac{1}{2}\Upsilon\right]{}_0F_1\left(\frac{\nu}{1}; \frac{1}{4}\Upsilon \Sigma^{-1} U\right)
\end{align}\]</span></p>
<p>The third distribution type is the <strong>Inverse Wishart distribution</strong> which is written as:</p>
<p><span class="math display">\[\begin{align}
\Sigma_{pxp} =  \sim \mathcal{IW}_p(\nu, V) \equiv \mathcal{W}_p^{-1}(\nu, V) 
\end{align}\]</span></p>
<p>where</p>
<ul>
<li><strong>V</strong> is a <strong>inverse</strong> covariance <strong>positive-definite scale</strong> matrix.</li>
<li><span class="math inline">\(\Sigma_{(pxp)}\)</span> is a pxp <strong>non-inverse</strong> covariance <strong>positive-definite</strong> matrix</li>
<li><strong>p</strong> is the number of random variables, e.g.Â p-variate distribution.</li>
<li><span class="math inline">\(\mathbf{\nu}\)</span> is degrees of freedom, where <span class="math inline">\(\nu\)</span> &gt; <strong>p</strong> - 1.</li>
</ul>
<p>The <strong>PDF</strong> for an <strong>Inverse Wishart distribution</strong> is expressed as:</p>
<p><span class="math display">\[\begin{align}
f_p(\Sigma_{(pxp)}; \nu,  V) = 
    \frac{ |\Sigma|^{-\frac{\nu +p+1}{2}}  exp\left[-\frac{1}{2}tr(\Sigma^{-1}V)\right]}
    {2^{\frac{\nu p}{2}}|V|^{-\frac{\nu}{2}}\ \Gamma_p\left(\frac{\nu}{2}\right)}
\end{align}\]</span></p>
<p>and</p>
<p><span class="math display">\[\begin{align}
mean = \frac{V}{v - p - 1}
\end{align}\]</span></p>
<p>It may help to point out that to optimize matrix computation, recall <strong>Cholesky factorization</strong> in <strong>Linear Algebra</strong> chapter for <strong>invertible positive definite square matrix</strong> using the upper Cholesky factor. We leave readers to investigate this topic.</p>
</div>
<div id="lkj-distribution" class="section level3">
<h3><span class="header-section-number">5.9.21</span> LKJ distribution </h3>
<p><strong>Lewandowski-Kurowicka-Joe (LKJ) distribution</strong> models a distribution around correlations of parameters, treated as random variables. In <strong>Bayesian inference</strong>, we often deal with events as uncertainty (and thus are treated as random). Such correlation is formed as a positive definite correlation matrix.</p>
<p>We leave readers to investigate this distribution as a modern alternative to <strong>Wishart distribution</strong>.</p>
</div>
<div id="mixture-distribution" class="section level3">
<h3><span class="header-section-number">5.9.22</span> Mixture distribution </h3>
<p>A <strong>Mixture distribution</strong> is a parent distribution formed from the weighted <span class="math inline">\(\lambda k\)</span> combination of more than one child distribution called components of the parent distribution.</p>
<p>Note that it is possible to plot the individual components. Figure  illustrates 3 components (K=3). The overall mixing proportions,<span class="math inline">\(\pi_{k}\)</span>, equates to 1, (<span class="math inline">\(\sum_{k}\pi_k = 1\)</span>).</p>
<p>A mixture model has the following <strong>PDF</strong> formula:</p>
<p><span class="math display">\[\begin{align}
f(x) = \sum_k \pi_k f(x|\theta_k)
\end{align}\]</span></p>
<p>where <span class="math inline">\(\pi_k\)</span> is the mixing proportion.</p>
<p>Below is a sample implementation of a <strong>Mixture distribution</strong> using a built-in <strong>KDE</strong> function called <strong>density()</strong> which we briefly introduce under <strong>Non-parametric distribution</strong> section.</p>

<div class="sourceCode" id="cb76"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb76-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">142</span>)</a>
<a class="sourceLine" id="cb76-2" data-line-number="2">n=<span class="dv">500</span></a>
<a class="sourceLine" id="cb76-3" data-line-number="3">x =<span class="st"> </span><span class="kw">c</span>( <span class="kw">rnorm</span>(<span class="dt">n=</span>n<span class="op">/</span><span class="fl">2.5</span>,  <span class="dv">4</span>,  <span class="fl">1.5</span>),</a>
<a class="sourceLine" id="cb76-4" data-line-number="4">           <span class="kw">rnorm</span>(<span class="dt">n=</span>n<span class="op">/</span><span class="fl">2.5</span>, <span class="fl">7.5</span>, <span class="fl">0.4</span>),</a>
<a class="sourceLine" id="cb76-5" data-line-number="5">           <span class="kw">rnorm</span>(<span class="dt">n=</span>n<span class="op">/</span><span class="fl">2.5</span>, <span class="dv">8</span>, <span class="dv">1</span>))</a>
<a class="sourceLine" id="cb76-6" data-line-number="6"></a>
<a class="sourceLine" id="cb76-7" data-line-number="7"><span class="co"># Plotting the main (parent) mixture distribution</span></a>
<a class="sourceLine" id="cb76-8" data-line-number="8"><span class="kw">plot</span>(<span class="kw">density</span>(x),  </a>
<a class="sourceLine" id="cb76-9" data-line-number="9">     <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>, <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">main=</span><span class="st">&quot;Mixture Density&quot;</span>,</a>
<a class="sourceLine" id="cb76-10" data-line-number="10">     <span class="dt">xlab=</span><span class="st">&quot;Three Independent Normal Distributions&quot;</span>)</a>
<a class="sourceLine" id="cb76-11" data-line-number="11"><span class="kw">grid</span>()</a>
<a class="sourceLine" id="cb76-12" data-line-number="12"></a>
<a class="sourceLine" id="cb76-13" data-line-number="13"><span class="co"># Let us use scale for plotting convenience only</span></a>
<a class="sourceLine" id="cb76-14" data-line-number="14"><span class="co"># to fit the components along the mixture distribution</span></a>
<a class="sourceLine" id="cb76-15" data-line-number="15">scale=<span class="fl">3.5</span></a>
<a class="sourceLine" id="cb76-16" data-line-number="16"></a>
<a class="sourceLine" id="cb76-17" data-line-number="17"><span class="co"># Plotting the 1st component distribution</span></a>
<a class="sourceLine" id="cb76-18" data-line-number="18">x =<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n=</span>n<span class="op">/</span><span class="fl">2.5</span>,  <span class="dv">4</span>,  <span class="fl">1.5</span>)</a>
<a class="sourceLine" id="cb76-19" data-line-number="19">c1 =<span class="st"> </span><span class="kw">curve</span>(<span class="kw">dnorm</span>(x, <span class="dv">4</span>, <span class="fl">1.5</span>)<span class="op">/</span>scale, <span class="dt">add=</span><span class="ot">TRUE</span>, <span class="dt">col=</span><span class="st">&quot;green&quot;</span> )</a>
<a class="sourceLine" id="cb76-20" data-line-number="20"></a>
<a class="sourceLine" id="cb76-21" data-line-number="21"><span class="co"># Plotting the 2nd component distribution</span></a>
<a class="sourceLine" id="cb76-22" data-line-number="22">x =<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n=</span>n<span class="op">/</span><span class="fl">2.5</span>, <span class="fl">7.5</span> , <span class="fl">0.4</span>)</a>
<a class="sourceLine" id="cb76-23" data-line-number="23">c2 =<span class="kw">curve</span>(<span class="kw">dnorm</span>(x, <span class="fl">7.5</span>, <span class="fl">0.4</span>)<span class="op">/</span>scale, <span class="dt">add=</span><span class="ot">TRUE</span>, <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>  )</a>
<a class="sourceLine" id="cb76-24" data-line-number="24"></a>
<a class="sourceLine" id="cb76-25" data-line-number="25"><span class="co"># Plotting the 3rd component distribution</span></a>
<a class="sourceLine" id="cb76-26" data-line-number="26">x =<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n=</span>n<span class="op">/</span><span class="fl">2.5</span>, <span class="dv">8</span>, <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb76-27" data-line-number="27">c3 =<span class="st"> </span><span class="kw">curve</span>(<span class="kw">dnorm</span>(x, <span class="dv">8</span>, <span class="dv">1</span>)<span class="op">/</span>scale, <span class="dt">add=</span><span class="ot">TRUE</span>, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>  )</a>
<a class="sourceLine" id="cb76-28" data-line-number="28"></a>
<a class="sourceLine" id="cb76-29" data-line-number="29"><span class="kw">rug</span>(<span class="kw">rnorm</span>(<span class="dt">n=</span><span class="dv">15</span>,  <span class="dv">4</span>,  <span class="fl">1.5</span>), <span class="dt">col=</span><span class="st">&quot;brown&quot;</span>)</a>
<a class="sourceLine" id="cb76-30" data-line-number="30"><span class="kw">rug</span>(<span class="kw">rnorm</span>(<span class="dt">n=</span><span class="dv">15</span>,  <span class="fl">7.5</span>,  <span class="fl">0.4</span>), <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>)</a>
<a class="sourceLine" id="cb76-31" data-line-number="31"><span class="kw">rug</span>(<span class="kw">rnorm</span>(<span class="dt">n=</span><span class="dv">15</span>,  <span class="dv">8</span>,  <span class="dv">1</span>), <span class="dt">col=</span><span class="st">&quot;red&quot;</span>)</a>
<a class="sourceLine" id="cb76-32" data-line-number="32"></a>
<a class="sourceLine" id="cb76-33" data-line-number="33"><span class="kw">legend</span>(<span class="st">&quot;topleft&quot;</span>, <span class="dt">inset=</span>.<span class="dv">02</span>, </a>
<a class="sourceLine" id="cb76-34" data-line-number="34">   <span class="kw">c</span>( <span class="st">&quot;Mixture Density&quot;</span>, </a>
<a class="sourceLine" id="cb76-35" data-line-number="35">      <span class="kw">expression</span>(<span class="kw">paste</span>(<span class="st">&quot;1st Component Density (&quot;</span>, mu,<span class="st">&quot; = 4,&quot;</span>, </a>
<a class="sourceLine" id="cb76-36" data-line-number="36">                       sigma<span class="op">^</span><span class="dv">2</span>, <span class="st">&quot; = 1.5)&quot;</span>)),</a>
<a class="sourceLine" id="cb76-37" data-line-number="37">      <span class="kw">expression</span>(<span class="kw">paste</span>(<span class="st">&quot;2nd Component Density (&quot;</span>, mu,<span class="st">&quot; = 7.5,&quot;</span>, </a>
<a class="sourceLine" id="cb76-38" data-line-number="38">                       sigma<span class="op">^</span><span class="dv">2</span>, <span class="st">&quot; = 0.4)&quot;</span>)),</a>
<a class="sourceLine" id="cb76-39" data-line-number="39">      <span class="kw">expression</span>(<span class="kw">paste</span>(<span class="st">&quot;34d Component Density (&quot;</span>, mu,<span class="st">&quot; = 8,&quot;</span>, </a>
<a class="sourceLine" id="cb76-40" data-line-number="40">                       sigma<span class="op">^</span><span class="dv">2</span>, <span class="st">&quot; = 1)&quot;</span>))</a>
<a class="sourceLine" id="cb76-41" data-line-number="41">      ),</a>
<a class="sourceLine" id="cb76-42" data-line-number="42">   <span class="dt">fill=</span><span class="kw">c</span>(<span class="st">&quot;navyblue&quot;</span>, <span class="st">&quot;brown&quot;</span>,<span class="st">&quot;darksalmon&quot;</span>, <span class="st">&quot;red&quot;</span>), </a>
<a class="sourceLine" id="cb76-43" data-line-number="43">   <span class="dt">horiz=</span><span class="ot">FALSE</span>, <span class="dt">cex=</span><span class="fl">0.8</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:mixture1b"></span>
<img src="DS_files/figure-html/mixture1b-1.png" alt="Mixture Distribution" width="80%" />
<p class="caption">
Figure 5.36: Mixture Distribution
</p>
</div>

<p>Note that <strong>mixture gaussian models</strong> are covered under <strong>Expectation-Maximization (EM)</strong> section in <strong>Bayesian Computation</strong> chapter as extension to <strong>mixture distribution</strong> discussion.</p>
</div>
<div id="non-parametric-distribution" class="section level3">
<h3><span class="header-section-number">5.9.23</span> Non-parametric distribution </h3>
<p>The previous section discusses about common <strong>PDFs</strong> and <strong>CDFs</strong>. For example, recall the following normal <strong>PDF</strong> function.</p>
<p><span class="math display">\[\begin{align}
f(x; \mu, \sigma) = \frac{1}{\sqrt{2 \pi \sigma^2 }}e^{\frac{(x-\mu)^2}{2\sigma^2}}
\end{align}\]</span></p>
<p>The function is parametric, e.g.Â for <strong>normal</strong> distribution, we use the <strong>mean</strong> and <strong>variance</strong> parameters. In a case in which our data set is not able to follow any of the formal distributions that we discussed to represent specific <strong>PDFs</strong> and <strong>CDFs</strong>, we then resort to an estimation of a distribution. For that, we want to simulate a <strong>non-parametric</strong> density function by which our data set can follow some <strong>estimated</strong> distribution. To do that, we use what we call <strong>Kernel Density Estimators (KDE)</strong>. <strong>KDE</strong> and the math involved are introduced in <strong>Numerical Linear Algebra</strong> chapter under <strong>Kernel Smoothing</strong> along with a list of <strong>kernel functions and kernel estimators</strong>.</p>
<p>Our guide to being able to construct such an estimated <strong>PDF</strong> is by visualizing a histogram and perhaps drawing a curve that matches it.</p>
<p>Here is a naive implementation of <strong>KDE</strong> (see Figure ) to show the curve and histogram. For our implementation of the function <strong>K()</strong>, refer to <strong>Numerical Linear Algebra</strong> chapter under <strong>Kernel Smoothing</strong>.</p>

<div class="sourceCode" id="cb77"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb77-1" data-line-number="1">kde &lt;-<span class="st"> </span><span class="cf">function</span>( x,  h, kernel) {</a>
<a class="sourceLine" id="cb77-2" data-line-number="2">      X =<span class="st"> </span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">10</span>, <span class="dv">15</span>, <span class="dt">length.out =</span> <span class="dv">200</span>)</a>
<a class="sourceLine" id="cb77-3" data-line-number="3">      m =<span class="st"> </span><span class="kw">length</span>(X); n =<span class="st"> </span><span class="kw">length</span>(x)</a>
<a class="sourceLine" id="cb77-4" data-line-number="4">      y =<span class="st"> </span><span class="kw">c</span>()</a>
<a class="sourceLine" id="cb77-5" data-line-number="5">      <span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>m) {</a>
<a class="sourceLine" id="cb77-6" data-line-number="6">          w =<span class="st"> </span><span class="kw">c</span>()</a>
<a class="sourceLine" id="cb77-7" data-line-number="7">          <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n) {</a>
<a class="sourceLine" id="cb77-8" data-line-number="8">              x_ =<span class="st"> </span>(<span class="dv">1</span> <span class="op">/</span><span class="st"> </span>h) <span class="op">*</span><span class="st"> </span><span class="kw">K</span> ( ( X[k] <span class="op">-</span><span class="st"> </span>x[i] ) <span class="op">/</span><span class="st"> </span>h , kernel )</a>
<a class="sourceLine" id="cb77-9" data-line-number="9">              w =<span class="st"> </span><span class="kw">c</span>(w, x_ )</a>
<a class="sourceLine" id="cb77-10" data-line-number="10">          }</a>
<a class="sourceLine" id="cb77-11" data-line-number="11">          y =<span class="st"> </span><span class="kw">c</span>(y, <span class="kw">sum</span>(w) <span class="op">/</span><span class="st"> </span>n  )</a>
<a class="sourceLine" id="cb77-12" data-line-number="12">      }</a>
<a class="sourceLine" id="cb77-13" data-line-number="13">      <span class="kw">list</span>(<span class="st">&quot;x&quot;</span>=X, <span class="st">&quot;y&quot;</span> =<span class="st"> </span>y)  </a>
<a class="sourceLine" id="cb77-14" data-line-number="14">}</a>
<a class="sourceLine" id="cb77-15" data-line-number="15">x =<span class="st"> </span><span class="kw">c</span>(  <span class="fl">-3.0</span>, <span class="fl">1.0</span>, <span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">7</span>, <span class="dv">9</span>, <span class="dv">10</span> )</a>
<a class="sourceLine" id="cb77-16" data-line-number="16"><span class="co"># Silverman Rule of Thumb (optimal bandwidth)</span></a>
<a class="sourceLine" id="cb77-17" data-line-number="17">h =<span class="st"> </span><span class="kw">bw.nrd</span>(x) <span class="op">-</span><span class="st"> </span><span class="fl">0.2</span></a>
<a class="sourceLine" id="cb77-18" data-line-number="18">kde.our.model =<span class="st"> </span><span class="kw">kde</span>( x, h, <span class="st">&quot;normal&quot;</span>) </a>
<a class="sourceLine" id="cb77-19" data-line-number="19">kde.sj.model =<span class="st"> </span><span class="kw">density</span>(x, <span class="dt">bw=</span><span class="st">&quot;sj&quot;</span>) <span class="co"># Sheather and Jones (1991)</span></a>
<a class="sourceLine" id="cb77-20" data-line-number="20">kde.nrd.model =<span class="st"> </span><span class="kw">density</span>(x, <span class="dt">bw=</span><span class="st">&quot;nrd&quot;</span>) <span class="co"># silverman rule</span></a>
<a class="sourceLine" id="cb77-21" data-line-number="21"></a>
<a class="sourceLine" id="cb77-22" data-line-number="22"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim =</span> <span class="kw">range</span>(<span class="op">-</span><span class="dv">5</span>, <span class="dv">12</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="dv">0</span>, <span class="fl">3.2</span> ),</a>
<a class="sourceLine" id="cb77-23" data-line-number="23">     <span class="dt">xlab=</span><span class="st">&quot;x-axis&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;y-axis&quot;</span>,</a>
<a class="sourceLine" id="cb77-24" data-line-number="24">     <span class="dt">main=</span><span class="st">&quot;Kernel Density Estimation&quot;</span>)</a>
<a class="sourceLine" id="cb77-25" data-line-number="25"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>)</a>
<a class="sourceLine" id="cb77-26" data-line-number="26"></a>
<a class="sourceLine" id="cb77-27" data-line-number="27"><span class="kw">hist</span>(x, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb77-28" data-line-number="28">scale =<span class="st"> </span><span class="dv">28</span></a>
<a class="sourceLine" id="cb77-29" data-line-number="29"><span class="kw">lines</span>(kde.our.model<span class="op">$</span>x, kde.our.model<span class="op">$</span>y <span class="op">*</span><span class="st"> </span>scale, <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>, </a>
<a class="sourceLine" id="cb77-30" data-line-number="30">      <span class="dt">lwd=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb77-31" data-line-number="31"><span class="kw">lines</span>(kde.sj.model<span class="op">$</span>x, kde.sj.model<span class="op">$</span>y <span class="op">*</span><span class="st"> </span>scale, <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, </a>
<a class="sourceLine" id="cb77-32" data-line-number="32">      <span class="dt">lwd=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb77-33" data-line-number="33"><span class="kw">lines</span>(kde.nrd.model<span class="op">$</span>x, kde.nrd.model<span class="op">$</span>y <span class="op">*</span><span class="st"> </span>scale, <span class="dt">col=</span><span class="st">&quot;brown&quot;</span>, </a>
<a class="sourceLine" id="cb77-34" data-line-number="34">      <span class="dt">lwd=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb77-35" data-line-number="35"></a>
<a class="sourceLine" id="cb77-36" data-line-number="36">n =<span class="st"> </span><span class="kw">length</span>(x)</a>
<a class="sourceLine" id="cb77-37" data-line-number="37"><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n) {</a>
<a class="sourceLine" id="cb77-38" data-line-number="38">    mu =<span class="st"> </span>x[i]</a>
<a class="sourceLine" id="cb77-39" data-line-number="39">    x_ =<span class="st"> </span><span class="kw">seq</span>( mu <span class="op">-</span><span class="st"> </span><span class="dv">3</span>, mu <span class="op">+</span><span class="st"> </span><span class="dv">3</span>, <span class="dt">length.out =</span> <span class="dv">50</span>)</a>
<a class="sourceLine" id="cb77-40" data-line-number="40">    y_ =<span class="st"> </span><span class="kw">dnorm</span>(x_, <span class="dt">mean=</span>mu, <span class="dt">sd =</span> <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb77-41" data-line-number="41">    <span class="kw">lines</span>(x_, y_, <span class="dt">col=</span><span class="st">&quot;brown&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb77-42" data-line-number="42">}</a>
<a class="sourceLine" id="cb77-43" data-line-number="43"><span class="kw">rug</span>(x, <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>)</a>
<a class="sourceLine" id="cb77-44" data-line-number="44"><span class="kw">legend</span>(<span class="op">-</span><span class="dv">5</span>, <span class="dv">3</span>, </a>
<a class="sourceLine" id="cb77-45" data-line-number="45">    <span class="dt">legend=</span><span class="kw">c</span>( <span class="st">&quot;our kde (h=1.5)&quot;</span>, </a>
<a class="sourceLine" id="cb77-46" data-line-number="46">              <span class="st">&quot;built-in density(bw=sj)&quot;</span>,</a>
<a class="sourceLine" id="cb77-47" data-line-number="47">              <span class="st">&quot;build-in density(bw=nrd)&quot;</span>),</a>
<a class="sourceLine" id="cb77-48" data-line-number="48">    <span class="dt">col=</span><span class="kw">c</span>( <span class="st">&quot;navyblue&quot;</span>, <span class="st">&quot;darksalmon&quot;</span>, <span class="st">&quot;brown&quot;</span>), <span class="dt">lty=</span><span class="dv">1</span>,  <span class="dt">cex=</span><span class="fl">0.8</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:kde"></span>
<img src="DS_files/figure-html/kde-1.png" alt="Kernel Density Estimation" width="80%" />
<p class="caption">
Figure 5.37: Kernel Density Estimation
</p>
</div>

<p>Notice that our implementation of KDE exactly matches the output of the built-in R function <strong>density()</strong>. The bandwidth is intentionally adjusted with an offset of 0.2 so that the curve produced by our KDE implementation is demonstratively visible and does not overlap with the built-in estimate.</p>
<p>For <strong>bandwidth selection</strong>, we can use the built-in R function <strong>bw.&lt;choices&gt;()</strong>:</p>
<div class="sourceCode" id="cb78"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb78-1" data-line-number="1">(<span class="dt">optimal_bandwidth =</span> <span class="kw">bw.nrd</span>(x)) <span class="co"># Silverman&#39;s Rule of Thumb</span></a></code></pre></div>
<pre><code>## [1] 2.038978</code></pre>
<p>Or we can use <strong>unbiased cross-validation</strong> with a list of random bandwidths between 2 and 5. We use a tolerance scaled at 0.1 (using the sample provided in the documentation of the built-in R function <strong>bw.ucv()</strong>):</p>
<div class="sourceCode" id="cb80"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb80-1" data-line-number="1"><span class="co"># unbiased cross-validation </span></a>
<a class="sourceLine" id="cb80-2" data-line-number="2">lower =<span class="st"> </span><span class="dv">2</span>; upper =<span class="st"> </span><span class="dv">5</span></a>
<a class="sourceLine" id="cb80-3" data-line-number="3">(<span class="dt">optimal_h =</span> <span class="kw">bw.ucv</span>(x, <span class="dt">nb =</span> <span class="dv">1000</span>, <span class="dt">lower =</span> <span class="fl">0.1</span> <span class="op">*</span><span class="st"> </span>upper, <span class="dt">upper =</span> upper, </a>
<a class="sourceLine" id="cb80-4" data-line-number="4">                    <span class="dt">tol =</span> <span class="fl">0.1</span> <span class="op">*</span><span class="st"> </span>lower))</a></code></pre></div>
<pre><code>## [1] 4.730645</code></pre>
</div>
<div id="multi-dimensional-density" class="section level3">
<h3><span class="header-section-number">5.9.24</span> Multi-dimensional Density </h3>
<p>Most of the <strong>parametric</strong> distributions that we discussed are <strong>unimodal</strong> - a distribution with only one peak. In <strong>mixture distribution</strong>, we begin to show <strong>multimodal</strong> characteristics of the distribution in which we see multiple peaks. The individual peak follows an individual normal distribution. Then finally, in <strong>KDE</strong> we continue to show <strong>multimodal</strong> behavior; however, high peaks represent stacks of weights (summation of weights) that are computed based on a choice of <strong>kernel functions</strong>. </p>
<p>Whether the distribution is <strong>unimodal</strong> or <strong>multimodal</strong>, it represents a <strong>univariate</strong> distribution - meaning, we deal with only one random independent variable.</p>
<p>In this section, we show two examples of <strong>multivariate</strong> distribution:</p>
<p><strong>First</strong>, we introduce <strong>multivariate unimodal distribution</strong> which deals with multiple independent variables with one peak.</p>
<p>We start by using a 3rd-party library called <strong>mvtnorm</strong> and then generate a data set that follows a <strong>multivariate normal distribution</strong> with noise:</p>

<div class="sourceCode" id="cb82"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb82-1" data-line-number="1"><span class="kw">library</span>(mvtnorm)</a>
<a class="sourceLine" id="cb82-2" data-line-number="2"><span class="kw">set.seed</span>(<span class="dv">142</span>)</a>
<a class="sourceLine" id="cb82-3" data-line-number="3">sample_size =<span class="st"> </span>n =<span class="st"> </span><span class="dv">200</span></a>
<a class="sourceLine" id="cb82-4" data-line-number="4">e =<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n=</span>sample_size, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span><span class="dv">1</span>) <span class="op">/</span><span class="st"> </span><span class="dv">30</span>  <span class="co"># Noise/Gaussian Residual</span></a>
<a class="sourceLine" id="cb82-5" data-line-number="5">x =<span class="st">  </span><span class="kw">sample</span>(<span class="kw">seq</span>(<span class="op">-</span><span class="dv">5</span>,<span class="dv">5</span>), <span class="dt">size=</span>n, <span class="dt">replace=</span><span class="ot">TRUE</span>) </a>
<a class="sourceLine" id="cb82-6" data-line-number="6">y =<span class="st">  </span><span class="kw">sample</span>(<span class="kw">seq</span>(<span class="op">-</span><span class="dv">5</span>,<span class="dv">5</span>), <span class="dt">size=</span>n, <span class="dt">replace=</span><span class="ot">TRUE</span>) </a>
<a class="sourceLine" id="cb82-7" data-line-number="7">mu =<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>,<span class="dv">2</span>); sigma =<span class="st"> </span><span class="kw">diag</span>(<span class="dv">1</span>,<span class="dv">2</span>)</a>
<a class="sourceLine" id="cb82-8" data-line-number="8">z =<span class="st"> </span><span class="kw">dmvnorm</span>(<span class="kw">cbind</span>(x, y), <span class="dt">mean =</span> mu,  <span class="dt">sigma=</span>sigma ) <span class="op">+</span><span class="st"> </span>e</a></code></pre></div>

<p>We then use an R function called <strong>loess()</strong> to fit a two-dimensional model to our data using a span of 0.5 and a polynomial degree of 2 - a parabolic polynomial.</p>

<div class="sourceCode" id="cb83"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb83-1" data-line-number="1"><span class="co"># Because we added noise, our goal is to demonstrate how to fit</span></a>
<a class="sourceLine" id="cb83-2" data-line-number="2"><span class="co"># a 2D loess model.</span></a>
<a class="sourceLine" id="cb83-3" data-line-number="3">loess.model =<span class="st"> </span><span class="kw">loess</span>(z <span class="op">~</span><span class="st"> </span>x <span class="op">+</span><span class="st"> </span>y, <span class="dt">degree=</span><span class="dv">2</span>, <span class="dt">span=</span><span class="fl">0.5</span>)</a>
<a class="sourceLine" id="cb83-4" data-line-number="4"><span class="co"># Perform smooth fit by prediction</span></a>
<a class="sourceLine" id="cb83-5" data-line-number="5">x =<span class="st"> </span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">5</span>,<span class="dv">5</span>, <span class="dt">length.out =</span> <span class="dv">50</span>)</a>
<a class="sourceLine" id="cb83-6" data-line-number="6">y =<span class="st"> </span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">5</span>,<span class="dv">5</span>, <span class="dt">length.out =</span> <span class="dv">50</span>)</a>
<a class="sourceLine" id="cb83-7" data-line-number="7">xy.grid =<span class="st"> </span><span class="kw">as.matrix</span>( <span class="kw">expand.grid</span>(x,y))</a>
<a class="sourceLine" id="cb83-8" data-line-number="8">z.fit =<span class="st"> </span><span class="kw">predict</span>(loess.model, <span class="dt">newdata =</span> xy.grid)</a>
<a class="sourceLine" id="cb83-9" data-line-number="9">z.fit =<span class="st"> </span><span class="kw">matrix</span>(<span class="dt">data =</span> z.fit, <span class="dt">nrow=</span><span class="kw">length</span>(x), <span class="dt">ncol=</span><span class="kw">length</span>(y))</a></code></pre></div>

<p>Finally, we plot a <strong>3D perspective view</strong> (See Figure ).</p>
<div class="sourceCode" id="cb84"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb84-1" data-line-number="1"><span class="kw">persp</span>(x, y, z.fit, <span class="dt">phi=</span><span class="dv">30</span>, <span class="dt">theta=</span><span class="dv">25</span>, </a>
<a class="sourceLine" id="cb84-2" data-line-number="2">      <span class="dt">xlim=</span><span class="kw">range</span>(<span class="op">-</span><span class="dv">5</span>,<span class="dv">5</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="op">-</span><span class="dv">5</span>,<span class="dv">5</span>),</a>
<a class="sourceLine" id="cb84-3" data-line-number="3">      <span class="dt">main=</span><span class="st">&quot;Fitting LOESS with Multi-Dimensional data&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:multiloess"></span>
<img src="DS_files/figure-html/multiloess-1.png" alt="Fitting LOESS with Multi-Dimensional data" width="100%" />
<p class="caption">
Figure 5.38: Fitting LOESS with Multi-Dimensional data
</p>
</div>
<p>In <strong>Statistical Computation</strong>, we extend our discussion on <strong>LOESS</strong> under <strong>Statistical Regression and Statistical Inference</strong>.</p>
<p><strong>Second</strong>, we introduce <strong>multivariate multimodal distribution</strong> which deals with multiple independent variables with multiple peaks.</p>
<p>We start by using a 3rd-party library called <strong>KernSmooth</strong> and then construct some random sample datasets.</p>
<div class="sourceCode" id="cb85"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb85-1" data-line-number="1"><span class="kw">library</span>(KernSmooth)</a></code></pre></div>
<pre><code>## KernSmooth 2.23 loaded
## Copyright M. P. Wand 1997-2009</code></pre>
<div class="sourceCode" id="cb87"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb87-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">142</span>)</a>
<a class="sourceLine" id="cb87-2" data-line-number="2">sample_size =<span class="st"> </span>n =<span class="st"> </span><span class="dv">40</span> </a>
<a class="sourceLine" id="cb87-3" data-line-number="3">y =<span class="st">  </span><span class="kw">sample</span>(<span class="kw">seq</span>(<span class="dv">1</span>,<span class="dv">9</span>), <span class="dt">size=</span>sample_size, <span class="dt">replace=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb87-4" data-line-number="4">x =<span class="st">  </span><span class="kw">sample</span>(<span class="kw">seq</span>(<span class="dv">1</span>,<span class="dv">9</span>), <span class="dt">size=</span>sample_size, <span class="dt">replace=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb87-5" data-line-number="5">data =<span class="st"> </span><span class="kw">cbind</span>(x, y)</a></code></pre></div>
<p>We then use an R function called <strong>bkde2d()</strong> to fit a two-dimensional <strong>KDE</strong> model to our data with an optimal bandwidth obtained from <strong>bw.nrd()</strong>. Note that <strong>bkde2d()</strong> uses a <strong>bivariate gaussian kernel</strong>. </p>
<div class="sourceCode" id="cb88"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb88-1" data-line-number="1">h =<span class="st"> </span><span class="kw">bw.nrd</span>(x)</a>
<a class="sourceLine" id="cb88-2" data-line-number="2">kde.grid =<span class="st"> </span><span class="kw">bkde2D</span>(<span class="dt">x =</span> data, <span class="dt">bandwidth=</span> h)</a></code></pre></div>
<p>Finally, let us plot a <strong>3D perspective view</strong> of our <strong>multi-dimensional KDE</strong> distribution (See Figure ).</p>
<div class="sourceCode" id="cb89"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb89-1" data-line-number="1"><span class="kw">persp</span>(kde.grid<span class="op">$</span>fhat, </a>
<a class="sourceLine" id="cb89-2" data-line-number="2">       <span class="dt">phi=</span><span class="dv">30</span>, <span class="dt">theta=</span><span class="dv">25</span>,</a>
<a class="sourceLine" id="cb89-3" data-line-number="3">       <span class="dt">zlab =</span> <span class="st">&quot;z-axis&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;y-axis&quot;</span>, <span class="dt">xlab =</span> <span class="st">&quot;x-axis&quot;</span>,</a>
<a class="sourceLine" id="cb89-4" data-line-number="4">       <span class="dt">main=</span><span class="st">&quot;Multi-dimensional density estimate (3D perspective)&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:kde2dpersp"></span>
<img src="DS_files/figure-html/kde2dpersp-1.png" alt="Multi-dimensional KDE (3D Perspective)" width="100%" />
<p class="caption">
Figure 5.39: Multi-dimensional KDE (3D Perspective)
</p>
</div>
<p>Additionally, we also can show the <strong>contour</strong> of our <strong>3D view</strong> (See Figure )</p>
<div class="sourceCode" id="cb90"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb90-1" data-line-number="1"><span class="kw">contour</span>(kde.grid<span class="op">$</span>x1, kde.grid<span class="op">$</span>x2, kde.grid<span class="op">$</span>fhat,</a>
<a class="sourceLine" id="cb90-2" data-line-number="2">        <span class="dt">xlab=</span><span class="st">&quot;x-axis&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;y-axis&quot;</span>,</a>
<a class="sourceLine" id="cb90-3" data-line-number="3">        <span class="dt">main=</span><span class="st">&quot;Multi-dimensional density estimate (Contour)&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:kde2dcontour"></span>
<img src="DS_files/figure-html/kde2dcontour-1.png" alt="Multi-dimensional KDE (Contour)" width="80%" />
<p class="caption">
Figure 5.40: Multi-dimensional KDE (Contour)
</p>
</div>
</div>
</div>
<div id="summary-3" class="section level2">
<h2><span class="header-section-number">5.10</span> Summary</h2>
<p>Let us review the list of distributions we covered in this chapter, along with built-in R packages that we can use in practice later.</p>

<table>
<caption><span id="tab:sumdist">Table 5.1: </span>Stochastic Distribution</caption>
<thead>
<tr class="header">
<th align="left">Distribution</th>
<th align="left">Sampling</th>
<th align="left">Density</th>
<th align="left">Cumulative</th>
<th align="left">Quartile</th>
<th align="left">Notation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Binomial</td>
<td align="left">rbinom</td>
<td align="left">dbinom</td>
<td align="left">pbinom</td>
<td align="left">qbinom</td>
<td align="left">X <span class="math inline">\(\sim\)</span> Bin(n, <span class="math inline">\(\rho\)</span>)</td>
</tr>
<tr class="even">
<td align="left">Multinomial</td>
<td align="left">rmultinom</td>
<td align="left">dmultinom</td>
<td align="left">pmultinom</td>
<td align="left">qmultinom</td>
<td align="left">X <span class="math inline">\(\sim\)</span> Multi(n, <span class="math inline">\(\rho\)</span>)</td>
</tr>
<tr class="odd">
<td align="left">Geometric</td>
<td align="left">rgeom</td>
<td align="left">dgeom</td>
<td align="left">pgeom</td>
<td align="left">qgeom</td>
<td align="left">X <span class="math inline">\(\sim\)</span> Geo(<span class="math inline">\(\rho\)</span>)</td>
</tr>
<tr class="even">
<td align="left">Beta</td>
<td align="left">rbeta</td>
<td align="left">dbeta</td>
<td align="left">pbeta</td>
<td align="left">qbeta</td>
<td align="left">X <span class="math inline">\(\sim\)</span> Beta(<span class="math inline">\(\alpha\)</span>, <span class="math inline">\(\beta\)</span>)</td>
</tr>
<tr class="odd">
<td align="left">Exponential</td>
<td align="left">rexp</td>
<td align="left">dexp</td>
<td align="left">pexp</td>
<td align="left">qexp</td>
<td align="left">X <span class="math inline">\(\sim\)</span> Expo(<span class="math inline">\(\lambda\)</span>)</td>
</tr>
<tr class="even">
<td align="left">Gamma</td>
<td align="left">rgamma</td>
<td align="left">dgamma</td>
<td align="left">pgamma</td>
<td align="left">qgamma</td>
<td align="left">X <span class="math inline">\(\sim\)</span> Gamma(<span class="math inline">\(\alpha\)</span>, <span class="math inline">\(\beta\)</span>)</td>
</tr>
<tr class="odd">
<td align="left">Weibull</td>
<td align="left">rweibull</td>
<td align="left">dweibull</td>
<td align="left">pweibull</td>
<td align="left">qweibull</td>
<td align="left">X <span class="math inline">\(\sim\)</span> Weib(<span class="math inline">\(\alpha\)</span>, <span class="math inline">\(\beta\)</span>)</td>
</tr>
<tr class="even">
<td align="left">Poisson</td>
<td align="left">rpois</td>
<td align="left">dpois</td>
<td align="left">ppois</td>
<td align="left">qpois</td>
<td align="left">X <span class="math inline">\(\sim\)</span> Pois(<span class="math inline">\(\lambda\)</span>)</td>
</tr>
<tr class="odd">
<td align="left">Normal</td>
<td align="left">rnorm</td>
<td align="left">dnorm</td>
<td align="left">pnorm</td>
<td align="left">qrnorm</td>
<td align="left">X <span class="math inline">\(\sim\)</span> N(<span class="math inline">\(\mu\)</span>, <span class="math inline">\(\sigma^2\)</span>)</td>
</tr>
<tr class="even">
<td align="left">Log-normal</td>
<td align="left">rlnorm</td>
<td align="left">dlnorm</td>
<td align="left">plnorm</td>
<td align="left">qlnorm</td>
<td align="left">X <span class="math inline">\(\sim\)</span> ln N(<span class="math inline">\(\mu\)</span>, <span class="math inline">\(\sigma^2\)</span>)</td>
</tr>
<tr class="odd">
<td align="left">T</td>
<td align="left">rt</td>
<td align="left">dt</td>
<td align="left">pt</td>
<td align="left">qt</td>
<td align="left">X <span class="math inline">\(\sim\)</span> T(<span class="math inline">\(\nu\)</span>)</td>
</tr>
<tr class="even">
<td align="left">F</td>
<td align="left">rf</td>
<td align="left">df</td>
<td align="left">pf</td>
<td align="left">qf</td>
<td align="left">X <span class="math inline">\(\sim F(\nu_1, \nu_2)\)</span></td>
</tr>
<tr class="odd">
<td align="left">Chi-Squared</td>
<td align="left">rchisq</td>
<td align="left">dchisq</td>
<td align="left">pchisq</td>
<td align="left">qchisq</td>
<td align="left">X <span class="math inline">\(\sim X^2(k)\)</span></td>
</tr>
<tr class="even">
<td align="left">Uniform</td>
<td align="left">runif</td>
<td align="left">dunif</td>
<td align="left">punif</td>
<td align="left">qunif</td>
<td align="left">X <span class="math inline">\(\sim U(a,b)\)</span></td>
</tr>
<tr class="odd">
<td align="left">Wilcoxon</td>
<td align="left">rwilcox</td>
<td align="left">dwilcox</td>
<td align="left">pwilcox</td>
<td align="left">qwilcox</td>
<td align="left">X <span class="math inline">\(\sim RankSum(m,n)\)</span></td>
</tr>
<tr class="even">
<td align="left">Wilcoxon</td>
<td align="left">rsignrank</td>
<td align="left">dsignrank</td>
<td align="left">psignrank</td>
<td align="left">qsignrank</td>
<td align="left">X <span class="math inline">\(\sim SignedRank(n)\)</span></td>
</tr>
<tr class="odd">
<td align="left">Logis</td>
<td align="left">rlogis</td>
<td align="left">dlogis</td>
<td align="left">plogis</td>
<td align="left">qlogis</td>
<td align="left">X <span class="math inline">\(\sim Logis(l,s)\)</span></td>
</tr>
</tbody>
</table>

<p>The build-in R packages allow us to analyze the different distributions. Each distribution is prefixed with the following letters: r, d, p q.</p>
<ul>
<li>r stands for random values.</li>
<li>d stands for density/mass.</li>
<li>p stands for probability distribution corresponding to its quartile (q).</li>
<li>q stands for quartile which corresponds to a probability distribution (p).</li>
</ul>
<p>Therefore, to generate random values for a <strong>Binomial distribution</strong>, we use <strong>rbinom</strong>. We use <strong>dbinom</strong> to get the <strong>PDF</strong>. We use <strong>pbinom</strong> to get the <strong>CDF</strong>. And we use <strong>qbinom</strong> to get the value <strong>x</strong> (or the quartile).</p>
<p>Note that four distributions (T-distribution, F-distribution, Chi-Squared distribution, Uniform) are covered in more detail in the next chapter under <strong>Statistics Computation</strong>.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="numerical-calculus.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="statistics.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "sepia",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["DS.pdf", "DS.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
