<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 5 Probability and Distribution | The Power and Art of Approximation</title>
  <meta name="description" content="Enthused by the promising future of self-learning machines and the continuous advancement of technology, we write this book to cover a compendium of analytical and numerical techniques conflated into a common idea that highlights the fundamental requirements of Data Science and Machine Learning (ML) Engineering. In this book, we review and give brief insights into numerous fundamental ideas around methods of approximation conceived by great experts. We aim to share them with those new to Data Science who are just beginning to develop an inclination toward this field but may not know where to begin. In addition, we hope to introduce some essential aspects of Data Science in a more progressive and possibly structured manner. This book avoids being specific to a target audience depending on interest. The premise is that Data Science can be for everybody, whether one is an engineer, a researcher within a particular domain, or, for that matter, an undergraduate student just trying to get into this field. While we note that our common theme across the book is intuition, contemplating more on basic operations than mathematical rigor, it is essential to revive our understanding of mathematical concepts first. That is founded upon the idea that we express most of what we do in Data Science in the language of mathematics, more numerically inclined in fact than analytical - meaning, we live to decide based on close approximation in many situations. Therefore, it is just right to have a historical perspective of the mathematical foundations which Machine Learning algorithms may have come about - if not at least what they depend upon fundamentally. For that reason, we cover a list of mathematical concepts that are no doubt valuable to eventually get us to Machine Learning concepts. However, only a particular elementary and introductory portion of each field of mathematics is covered as we emphasize only relevant and essential areas. That said, this book comes in three volumes. Volumes I and II of this book briefly cover common topics in Linear Algebra, Numerical Analysis, Statistical Analysis, and Bayesian Analysis. The third part (or volume III) of this book covers Machine Learning and Deep Learning in detail." />
  <meta name="generator" content="bookdown 0.32 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 5 Probability and Distribution | The Power and Art of Approximation" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Enthused by the promising future of self-learning machines and the continuous advancement of technology, we write this book to cover a compendium of analytical and numerical techniques conflated into a common idea that highlights the fundamental requirements of Data Science and Machine Learning (ML) Engineering. In this book, we review and give brief insights into numerous fundamental ideas around methods of approximation conceived by great experts. We aim to share them with those new to Data Science who are just beginning to develop an inclination toward this field but may not know where to begin. In addition, we hope to introduce some essential aspects of Data Science in a more progressive and possibly structured manner. This book avoids being specific to a target audience depending on interest. The premise is that Data Science can be for everybody, whether one is an engineer, a researcher within a particular domain, or, for that matter, an undergraduate student just trying to get into this field. While we note that our common theme across the book is intuition, contemplating more on basic operations than mathematical rigor, it is essential to revive our understanding of mathematical concepts first. That is founded upon the idea that we express most of what we do in Data Science in the language of mathematics, more numerically inclined in fact than analytical - meaning, we live to decide based on close approximation in many situations. Therefore, it is just right to have a historical perspective of the mathematical foundations which Machine Learning algorithms may have come about - if not at least what they depend upon fundamentally. For that reason, we cover a list of mathematical concepts that are no doubt valuable to eventually get us to Machine Learning concepts. However, only a particular elementary and introductory portion of each field of mathematics is covered as we emphasize only relevant and essential areas. That said, this book comes in three volumes. Volumes I and II of this book briefly cover common topics in Linear Algebra, Numerical Analysis, Statistical Analysis, and Bayesian Analysis. The third part (or volume III) of this book covers Machine Learning and Deep Learning in detail." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 Probability and Distribution | The Power and Art of Approximation" />
  
  <meta name="twitter:description" content="Enthused by the promising future of self-learning machines and the continuous advancement of technology, we write this book to cover a compendium of analytical and numerical techniques conflated into a common idea that highlights the fundamental requirements of Data Science and Machine Learning (ML) Engineering. In this book, we review and give brief insights into numerous fundamental ideas around methods of approximation conceived by great experts. We aim to share them with those new to Data Science who are just beginning to develop an inclination toward this field but may not know where to begin. In addition, we hope to introduce some essential aspects of Data Science in a more progressive and possibly structured manner. This book avoids being specific to a target audience depending on interest. The premise is that Data Science can be for everybody, whether one is an engineer, a researcher within a particular domain, or, for that matter, an undergraduate student just trying to get into this field. While we note that our common theme across the book is intuition, contemplating more on basic operations than mathematical rigor, it is essential to revive our understanding of mathematical concepts first. That is founded upon the idea that we express most of what we do in Data Science in the language of mathematics, more numerically inclined in fact than analytical - meaning, we live to decide based on close approximation in many situations. Therefore, it is just right to have a historical perspective of the mathematical foundations which Machine Learning algorithms may have come about - if not at least what they depend upon fundamentally. For that reason, we cover a list of mathematical concepts that are no doubt valuable to eventually get us to Machine Learning concepts. However, only a particular elementary and introductory portion of each field of mathematics is covered as we emphasize only relevant and essential areas. That said, this book comes in three volumes. Volumes I and II of this book briefly cover common topics in Linear Algebra, Numerical Analysis, Statistical Analysis, and Bayesian Analysis. The third part (or volume III) of this book covers Machine Learning and Deep Learning in detail." />
  

<meta name="author" content="Raymond Michael Ofiaza OrdoÃ±a" />


<meta name="date" content="2023-02-14" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="numericalcalculus.html"/>
<link rel="next" href="statistics.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">The Power and Art of Approximation</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="0.1" data-path="index.html"><a href="index.html#acknowledgment-and-motivations"><i class="fa fa-check"></i><b>0.1</b> Acknowledgment and Motivations</a></li>
<li class="chapter" data-level="0.2" data-path="index.html"><a href="index.html#caveat"><i class="fa fa-check"></i><b>0.2</b> Caveat</a></li>
<li class="chapter" data-level="0.3" data-path="index.html"><a href="index.html#about-the-author"><i class="fa fa-check"></i><b>0.3</b> About the Author</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="" data-path="mathematical-notation.html"><a href="mathematical-notation.html"><i class="fa fa-check"></i>Mathematical Notation</a><ul>
<li class="chapter" data-level="0.4" data-path="mathematical-notation.html"><a href="mathematical-notation.html#notation"><i class="fa fa-check"></i><b>0.4</b> Notation</a></li>
<li class="chapter" data-level="0.5" data-path="mathematical-notation.html"><a href="mathematical-notation.html#number-system"><i class="fa fa-check"></i><b>0.5</b> Number System</a></li>
<li class="chapter" data-level="0.6" data-path="mathematical-notation.html"><a href="mathematical-notation.html#implementation"><i class="fa fa-check"></i><b>0.6</b> Implementation</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="numericalmethods.html"><a href="numericalmethods.html"><i class="fa fa-check"></i><b>1</b> Direct and Indirect Methods</a><ul>
<li class="chapter" data-level="1.1" data-path="numericalmethods.html"><a href="numericalmethods.html#closed-form-equation"><i class="fa fa-check"></i><b>1.1</b> Closed-form equation</a></li>
<li class="chapter" data-level="1.2" data-path="numericalmethods.html"><a href="numericalmethods.html#analytical-and-numerical-solutions"><i class="fa fa-check"></i><b>1.2</b> Analytical and Numerical solutions  </a></li>
<li class="chapter" data-level="1.3" data-path="numericalmethods.html"><a href="numericalmethods.html#significant-figures"><i class="fa fa-check"></i><b>1.3</b> Significant figures</a></li>
<li class="chapter" data-level="1.4" data-path="numericalmethods.html"><a href="numericalmethods.html#accuracy"><i class="fa fa-check"></i><b>1.4</b> Accuracy</a></li>
<li class="chapter" data-level="1.5" data-path="numericalmethods.html"><a href="numericalmethods.html#precision"><i class="fa fa-check"></i><b>1.5</b> Precision </a></li>
<li class="chapter" data-level="1.6" data-path="numericalmethods.html"><a href="numericalmethods.html#stability-and-sensitivity"><i class="fa fa-check"></i><b>1.6</b> Stability and Sensitivity  </a></li>
<li class="chapter" data-level="1.7" data-path="numericalmethods.html"><a href="numericalmethods.html#stiffness-and-implicitness"><i class="fa fa-check"></i><b>1.7</b> Stiffness and Implicitness  </a></li>
<li class="chapter" data-level="1.8" data-path="numericalmethods.html"><a href="numericalmethods.html#conditioning-and-posedness"><i class="fa fa-check"></i><b>1.8</b> Conditioning and Posedness  </a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="linearalgebra.html"><a href="linearalgebra.html"><i class="fa fa-check"></i><b>2</b> Numerical Linear Algebra I</a><ul>
<li class="chapter" data-level="2.1" data-path="linearalgebra.html"><a href="linearalgebra.html#system-of-linear-equations"><i class="fa fa-check"></i><b>2.1</b> System of Linear Equations</a></li>
<li class="chapter" data-level="2.2" data-path="linearalgebra.html"><a href="linearalgebra.html#scalar-vector-and-matrix-tensor"><i class="fa fa-check"></i><b>2.2</b> Scalar, Vector, and Matrix, Tensor</a></li>
<li class="chapter" data-level="2.3" data-path="linearalgebra.html"><a href="linearalgebra.html#transposition-and-multiplication"><i class="fa fa-check"></i><b>2.3</b> Transposition and Multiplication</a><ul>
<li class="chapter" data-level="2.3.1" data-path="linearalgebra.html"><a href="linearalgebra.html#transposition"><i class="fa fa-check"></i><b>2.3.1</b> Transposition</a></li>
<li class="chapter" data-level="2.3.2" data-path="linearalgebra.html"><a href="linearalgebra.html#dot-product"><i class="fa fa-check"></i><b>2.3.2</b> Dot Product</a></li>
<li class="chapter" data-level="2.3.3" data-path="linearalgebra.html"><a href="linearalgebra.html#hadamard-product"><i class="fa fa-check"></i><b>2.3.3</b> Hadamard Product</a></li>
<li class="chapter" data-level="2.3.4" data-path="linearalgebra.html"><a href="linearalgebra.html#kronecker-product"><i class="fa fa-check"></i><b>2.3.4</b> Kronecker Product</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="linearalgebra.html"><a href="linearalgebra.html#magnitude-direction-unit-vectors"><i class="fa fa-check"></i><b>2.4</b> Magnitude, Direction, Unit Vectors</a></li>
<li class="chapter" data-level="2.5" data-path="linearalgebra.html"><a href="linearalgebra.html#linear-combination-and-independence"><i class="fa fa-check"></i><b>2.5</b> Linear Combination and Independence</a></li>
<li class="chapter" data-level="2.6" data-path="linearalgebra.html"><a href="linearalgebra.html#space-span-and-basis"><i class="fa fa-check"></i><b>2.6</b> Space, Span, and Basis</a></li>
<li class="chapter" data-level="2.7" data-path="linearalgebra.html"><a href="linearalgebra.html#determinants"><i class="fa fa-check"></i><b>2.7</b> Determinants </a></li>
<li class="chapter" data-level="2.8" data-path="linearalgebra.html"><a href="linearalgebra.html#minors-cofactors-and-adjugate-forms"><i class="fa fa-check"></i><b>2.8</b> Minors, Cofactors, and Adjugate Forms</a></li>
<li class="chapter" data-level="2.9" data-path="linearalgebra.html"><a href="linearalgebra.html#inverse-form-and-row-echelon-form"><i class="fa fa-check"></i><b>2.9</b> Inverse Form and Row-Echelon Form</a></li>
<li class="chapter" data-level="2.10" data-path="linearalgebra.html"><a href="linearalgebra.html#linear-transformations"><i class="fa fa-check"></i><b>2.10</b> Linear Transformations</a><ul>
<li class="chapter" data-level="2.10.1" data-path="linearalgebra.html"><a href="linearalgebra.html#scaling"><i class="fa fa-check"></i><b>2.10.1</b> Scaling </a></li>
<li class="chapter" data-level="2.10.2" data-path="linearalgebra.html"><a href="linearalgebra.html#transvection-shearing"><i class="fa fa-check"></i><b>2.10.2</b> Transvection (Shearing)  </a></li>
<li class="chapter" data-level="2.10.3" data-path="linearalgebra.html"><a href="linearalgebra.html#rotation"><i class="fa fa-check"></i><b>2.10.3</b> Rotation </a></li>
<li class="chapter" data-level="2.10.4" data-path="linearalgebra.html"><a href="linearalgebra.html#reflection"><i class="fa fa-check"></i><b>2.10.4</b> Reflection </a></li>
<li class="chapter" data-level="2.10.5" data-path="linearalgebra.html"><a href="linearalgebra.html#projection"><i class="fa fa-check"></i><b>2.10.5</b> Projection </a></li>
<li class="chapter" data-level="2.10.6" data-path="linearalgebra.html"><a href="linearalgebra.html#translation"><i class="fa fa-check"></i><b>2.10.6</b> Translation </a></li>
<li class="chapter" data-level="2.10.7" data-path="linearalgebra.html"><a href="linearalgebra.html#dilation-and-composition"><i class="fa fa-check"></i><b>2.10.7</b> Dilation and Composition  </a></li>
</ul></li>
<li class="chapter" data-level="2.11" data-path="linearalgebra.html"><a href="linearalgebra.html#rank-and-nullity"><i class="fa fa-check"></i><b>2.11</b> Rank and Nullity  </a></li>
<li class="chapter" data-level="2.12" data-path="linearalgebra.html"><a href="linearalgebra.html#singularity-and-triviality"><i class="fa fa-check"></i><b>2.12</b> Singularity and Triviality  </a></li>
<li class="chapter" data-level="2.13" data-path="linearalgebra.html"><a href="linearalgebra.html#orthogonality-and-orthonormality"><i class="fa fa-check"></i><b>2.13</b> Orthogonality and Orthonormality  </a></li>
<li class="chapter" data-level="2.14" data-path="linearalgebra.html"><a href="linearalgebra.html#eigenvectors-and-eigenvalues"><i class="fa fa-check"></i><b>2.14</b> Eigenvectors and Eigenvalues  </a></li>
<li class="chapter" data-level="2.15" data-path="linearalgebra.html"><a href="linearalgebra.html#matrix-reconstruction-using-eigenvalues-and-eigenvectors"><i class="fa fa-check"></i><b>2.15</b> Matrix Reconstruction using Eigenvalues and Eigenvectors</a></li>
<li class="chapter" data-level="2.16" data-path="linearalgebra.html"><a href="linearalgebra.html#diagonalizability-of-a-matrix"><i class="fa fa-check"></i><b>2.16</b> Diagonalizability of a Matrix </a></li>
<li class="chapter" data-level="2.17" data-path="linearalgebra.html"><a href="linearalgebra.html#trace-of-a-square-matrix"><i class="fa fa-check"></i><b>2.17</b> Trace of a Square Matrix </a></li>
<li class="chapter" data-level="2.18" data-path="linearalgebra.html"><a href="linearalgebra.html#algebraic-and-geometric-multiplicity"><i class="fa fa-check"></i><b>2.18</b> Algebraic and Geometric Multiplicity</a></li>
<li class="chapter" data-level="2.19" data-path="linearalgebra.html"><a href="linearalgebra.html#types-of-matrices"><i class="fa fa-check"></i><b>2.19</b> Types of Matrices</a></li>
<li class="chapter" data-level="2.20" data-path="linearalgebra.html"><a href="linearalgebra.html#matrix-factorization"><i class="fa fa-check"></i><b>2.20</b> Matrix Factorization </a><ul>
<li class="chapter" data-level="2.20.1" data-path="linearalgebra.html"><a href="linearalgebra.html#eigen-spectral-decomposition"><i class="fa fa-check"></i><b>2.20.1</b> Eigen (Spectral) Decomposition  </a></li>
<li class="chapter" data-level="2.20.2" data-path="linearalgebra.html"><a href="linearalgebra.html#ludecomposition"><i class="fa fa-check"></i><b>2.20.2</b> LU Decomposition (Doolittle Algorithm)</a></li>
<li class="chapter" data-level="2.20.3" data-path="linearalgebra.html"><a href="linearalgebra.html#ldu-factorization"><i class="fa fa-check"></i><b>2.20.3</b> LDU Factorization </a></li>
<li class="chapter" data-level="2.20.4" data-path="linearalgebra.html"><a href="linearalgebra.html#qr-factorization-gram-schmidt-householder-and-givens"><i class="fa fa-check"></i><b>2.20.4</b> QR Factorization (Gram-Schmidt, Householder, and Givens) </a></li>
<li class="chapter" data-level="2.20.5" data-path="linearalgebra.html"><a href="linearalgebra.html#cholesky-factorization"><i class="fa fa-check"></i><b>2.20.5</b> Cholesky Factorization </a></li>
<li class="chapter" data-level="2.20.6" data-path="linearalgebra.html"><a href="linearalgebra.html#svd-factorization"><i class="fa fa-check"></i><b>2.20.6</b> SVD Factorization </a></li>
<li class="chapter" data-level="2.20.7" data-path="linearalgebra.html"><a href="linearalgebra.html#jordan-decomposition"><i class="fa fa-check"></i><b>2.20.7</b> Jordan Decomposition </a></li>
<li class="chapter" data-level="2.20.8" data-path="linearalgebra.html"><a href="linearalgebra.html#other-decomposition"><i class="fa fa-check"></i><b>2.20.8</b> Other Decomposition</a></li>
</ul></li>
<li class="chapter" data-level="2.21" data-path="linearalgebra.html"><a href="linearalgebra.html#software-libraries"><i class="fa fa-check"></i><b>2.21</b> Software libraries    </a></li>
<li class="chapter" data-level="2.22" data-path="linearalgebra.html"><a href="linearalgebra.html#summary"><i class="fa fa-check"></i><b>2.22</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html"><i class="fa fa-check"></i><b>3</b> Numerical Linear Algebra II</a><ul>
<li class="chapter" data-level="3.1" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#iteration-and-convergence"><i class="fa fa-check"></i><b>3.1</b> Iteration and Convergence </a></li>
<li class="chapter" data-level="3.2" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#approximating-eigenvalues-and-eigenvectors-by-iteration-av-lambda-v"><i class="fa fa-check"></i><b>3.2</b> Approximating Eigenvalues and EigenVectors by Iteration (<span class="math inline">\(Av = \lambda v\)</span>)</a><ul>
<li class="chapter" data-level="3.2.1" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#power-method"><i class="fa fa-check"></i><b>3.2.1</b> Power Method </a></li>
<li class="chapter" data-level="3.2.2" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#inverse-power-method-using-lu-decomposition"><i class="fa fa-check"></i><b>3.2.2</b> Inverse Power Method (using LU Decomposition)</a></li>
<li class="chapter" data-level="3.2.3" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#rayleigh-quotient-method-using-lu-decomposition"><i class="fa fa-check"></i><b>3.2.3</b> Rayleigh Quotient Method (using LU Decomposition)</a></li>
<li class="chapter" data-level="3.2.4" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#qr-method-using-qr-decomposition-by-givens"><i class="fa fa-check"></i><b>3.2.4</b> QR Method (using QR Decomposition by Givens)</a></li>
<li class="chapter" data-level="3.2.5" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#jacobi-eigenvalue-method-using-jacobi-rotation"><i class="fa fa-check"></i><b>3.2.5</b> Jacobi Eigenvalue Method (using Jacobi Rotation)</a></li>
<li class="chapter" data-level="3.2.6" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#arnoldi-method-using-gram-schmidt-in-krylov-subspace"><i class="fa fa-check"></i><b>3.2.6</b> Arnoldi Method (using Gram-Schmidt in Krylov Subspace) </a></li>
<li class="chapter" data-level="3.2.7" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#lanczos-method-using-gram-schmidt-in-krylov-subspace"><i class="fa fa-check"></i><b>3.2.7</b> Lanczos Method (using Gram-Schmidt in Krylov Subspace)</a></li>
<li class="chapter" data-level="3.2.8" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#fine-tuning-of-iteration-and-convergence"><i class="fa fa-check"></i><b>3.2.8</b> Fine-Tuning of Iteration and Convergence</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#approximating-root-and-fixed-point-by-iteration"><i class="fa fa-check"></i><b>3.3</b> Approximating Root and Fixed-Point by Iteration</a><ul>
<li class="chapter" data-level="3.3.1" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#root-finding-method-fx-0"><i class="fa fa-check"></i><b>3.3.1</b> Root-Finding Method (<span class="math inline">\(f(x) = 0\)</span>) </a></li>
<li class="chapter" data-level="3.3.2" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#fixed-point-method-fx-x"><i class="fa fa-check"></i><b>3.3.2</b> Fixed-Point Method (<span class="math inline">\(f(x) = x\)</span>) </a></li>
<li class="chapter" data-level="3.3.3" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#bisection-method"><i class="fa fa-check"></i><b>3.3.3</b> Bisection Method </a></li>
<li class="chapter" data-level="3.3.4" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#newton-raphson-method-using-the-tangent-line"><i class="fa fa-check"></i><b>3.3.4</b> Newton-Raphson Method (using the Tangent Line)</a></li>
<li class="chapter" data-level="3.3.5" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#secant-method-using-the-secant-line"><i class="fa fa-check"></i><b>3.3.5</b> Secant Method (using the Secant Line)</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#approximating-solutions-to-systems-of-eqs-by-iteration-ax-b"><i class="fa fa-check"></i><b>3.4</b> Approximating Solutions to Systems of Eqs by Iteration (<span class="math inline">\(Ax = b\)</span>)</a><ul>
<li class="chapter" data-level="3.4.1" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#krylovmethods"><i class="fa fa-check"></i><b>3.4.1</b> Krylov Methods</a></li>
<li class="chapter" data-level="3.4.2" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#gmres-generalized-minimal-residual"><i class="fa fa-check"></i><b>3.4.2</b> GMRES (Generalized Minimal Residual)  </a></li>
<li class="chapter" data-level="3.4.3" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#conjugate-gradient-method-cg"><i class="fa fa-check"></i><b>3.4.3</b> Conjugate Gradient Method (CG)  </a></li>
<li class="chapter" data-level="3.4.4" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#jacobi-and-gauss-seidel-method"><i class="fa fa-check"></i><b>3.4.4</b> Jacobi and Gauss-Seidel Method </a></li>
<li class="chapter" data-level="3.4.5" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#successive-over-relaxation-sor-method"><i class="fa fa-check"></i><b>3.4.5</b> Successive Over-Relaxation (SOR) Method  </a></li>
<li class="chapter" data-level="3.4.6" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#newtons-method"><i class="fa fa-check"></i><b>3.4.6</b> Newtonâs Method </a></li>
<li class="chapter" data-level="3.4.7" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#broydens-method"><i class="fa fa-check"></i><b>3.4.7</b> Broydenâs Method </a></li>
<li class="chapter" data-level="3.4.8" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#bfgs-broyden-fletcher-goldfarb-shanno-method"><i class="fa fa-check"></i><b>3.4.8</b> BFGS (Broyden-Fletcher-Goldfarb-Shanno) method </a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#polynomialregression"><i class="fa fa-check"></i><b>3.5</b> Approximating Polynomial Functions by Regression</a><ul>
<li class="chapter" data-level="3.5.1" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#least-squares"><i class="fa fa-check"></i><b>3.5.1</b> Least-Squares </a></li>
<li class="chapter" data-level="3.5.2" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#linear-regression"><i class="fa fa-check"></i><b>3.5.2</b> Linear Regression </a></li>
<li class="chapter" data-level="3.5.3" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#higherdegreepolynomials"><i class="fa fa-check"></i><b>3.5.3</b> Higher Degree Polynomials</a></li>
<li class="chapter" data-level="3.5.4" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#non-linear-regression"><i class="fa fa-check"></i><b>3.5.4</b> Non-Linear Regression </a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#approximating-polynomial-functions-by-series-expansion"><i class="fa fa-check"></i><b>3.6</b> Approximating Polynomial Functions by Series Expansion </a></li>
<li class="chapter" data-level="3.7" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#polynomialinterpolation"><i class="fa fa-check"></i><b>3.7</b> Approximating Polynomial Functions by Interpolation</a><ul>
<li class="chapter" data-level="3.7.1" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#polynomial-interpolation"><i class="fa fa-check"></i><b>3.7.1</b> Polynomial interpolation </a></li>
<li class="chapter" data-level="3.7.2" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#lagrange-interpolation"><i class="fa fa-check"></i><b>3.7.2</b> Lagrange interpolation </a></li>
<li class="chapter" data-level="3.7.3" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#newton-interpolation"><i class="fa fa-check"></i><b>3.7.3</b> Newton interpolation </a></li>
<li class="chapter" data-level="3.7.4" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#newton-forward-interpolation"><i class="fa fa-check"></i><b>3.7.4</b> Newton Forward interpolation </a></li>
<li class="chapter" data-level="3.7.5" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#newton-backward-interpolation"><i class="fa fa-check"></i><b>3.7.5</b> Newton Backward interpolation </a></li>
<li class="chapter" data-level="3.7.6" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#interpolation-considerations"><i class="fa fa-check"></i><b>3.7.6</b> Interpolation Considerations</a></li>
<li class="chapter" data-level="3.7.7" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#lebesque-constant"><i class="fa fa-check"></i><b>3.7.7</b> Lebesque Constant </a></li>
<li class="chapter" data-level="3.7.8" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#horners-method"><i class="fa fa-check"></i><b>3.7.8</b> Hornerâs method </a></li>
<li class="chapter" data-level="3.7.9" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#piecewise-polynomial-interpolation"><i class="fa fa-check"></i><b>3.7.9</b> Piecewise Polynomial Interpolation </a></li>
<li class="chapter" data-level="3.7.10" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#b-spline-interpolation"><i class="fa fa-check"></i><b>3.7.10</b> B-Spline interpolation </a></li>
<li class="chapter" data-level="3.7.11" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#bspline"><i class="fa fa-check"></i><b>3.7.11</b> B-Spline Regression</a></li>
<li class="chapter" data-level="3.7.12" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#p-spline-regression"><i class="fa fa-check"></i><b>3.7.12</b> P-Spline Regression </a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#polynomialsmoothing"><i class="fa fa-check"></i><b>3.8</b> Approximating Polynomial Functions by Smoothing</a><ul>
<li class="chapter" data-level="3.8.1" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#bin-smoothing"><i class="fa fa-check"></i><b>3.8.1</b> Bin Smoothing </a></li>
<li class="chapter" data-level="3.8.2" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#kernel-smoothing"><i class="fa fa-check"></i><b>3.8.2</b> Kernel Smoothing </a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#polynomial-optimization"><i class="fa fa-check"></i><b>3.9</b> Polynomial Optimization </a><ul>
<li class="chapter" data-level="3.9.1" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#simplexmethod"><i class="fa fa-check"></i><b>3.9.1</b> Simplex Method</a></li>
<li class="chapter" data-level="3.9.2" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#dualsimplex"><i class="fa fa-check"></i><b>3.9.2</b> Dual Simplex</a></li>
<li class="chapter" data-level="3.9.3" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#primaldual"><i class="fa fa-check"></i><b>3.9.3</b> Primal-Dual Formulation</a></li>
<li class="chapter" data-level="3.9.4" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#lagrange-multiplier"><i class="fa fa-check"></i><b>3.9.4</b> Lagrange Multiplier </a></li>
<li class="chapter" data-level="3.9.5" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#karush-khun-tucker-conditions"><i class="fa fa-check"></i><b>3.9.5</b> Karush-Khun-Tucker Conditions </a></li>
</ul></li>
<li class="chapter" data-level="3.10" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#summary-1"><i class="fa fa-check"></i><b>3.10</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="numericalcalculus.html"><a href="numericalcalculus.html"><i class="fa fa-check"></i><b>4</b> Numerical Calculus</a><ul>
<li class="chapter" data-level="4.1" data-path="numericalcalculus.html"><a href="numericalcalculus.html#introductory-calculus"><i class="fa fa-check"></i><b>4.1</b> Introductory Calculus</a><ul>
<li class="chapter" data-level="4.1.1" data-path="numericalcalculus.html"><a href="numericalcalculus.html#function"><i class="fa fa-check"></i><b>4.1.1</b> Function</a></li>
<li class="chapter" data-level="4.1.2" data-path="numericalcalculus.html"><a href="numericalcalculus.html#slopes"><i class="fa fa-check"></i><b>4.1.2</b> Slopes</a></li>
<li class="chapter" data-level="4.1.3" data-path="numericalcalculus.html"><a href="numericalcalculus.html#limits"><i class="fa fa-check"></i><b>4.1.3</b> Limits</a></li>
<li class="chapter" data-level="4.1.4" data-path="numericalcalculus.html"><a href="numericalcalculus.html#derivatives"><i class="fa fa-check"></i><b>4.1.4</b> Derivatives</a></li>
<li class="chapter" data-level="4.1.5" data-path="numericalcalculus.html"><a href="numericalcalculus.html#integrals"><i class="fa fa-check"></i><b>4.1.5</b> Integrals </a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="numericalcalculus.html"><a href="numericalcalculus.html#approximation-by-numerical-integration"><i class="fa fa-check"></i><b>4.2</b> Approximation by Numerical Integration </a><ul>
<li class="chapter" data-level="4.2.1" data-path="numericalcalculus.html"><a href="numericalcalculus.html#newton-cotes-quadrature"><i class="fa fa-check"></i><b>4.2.1</b> Newton-Cotes Quadrature </a></li>
<li class="chapter" data-level="4.2.2" data-path="numericalcalculus.html"><a href="numericalcalculus.html#composite-and-adaptive-quadrature"><i class="fa fa-check"></i><b>4.2.2</b> Composite and Adaptive Quadrature </a></li>
<li class="chapter" data-level="4.2.3" data-path="numericalcalculus.html"><a href="numericalcalculus.html#gaussianquadrature"><i class="fa fa-check"></i><b>4.2.3</b> Gaussian Quadrature</a></li>
<li class="chapter" data-level="4.2.4" data-path="numericalcalculus.html"><a href="numericalcalculus.html#romberg-integration"><i class="fa fa-check"></i><b>4.2.4</b> Romberg integration </a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="numericalcalculus.html"><a href="numericalcalculus.html#approximation-by-numerical-differentiation"><i class="fa fa-check"></i><b>4.3</b> Approximation by Numerical Differentiation </a><ul>
<li class="chapter" data-level="4.3.1" data-path="numericalcalculus.html"><a href="numericalcalculus.html#order-of-accuracy"><i class="fa fa-check"></i><b>4.3.1</b> Order of Accuracy</a></li>
<li class="chapter" data-level="4.3.2" data-path="numericalcalculus.html"><a href="numericalcalculus.html#finite-difference"><i class="fa fa-check"></i><b>4.3.2</b> Finite Difference </a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="numericalcalculus.html"><a href="numericalcalculus.html#approximation-using-ordinary-differential-equations"><i class="fa fa-check"></i><b>4.4</b> Approximation using Ordinary Differential Equations  </a><ul>
<li class="chapter" data-level="4.4.1" data-path="numericalcalculus.html"><a href="numericalcalculus.html#eulers-method-explicit"><i class="fa fa-check"></i><b>4.4.1</b> Eulerâs Method (Explicit) </a></li>
<li class="chapter" data-level="4.4.2" data-path="numericalcalculus.html"><a href="numericalcalculus.html#eulers-method-implicit"><i class="fa fa-check"></i><b>4.4.2</b> Eulerâs Method (Implicit)</a></li>
<li class="chapter" data-level="4.4.3" data-path="numericalcalculus.html"><a href="numericalcalculus.html#heuns-method"><i class="fa fa-check"></i><b>4.4.3</b> Heunâs Method </a></li>
<li class="chapter" data-level="4.4.4" data-path="numericalcalculus.html"><a href="numericalcalculus.html#runge-kutta-method"><i class="fa fa-check"></i><b>4.4.4</b> Runge-Kutta Method </a></li>
<li class="chapter" data-level="4.4.5" data-path="numericalcalculus.html"><a href="numericalcalculus.html#shooting-method"><i class="fa fa-check"></i><b>4.4.5</b> Shooting Method </a></li>
<li class="chapter" data-level="4.4.6" data-path="numericalcalculus.html"><a href="numericalcalculus.html#finite-difference-method"><i class="fa fa-check"></i><b>4.4.6</b> Finite Difference Method  </a></li>
<li class="chapter" data-level="4.4.7" data-path="numericalcalculus.html"><a href="numericalcalculus.html#finite-element-method-based-on-wrm-and-vm"><i class="fa fa-check"></i><b>4.4.7</b> Finite Element Method (based on WRM and VM) </a></li>
<li class="chapter" data-level="4.4.8" data-path="numericalcalculus.html"><a href="numericalcalculus.html#least-square-method-using-wrm"><i class="fa fa-check"></i><b>4.4.8</b> Least-Square Method (using WRM)</a></li>
<li class="chapter" data-level="4.4.9" data-path="numericalcalculus.html"><a href="numericalcalculus.html#galerkin-method-using-wrm"><i class="fa fa-check"></i><b>4.4.9</b> Galerkin Method (using WRM)</a></li>
<li class="chapter" data-level="4.4.10" data-path="numericalcalculus.html"><a href="numericalcalculus.html#petrov-galerkin-method-using-wrm"><i class="fa fa-check"></i><b>4.4.10</b> Petrov-Galerkin Method (using WRM)</a></li>
<li class="chapter" data-level="4.4.11" data-path="numericalcalculus.html"><a href="numericalcalculus.html#rayleigh-ritz-method-using-wrm"><i class="fa fa-check"></i><b>4.4.11</b> Rayleigh-Ritz Method (using WRM)</a></li>
<li class="chapter" data-level="4.4.12" data-path="numericalcalculus.html"><a href="numericalcalculus.html#subdomain-method-using-subdomains"><i class="fa fa-check"></i><b>4.4.12</b> Subdomain Method (using subdomains)</a></li>
<li class="chapter" data-level="4.4.13" data-path="numericalcalculus.html"><a href="numericalcalculus.html#collocation-method-using-direct-location-points"><i class="fa fa-check"></i><b>4.4.13</b> Collocation Method (using direct location points) </a></li>
<li class="chapter" data-level="4.4.14" data-path="numericalcalculus.html"><a href="numericalcalculus.html#weighted-residual-summary"><i class="fa fa-check"></i><b>4.4.14</b> Weighted Residual Summary </a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="numericalcalculus.html"><a href="numericalcalculus.html#approximation-using-functional-differential-equations"><i class="fa fa-check"></i><b>4.5</b> Approximation using Functional Differential Equations </a><ul>
<li class="chapter" data-level="4.5.1" data-path="numericalcalculus.html"><a href="numericalcalculus.html#variational-functions"><i class="fa fa-check"></i><b>4.5.1</b> Variational Functions </a></li>
<li class="chapter" data-level="4.5.2" data-path="numericalcalculus.html"><a href="numericalcalculus.html#variational-methods"><i class="fa fa-check"></i><b>4.5.2</b> Variational Methods </a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="numericalcalculus.html"><a href="numericalcalculus.html#approximation-using-partial-differential-equations"><i class="fa fa-check"></i><b>4.6</b> Approximation using Partial Differential Equations </a><ul>
<li class="chapter" data-level="4.6.1" data-path="numericalcalculus.html"><a href="numericalcalculus.html#the-laplace-equation-elliptic-pde"><i class="fa fa-check"></i><b>4.6.1</b> The Laplace Equation (Elliptic PDE)  </a></li>
<li class="chapter" data-level="4.6.2" data-path="numericalcalculus.html"><a href="numericalcalculus.html#the-heat-equation-parabolic-pde"><i class="fa fa-check"></i><b>4.6.2</b> The Heat equation (Parabolic PDE)  </a></li>
<li class="chapter" data-level="4.6.3" data-path="numericalcalculus.html"><a href="numericalcalculus.html#the-wave-equation-hyperbolic-pde"><i class="fa fa-check"></i><b>4.6.3</b> The Wave equation (Hyperbolic PDE)  </a></li>
<li class="chapter" data-level="4.6.4" data-path="numericalcalculus.html"><a href="numericalcalculus.html#the-crank-nicolson-equation"><i class="fa fa-check"></i><b>4.6.4</b> The Crank-Nicolson Equation </a></li>
<li class="chapter" data-level="4.6.5" data-path="numericalcalculus.html"><a href="numericalcalculus.html#the-burgers-equation"><i class="fa fa-check"></i><b>4.6.5</b> The Burgerâs Equation </a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="numericalcalculus.html"><a href="numericalcalculus.html#approximation-using-fourier-series-and-transform"><i class="fa fa-check"></i><b>4.7</b> Approximation using Fourier Series And Transform </a><ul>
<li class="chapter" data-level="4.7.1" data-path="numericalcalculus.html"><a href="numericalcalculus.html#discrete-fourier-transform-dft"><i class="fa fa-check"></i><b>4.7.1</b> Discrete Fourier Transform (DFT)  </a></li>
<li class="chapter" data-level="4.7.2" data-path="numericalcalculus.html"><a href="numericalcalculus.html#inverse-discrete-fourier-transformation-idft"><i class="fa fa-check"></i><b>4.7.2</b> Inverse Discrete Fourier Transformation (IDFT)  </a></li>
<li class="chapter" data-level="4.7.3" data-path="numericalcalculus.html"><a href="numericalcalculus.html#fast-fourier-transform-fft"><i class="fa fa-check"></i><b>4.7.3</b> Fast Fourier Transform (FFT)  </a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="numericalcalculus.html"><a href="numericalcalculus.html#summary-2"><i class="fa fa-check"></i><b>4.8</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="numericalprobability.html"><a href="numericalprobability.html"><i class="fa fa-check"></i><b>5</b> Probability and Distribution</a><ul>
<li class="chapter" data-level="5.1" data-path="numericalprobability.html"><a href="numericalprobability.html#approximation-based-on-random-chances"><i class="fa fa-check"></i><b>5.1</b> Approximation based on Random Chances </a></li>
<li class="chapter" data-level="5.2" data-path="numericalprobability.html"><a href="numericalprobability.html#distribution"><i class="fa fa-check"></i><b>5.2</b> Distribution</a></li>
<li class="chapter" data-level="5.3" data-path="numericalprobability.html"><a href="numericalprobability.html#mass-and-density"><i class="fa fa-check"></i><b>5.3</b> Mass and Density  </a></li>
<li class="chapter" data-level="5.4" data-path="numericalprobability.html"><a href="numericalprobability.html#probability"><i class="fa fa-check"></i><b>5.4</b> Probability  </a></li>
<li class="chapter" data-level="5.5" data-path="numericalprobability.html"><a href="numericalprobability.html#probability-density-function-pdf"><i class="fa fa-check"></i><b>5.5</b> Probability Density Function (PDF)  </a></li>
<li class="chapter" data-level="5.6" data-path="numericalprobability.html"><a href="numericalprobability.html#probability-mass-function-pmf"><i class="fa fa-check"></i><b>5.6</b> Probability Mass function (PMF)  </a></li>
<li class="chapter" data-level="5.7" data-path="numericalprobability.html"><a href="numericalprobability.html#cumulative-distribution-function-cdf"><i class="fa fa-check"></i><b>5.7</b> Cumulative Distribution Function (CDF)  </a></li>
<li class="chapter" data-level="5.8" data-path="numericalprobability.html"><a href="numericalprobability.html#special-functions"><i class="fa fa-check"></i><b>5.8</b> Special Functions</a><ul>
<li class="chapter" data-level="5.8.1" data-path="numericalprobability.html"><a href="numericalprobability.html#gamma-function"><i class="fa fa-check"></i><b>5.8.1</b> Gamma function </a></li>
<li class="chapter" data-level="5.8.2" data-path="numericalprobability.html"><a href="numericalprobability.html#incomplete-gamma-function"><i class="fa fa-check"></i><b>5.8.2</b> Incomplete Gamma function </a></li>
<li class="chapter" data-level="5.8.3" data-path="numericalprobability.html"><a href="numericalprobability.html#digamma-function"><i class="fa fa-check"></i><b>5.8.3</b> Digamma Function </a></li>
<li class="chapter" data-level="5.8.4" data-path="numericalprobability.html"><a href="numericalprobability.html#beta-function"><i class="fa fa-check"></i><b>5.8.4</b> Beta function </a></li>
<li class="chapter" data-level="5.8.5" data-path="numericalprobability.html"><a href="numericalprobability.html#incomplete-beta-function"><i class="fa fa-check"></i><b>5.8.5</b> Incomplete Beta function </a></li>
<li class="chapter" data-level="5.8.6" data-path="numericalprobability.html"><a href="numericalprobability.html#regularized-beta-function"><i class="fa fa-check"></i><b>5.8.6</b> Regularized Beta function  </a></li>
<li class="chapter" data-level="5.8.7" data-path="numericalprobability.html"><a href="numericalprobability.html#hypergeometric-function"><i class="fa fa-check"></i><b>5.8.7</b> Hypergeometric function </a></li>
<li class="chapter" data-level="5.8.8" data-path="numericalprobability.html"><a href="numericalprobability.html#continued-fraction"><i class="fa fa-check"></i><b>5.8.8</b> Continued Fraction </a></li>
<li class="chapter" data-level="5.8.9" data-path="numericalprobability.html"><a href="numericalprobability.html#dirac-delta-function"><i class="fa fa-check"></i><b>5.8.9</b> Dirac Delta Function </a></li>
<li class="chapter" data-level="5.8.10" data-path="numericalprobability.html"><a href="numericalprobability.html#kronecker-delta-function"><i class="fa fa-check"></i><b>5.8.10</b> Kronecker Delta Function </a></li>
</ul></li>
<li class="chapter" data-level="5.9" data-path="numericalprobability.html"><a href="numericalprobability.html#distributiontypes"><i class="fa fa-check"></i><b>5.9</b> Types of Distribution</a><ul>
<li class="chapter" data-level="5.9.1" data-path="numericalprobability.html"><a href="numericalprobability.html#bernoulli-distribution"><i class="fa fa-check"></i><b>5.9.1</b> Bernoulli distribution </a></li>
<li class="chapter" data-level="5.9.2" data-path="numericalprobability.html"><a href="numericalprobability.html#binomial-distribution"><i class="fa fa-check"></i><b>5.9.2</b> Binomial distribution </a></li>
<li class="chapter" data-level="5.9.3" data-path="numericalprobability.html"><a href="numericalprobability.html#multinomial-distribution"><i class="fa fa-check"></i><b>5.9.3</b> Multinomial distribution </a></li>
<li class="chapter" data-level="5.9.4" data-path="numericalprobability.html"><a href="numericalprobability.html#geometric-distribution"><i class="fa fa-check"></i><b>5.9.4</b> Geometric distribution </a></li>
<li class="chapter" data-level="5.9.5" data-path="numericalprobability.html"><a href="numericalprobability.html#beta-distribution"><i class="fa fa-check"></i><b>5.9.5</b> Beta distribution </a></li>
<li class="chapter" data-level="5.9.6" data-path="numericalprobability.html"><a href="numericalprobability.html#dirichlet-distribution"><i class="fa fa-check"></i><b>5.9.6</b> Dirichlet distribution </a></li>
<li class="chapter" data-level="5.9.7" data-path="numericalprobability.html"><a href="numericalprobability.html#exponential-distribution"><i class="fa fa-check"></i><b>5.9.7</b> Exponential distribution </a></li>
<li class="chapter" data-level="5.9.8" data-path="numericalprobability.html"><a href="numericalprobability.html#gamma-distribution"><i class="fa fa-check"></i><b>5.9.8</b> Gamma distribution </a></li>
<li class="chapter" data-level="5.9.9" data-path="numericalprobability.html"><a href="numericalprobability.html#inverse-gamma-distribution"><i class="fa fa-check"></i><b>5.9.9</b> Inverse Gamma distribution </a></li>
<li class="chapter" data-level="5.9.10" data-path="numericalprobability.html"><a href="numericalprobability.html#weibull-distribution"><i class="fa fa-check"></i><b>5.9.10</b> Weibull distribution </a></li>
<li class="chapter" data-level="5.9.11" data-path="numericalprobability.html"><a href="numericalprobability.html#poisson-distribution"><i class="fa fa-check"></i><b>5.9.11</b> Poisson distribution </a></li>
<li class="chapter" data-level="5.9.12" data-path="numericalprobability.html"><a href="numericalprobability.html#pareto-distribution"><i class="fa fa-check"></i><b>5.9.12</b> Pareto distribution </a></li>
<li class="chapter" data-level="5.9.13" data-path="numericalprobability.html"><a href="numericalprobability.html#normal-distribution"><i class="fa fa-check"></i><b>5.9.13</b> Normal distribution </a></li>
<li class="chapter" data-level="5.9.14" data-path="numericalprobability.html"><a href="numericalprobability.html#wald-distribution"><i class="fa fa-check"></i><b>5.9.14</b> Wald Distribution </a></li>
<li class="chapter" data-level="5.9.15" data-path="numericalprobability.html"><a href="numericalprobability.html#log-normal-distribution"><i class="fa fa-check"></i><b>5.9.15</b> Log-normal Distribution </a></li>
<li class="chapter" data-level="5.9.16" data-path="numericalprobability.html"><a href="numericalprobability.html#uniform-distribution"><i class="fa fa-check"></i><b>5.9.16</b> Uniform Distribution </a></li>
<li class="chapter" data-level="5.9.17" data-path="numericalprobability.html"><a href="numericalprobability.html#t-distribution"><i class="fa fa-check"></i><b>5.9.17</b> T-Distribution </a></li>
<li class="chapter" data-level="5.9.18" data-path="numericalprobability.html"><a href="numericalprobability.html#f-distribution"><i class="fa fa-check"></i><b>5.9.18</b> F-Distribution </a></li>
<li class="chapter" data-level="5.9.19" data-path="numericalprobability.html"><a href="numericalprobability.html#chi-square-distribution"><i class="fa fa-check"></i><b>5.9.19</b> Chi-square Distribution </a></li>
<li class="chapter" data-level="5.9.20" data-path="numericalprobability.html"><a href="numericalprobability.html#wishartdistribution"><i class="fa fa-check"></i><b>5.9.20</b> Wishart distribution</a></li>
<li class="chapter" data-level="5.9.21" data-path="numericalprobability.html"><a href="numericalprobability.html#lkj-distribution"><i class="fa fa-check"></i><b>5.9.21</b> LKJ distribution </a></li>
<li class="chapter" data-level="5.9.22" data-path="numericalprobability.html"><a href="numericalprobability.html#mixture-distribution"><i class="fa fa-check"></i><b>5.9.22</b> Mixture distribution </a></li>
<li class="chapter" data-level="5.9.23" data-path="numericalprobability.html"><a href="numericalprobability.html#non-parametric-distribution"><i class="fa fa-check"></i><b>5.9.23</b> Non-parametric distribution </a></li>
<li class="chapter" data-level="5.9.24" data-path="numericalprobability.html"><a href="numericalprobability.html#multi-dimensional-density"><i class="fa fa-check"></i><b>5.9.24</b> Multi-dimensional Density </a></li>
</ul></li>
<li class="chapter" data-level="5.10" data-path="numericalprobability.html"><a href="numericalprobability.html#summary-3"><i class="fa fa-check"></i><b>5.10</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="statistics.html"><a href="statistics.html"><i class="fa fa-check"></i><b>6</b> Statistical Computation</a><ul>
<li class="chapter" data-level="6.1" data-path="statistics.html"><a href="statistics.html#descriptive-statistics"><i class="fa fa-check"></i><b>6.1</b> Descriptive Statistics</a><ul>
<li class="chapter" data-level="6.1.1" data-path="statistics.html"><a href="statistics.html#visual-representation"><i class="fa fa-check"></i><b>6.1.1</b> Visual Representation</a></li>
<li class="chapter" data-level="6.1.2" data-path="statistics.html"><a href="statistics.html#central-tendency"><i class="fa fa-check"></i><b>6.1.2</b> Central Tendency </a></li>
<li class="chapter" data-level="6.1.3" data-path="statistics.html"><a href="statistics.html#variability"><i class="fa fa-check"></i><b>6.1.3</b> Variability </a></li>
<li class="chapter" data-level="6.1.4" data-path="statistics.html"><a href="statistics.html#kurtosis-and-skewness"><i class="fa fa-check"></i><b>6.1.4</b> Kurtosis and Skewness  </a></li>
<li class="chapter" data-level="6.1.5" data-path="statistics.html"><a href="statistics.html#five-number-summary"><i class="fa fa-check"></i><b>6.1.5</b> Five Number Summary  </a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="statistics.html"><a href="statistics.html#inferential-statistics"><i class="fa fa-check"></i><b>6.2</b> Inferential Statistics</a></li>
<li class="chapter" data-level="6.3" data-path="statistics.html"><a href="statistics.html#the-significance-of-difference"><i class="fa fa-check"></i><b>6.3</b> The Significance of Difference </a><ul>
<li class="chapter" data-level="6.3.1" data-path="statistics.html"><a href="statistics.html#hypothesis"><i class="fa fa-check"></i><b>6.3.1</b> Hypothesis</a></li>
<li class="chapter" data-level="6.3.2" data-path="statistics.html"><a href="statistics.html#t-test-true-variance-unknown"><i class="fa fa-check"></i><b>6.3.2</b> T-Test (True Variance unknown) </a></li>
<li class="chapter" data-level="6.3.3" data-path="statistics.html"><a href="statistics.html#z-test-true-variance-known"><i class="fa fa-check"></i><b>6.3.3</b> Z-Test (True Variance known)</a></li>
<li class="chapter" data-level="6.3.4" data-path="statistics.html"><a href="statistics.html#f-test-using-f-ratio"><i class="fa fa-check"></i><b>6.3.4</b> F-Test using F-ratio  </a></li>
<li class="chapter" data-level="6.3.5" data-path="statistics.html"><a href="statistics.html#f-test-with-one-way-anova"><i class="fa fa-check"></i><b>6.3.5</b> F-Test with One-Way ANOVA </a></li>
<li class="chapter" data-level="6.3.6" data-path="statistics.html"><a href="statistics.html#f-test-with-two-way-anova"><i class="fa fa-check"></i><b>6.3.6</b> F-Test with Two-Way ANOVA </a></li>
<li class="chapter" data-level="6.3.7" data-path="statistics.html"><a href="statistics.html#pearsons-chi-square-test"><i class="fa fa-check"></i><b>6.3.7</b> Pearsonâs Chi-square Test </a></li>
<li class="chapter" data-level="6.3.8" data-path="statistics.html"><a href="statistics.html#wilcoxon-test"><i class="fa fa-check"></i><b>6.3.8</b> Wilcoxon Test  </a></li>
<li class="chapter" data-level="6.3.9" data-path="statistics.html"><a href="statistics.html#kruskal-wallis-test"><i class="fa fa-check"></i><b>6.3.9</b> Kruskal-Wallis Test </a></li>
<li class="chapter" data-level="6.3.10" data-path="statistics.html"><a href="statistics.html#friedman-test"><i class="fa fa-check"></i><b>6.3.10</b> Friedman Test </a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="statistics.html"><a href="statistics.html#post-hoc-analysis"><i class="fa fa-check"></i><b>6.4</b> Post-HOC Analysis </a><ul>
<li class="chapter" data-level="6.4.1" data-path="statistics.html"><a href="statistics.html#bonferroni-correction"><i class="fa fa-check"></i><b>6.4.1</b> Bonferroni Correction </a></li>
<li class="chapter" data-level="6.4.2" data-path="statistics.html"><a href="statistics.html#benjamini-hochberg-correction"><i class="fa fa-check"></i><b>6.4.2</b> Benjamini-Hochberg Correction </a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="statistics.html"><a href="statistics.html#multiple-comparison-tests"><i class="fa fa-check"></i><b>6.5</b> Multiple Comparison Tests </a><ul>
<li class="chapter" data-level="6.5.1" data-path="statistics.html"><a href="statistics.html#scheffes-test"><i class="fa fa-check"></i><b>6.5.1</b> Scheffeâs Test </a></li>
<li class="chapter" data-level="6.5.2" data-path="statistics.html"><a href="statistics.html#fishers-test"><i class="fa fa-check"></i><b>6.5.2</b> Fisherâs Test </a></li>
<li class="chapter" data-level="6.5.3" data-path="statistics.html"><a href="statistics.html#tukeys-test"><i class="fa fa-check"></i><b>6.5.3</b> Tukeyâs Test </a></li>
<li class="chapter" data-level="6.5.4" data-path="statistics.html"><a href="statistics.html#newman-keul-test"><i class="fa fa-check"></i><b>6.5.4</b> Newman-Keul Test  </a></li>
<li class="chapter" data-level="6.5.5" data-path="statistics.html"><a href="statistics.html#games-howell-test"><i class="fa fa-check"></i><b>6.5.5</b> Games-Howell Test </a></li>
<li class="chapter" data-level="6.5.6" data-path="statistics.html"><a href="statistics.html#dunnetts-test"><i class="fa fa-check"></i><b>6.5.6</b> Dunnettâs Test </a></li>
<li class="chapter" data-level="6.5.7" data-path="statistics.html"><a href="statistics.html#duncans-test"><i class="fa fa-check"></i><b>6.5.7</b> Duncanâs Test </a></li>
<li class="chapter" data-level="6.5.8" data-path="statistics.html"><a href="statistics.html#meta-analysis-test"><i class="fa fa-check"></i><b>6.5.8</b> Meta-Analysis Test </a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="statistics.html"><a href="statistics.html#statistical-modeling"><i class="fa fa-check"></i><b>6.6</b> Statistical Modeling </a><ul>
<li class="chapter" data-level="6.6.1" data-path="statistics.html"><a href="statistics.html#model-specification"><i class="fa fa-check"></i><b>6.6.1</b> Model Specification </a></li>
<li class="chapter" data-level="6.6.2" data-path="statistics.html"><a href="statistics.html#statistical-interaction"><i class="fa fa-check"></i><b>6.6.2</b> Statistical Interaction </a></li>
<li class="chapter" data-level="6.6.3" data-path="statistics.html"><a href="statistics.html#dummy-variables"><i class="fa fa-check"></i><b>6.6.3</b> Dummy Variables </a></li>
<li class="chapter" data-level="6.6.4" data-path="statistics.html"><a href="statistics.html#model-selection"><i class="fa fa-check"></i><b>6.6.4</b> Model Selection </a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="statistics.html"><a href="statistics.html#regression-analysis"><i class="fa fa-check"></i><b>6.7</b> Regression Analysis </a><ul>
<li class="chapter" data-level="6.7.1" data-path="statistics.html"><a href="statistics.html#assumptions"><i class="fa fa-check"></i><b>6.7.1</b> Assumptions</a></li>
<li class="chapter" data-level="6.7.2" data-path="statistics.html"><a href="statistics.html#correlation-coefficients"><i class="fa fa-check"></i><b>6.7.2</b> Correlation Coefficients </a></li>
<li class="chapter" data-level="6.7.3" data-path="statistics.html"><a href="statistics.html#homoscedasticity-and-heteroscedasticity"><i class="fa fa-check"></i><b>6.7.3</b> Homoscedasticity and Heteroscedasticity  </a></li>
<li class="chapter" data-level="6.7.4" data-path="statistics.html"><a href="statistics.html#normality-and-leverage"><i class="fa fa-check"></i><b>6.7.4</b> Normality and Leverage  </a></li>
<li class="chapter" data-level="6.7.5" data-path="statistics.html"><a href="statistics.html#collinearity"><i class="fa fa-check"></i><b>6.7.5</b> Collinearity </a></li>
<li class="chapter" data-level="6.7.6" data-path="statistics.html"><a href="statistics.html#dispersion"><i class="fa fa-check"></i><b>6.7.6</b> Dispersion </a></li>
<li class="chapter" data-level="6.7.7" data-path="statistics.html"><a href="statistics.html#diagnostic-plots"><i class="fa fa-check"></i><b>6.7.7</b> Diagnostic Plots</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="statistics.html"><a href="statistics.html#the-significance-of-regression"><i class="fa fa-check"></i><b>6.8</b> The Significance of Regression </a><ul>
<li class="chapter" data-level="6.8.1" data-path="statistics.html"><a href="statistics.html#simple-linear-regression"><i class="fa fa-check"></i><b>6.8.1</b> Simple Linear Regression</a></li>
<li class="chapter" data-level="6.8.2" data-path="statistics.html"><a href="statistics.html#multilinear-regression"><i class="fa fa-check"></i><b>6.8.2</b> Multilinear Regression </a></li>
<li class="chapter" data-level="6.8.3" data-path="statistics.html"><a href="statistics.html#logistic-regression"><i class="fa fa-check"></i><b>6.8.3</b> Logistic Regression </a></li>
<li class="chapter" data-level="6.8.4" data-path="statistics.html"><a href="statistics.html#poisson-regression"><i class="fa fa-check"></i><b>6.8.4</b> Poisson Regression </a></li>
<li class="chapter" data-level="6.8.5" data-path="statistics.html"><a href="statistics.html#cox-regression"><i class="fa fa-check"></i><b>6.8.5</b> Cox Regression </a></li>
<li class="chapter" data-level="6.8.6" data-path="statistics.html"><a href="statistics.html#polynomial-regression"><i class="fa fa-check"></i><b>6.8.6</b> Polynomial Regression </a></li>
<li class="chapter" data-level="6.8.7" data-path="statistics.html"><a href="statistics.html#b-splines-and-natural-splines"><i class="fa fa-check"></i><b>6.8.7</b> B-Splines and Natural Splines  </a></li>
<li class="chapter" data-level="6.8.8" data-path="statistics.html"><a href="statistics.html#spline-smoothing"><i class="fa fa-check"></i><b>6.8.8</b> Spline Smoothing </a></li>
<li class="chapter" data-level="6.8.9" data-path="statistics.html"><a href="statistics.html#loess-and-lowess"><i class="fa fa-check"></i><b>6.8.9</b> LOESS and LOWESS  </a></li>
</ul></li>
<li class="chapter" data-level="6.9" data-path="statistics.html"><a href="statistics.html#inference-for-regression"><i class="fa fa-check"></i><b>6.9</b> Inference for Regression</a><ul>
<li class="chapter" data-level="6.9.1" data-path="statistics.html"><a href="statistics.html#goodness-of-fit-linear-regression"><i class="fa fa-check"></i><b>6.9.1</b> Goodness of Fit (Linear Regression) </a></li>
<li class="chapter" data-level="6.9.2" data-path="statistics.html"><a href="statistics.html#goodness-of-fit-non-linear-regression"><i class="fa fa-check"></i><b>6.9.2</b> Goodness of Fit (Non-Linear Regression) </a></li>
<li class="chapter" data-level="6.9.3" data-path="statistics.html"><a href="statistics.html#confidence-interval"><i class="fa fa-check"></i><b>6.9.3</b> Confidence interval </a></li>
</ul></li>
<li class="chapter" data-level="6.10" data-path="statistics.html"><a href="statistics.html#summary-4"><i class="fa fa-check"></i><b>6.10</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="bayesian.html"><a href="bayesian.html"><i class="fa fa-check"></i><b>7</b> Bayesian Computation I</a><ul>
<li class="chapter" data-level="7.1" data-path="bayesian.html"><a href="bayesian.html#probability-1"><i class="fa fa-check"></i><b>7.1</b> Probability </a><ul>
<li class="chapter" data-level="7.1.1" data-path="bayesian.html"><a href="bayesian.html#marginal-probability"><i class="fa fa-check"></i><b>7.1.1</b> Marginal Probability </a></li>
<li class="chapter" data-level="7.1.2" data-path="bayesian.html"><a href="bayesian.html#joint-probability"><i class="fa fa-check"></i><b>7.1.2</b> Joint Probability </a></li>
<li class="chapter" data-level="7.1.3" data-path="bayesian.html"><a href="bayesian.html#conditional-probability"><i class="fa fa-check"></i><b>7.1.3</b> Conditional Probability </a></li>
<li class="chapter" data-level="7.1.4" data-path="bayesian.html"><a href="bayesian.html#negation-probability"><i class="fa fa-check"></i><b>7.1.4</b> Negation Probability </a></li>
<li class="chapter" data-level="7.1.5" data-path="bayesian.html"><a href="bayesian.html#combination-of-probabilities"><i class="fa fa-check"></i><b>7.1.5</b> Combination of Probabilities</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="bayesian.html"><a href="bayesian.html#probability-rules"><i class="fa fa-check"></i><b>7.2</b> Probability Rules</a><ul>
<li class="chapter" data-level="7.2.1" data-path="bayesian.html"><a href="bayesian.html#law-of-total-probability"><i class="fa fa-check"></i><b>7.2.1</b> Law of Total Probability</a></li>
<li class="chapter" data-level="7.2.2" data-path="bayesian.html"><a href="bayesian.html#law-of-total-expectation"><i class="fa fa-check"></i><b>7.2.2</b> Law of Total Expectation </a></li>
<li class="chapter" data-level="7.2.3" data-path="bayesian.html"><a href="bayesian.html#law-of-total-variance"><i class="fa fa-check"></i><b>7.2.3</b> Law of Total Variance </a></li>
<li class="chapter" data-level="7.2.4" data-path="bayesian.html"><a href="bayesian.html#law-of-total-covariance"><i class="fa fa-check"></i><b>7.2.4</b> Law of Total Covariance </a></li>
<li class="chapter" data-level="7.2.5" data-path="bayesian.html"><a href="bayesian.html#law-of-large-numbers"><i class="fa fa-check"></i><b>7.2.5</b> Law of Large Numbers </a></li>
<li class="chapter" data-level="7.2.6" data-path="bayesian.html"><a href="bayesian.html#central-limit-theorem"><i class="fa fa-check"></i><b>7.2.6</b> Central Limit Theorem </a></li>
<li class="chapter" data-level="7.2.7" data-path="bayesian.html"><a href="bayesian.html#rule-of-independence"><i class="fa fa-check"></i><b>7.2.7</b> Rule of Independence </a></li>
<li class="chapter" data-level="7.2.8" data-path="bayesian.html"><a href="bayesian.html#rule-of-exchangeability"><i class="fa fa-check"></i><b>7.2.8</b> Rule of Exchangeability </a></li>
<li class="chapter" data-level="7.2.9" data-path="bayesian.html"><a href="bayesian.html#rule-of-expectation-and-variance"><i class="fa fa-check"></i><b>7.2.9</b> Rule of Expectation and Variance</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="bayesian.html"><a href="bayesian.html#bayes-theorem"><i class="fa fa-check"></i><b>7.3</b> Bayes Theorem </a><ul>
<li class="chapter" data-level="7.3.1" data-path="bayesian.html"><a href="bayesian.html#naÃ¯ve-bayes"><i class="fa fa-check"></i><b>7.3.1</b> NaÃ¯ve Bayes </a></li>
<li class="chapter" data-level="7.3.2" data-path="bayesian.html"><a href="bayesian.html#likelihood"><i class="fa fa-check"></i><b>7.3.2</b> Likelihood</a></li>
<li class="chapter" data-level="7.3.3" data-path="bayesian.html"><a href="bayesian.html#posterior-probability"><i class="fa fa-check"></i><b>7.3.3</b> Posterior Probability  </a></li>
<li class="chapter" data-level="7.3.4" data-path="bayesian.html"><a href="bayesian.html#prior-probability"><i class="fa fa-check"></i><b>7.3.4</b> Prior Probability  </a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="bayesian.html"><a href="bayesian.html#conjugacy"><i class="fa fa-check"></i><b>7.4</b> Conjugacy</a><ul>
<li class="chapter" data-level="7.4.1" data-path="bayesian.html"><a href="bayesian.html#precision-1"><i class="fa fa-check"></i><b>7.4.1</b> Precision </a></li>
<li class="chapter" data-level="7.4.2" data-path="bayesian.html"><a href="bayesian.html#conjugate-prior"><i class="fa fa-check"></i><b>7.4.2</b> Conjugate Prior </a></li>
<li class="chapter" data-level="7.4.3" data-path="bayesian.html"><a href="bayesian.html#normal-normal-conjugacy"><i class="fa fa-check"></i><b>7.4.3</b> Normal-Normal Conjugacy </a></li>
<li class="chapter" data-level="7.4.4" data-path="bayesian.html"><a href="bayesian.html#normal-inverse-gamma-conjugacy"><i class="fa fa-check"></i><b>7.4.4</b> Normal-Inverse Gamma Conjugacy </a></li>
<li class="chapter" data-level="7.4.5" data-path="bayesian.html"><a href="bayesian.html#multivariate-normal-conjugacy"><i class="fa fa-check"></i><b>7.4.5</b> Multivariate Normal Conjugacy </a></li>
<li class="chapter" data-level="7.4.6" data-path="bayesian.html"><a href="bayesian.html#normal-wishart-conjugacy"><i class="fa fa-check"></i><b>7.4.6</b> Normal Wishart Conjugacy </a></li>
<li class="chapter" data-level="7.4.7" data-path="bayesian.html"><a href="bayesian.html#normal-inverse-wishart-conjugacy"><i class="fa fa-check"></i><b>7.4.7</b> Normal-Inverse Wishart Conjugacy </a></li>
<li class="chapter" data-level="7.4.8" data-path="bayesian.html"><a href="bayesian.html#normal-lkj-conjugacy"><i class="fa fa-check"></i><b>7.4.8</b> Normal-LKJ Conjugacy </a></li>
<li class="chapter" data-level="7.4.9" data-path="bayesian.html"><a href="bayesian.html#binomial-beta-conjugacy"><i class="fa fa-check"></i><b>7.4.9</b> Binomial-Beta Conjugacy </a></li>
<li class="chapter" data-level="7.4.10" data-path="bayesian.html"><a href="bayesian.html#geometric-beta-conjugacy"><i class="fa fa-check"></i><b>7.4.10</b> Geometric-Beta Conjugacy </a></li>
<li class="chapter" data-level="7.4.11" data-path="bayesian.html"><a href="bayesian.html#poisson-gamma-conjugacy"><i class="fa fa-check"></i><b>7.4.11</b> Poisson-Gamma Conjugacy </a></li>
<li class="chapter" data-level="7.4.12" data-path="bayesian.html"><a href="bayesian.html#exponential-gamma-conjugacy"><i class="fa fa-check"></i><b>7.4.12</b> Exponential-Gamma Conjugacy </a></li>
<li class="chapter" data-level="7.4.13" data-path="bayesian.html"><a href="bayesian.html#multinomial-dirichlet-conjugacy"><i class="fa fa-check"></i><b>7.4.13</b> Multinomial-Dirichlet Conjugacy </a></li>
<li class="chapter" data-level="7.4.14" data-path="bayesian.html"><a href="bayesian.html#hyperparameters"><i class="fa fa-check"></i><b>7.4.14</b> Hyperparameters </a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="bayesian.html"><a href="bayesian.html#information-theory"><i class="fa fa-check"></i><b>7.5</b> Information Theory </a><ul>
<li class="chapter" data-level="7.5.1" data-path="bayesian.html"><a href="bayesian.html#information"><i class="fa fa-check"></i><b>7.5.1</b> Information </a></li>
<li class="chapter" data-level="7.5.2" data-path="bayesian.html"><a href="bayesian.html#entropy"><i class="fa fa-check"></i><b>7.5.2</b> Entropy </a></li>
<li class="chapter" data-level="7.5.3" data-path="bayesian.html"><a href="bayesian.html#gini-index"><i class="fa fa-check"></i><b>7.5.3</b> Gini Index </a></li>
<li class="chapter" data-level="7.5.4" data-path="bayesian.html"><a href="bayesian.html#information-gain"><i class="fa fa-check"></i><b>7.5.4</b> Information Gain </a></li>
<li class="chapter" data-level="7.5.5" data-path="bayesian.html"><a href="bayesian.html#mutual-information"><i class="fa fa-check"></i><b>7.5.5</b> Mutual Information </a></li>
<li class="chapter" data-level="7.5.6" data-path="bayesian.html"><a href="bayesian.html#kullback-leibler-divergence"><i class="fa fa-check"></i><b>7.5.6</b> Kullback-Leibler Divergence  </a></li>
<li class="chapter" data-level="7.5.7" data-path="bayesian.html"><a href="bayesian.html#jensens-inequality"><i class="fa fa-check"></i><b>7.5.7</b> Jensenâs Inequality</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="bayesian.html"><a href="bayesian.html#bayesianinference"><i class="fa fa-check"></i><b>7.6</b> Bayesian Inference</a><ul>
<li class="chapter" data-level="7.6.1" data-path="bayesian.html"><a href="bayesian.html#maximum-likelihood-mle"><i class="fa fa-check"></i><b>7.6.1</b> Maximum Likelihood (MLE)  </a></li>
<li class="chapter" data-level="7.6.2" data-path="bayesian.html"><a href="bayesian.html#maximum-a-posteriori-map"><i class="fa fa-check"></i><b>7.6.2</b> Maximum A-posteriori (MAP)  </a></li>
<li class="chapter" data-level="7.6.3" data-path="bayesian.html"><a href="bayesian.html#laplace-approximation"><i class="fa fa-check"></i><b>7.6.3</b> Laplace Approximation </a></li>
<li class="chapter" data-level="7.6.4" data-path="bayesian.html"><a href="bayesian.html#expectation-maximization-em"><i class="fa fa-check"></i><b>7.6.4</b> Expectation-Maximization (EM)  </a></li>
<li class="chapter" data-level="7.6.5" data-path="bayesian.html"><a href="bayesian.html#variational-inference"><i class="fa fa-check"></i><b>7.6.5</b> Variational Inference </a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="bayesian2.html"><a href="bayesian2.html"><i class="fa fa-check"></i><b>8</b> Bayesian Computation II</a><ul>
<li class="chapter" data-level="8.1" data-path="bayesian2.html"><a href="bayesian2.html#bayesian-models"><i class="fa fa-check"></i><b>8.1</b> Bayesian Models </a><ul>
<li class="chapter" data-level="8.1.1" data-path="bayesian2.html"><a href="bayesian2.html#belief-propagation"><i class="fa fa-check"></i><b>8.1.1</b> Belief Propagation </a></li>
<li class="chapter" data-level="8.1.2" data-path="bayesian2.html"><a href="bayesian2.html#expectation-propagation"><i class="fa fa-check"></i><b>8.1.2</b> Expectation Propagation </a></li>
<li class="chapter" data-level="8.1.3" data-path="bayesian2.html"><a href="bayesian2.html#markov-chain"><i class="fa fa-check"></i><b>8.1.3</b> Markov Chain </a></li>
<li class="chapter" data-level="8.1.4" data-path="bayesian2.html"><a href="bayesian2.html#hidden-markov-model"><i class="fa fa-check"></i><b>8.1.4</b> Hidden Markov Model  </a></li>
<li class="chapter" data-level="8.1.5" data-path="bayesian2.html"><a href="bayesian2.html#dynamic-system-model"><i class="fa fa-check"></i><b>8.1.5</b> Dynamic System Model</a></li>
<li class="chapter" data-level="8.1.6" data-path="bayesian2.html"><a href="bayesian2.html#bayes-filter"><i class="fa fa-check"></i><b>8.1.6</b> Bayes Filter </a></li>
<li class="chapter" data-level="8.1.7" data-path="bayesian2.html"><a href="bayesian2.html#kalman-filter"><i class="fa fa-check"></i><b>8.1.7</b> Kalman Filter </a></li>
<li class="chapter" data-level="8.1.8" data-path="bayesian2.html"><a href="bayesian2.html#extended-kalman-filter"><i class="fa fa-check"></i><b>8.1.8</b> Extended Kalman Filter </a></li>
<li class="chapter" data-level="8.1.9" data-path="bayesian2.html"><a href="bayesian2.html#unscented-kalman-filter"><i class="fa fa-check"></i><b>8.1.9</b> Unscented Kalman Filter </a></li>
<li class="chapter" data-level="8.1.10" data-path="bayesian2.html"><a href="bayesian2.html#particle-filter"><i class="fa fa-check"></i><b>8.1.10</b> Particle Filter </a></li>
<li class="chapter" data-level="8.1.11" data-path="bayesian2.html"><a href="bayesian2.html#ensemble-kalman-filter"><i class="fa fa-check"></i><b>8.1.11</b> Ensemble Kalman Filter </a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="bayesian2.html"><a href="bayesian2.html#simulation-and-sampling"><i class="fa fa-check"></i><b>8.2</b> Simulation and Sampling</a><ul>
<li class="chapter" data-level="8.2.1" data-path="bayesian2.html"><a href="bayesian2.html#monte-carlo-estimation"><i class="fa fa-check"></i><b>8.2.1</b> Monte Carlo Estimation </a></li>
<li class="chapter" data-level="8.2.2" data-path="bayesian2.html"><a href="bayesian2.html#monte-carlo-simulation"><i class="fa fa-check"></i><b>8.2.2</b> Monte Carlo Simulation </a></li>
<li class="chapter" data-level="8.2.3" data-path="bayesian2.html"><a href="bayesian2.html#markov-chain-monte-carlo"><i class="fa fa-check"></i><b>8.2.3</b> Markov Chain Monte Carlo  </a></li>
<li class="chapter" data-level="8.2.4" data-path="bayesian2.html"><a href="bayesian2.html#metropolis-hastings-monte-carlo"><i class="fa fa-check"></i><b>8.2.4</b> Metropolis-Hastings Monte Carlo  </a></li>
<li class="chapter" data-level="8.2.5" data-path="bayesian2.html"><a href="bayesian2.html#hamiltonian-monte-carlo"><i class="fa fa-check"></i><b>8.2.5</b> Hamiltonian Monte Carlo  </a></li>
<li class="chapter" data-level="8.2.6" data-path="bayesian2.html"><a href="bayesian2.html#gibbs-sampling"><i class="fa fa-check"></i><b>8.2.6</b> Gibbs Sampling </a></li>
<li class="chapter" data-level="8.2.7" data-path="bayesian2.html"><a href="bayesian2.html#importance-sampling"><i class="fa fa-check"></i><b>8.2.7</b> Importance Sampling </a></li>
<li class="chapter" data-level="8.2.8" data-path="bayesian2.html"><a href="bayesian2.html#rejection-sampling"><i class="fa fa-check"></i><b>8.2.8</b> Rejection Sampling </a></li>
<li class="chapter" data-level="8.2.9" data-path="bayesian2.html"><a href="bayesian2.html#jags-modeling"><i class="fa fa-check"></i><b>8.2.9</b> JAGS Modeling </a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="bayesian2.html"><a href="bayesian2.html#bayesian-analysis"><i class="fa fa-check"></i><b>8.3</b> Bayesian Analysis</a><ul>
<li class="chapter" data-level="8.3.1" data-path="bayesian2.html"><a href="bayesian2.html#autocorrelation"><i class="fa fa-check"></i><b>8.3.1</b> Autocorrelation </a></li>
<li class="chapter" data-level="8.3.2" data-path="bayesian2.html"><a href="bayesian2.html#predictive-probability"><i class="fa fa-check"></i><b>8.3.2</b> Predictive Probability </a></li>
<li class="chapter" data-level="8.3.3" data-path="bayesian2.html"><a href="bayesian2.html#posterior-interval"><i class="fa fa-check"></i><b>8.3.3</b> Posterior Interval </a></li>
<li class="chapter" data-level="8.3.4" data-path="bayesian2.html"><a href="bayesian2.html#bayes-factor"><i class="fa fa-check"></i><b>8.3.4</b> Bayes Factor </a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="bayesian2.html"><a href="bayesian2.html#summary-5"><i class="fa fa-check"></i><b>8.4</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="machinelearning1.html"><a href="machinelearning1.html"><i class="fa fa-check"></i><b>9</b> Computational Learning I</a><ul>
<li class="chapter" data-level="9.1" data-path="machinelearning1.html"><a href="machinelearning1.html#observation-and-measurement"><i class="fa fa-check"></i><b>9.1</b> Observation and Measurement</a><ul>
<li class="chapter" data-level="9.1.1" data-path="machinelearning1.html"><a href="machinelearning1.html#levels-of-measurements"><i class="fa fa-check"></i><b>9.1.1</b> Levels of Measurements</a></li>
<li class="chapter" data-level="9.1.2" data-path="machinelearning1.html"><a href="machinelearning1.html#levels-of-categorical-measurements"><i class="fa fa-check"></i><b>9.1.2</b> Levels of Categorical measurements</a></li>
<li class="chapter" data-level="9.1.3" data-path="machinelearning1.html"><a href="machinelearning1.html#levels-of-continuous-measurements"><i class="fa fa-check"></i><b>9.1.3</b> Levels of Continuous measurements</a></li>
<li class="chapter" data-level="9.1.4" data-path="machinelearning1.html"><a href="machinelearning1.html#discrete-vs-continuous-measurements"><i class="fa fa-check"></i><b>9.1.4</b> Discrete vs Continuous measurements</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="machinelearning1.html"><a href="machinelearning1.html#input-data"><i class="fa fa-check"></i><b>9.2</b> Input Data</a><ul>
<li class="chapter" data-level="9.2.1" data-path="machinelearning1.html"><a href="machinelearning1.html#structured-data"><i class="fa fa-check"></i><b>9.2.1</b> Structured Data</a></li>
<li class="chapter" data-level="9.2.2" data-path="machinelearning1.html"><a href="machinelearning1.html#non-structured-data"><i class="fa fa-check"></i><b>9.2.2</b> Non-Structured Data</a></li>
<li class="chapter" data-level="9.2.3" data-path="machinelearning1.html"><a href="machinelearning1.html#statistical-data"><i class="fa fa-check"></i><b>9.2.3</b> Statistical Data</a></li>
<li class="chapter" data-level="9.2.4" data-path="machinelearning1.html"><a href="machinelearning1.html#real-time-and-near-real-time-data"><i class="fa fa-check"></i><b>9.2.4</b> Real-Time and Near Real-Time Data</a></li>
<li class="chapter" data-level="9.2.5" data-path="machinelearning1.html"><a href="machinelearning1.html#oltp-and-datawarehouse"><i class="fa fa-check"></i><b>9.2.5</b> OLTP and Datawarehouse</a></li>
<li class="chapter" data-level="9.2.6" data-path="machinelearning1.html"><a href="machinelearning1.html#data-lake"><i class="fa fa-check"></i><b>9.2.6</b> Data lake</a></li>
<li class="chapter" data-level="9.2.7" data-path="machinelearning1.html"><a href="machinelearning1.html#natural-language-nl"><i class="fa fa-check"></i><b>9.2.7</b> Natural Language (NL)</a></li>
<li class="chapter" data-level="9.2.8" data-path="machinelearning1.html"><a href="machinelearning1.html#multimedia-md"><i class="fa fa-check"></i><b>9.2.8</b> Multimedia (MD)</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="machinelearning1.html"><a href="machinelearning1.html#primitive-methods"><i class="fa fa-check"></i><b>9.3</b> Primitive Methods</a><ul>
<li class="chapter" data-level="9.3.1" data-path="machinelearning1.html"><a href="machinelearning1.html#weighting"><i class="fa fa-check"></i><b>9.3.1</b> Weighting</a></li>
<li class="chapter" data-level="9.3.2" data-path="machinelearning1.html"><a href="machinelearning1.html#smoothing"><i class="fa fa-check"></i><b>9.3.2</b> Smoothing</a></li>
<li class="chapter" data-level="9.3.3" data-path="machinelearning1.html"><a href="machinelearning1.html#normalizing"><i class="fa fa-check"></i><b>9.3.3</b> Normalizing</a></li>
<li class="chapter" data-level="9.3.4" data-path="machinelearning1.html"><a href="machinelearning1.html#standardizing"><i class="fa fa-check"></i><b>9.3.4</b> Standardizing </a></li>
<li class="chapter" data-level="9.3.5" data-path="machinelearning1.html"><a href="machinelearning1.html#centering"><i class="fa fa-check"></i><b>9.3.5</b> Centering </a></li>
<li class="chapter" data-level="9.3.6" data-path="machinelearning1.html"><a href="machinelearning1.html#scaling-1"><i class="fa fa-check"></i><b>9.3.6</b> Scaling </a></li>
<li class="chapter" data-level="9.3.7" data-path="machinelearning1.html"><a href="machinelearning1.html#transforming"><i class="fa fa-check"></i><b>9.3.7</b> Transforming</a></li>
<li class="chapter" data-level="9.3.8" data-path="machinelearning1.html"><a href="machinelearning1.html#clipping"><i class="fa fa-check"></i><b>9.3.8</b> Clipping </a></li>
<li class="chapter" data-level="9.3.9" data-path="machinelearning1.html"><a href="machinelearning1.html#regularizing"><i class="fa fa-check"></i><b>9.3.9</b> Regularizing</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="machinelearning1.html"><a href="machinelearning1.html#distance-metrics"><i class="fa fa-check"></i><b>9.4</b> Distance Metrics</a><ul>
<li class="chapter" data-level="9.4.1" data-path="machinelearning1.html"><a href="machinelearning1.html#cosine-similarity"><i class="fa fa-check"></i><b>9.4.1</b> Cosine Similarity</a></li>
<li class="chapter" data-level="9.4.2" data-path="machinelearning1.html"><a href="machinelearning1.html#manhattan-and-euclidean-distance"><i class="fa fa-check"></i><b>9.4.2</b> Manhattan and Euclidean Distance  </a></li>
<li class="chapter" data-level="9.4.3" data-path="machinelearning1.html"><a href="machinelearning1.html#minkowski-and-chebyshev-supremum-distance"><i class="fa fa-check"></i><b>9.4.3</b> Minkowski and Chebyshev (Supremum) Distance  </a></li>
<li class="chapter" data-level="9.4.4" data-path="machinelearning1.html"><a href="machinelearning1.html#jaccard-similarity-and-distance"><i class="fa fa-check"></i><b>9.4.4</b> Jaccard (Similarity and Distance) </a></li>
<li class="chapter" data-level="9.4.5" data-path="machinelearning1.html"><a href="machinelearning1.html#hamming-distance"><i class="fa fa-check"></i><b>9.4.5</b> Hamming Distance </a></li>
<li class="chapter" data-level="9.4.6" data-path="machinelearning1.html"><a href="machinelearning1.html#mahalanobis-distance"><i class="fa fa-check"></i><b>9.4.6</b> Mahalanobis Distance </a></li>
<li class="chapter" data-level="9.4.7" data-path="machinelearning1.html"><a href="machinelearning1.html#precision-and-accuracy"><i class="fa fa-check"></i><b>9.4.7</b> Precision and Accuracy  </a></li>
<li class="chapter" data-level="9.4.8" data-path="machinelearning1.html"><a href="machinelearning1.html#auc-on-roc"><i class="fa fa-check"></i><b>9.4.8</b> AUC on ROC </a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="machinelearning1.html"><a href="machinelearning1.html#exploratory-data-analysis"><i class="fa fa-check"></i><b>9.5</b> Exploratory Data Analysis</a><ul>
<li class="chapter" data-level="9.5.1" data-path="machinelearning1.html"><a href="machinelearning1.html#data-cleaning-wrangling"><i class="fa fa-check"></i><b>9.5.1</b> Data Cleaning (Wrangling)  </a></li>
<li class="chapter" data-level="9.5.2" data-path="machinelearning1.html"><a href="machinelearning1.html#association"><i class="fa fa-check"></i><b>9.5.2</b> Association</a></li>
<li class="chapter" data-level="9.5.3" data-path="machinelearning1.html"><a href="machinelearning1.html#pattern-discovery"><i class="fa fa-check"></i><b>9.5.3</b> Pattern Discovery</a></li>
<li class="chapter" data-level="9.5.4" data-path="machinelearning1.html"><a href="machinelearning1.html#null-invariance"><i class="fa fa-check"></i><b>9.5.4</b> Null Invariance </a></li>
<li class="chapter" data-level="9.5.5" data-path="machinelearning1.html"><a href="machinelearning1.html#correlation-and-collinearity"><i class="fa fa-check"></i><b>9.5.5</b> Correlation and Collinearity  </a></li>
<li class="chapter" data-level="9.5.6" data-path="machinelearning1.html"><a href="machinelearning1.html#covariance"><i class="fa fa-check"></i><b>9.5.6</b> Covariance </a></li>
<li class="chapter" data-level="9.5.7" data-path="machinelearning1.html"><a href="machinelearning1.html#outliers-leverage-influence"><i class="fa fa-check"></i><b>9.5.7</b> Outliers, Leverage, Influence   </a></li>
<li class="chapter" data-level="9.5.8" data-path="machinelearning1.html"><a href="machinelearning1.html#dominating-factors"><i class="fa fa-check"></i><b>9.5.8</b> Dominating Factors </a></li>
<li class="chapter" data-level="9.5.9" data-path="machinelearning1.html"><a href="machinelearning1.html#missingness-and-imputation"><i class="fa fa-check"></i><b>9.5.9</b> Missingness and Imputation  </a></li>
<li class="chapter" data-level="9.5.10" data-path="machinelearning1.html"><a href="machinelearning1.html#confounding-variable"><i class="fa fa-check"></i><b>9.5.10</b> Confounding Variable </a></li>
<li class="chapter" data-level="9.5.11" data-path="machinelearning1.html"><a href="machinelearning1.html#data-leakage"><i class="fa fa-check"></i><b>9.5.11</b> Data Leakage </a></li>
<li class="chapter" data-level="9.5.12" data-path="machinelearning1.html"><a href="machinelearning1.html#one-hot-encoding"><i class="fa fa-check"></i><b>9.5.12</b> One Hot Encoding </a></li>
<li class="chapter" data-level="9.5.13" data-path="machinelearning1.html"><a href="machinelearning1.html#winsorization-and-trimming"><i class="fa fa-check"></i><b>9.5.13</b> Winsorization and Trimming  </a></li>
<li class="chapter" data-level="9.5.14" data-path="machinelearning1.html"><a href="machinelearning1.html#discretization"><i class="fa fa-check"></i><b>9.5.14</b> Discretization </a></li>
<li class="chapter" data-level="9.5.15" data-path="machinelearning1.html"><a href="machinelearning1.html#stratification"><i class="fa fa-check"></i><b>9.5.15</b> Stratification </a></li>
<li class="chapter" data-level="9.5.16" data-path="machinelearning1.html"><a href="machinelearning1.html#fine-and-coarse-classing"><i class="fa fa-check"></i><b>9.5.16</b> Fine and Coarse Classing</a></li>
<li class="chapter" data-level="9.5.17" data-path="machinelearning1.html"><a href="machinelearning1.html#embedding"><i class="fa fa-check"></i><b>9.5.17</b> Embedding </a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="machinelearning1.html"><a href="machinelearning1.html#featureengineering"><i class="fa fa-check"></i><b>9.6</b> Feature Engineering</a><ul>
<li class="chapter" data-level="9.6.1" data-path="machinelearning1.html"><a href="machinelearning1.html#machine-learning-features"><i class="fa fa-check"></i><b>9.6.1</b> Machine Learning Features</a></li>
<li class="chapter" data-level="9.6.2" data-path="machinelearning1.html"><a href="machinelearning1.html#dimensionality-reduction"><i class="fa fa-check"></i><b>9.6.2</b> Dimensionality Reduction </a></li>
<li class="chapter" data-level="9.6.3" data-path="machinelearning1.html"><a href="machinelearning1.html#principal-component-analysis"><i class="fa fa-check"></i><b>9.6.3</b> Principal Component Analysis  </a></li>
<li class="chapter" data-level="9.6.4" data-path="machinelearning1.html"><a href="machinelearning1.html#linear-discriminant-analysis-lda"><i class="fa fa-check"></i><b>9.6.4</b> Linear Discriminant Analysis (LDA)  </a></li>
<li class="chapter" data-level="9.6.5" data-path="machinelearning1.html"><a href="machinelearning1.html#feature-construction"><i class="fa fa-check"></i><b>9.6.5</b> Feature Construction </a></li>
<li class="chapter" data-level="9.6.6" data-path="machinelearning1.html"><a href="machinelearning1.html#featureselection"><i class="fa fa-check"></i><b>9.6.6</b> Feature Selection</a></li>
<li class="chapter" data-level="9.6.7" data-path="machinelearning1.html"><a href="machinelearning1.html#feature-transformation"><i class="fa fa-check"></i><b>9.6.7</b> Feature Transformation </a></li>
<li class="chapter" data-level="9.6.8" data-path="machinelearning1.html"><a href="machinelearning1.html#model-specification-1"><i class="fa fa-check"></i><b>9.6.8</b> Model Specification </a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="machinelearning1.html"><a href="machinelearning1.html#general-modeling"><i class="fa fa-check"></i><b>9.7</b> General Modeling</a><ul>
<li class="chapter" data-level="9.7.1" data-path="machinelearning1.html"><a href="machinelearning1.html#training-learning"><i class="fa fa-check"></i><b>9.7.1</b> Training (Learning)</a></li>
<li class="chapter" data-level="9.7.2" data-path="machinelearning1.html"><a href="machinelearning1.html#validation-tuning"><i class="fa fa-check"></i><b>9.7.2</b> Validation (Tuning) </a></li>
<li class="chapter" data-level="9.7.3" data-path="machinelearning1.html"><a href="machinelearning1.html#testing-assessing"><i class="fa fa-check"></i><b>9.7.3</b> Testing (Assessing) </a></li>
<li class="chapter" data-level="9.7.4" data-path="machinelearning1.html"><a href="machinelearning1.html#cross-validation-cv"><i class="fa fa-check"></i><b>9.7.4</b> Cross-Validation (CV)  </a></li>
<li class="chapter" data-level="9.7.5" data-path="machinelearning1.html"><a href="machinelearning1.html#bias-and-variance"><i class="fa fa-check"></i><b>9.7.5</b> Bias and Variance </a></li>
<li class="chapter" data-level="9.7.6" data-path="machinelearning1.html"><a href="machinelearning1.html#loss-and-cost-functions"><i class="fa fa-check"></i><b>9.7.6</b> Loss and Cost Functions  </a></li>
<li class="chapter" data-level="9.7.7" data-path="machinelearning1.html"><a href="machinelearning1.html#global-and-local-minima"><i class="fa fa-check"></i><b>9.7.7</b> Global and Local Minima  </a></li>
<li class="chapter" data-level="9.7.8" data-path="machinelearning1.html"><a href="machinelearning1.html#regularization"><i class="fa fa-check"></i><b>9.7.8</b> Regularization</a></li>
</ul></li>
<li class="chapter" data-level="9.8" data-path="machinelearning1.html"><a href="machinelearning1.html#supervised-vs.unsupervised-learning"><i class="fa fa-check"></i><b>9.8</b> Supervised vs.Â Unsupervised Learning  </a></li>
<li class="chapter" data-level="9.9" data-path="machinelearning1.html"><a href="machinelearning1.html#summary-6"><i class="fa fa-check"></i><b>9.9</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="machinelearning2.html"><a href="machinelearning2.html"><i class="fa fa-check"></i><b>10</b> Computational Learning II</a><ul>
<li class="chapter" data-level="10.1" data-path="machinelearning2.html"><a href="machinelearning2.html#regression"><i class="fa fa-check"></i><b>10.1</b> Regression (Supervised)</a><ul>
<li class="chapter" data-level="10.1.1" data-path="machinelearning2.html"><a href="machinelearning2.html#regression-trees"><i class="fa fa-check"></i><b>10.1.1</b> Regression Trees </a></li>
<li class="chapter" data-level="10.1.2" data-path="machinelearning2.html"><a href="machinelearning2.html#ensemble-methods"><i class="fa fa-check"></i><b>10.1.2</b> Ensemble Methods </a></li>
<li class="chapter" data-level="10.1.3" data-path="machinelearning2.html"><a href="machinelearning2.html#random-forest"><i class="fa fa-check"></i><b>10.1.3</b> Random Forest </a></li>
<li class="chapter" data-level="10.1.4" data-path="machinelearning2.html"><a href="machinelearning2.html#Adaoost"><i class="fa fa-check"></i><b>10.1.4</b> AdaBoost</a></li>
<li class="chapter" data-level="10.1.5" data-path="machinelearning2.html"><a href="machinelearning2.html#gradient-boost"><i class="fa fa-check"></i><b>10.1.5</b> Gradient Boost </a></li>
<li class="chapter" data-level="10.1.6" data-path="machinelearning2.html"><a href="machinelearning2.html#xgboost"><i class="fa fa-check"></i><b>10.1.6</b> XGBoost </a></li>
<li class="chapter" data-level="10.1.7" data-path="machinelearning2.html"><a href="machinelearning2.html#generalized-linear-modeling-glm"><i class="fa fa-check"></i><b>10.1.7</b> Generalized Linear Modeling (GLM)  </a></li>
<li class="chapter" data-level="10.1.8" data-path="machinelearning2.html"><a href="machinelearning2.html#logisticregression"><i class="fa fa-check"></i><b>10.1.8</b> Logistic Regression (GLM)</a></li>
<li class="chapter" data-level="10.1.9" data-path="machinelearning2.html"><a href="machinelearning2.html#poisson"><i class="fa fa-check"></i><b>10.1.9</b> Poisson Regression (GLM)</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="machinelearning2.html"><a href="machinelearning2.html#binary-classification-supervised"><i class="fa fa-check"></i><b>10.2</b> Binary Classification (Supervised)</a><ul>
<li class="chapter" data-level="10.2.1" data-path="machinelearning2.html"><a href="machinelearning2.html#linear-svm-sgdpegasos"><i class="fa fa-check"></i><b>10.2.1</b> Linear SVM (SGD/PEGASOS)  </a></li>
<li class="chapter" data-level="10.2.2" data-path="machinelearning2.html"><a href="machinelearning2.html#kernel-svm-smo"><i class="fa fa-check"></i><b>10.2.2</b> Kernel SVM (SMO)  </a></li>
<li class="chapter" data-level="10.2.3" data-path="machinelearning2.html"><a href="machinelearning2.html#sdca-based-svm"><i class="fa fa-check"></i><b>10.2.3</b> SDCA-based SVM </a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="machinelearning2.html"><a href="machinelearning2.html#multi-class-classification-supervised"><i class="fa fa-check"></i><b>10.3</b> Multi-class Classification (Supervised) </a><ul>
<li class="chapter" data-level="10.3.1" data-path="machinelearning2.html"><a href="machinelearning2.html#bayesian-classification"><i class="fa fa-check"></i><b>10.3.1</b> Bayesian Classification </a></li>
<li class="chapter" data-level="10.3.2" data-path="machinelearning2.html"><a href="machinelearning2.html#classification-trees"><i class="fa fa-check"></i><b>10.3.2</b> Classification Trees </a></li>
<li class="chapter" data-level="10.3.3" data-path="machinelearning2.html"><a href="machinelearning2.html#ensemble-methods-1"><i class="fa fa-check"></i><b>10.3.3</b> Ensemble Methods </a></li>
<li class="chapter" data-level="10.3.4" data-path="machinelearning2.html"><a href="machinelearning2.html#random-forest-1"><i class="fa fa-check"></i><b>10.3.4</b> Random Forest </a></li>
<li class="chapter" data-level="10.3.5" data-path="machinelearning2.html"><a href="machinelearning2.html#AdaBoost"><i class="fa fa-check"></i><b>10.3.5</b> AdaBoost &amp; SAMME</a></li>
<li class="chapter" data-level="10.3.6" data-path="machinelearning2.html"><a href="machinelearning2.html#logitboost-j-classes"><i class="fa fa-check"></i><b>10.3.6</b> LogitBoost (J Classes)</a></li>
<li class="chapter" data-level="10.3.7" data-path="machinelearning2.html"><a href="machinelearning2.html#gradient-boost-1"><i class="fa fa-check"></i><b>10.3.7</b> Gradient Boost </a></li>
<li class="chapter" data-level="10.3.8" data-path="machinelearning2.html"><a href="machinelearning2.html#k-next-neighbors-knn"><i class="fa fa-check"></i><b>10.3.8</b> K-Next Neighbors (KNN)  </a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="machinelearning3.html"><a href="machinelearning3.html"><i class="fa fa-check"></i><b>11</b> Computational Learning III</a><ul>
<li class="chapter" data-level="11.1" data-path="machinelearning3.html"><a href="machinelearning3.html#clustering-unsupervised"><i class="fa fa-check"></i><b>11.1</b> Clustering (Unsupervised) </a><ul>
<li class="chapter" data-level="11.1.1" data-path="machinelearning3.html"><a href="machinelearning3.html#k-means-clustering"><i class="fa fa-check"></i><b>11.1.1</b> K-means (clustering) </a></li>
<li class="chapter" data-level="11.1.2" data-path="machinelearning3.html"><a href="machinelearning3.html#hierarchical-clustering"><i class="fa fa-check"></i><b>11.1.2</b> Hierarchical (clustering) </a></li>
<li class="chapter" data-level="11.1.3" data-path="machinelearning3.html"><a href="machinelearning3.html#dbscan-clustering"><i class="fa fa-check"></i><b>11.1.3</b> DBSCAN (clustering) </a></li>
<li class="chapter" data-level="11.1.4" data-path="machinelearning3.html"><a href="machinelearning3.html#quality-of-clustering"><i class="fa fa-check"></i><b>11.1.4</b> Quality of Clustering</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="machinelearning3.html"><a href="machinelearning3.html#meta-learning"><i class="fa fa-check"></i><b>11.2</b> Meta-Learning </a></li>
<li class="chapter" data-level="11.3" data-path="machinelearning3.html"><a href="machinelearning3.html#natural-language-processing-nlp"><i class="fa fa-check"></i><b>11.3</b> Natural Language Processing (NLP)  </a><ul>
<li class="chapter" data-level="11.3.1" data-path="machinelearning3.html"><a href="machinelearning3.html#pre-processing-texts"><i class="fa fa-check"></i><b>11.3.1</b> Pre-Processing Texts</a></li>
<li class="chapter" data-level="11.3.2" data-path="machinelearning3.html"><a href="machinelearning3.html#ranking-and-scoring"><i class="fa fa-check"></i><b>11.3.2</b> Ranking and Scoring </a></li>
<li class="chapter" data-level="11.3.3" data-path="machinelearning3.html"><a href="machinelearning3.html#document-similarity"><i class="fa fa-check"></i><b>11.3.3</b> Document Similarity </a></li>
<li class="chapter" data-level="11.3.4" data-path="machinelearning3.html"><a href="machinelearning3.html#linguistic-analysis"><i class="fa fa-check"></i><b>11.3.4</b> Linguistic Analysis </a></li>
<li class="chapter" data-level="11.3.5" data-path="machinelearning3.html"><a href="machinelearning3.html#lexical-analysis"><i class="fa fa-check"></i><b>11.3.5</b> Lexical Analysis </a></li>
<li class="chapter" data-level="11.3.6" data-path="machinelearning3.html"><a href="machinelearning3.html#semantic-analysis"><i class="fa fa-check"></i><b>11.3.6</b> Semantic Analysis </a></li>
<li class="chapter" data-level="11.3.7" data-path="machinelearning3.html"><a href="machinelearning3.html#named-entity-recognition-ner"><i class="fa fa-check"></i><b>11.3.7</b> Named Entity Recognition (NER)  </a></li>
<li class="chapter" data-level="11.3.8" data-path="machinelearning3.html"><a href="machinelearning3.html#sentiment-and-opinion-analysis"><i class="fa fa-check"></i><b>11.3.8</b> Sentiment and Opinion Analysis  </a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="machinelearning3.html"><a href="machinelearning3.html#time-series-forecasting"><i class="fa fa-check"></i><b>11.4</b> Time-Series Forecasting </a><ul>
<li class="chapter" data-level="11.4.1" data-path="machinelearning3.html"><a href="machinelearning3.html#seasonal-trend-decomposition-using-loess-stl"><i class="fa fa-check"></i><b>11.4.1</b> Seasonal Trend Decomposition using LOESS (STL)  </a></li>
<li class="chapter" data-level="11.4.2" data-path="machinelearning3.html"><a href="machinelearning3.html#forecasting-models"><i class="fa fa-check"></i><b>11.4.2</b> Forecasting Models </a></li>
<li class="chapter" data-level="11.4.3" data-path="machinelearning3.html"><a href="machinelearning3.html#time-series-linear-model-tslm"><i class="fa fa-check"></i><b>11.4.3</b> Time-Series Linear Model (TSLM)  </a></li>
<li class="chapter" data-level="11.4.4" data-path="machinelearning3.html"><a href="machinelearning3.html#autoregressive-integrated-moving-average-arima"><i class="fa fa-check"></i><b>11.4.4</b> AutoRegressive Integrated Moving Average (ARIMA)  </a></li>
<li class="chapter" data-level="11.4.5" data-path="machinelearning3.html"><a href="machinelearning3.html#multiplicative-seasonal-arima-sarima"><i class="fa fa-check"></i><b>11.4.5</b> Multiplicative Seasonal ARIMA (SARIMA) </a></li>
<li class="chapter" data-level="11.4.6" data-path="machinelearning3.html"><a href="machinelearning3.html#time-series-decomposition"><i class="fa fa-check"></i><b>11.4.6</b> Time-Series Decomposition </a></li>
<li class="chapter" data-level="11.4.7" data-path="machinelearning3.html"><a href="machinelearning3.html#stl-with-aicbic"><i class="fa fa-check"></i><b>11.4.7</b> STL with AIC/BIC</a></li>
<li class="chapter" data-level="11.4.8" data-path="machinelearning3.html"><a href="machinelearning3.html#multivariate-time-series"><i class="fa fa-check"></i><b>11.4.8</b> Multivariate Time-Series</a></li>
<li class="chapter" data-level="11.4.9" data-path="machinelearning3.html"><a href="machinelearning3.html#forecasting-considerations"><i class="fa fa-check"></i><b>11.4.9</b> Forecasting Considerations</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="machinelearning3.html"><a href="machinelearning3.html#recommender-systems"><i class="fa fa-check"></i><b>11.5</b> Recommender Systems </a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="deeplearning1.html"><a href="deeplearning1.html"><i class="fa fa-check"></i><b>12</b> Computational Deep Learning I</a><ul>
<li class="chapter" data-level="12.1" data-path="deeplearning1.html"><a href="deeplearning1.html#simple-perceptron"><i class="fa fa-check"></i><b>12.1</b> Simple Perceptron  </a></li>
<li class="chapter" data-level="12.2" data-path="deeplearning1.html"><a href="deeplearning1.html#adaptive-linear-neuron-adaline"><i class="fa fa-check"></i><b>12.2</b> Adaptive Linear Neuron (ADALINE)  </a></li>
<li class="chapter" data-level="12.3" data-path="deeplearning1.html"><a href="deeplearning1.html#multi-layer-perceptron-mlp"><i class="fa fa-check"></i><b>12.3</b> Multi Layer Perceptron (MLP)  </a><ul>
<li class="chapter" data-level="12.3.1" data-path="deeplearning1.html"><a href="deeplearning1.html#forward-feed"><i class="fa fa-check"></i><b>12.3.1</b> Forward Feed </a></li>
<li class="chapter" data-level="12.3.2" data-path="deeplearning1.html"><a href="deeplearning1.html#backward-feed"><i class="fa fa-check"></i><b>12.3.2</b> Backward Feed </a></li>
<li class="chapter" data-level="12.3.3" data-path="deeplearning1.html"><a href="deeplearning1.html#backpropagation"><i class="fa fa-check"></i><b>12.3.3</b> BackPropagation </a></li>
<li class="chapter" data-level="12.3.4" data-path="deeplearning1.html"><a href="deeplearning1.html#mlp-example"><i class="fa fa-check"></i><b>12.3.4</b> MLP Example</a></li>
<li class="chapter" data-level="12.3.5" data-path="deeplearning1.html"><a href="deeplearning1.html#activation-function"><i class="fa fa-check"></i><b>12.3.5</b> Activation Function </a></li>
<li class="chapter" data-level="12.3.6" data-path="deeplearning1.html"><a href="deeplearning1.html#mlp-implementation"><i class="fa fa-check"></i><b>12.3.6</b> MLP Implementation</a></li>
<li class="chapter" data-level="12.3.7" data-path="deeplearning1.html"><a href="deeplearning1.html#deep-neural-network-dnn"><i class="fa fa-check"></i><b>12.3.7</b> Deep Neural Network (DNN)  </a></li>
<li class="chapter" data-level="12.3.8" data-path="deeplearning1.html"><a href="deeplearning1.html#vanishing-and-exploding-gradient"><i class="fa fa-check"></i><b>12.3.8</b> Vanishing and Exploding Gradient  </a></li>
<li class="chapter" data-level="12.3.9" data-path="deeplearning1.html"><a href="deeplearning1.html#dead-relu"><i class="fa fa-check"></i><b>12.3.9</b> Dead Relu </a></li>
<li class="chapter" data-level="12.3.10" data-path="deeplearning1.html"><a href="deeplearning1.html#gradient-clipping-gc"><i class="fa fa-check"></i><b>12.3.10</b> Gradient Clipping (GC) </a></li>
<li class="chapter" data-level="12.3.11" data-path="deeplearning1.html"><a href="deeplearning1.html#parameter-initialization"><i class="fa fa-check"></i><b>12.3.11</b> Parameter Initialization </a></li>
<li class="chapter" data-level="12.3.12" data-path="deeplearning1.html"><a href="deeplearning1.html#regularization-by-dropouts"><i class="fa fa-check"></i><b>12.3.12</b> Regularization by Dropouts </a></li>
<li class="chapter" data-level="12.3.13" data-path="deeplearning1.html"><a href="deeplearning1.html#batch-normalization"><i class="fa fa-check"></i><b>12.3.13</b> Batch Normalization </a></li>
<li class="chapter" data-level="12.3.14" data-path="deeplearning1.html"><a href="deeplearning1.html#optimization"><i class="fa fa-check"></i><b>12.3.14</b> Optimization </a></li>
<li class="chapter" data-level="12.3.15" data-path="deeplearning1.html"><a href="deeplearning1.html#interpretability"><i class="fa fa-check"></i><b>12.3.15</b> Interpretability</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="deeplearning1.html"><a href="deeplearning1.html#convolutional-neural-network-cnn"><i class="fa fa-check"></i><b>12.4</b> Convolutional Neural Network (CNN)  </a><ul>
<li class="chapter" data-level="12.4.1" data-path="deeplearning1.html"><a href="deeplearning1.html#computer-graphics"><i class="fa fa-check"></i><b>12.4.1</b> Computer Graphics</a></li>
<li class="chapter" data-level="12.4.2" data-path="deeplearning1.html"><a href="deeplearning1.html#convolution"><i class="fa fa-check"></i><b>12.4.2</b> Convolution </a></li>
<li class="chapter" data-level="12.4.3" data-path="deeplearning1.html"><a href="deeplearning1.html#stride-and-padding"><i class="fa fa-check"></i><b>12.4.3</b> Stride and Padding  </a></li>
<li class="chapter" data-level="12.4.4" data-path="deeplearning1.html"><a href="deeplearning1.html#kernels-and-filters"><i class="fa fa-check"></i><b>12.4.4</b> Kernels And Filters</a></li>
<li class="chapter" data-level="12.4.5" data-path="deeplearning1.html"><a href="deeplearning1.html#dilation"><i class="fa fa-check"></i><b>12.4.5</b> Dilation </a></li>
<li class="chapter" data-level="12.4.6" data-path="deeplearning1.html"><a href="deeplearning1.html#pooling"><i class="fa fa-check"></i><b>12.4.6</b> Pooling </a></li>
<li class="chapter" data-level="12.4.7" data-path="deeplearning1.html"><a href="deeplearning1.html#cnn-architectures"><i class="fa fa-check"></i><b>12.4.7</b> CNN Architectures</a></li>
<li class="chapter" data-level="12.4.8" data-path="deeplearning1.html"><a href="deeplearning1.html#forward-feed-1"><i class="fa fa-check"></i><b>12.4.8</b> Forward Feed </a></li>
<li class="chapter" data-level="12.4.9" data-path="deeplearning1.html"><a href="deeplearning1.html#backpropagation-1"><i class="fa fa-check"></i><b>12.4.9</b> BackPropagation </a></li>
<li class="chapter" data-level="12.4.10" data-path="deeplearning1.html"><a href="deeplearning1.html#optimization-1"><i class="fa fa-check"></i><b>12.4.10</b> Optimization</a></li>
<li class="chapter" data-level="12.4.11" data-path="deeplearning1.html"><a href="deeplearning1.html#normalization"><i class="fa fa-check"></i><b>12.4.11</b> Normalization</a></li>
<li class="chapter" data-level="12.4.12" data-path="deeplearning1.html"><a href="deeplearning1.html#step-decay"><i class="fa fa-check"></i><b>12.4.12</b> Step Decay</a></li>
<li class="chapter" data-level="12.4.13" data-path="deeplearning1.html"><a href="deeplearning1.html#gemm-matrix-multiplication"><i class="fa fa-check"></i><b>12.4.13</b> GEMM (Matrix Multiplication) </a></li>
<li class="chapter" data-level="12.4.14" data-path="deeplearning1.html"><a href="deeplearning1.html#depthwise-separable-convolution-dsc"><i class="fa fa-check"></i><b>12.4.14</b> Depthwise Separable Convolution (DSC)  </a></li>
<li class="chapter" data-level="12.4.15" data-path="deeplearning1.html"><a href="deeplearning1.html#cnn-implementation"><i class="fa fa-check"></i><b>12.4.15</b> CNN Implementation</a></li>
<li class="chapter" data-level="12.4.16" data-path="deeplearning1.html"><a href="deeplearning1.html#cnn-application"><i class="fa fa-check"></i><b>12.4.16</b> CNN Application</a></li>
<li class="chapter" data-level="12.4.17" data-path="deeplearning1.html"><a href="deeplearning1.html#summary-7"><i class="fa fa-check"></i><b>12.4.17</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="deeplearning2.html"><a href="deeplearning2.html"><i class="fa fa-check"></i><b>13</b> Computational Deep Learning II</a><ul>
<li class="chapter" data-level="13.1" data-path="deeplearning2.html"><a href="deeplearning2.html#residual-network-resnet"><i class="fa fa-check"></i><b>13.1</b> Residual Network (ResNet)  </a></li>
<li class="chapter" data-level="13.2" data-path="deeplearning2.html"><a href="deeplearning2.html#recurrent-neural-network-rnn"><i class="fa fa-check"></i><b>13.2</b> Recurrent Neural Network (RNN)  </a><ul>
<li class="chapter" data-level="13.2.1" data-path="deeplearning2.html"><a href="deeplearning2.html#vanilla-rnn"><i class="fa fa-check"></i><b>13.2.1</b> Vanilla RNN</a></li>
<li class="chapter" data-level="13.2.2" data-path="deeplearning2.html"><a href="deeplearning2.html#long-short-term-memory-lstm"><i class="fa fa-check"></i><b>13.2.2</b> Long Short-Term Memory (LSTM)  </a></li>
<li class="chapter" data-level="13.2.3" data-path="deeplearning2.html"><a href="deeplearning2.html#gated-recurrent-units-gru"><i class="fa fa-check"></i><b>13.2.3</b> Gated Recurrent Units (GRU)  </a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="deeplearning2.html"><a href="deeplearning2.html#deep-stacked-rnn"><i class="fa fa-check"></i><b>13.3</b> Deep Stacked RNN </a></li>
<li class="chapter" data-level="13.4" data-path="deeplearning2.html"><a href="deeplearning2.html#deep-stacked-bidirectional-rnn"><i class="fa fa-check"></i><b>13.4</b> Deep Stacked Bidirectional RNN </a></li>
<li class="chapter" data-level="13.5" data-path="deeplearning2.html"><a href="deeplearning2.html#transformer-neural-network-tnn"><i class="fa fa-check"></i><b>13.5</b> Transformer Neural Network (TNN)  </a><ul>
<li class="chapter" data-level="13.5.1" data-path="deeplearning2.html"><a href="deeplearning2.html#attention"><i class="fa fa-check"></i><b>13.5.1</b> Attention </a></li>
<li class="chapter" data-level="13.5.2" data-path="deeplearning2.html"><a href="deeplearning2.html#self-attention-and-trainability"><i class="fa fa-check"></i><b>13.5.2</b> Self-Attention and Trainability </a></li>
<li class="chapter" data-level="13.5.3" data-path="deeplearning2.html"><a href="deeplearning2.html#multi-head-attention"><i class="fa fa-check"></i><b>13.5.3</b> Multi-Head Attention </a></li>
<li class="chapter" data-level="13.5.4" data-path="deeplearning2.html"><a href="deeplearning2.html#word-embedding"><i class="fa fa-check"></i><b>13.5.4</b> Word Embedding </a></li>
<li class="chapter" data-level="13.5.5" data-path="deeplearning2.html"><a href="deeplearning2.html#positional-embedding"><i class="fa fa-check"></i><b>13.5.5</b> Positional Embedding </a></li>
<li class="chapter" data-level="13.5.6" data-path="deeplearning2.html"><a href="deeplearning2.html#sequence-alignment"><i class="fa fa-check"></i><b>13.5.6</b> Sequence Alignment</a></li>
<li class="chapter" data-level="13.5.7" data-path="deeplearning2.html"><a href="deeplearning2.html#transformer-architectures"><i class="fa fa-check"></i><b>13.5.7</b> Transformer Architectures </a></li>
</ul></li>
<li class="chapter" data-level="13.6" data-path="deeplearning2.html"><a href="deeplearning2.html#applications-using-tnn-and-rnn"><i class="fa fa-check"></i><b>13.6</b> Applications using TNN (and RNN)</a><ul>
<li class="chapter" data-level="13.6.1" data-path="deeplearning2.html"><a href="deeplearning2.html#speech-recognition"><i class="fa fa-check"></i><b>13.6.1</b> Speech Recognition </a></li>
<li class="chapter" data-level="13.6.2" data-path="deeplearning2.html"><a href="deeplearning2.html#mel-coefficients-feature-extraction"><i class="fa fa-check"></i><b>13.6.2</b> Mel Coefficients (Feature Extraction) </a></li>
<li class="chapter" data-level="13.6.3" data-path="deeplearning2.html"><a href="deeplearning2.html#connectionist-temporal-classification-ctc"><i class="fa fa-check"></i><b>13.6.3</b> Connectionist Temporal Classification (CTC)  </a></li>
<li class="chapter" data-level="13.6.4" data-path="deeplearning2.html"><a href="deeplearning2.html#model-evaluation"><i class="fa fa-check"></i><b>13.6.4</b> Model Evaluation</a></li>
</ul></li>
<li class="chapter" data-level="13.7" data-path="deeplearning2.html"><a href="deeplearning2.html#generative-adversarial-network-gan"><i class="fa fa-check"></i><b>13.7</b> Generative Adversarial Network (GAN)  </a></li>
<li class="chapter" data-level="13.8" data-path="deeplearning2.html"><a href="deeplearning2.html#deep-reinforcement-network-dqn"><i class="fa fa-check"></i><b>13.8</b> Deep Reinforcement Network (DQN)  </a></li>
<li class="chapter" data-level="13.9" data-path="deeplearning2.html"><a href="deeplearning2.html#summary-8"><i class="fa fa-check"></i><b>13.9</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="distributedcomputation.html"><a href="distributedcomputation.html"><i class="fa fa-check"></i><b>14</b> Distributed Computation</a><ul>
<li class="chapter" data-level="14.1" data-path="distributedcomputation.html"><a href="distributedcomputation.html#integration-and-interoperability"><i class="fa fa-check"></i><b>14.1</b> Integration and Interoperability</a></li>
<li class="chapter" data-level="14.2" data-path="distributedcomputation.html"><a href="distributedcomputation.html#ml-pipelines"><i class="fa fa-check"></i><b>14.2</b> ML Pipelines</a></li>
<li class="chapter" data-level="14.3" data-path="distributedcomputation.html"><a href="distributedcomputation.html#open-standards"><i class="fa fa-check"></i><b>14.3</b> Open Standards</a><ul>
<li class="chapter" data-level="14.3.1" data-path="distributedcomputation.html"><a href="distributedcomputation.html#predictive-model-markup-language-pmml"><i class="fa fa-check"></i><b>14.3.1</b> Predictive Model Markup Language (PMML)</a></li>
<li class="chapter" data-level="14.3.2" data-path="distributedcomputation.html"><a href="distributedcomputation.html#portable-format-for-analytics-pfa"><i class="fa fa-check"></i><b>14.3.2</b> Portable Format for Analytics (PFA)</a></li>
<li class="chapter" data-level="14.3.3" data-path="distributedcomputation.html"><a href="distributedcomputation.html#open-neural-network-exchange-onnx"><i class="fa fa-check"></i><b>14.3.3</b> Open Neural Network Exchange (ONNX)</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="distributedcomputation.html"><a href="distributedcomputation.html#general-summary"><i class="fa fa-check"></i><b>14.4</b> General Summary</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i><b>15</b> Appendix</a><ul>
<li class="chapter" data-level="15.1" data-path="appendix.html"><a href="appendix.html#appendix-a"><i class="fa fa-check"></i><b>15.1</b> Appendix A</a><ul>
<li class="chapter" data-level="15.1.1" data-path="appendix.html"><a href="appendix.html#trigonometry"><i class="fa fa-check"></i><b>15.1.1</b> Trigonometry</a></li>
<li class="chapter" data-level="15.1.2" data-path="appendix.html"><a href="appendix.html#logarithms"><i class="fa fa-check"></i><b>15.1.2</b> Logarithms</a></li>
<li class="chapter" data-level="15.1.3" data-path="appendix.html"><a href="appendix.html#category-theory"><i class="fa fa-check"></i><b>15.1.3</b> Category Theory</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="appendix.html"><a href="appendix.html#appendix-b"><i class="fa fa-check"></i><b>15.2</b> Appendix B</a><ul>
<li class="chapter" data-level="15.2.1" data-path="appendix.html"><a href="appendix.html#on-random-chances"><i class="fa fa-check"></i><b>15.2.1</b> On Random chances</a></li>
<li class="chapter" data-level="15.2.2" data-path="appendix.html"><a href="appendix.html#on-replacements"><i class="fa fa-check"></i><b>15.2.2</b> On Replacements</a></li>
<li class="chapter" data-level="15.2.3" data-path="appendix.html"><a href="appendix.html#on-permutations-and-combinations"><i class="fa fa-check"></i><b>15.2.3</b> On Permutations and Combinations</a></li>
<li class="chapter" data-level="15.2.4" data-path="appendix.html"><a href="appendix.html#on-conditional-probabilities"><i class="fa fa-check"></i><b>15.2.4</b> On Conditional Probabilities</a></li>
<li class="chapter" data-level="15.2.5" data-path="appendix.html"><a href="appendix.html#the-arithmetic-of-probabilities"><i class="fa fa-check"></i><b>15.2.5</b> The Arithmetic of Probabilities</a></li>
<li class="chapter" data-level="15.2.6" data-path="appendix.html"><a href="appendix.html#on-dependent-and-independent-events"><i class="fa fa-check"></i><b>15.2.6</b> On Dependent and Independent Events</a></li>
<li class="chapter" data-level="15.2.7" data-path="appendix.html"><a href="appendix.html#on-mutual-exclusivity"><i class="fa fa-check"></i><b>15.2.7</b> On Mutual Exclusivity</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="appendix.html"><a href="appendix.html#appendix-c"><i class="fa fa-check"></i><b>15.3</b> Appendix C</a></li>
<li class="chapter" data-level="15.4" data-path="appendix.html"><a href="appendix.html#appendix-d"><i class="fa fa-check"></i><b>15.4</b> Appendix D</a><ul>
<li class="chapter" data-level="15.4.1" data-path="appendix.html"><a href="appendix.html#lubridate-library"><i class="fa fa-check"></i><b>15.4.1</b> Lubridate Library</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="bibliography.html"><a href="bibliography.html"><i class="fa fa-check"></i>Bibliography</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">The Power and Art of Approximation</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="numericalprobability" class="section level1 hasAnchor">
<h1><span class="header-section-number">Chapter 5</span> Probability and Distribution<a href="numericalprobability.html#numericalprobability" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { 
      equationNumbers: {
            autoNumber: "AMS",
            formatNumber: function (n) {return '5.'+n}
      } 
  }
});
</script>
<p>We covered many Numerical methods in previous chapters of Volume I, providing approximations to solutions that otherwise tend to be impractical or impossible to attain.</p>
<p>In the chapters ahead in Volume II, we begin to review approximations of random chances (or random events). Unlike approximating linear or non-linear functions, we focus on <strong>approximate functions that follow the distribution</strong> of data. Note that there are cases when we only have a subset of the whole data. In that respect, we analyze the sample and produce an estimate or approximate analysis that may closely explain the complete set.</p>
<p>Particularly, in this chapter, we continue to focus on approximations in the context of Probabilities and Distribution as we reference the great works of Vapnik V. <span class="citation">(<a href="bibliography.html#ref-ref572v">2000</a>)</span>, Press W.H et al. <span class="citation">(<a href="bibliography.html#ref-ref215w">2007</a>)</span>, Stewart W.J. <span class="citation">(<a href="bibliography.html#ref-ref233w">2009</a>)</span>, Murphy K.P. <span class="citation">(<a href="bibliography.html#ref-ref224k">2012</a>)</span>, Forsyth D. <span class="citation">(<a href="bibliography.html#ref-ref232d">2018</a>)</span>, and Lambert B. <span class="citation">(<a href="bibliography.html#ref-ref240b">2018</a>)</span>, along with other additional references for consistency.</p>
<div id="approximation-based-on-random-chances" class="section level2 hasAnchor">
<h2><span class="header-section-number">5.1</span> Approximation based on Random Chances <a href="numericalprobability.html#approximation-based-on-random-chances" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Essentially, when we speak about data, we rely upon a measured value (whether in quantity or quality). Given some sample data, <span class="math inline">\(\Omega = \{0.11, 0.14, 0.09, 0.11, 0.15, ... \}\)</span>, we may be dealing with a set of random measurements of observations. Thus, we have to ask the following questions:</p>
<ul>
<li>How many observations have we sampled? Here, we take the number of observations.</li>
<li>How many of those observations are unique? Here, we take the cardinality of the observation - a measure of uniqueness. The higher the uniqueness, the higher the cardinality.</li>
<li>Can we group non-unique observations? If so, how many groups would there be?</li>
<li>Do these groups have the same number of observations? Here, we now look at central tendencies such as mean, median, and mode.</li>
<li>How many groups do we have? What group(s) have the highest number of similar observations, and what group(s) have the lowest number of similar observations? Here, we begin to measure the spread or variance.</li>
<li>Finally, can we get a picture of the groupings? Here, we want to plot the groupings - the distribution.</li>
</ul>
<p>In other words, we want to know all about how data is <strong>distributed</strong>. We also want to use charts to visualize the distribution. However, before doing so, let us first review a few terms:</p>
<p><strong>Random variables</strong> hold numerical values resulting from a random outcome or random chance, e.g., tossing a coin five times. What is the chance of getting a tail each time - could it be 0.50 (50% chance)?</p>
<p><strong>Orthogonal random variables</strong> are independent random variables. A change in one random variable does not affect the other; in other words, one is completely orthogonal to the other.</p>
<p><strong>Covariates or Variates</strong> hold values of random variables (one being for independent variables and the other being for dependent variables). So if we toss a coin and get a tail, the outcome of having a tail is considered a random outcome or, to be more specific, a <strong>random variate</strong>. On the other hand, a <strong>covariate</strong> is regarded as a random outcome that is statistically dependent on the independent variable.</p>
<p><strong>Factor variables</strong> are categorical variables that hold categorical values called <strong>levels</strong>. So if we are talking about gender as a factor (or categorical) variable, then <strong>male</strong> is a level, and <strong>female</strong> is also a level.</p>
<p>As for random variables, because of the absence of concrete and precise measurements, the distribution of values of random variables requires analysis. We commonly use two distributions to explain data distribution in other literature: <strong>Uniform</strong> and <strong>Normal</strong> distribution.</p>
<p><strong>Uniform</strong> distribution of random variables tends to follow a rectangular shape as the size of sampled data increases. Figure <a href="numericalprobability.html#fig:uniform">5.1</a> shows chart of a uniform distribution. Below is the R code that plots the chart.</p>
<div class="sourceCode" id="cb193"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb193-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">142</span>)</a>
<a class="sourceLine" id="cb193-2" data-line-number="2">x =<span class="st"> </span><span class="kw">runif</span>(<span class="dt">n=</span><span class="dv">5000</span>, <span class="dt">min=</span><span class="op">-</span><span class="fl">1.5</span>, <span class="dt">max=</span><span class="fl">1.5</span>)</a>
<a class="sourceLine" id="cb193-3" data-line-number="3"><span class="kw">hist</span>(x, <span class="dt">breaks=</span><span class="dv">20</span>, <span class="dt">prob=</span><span class="ot">TRUE</span>, <span class="dt">main=</span><span class="st">&#39;Uniform Distribution&#39;</span>, </a>
<a class="sourceLine" id="cb193-4" data-line-number="4">     <span class="dt">xlab=</span><span class="st">&#39;Random Variable&#39;</span>,  <span class="dt">xlim=</span><span class="kw">range</span>(<span class="op">-</span><span class="fl">1.5</span>,<span class="fl">1.5</span>))</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:uniform"></span>
<img src="DS_files/figure-html/uniform-1.png" alt="Uniform Distribution" width="70%" />
<p class="caption">
Figure 5.1: Uniform Distribution
</p>
</div>
<p><strong>Normal</strong> distribution of random variables tends to follow a bell shape as the size of sampled data increases.</p>
<div class="sourceCode" id="cb194"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb194-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">142</span>)</a>
<a class="sourceLine" id="cb194-2" data-line-number="2">x =<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n=</span><span class="dv">5000</span>,<span class="dt">mean=</span><span class="dv">0</span>,<span class="dt">sd=</span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb194-3" data-line-number="3"><span class="kw">hist</span>(x, <span class="dt">breaks=</span><span class="dv">20</span>, <span class="dt">prob=</span><span class="ot">TRUE</span>, <span class="dt">main=</span><span class="st">&#39;Standard Normal Distribution&#39;</span>,</a>
<a class="sourceLine" id="cb194-4" data-line-number="4">     <span class="dt">xlab=</span><span class="st">&#39;Standard Deviation&#39;</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="op">-</span><span class="dv">4</span>,<span class="dv">4</span>))</a>
<a class="sourceLine" id="cb194-5" data-line-number="5"><span class="kw">curve</span>(<span class="kw">dnorm</span>(x, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span><span class="dv">1</span>),<span class="dt">add=</span><span class="ot">TRUE</span>, <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-100"></span>
<img src="DS_files/figure-html/unnamed-chunk-100-1.png" alt="Standard Normal Distribution" width="70%" />
<p class="caption">
Figure 5.2: Standard Normal Distribution
</p>
</div>
<p>In the rest of this book, we use uniform and normal distribution to simulate most of our data distribution. We emphasize, however, that in practice, not all data are distributed uniformly or normally. We will encounter different kinds of distribution. To name a few, we cover Logistic distribution, Gamma distribution, Beta distribution, Poisson distribution, and Power-law distribution. Furthermore, some distributions do not follow the characteristics of uniform or normal distribution. Because of that, we use some clever means to simulate the distribution. We will discuss more on that in the next chapter.</p>
<p>Also, note that there are cases when we need to take multiple samples of a population. Instead of dealing with one group of sampled data, we deal with numerous groups of sampled data. This grouping (or sampling) of sampled data can form some distribution. We regard these samples as <strong>sampling distribution</strong>, which we will cover later.</p>
<p>Also, note that we are literal when referring to data distribution as the distribution of data. As we mostly deal with statistics, each data attribute is assumed to be already measured. Each computed <strong>measure</strong> of one attribute, such as the average temperature in Fahrenheit, is what we regard as a <strong>statistic</strong>.</p>
<p>In terms of the number of variables and number of outcomes per variable, we can categorize them into the following:</p>
<ul>
<li><p><strong>Univariate</strong> - refers to dealing with one variable.</p></li>
<li><p><strong>Multivariate</strong> - refers to dealing with multiple variables.</p></li>
<li><p><strong>Bivariate</strong> - refers to dealing with two variables.</p></li>
<li><p><strong>Binomial</strong> - refers to a response variable with only two possible outcomes (dichotomous), e.g., 1 or 0, true or false.</p></li>
<li><p><strong>Multinomial</strong> - refers to a response variable with more than two possible outcomes, e.g., nominal values</p></li>
</ul>
</div>
<div id="distribution" class="section level2 hasAnchor">
<h2><span class="header-section-number">5.2</span> Distribution<a href="numericalprobability.html#distribution" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>To understand <strong>data distribution</strong>, we need to be familiar with a couple of terms. We start with the term <strong>stochastic</strong>, which is a property commonly associated with <strong>randomness of events</strong>. Then, we have <strong>stochastic process</strong>, which is the process that generates the <strong>randomness of events</strong>, leading to an observed outcome in the form of distribution, e.g., tossing a coin renders a binomial distribution.</p>
<p>Here, we are interested to know how data is distributed, such as below:</p>
<div class="sourceCode" id="cb195"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb195-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">142</span>)</a>
<a class="sourceLine" id="cb195-2" data-line-number="2">h =<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n=</span><span class="dv">5000</span>,<span class="dt">mean=</span><span class="fl">5.5</span>,<span class="dt">sd=</span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb195-3" data-line-number="3"><span class="kw">hist</span>(<span class="dt">x=</span>h, <span class="dt">breaks=</span><span class="dv">20</span>, <span class="dt">prob=</span><span class="ot">FALSE</span>, <span class="dt">main=</span><span class="st">&#39;Normal Distribution&#39;</span>, </a>
<a class="sourceLine" id="cb195-4" data-line-number="4">     <span class="dt">xlab=</span><span class="st">&#39;Spread&#39;</span>, <span class="dt">ylab=</span><span class="st">&quot;Number of Individuals&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:heightdist"></span>
<img src="DS_files/figure-html/heightdist-1.png" alt="Height Distribution" width="70%" />
<p class="caption">
Figure 5.3: Height Distribution
</p>
</div>
<p>Intuitively, in Figure <a href="numericalprobability.html#fig:heightdist">5.3</a>, we see a peak (the highest point) centered in the middle of the chart in the distribution. Here, the peak indicates the highest concentration of data in the distribution. To put that into perspective, suppose we sample the height of a given population and use a histogram similar to Figure <a href="numericalprobability.html#fig:heightdist">5.3</a>. We should notice that the highest point in the histogram seem to be between 5 and 6 feet in height. In actuality, the average is at 5.5 ft - that is the <strong>mean</strong> denoted as <span class="math inline">\(\mu_{\vec{x}}\)</span>. Note that the <strong>mean</strong> is also often referred to as the <strong>expected value</strong> or <strong>expectation</strong> denoted as <span class="math inline">\(\mathbb{E}(\vec{x})\)</span>. However, <strong>expectation</strong> has another representation especially when random variables are weighted - see <strong>Probability Rules</strong> in Chapter <strong>7</strong> (<strong>Bayesian Computation I</strong>). If we then try to determine the next highest peak after the mean, we may see a 5.0 ft and a 6.0 ft. And as we look for the next highest peak after 5.0 ft or 6.0 ft, we then see 2.0 ft and 8.0 ft. The count is much less than the highest peak and the second-highest peak. It gets lesser as we keep counting for the next highest count. The <strong>spread of the distribution</strong> spans from 2ft through 8 ft. - that is the <strong>variance</strong> denoted as <span class="math inline">\(Var(\vec{x}) = \mathbb{E}(\vec{x}^2) - \mathbb{E}(\vec{x})^2\)</span>.</p>
<p>The illustration above characterizes a normal distribution. We start from a peak - in the center - and then the bars taper off, gradually decreasing in height almost symmetrically on each side. Two parameters characterize our normal distribution: <strong>mean</strong> and <strong>variance</strong>. Here, <strong>mean</strong> is given the symbol <strong><span class="math inline">\(\mu\)</span></strong> and <strong>variance</strong> is given the symbol <strong><span class="math inline">\(\sigma^2\)</span></strong>. The notation for a normal distribution is then expressed this way:</p>
<p><span class="math display">\[\begin{align}
X \sim N(\mu, \sigma^2 )
\end{align}\]</span></p>
<p>It reads: <strong>X is distributed as a normal distribution with mean and variance</strong> as the parameters.</p>
<p>It also can be read as: <strong>the random variable X follows a normal distribution with mean and variance</strong> parameters.</p>
<p>Here, the <strong>mean</strong> parameter for a normal distribution is needed to see the most popular item in the data. We need the <strong>variance</strong> parameter to understand the popularity of items by ranking them according to popularity. In some way, this gives us a picture of how items are spread out based on rank. Graphically, if we use a bar chart, most popular items have <strong>taller</strong> ranks (taller bars) than low-ranking items.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:spread1"></span>
<img src="DS_files/figure-html/spread1-1.png" alt="Height Distribution" width="70%" />
<p class="caption">
Figure 5.4: Height Distribution
</p>
</div>
<p>Figure <a href="numericalprobability.html#fig:spread1">5.4</a> shows four un-normalized distributions. Notice that the un-normalized distribution with <strong><span class="math inline">\(\mu=50\)</span></strong> has a peak around 50 in the chart. Notice that the un-normalized distribution with <strong><span class="math inline">\(\sigma^2=50\)</span></strong> has a wider spread.</p>
<p>In many cases, when we deal with data, we may prefer to normalize the distribution. Furthermore, on top of that, we may also prefer to standardize the normalized distribution.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:spread2"></span>
<img src="DS_files/figure-html/spread2-1.png" alt="Height Distribution" width="70%" />
<p class="caption">
Figure 5.5: Height Distribution
</p>
</div>
<p>As shown in figure <a href="numericalprobability.html#fig:spread2">5.5</a>, there is one particular kind of normal distribution called standard normal distribution.</p>
<p>A <strong>Standard Normal Distribution</strong> is a distribution that is both <strong>scaled down</strong> and <strong>centered</strong> so that its <strong>mean</strong> is forced down to zero, e.g. <span class="math inline">\((x - \mu)/\sigma^2\)</span>.</p>

<div class="sourceCode" id="cb196"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb196-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">142</span>)</a>
<a class="sourceLine" id="cb196-2" data-line-number="2">x =<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n=</span><span class="dv">5000</span>,<span class="dt">mean=</span><span class="dv">0</span>,<span class="dt">sd=</span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb196-3" data-line-number="3"><span class="kw">hist</span>(x, <span class="dt">breaks=</span><span class="dv">20</span>, <span class="dt">prob=</span><span class="ot">TRUE</span>, <span class="dt">main=</span><span class="st">&#39;Standard Normal Distribution&#39;</span>, </a>
<a class="sourceLine" id="cb196-4" data-line-number="4">     <span class="dt">xlab=</span><span class="st">&#39;Standard Deviation&#39;</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="op">-</span><span class="dv">4</span>,<span class="dv">4</span>))</a>
<a class="sourceLine" id="cb196-5" data-line-number="5"><span class="kw">curve</span>(<span class="kw">dnorm</span>(x, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span><span class="dv">1</span>),<span class="dt">add=</span><span class="ot">TRUE</span>, <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:bellshape"></span>
<img src="DS_files/figure-html/bellshape-1.png" alt="Standard Normal Distribution" width="70%" />
<p class="caption">
Figure 5.6: Standard Normal Distribution
</p>
</div>

</div>
<div id="mass-and-density" class="section level2 hasAnchor">
<h2><span class="header-section-number">5.3</span> Mass and Density  <a href="numericalprobability.html#mass-and-density" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><strong>Mass</strong> refers to the data distribution formed by discrete random variables.</p>
<p><strong>Density</strong> refers to the data distribution formed by continuous random variables.</p>
<p>Geometrically, a <strong>Density</strong> represents a curve formed by a <strong>Density function</strong>, which we discuss later; e.g., the curve that forms the bell shape in a normal distribution. See Figure <a href="numericalprobability.html#fig:gaussianpdf">5.8</a>.</p>
<p>Here, we use the greek symbol (<span class="math inline">\(\rho\)</span>) for <strong>Density</strong>, and it reads as <strong>rho</strong>:</p>
<p><span class="math display">\[
\rho(x)
\]</span></p>
<p>Although from time to time, we may also use the notation: <span class="math inline">\(f(x)\)</span>.</p>
<p>Recall that when talking about distribution, mathematically, we use the following notation (e.g., for normal distribution):</p>
<p><span class="math display">\[\begin{align}
X \sim \mathcal{N}(\mu, \sigma^2 )
\end{align}\]</span></p>
<p>We can use a density notation like so:</p>
<p><span class="math display">\[\begin{align}
\rho(x) \sim \mathcal{N}(\mu, \sigma^2 )
\end{align}\]</span></p>
<p>We can also use a parameterized notation to be more complete:</p>
<p><span class="math display">\[\begin{align}
\rho(x|\mu,\sigma^2) \sim \mathcal{N}(\mu, \sigma^2 )
\end{align}\]</span></p>
<p>which reads: <strong>the density of x is distributed as normal distribution</strong> - the first notation having the parameters for <span class="math inline">\(\mu\ and\ \sigma^2\)</span> can be implicit; meaning, we do not have to show the parameters in the notation.</p>
</div>
<div id="probability" class="section level2 hasAnchor">
<h2><span class="header-section-number">5.4</span> Probability  <a href="numericalprobability.html#probability" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><strong>Probability</strong> is a measure of the number of occurrences of a random event. That is the non-Bayesian definition. Bayesian definition puts a different perspective; instead, that <strong>Probability</strong> measures the degree of <strong>uncertainty</strong> (the <strong>likelihood</strong>) of <strong>information</strong>. After all, when we say that there is a possible chance that a certain event will occur, we claim that we are uncertain about the event to occur. Therefore, the higher the chance an event would occur, the lower our uncertainty of the information.</p>
<p>When dealing with all probabilities of a random event, we know that the totality comprises the whole. In that respect, we express <strong>Probability</strong> in terms of <strong>Proportionality</strong>. For example, in the world population, what is the proportion of vegans vs.Â non-vegans if there are 1 billion vegans out of 7 billion? The proportion is about 14.29% (1/7).</p>
<p>One of the better exercises when working on proportions (and probability) is developing our familiarity with the different distributions (densities) of data. It is simply about how distributed our data can be. Then, we estimate the probability that a given event (or proportion) falls somewhere in the distribution.</p>
<p>To plot this, let us recall the description of a function in Calculus in which we show how a function drives the slope of a line or the curvature of a curve (or shape of hyperplanes in higher dimensional space).</p>
<p>Let us start with a curve using a simple quadratic function: <span class="math inline">\(f(x) = x^2 \text{, where } 0 \leq x \leq 1\)</span>. See figure <a href="numericalprobability.html#fig:probability4">5.7</a>.</p>

<div class="sourceCode" id="cb197"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb197-1" data-line-number="1"><span class="kw">suppressWarnings</span>(<span class="kw">suppressMessages</span>(<span class="kw">library</span>(scales)))</a>
<a class="sourceLine" id="cb197-2" data-line-number="2">slope =<span class="st"> </span><span class="dv">6</span></a>
<a class="sourceLine" id="cb197-3" data-line-number="3"></a>
<a class="sourceLine" id="cb197-4" data-line-number="4"><span class="co"># Generate X-Axis</span></a>
<a class="sourceLine" id="cb197-5" data-line-number="5">x =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="fl">.01</span>)</a>
<a class="sourceLine" id="cb197-6" data-line-number="6"></a>
<a class="sourceLine" id="cb197-7" data-line-number="7"><span class="co"># Formulate the functions for a curve with 0 intercept so that the </span></a>
<a class="sourceLine" id="cb197-8" data-line-number="8"><span class="co"># curve touches the y-axis at zero.</span></a>
<a class="sourceLine" id="cb197-9" data-line-number="9">intercept =<span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb197-10" data-line-number="10">quadratic_function =<span class="st"> </span>x<span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span>intercept</a>
<a class="sourceLine" id="cb197-11" data-line-number="11"></a>
<a class="sourceLine" id="cb197-12" data-line-number="12"><span class="co"># Plot the curve, the secant, and the tangent</span></a>
<a class="sourceLine" id="cb197-13" data-line-number="13"><span class="kw">plot</span>(x, quadratic_function, <span class="dt">lwd=</span><span class="dv">1</span>, <span class="dt">pch=</span><span class="dv">16</span>, </a>
<a class="sourceLine" id="cb197-14" data-line-number="14">     <span class="dt">col=</span><span class="kw">alpha</span>(<span class="st">&quot;navyblue&quot;</span>, <span class="fl">0.0</span>),</a>
<a class="sourceLine" id="cb197-15" data-line-number="15">     <span class="dt">main=</span><span class="st">&quot;Area bounded by a curve and a line&quot;</span>,</a>
<a class="sourceLine" id="cb197-16" data-line-number="16">     <span class="dt">xlab=</span><span class="st">&quot;X-Axis&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;Y-Axis&quot;</span>)</a>
<a class="sourceLine" id="cb197-17" data-line-number="17"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>)</a>
<a class="sourceLine" id="cb197-18" data-line-number="18"></a>
<a class="sourceLine" id="cb197-19" data-line-number="19"><span class="co"># The Curve</span></a>
<a class="sourceLine" id="cb197-20" data-line-number="20"><span class="kw">lines</span>(x, quadratic_function, <span class="dt">col=</span><span class="kw">alpha</span>(<span class="st">&quot;navyblue&quot;</span>,<span class="dv">1</span>), <span class="dt">lwd=</span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb197-21" data-line-number="21"><span class="kw">text</span>(<span class="dt">x=</span>.<span class="dv">8</span>, <span class="dt">y=</span>.<span class="dv">5</span>, <span class="dt">label=</span><span class="st">&quot;f(x) = x^2&quot;</span>)</a>
<a class="sourceLine" id="cb197-22" data-line-number="22"></a>
<a class="sourceLine" id="cb197-23" data-line-number="23"><span class="co"># The Area Limits</span></a>
<a class="sourceLine" id="cb197-24" data-line-number="24">a=.<span class="dv">2</span>;  b=.<span class="dv">4</span>;  c=.<span class="dv">6</span></a>
<a class="sourceLine" id="cb197-25" data-line-number="25"><span class="kw">abline</span>(<span class="dt">v=</span><span class="kw">c</span>(a,c), <span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>)</a>
<a class="sourceLine" id="cb197-26" data-line-number="26"></a>
<a class="sourceLine" id="cb197-27" data-line-number="27"><span class="co"># The Area for P(a &lt; x &lt; c)</span></a>
<a class="sourceLine" id="cb197-28" data-line-number="28">p =<span class="st"> </span><span class="kw">which</span>(x <span class="op">&gt;</span><span class="st"> </span>a <span class="op">&amp;</span><span class="st"> </span>x <span class="op">&lt;</span><span class="st"> </span>c)</a>
<a class="sourceLine" id="cb197-29" data-line-number="29">y1 =<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, <span class="kw">length</span>(quadratic_function[p]))</a>
<a class="sourceLine" id="cb197-30" data-line-number="30">y2 =<span class="st"> </span>quadratic_function[p]</a>
<a class="sourceLine" id="cb197-31" data-line-number="31"><span class="kw">segments</span>(x[p], y1, x[p], y2, <span class="dt">lwd=</span><span class="dv">1</span>, <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span> )</a>
<a class="sourceLine" id="cb197-32" data-line-number="32"><span class="kw">text</span>(<span class="dt">x=</span>c, <span class="dt">y=</span>.<span class="dv">65</span>, <span class="dt">label=</span><span class="st">&quot;c&quot;</span>)</a>
<a class="sourceLine" id="cb197-33" data-line-number="33"><span class="kw">text</span>(<span class="dt">x=</span>.<span class="dv">4</span>, <span class="dt">y=</span>.<span class="dv">65</span>, <span class="dt">label=</span><span class="kw">expression</span>(<span class="st">&quot;P(a &lt;= X &lt;= c)&quot;</span>), <span class="dt">lty=</span>.<span class="dv">5</span>, <span class="dt">cex=</span>.<span class="dv">9</span>)</a>
<a class="sourceLine" id="cb197-34" data-line-number="34"><span class="kw">segments</span>(a, <span class="dv">0</span>, a, <span class="fl">.6</span>, <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">col=</span><span class="st">&quot;steelblue&quot;</span> )</a>
<a class="sourceLine" id="cb197-35" data-line-number="35"><span class="kw">segments</span>(c, <span class="dv">0</span>, c, <span class="fl">.6</span>, <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">col=</span><span class="st">&quot;steelblue&quot;</span> )</a>
<a class="sourceLine" id="cb197-36" data-line-number="36"></a>
<a class="sourceLine" id="cb197-37" data-line-number="37"><span class="co"># The Area for P(a &lt; x &lt; b)</span></a>
<a class="sourceLine" id="cb197-38" data-line-number="38">p =<span class="st"> </span><span class="kw">which</span>(x <span class="op">&gt;=</span><span class="st"> </span>a <span class="op">&amp;</span><span class="st"> </span>x <span class="op">&lt;</span><span class="st"> </span>b)</a>
<a class="sourceLine" id="cb197-39" data-line-number="39">y1 =<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, <span class="kw">length</span>(quadratic_function[p]))</a>
<a class="sourceLine" id="cb197-40" data-line-number="40">y2 =<span class="st"> </span>quadratic_function[p]</a>
<a class="sourceLine" id="cb197-41" data-line-number="41"><span class="kw">segments</span>(x[p], y1, x[p], y2, <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">col=</span><span class="st">&quot;steelblue&quot;</span> )</a>
<a class="sourceLine" id="cb197-42" data-line-number="42"><span class="kw">text</span>(<span class="dt">x=</span>a, <span class="dt">y=</span>.<span class="dv">65</span>, <span class="dt">label=</span><span class="st">&quot;a&quot;</span>)</a>
<a class="sourceLine" id="cb197-43" data-line-number="43"><span class="kw">text</span>(<span class="dt">x=</span>b, <span class="dt">y=</span>.<span class="dv">45</span>, <span class="dt">label=</span><span class="st">&quot;b&quot;</span>)</a>
<a class="sourceLine" id="cb197-44" data-line-number="44"><span class="kw">segments</span>(b, <span class="dv">0</span>, b, <span class="fl">.4</span>, <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">col=</span><span class="st">&quot;steelblue&quot;</span> )</a>
<a class="sourceLine" id="cb197-45" data-line-number="45"><span class="kw">text</span>(<span class="dt">x=</span>.<span class="dv">3</span>, <span class="dt">y =</span> <span class="fl">.25</span>, <span class="dt">label=</span><span class="st">&quot;P(a &lt;= X &lt;= b)&quot;</span>, <span class="dt">lty=</span>.<span class="dv">5</span>, <span class="dt">cex=</span>.<span class="dv">9</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:probability4"></span>
<img src="DS_files/figure-html/probability4-1.png" alt="Area under Density Curve" width="70%" />
<p class="caption">
Figure 5.7: Area under Density Curve
</p>
</div>

<p>The totality of a continuous density in terms of proportion equates to 1 given the following formula:</p>
<p><span class="math display">\[\begin{align}
\int_{-\infty}^{\infty} f(x) dx = 1
\end{align}\]</span></p>
<p>We can also say that the total proportion or probability (<strong>all probable outcome</strong>) of a density unites into 1. There are no other outcomes after accounting for all other probable outcomes; hence, the 1.</p>
<p>Similarly, the probability of a discrete distribution of data equates to 1 given the following formula:</p>
<p><span class="math display">\[\begin{align}
\sum_{i\to0}^{1} P(x) = 1
\end{align}\]</span></p>
<p>As an example, if we claim that vegans represent the 14.3 proportion of the world population, that is 0.143 of the total sum of 1. Therefore, 0.857 are non-vegans.</p>
<p>In figure <a href="numericalprobability.html#fig:probability4">5.7</a>, we are only interested in the proportion between limit <strong>a</strong> and <strong>b</strong>. The probability (or area) bounded by <strong>a</strong> and <strong>b</strong> is:</p>
<p><span class="math display">\[\begin{align}
\int_{a}^{b} f(x) dx {}&amp;= \int_{0.2}^{0.4} x^2 dx \\
&amp;= F(f&#39;(b)) - F(f&#39;(a))\\
&amp;=\lim_{x\to b} F(x)\ - \lim_{x\to a} F(x)\\
&amp;= \left[\frac{x^3}{3} + c\right]_{0.2}^{0.4} = \left(\frac{0.4^3}{3}\right)\ - \left(\frac{0.2^3}{3}\right) \nonumber \\
&amp;= 0.0187 \nonumber
\end{align}\]</span></p>
<p>Similarly, the probability (or area) bounded by <strong>a</strong> and <strong>c</strong> is calculated as such:</p>
<p><span class="math display">\[\begin{align}
\int_{a}^{c} f(x) dx {}&amp;= \int_{0.2}^{0.6} x^2 dx \\
&amp;= F(f&#39;(c)) - F(f&#39;(a))\\
&amp;=\lim_{x\to c} F(x)\ - \lim_{x\to a} F(x)\\
&amp;= \left[\frac{x^3}{3} + c\right]_{0.2}^{0.6} = \left(\frac{0.6^3}{3}\right)\ - \left(\frac{0.2^3}{3}\right)  \nonumber\\
&amp;= 0.0693 \nonumber
\end{align}\]</span></p>
<p>The plot shows a synthetic (only made up) quadratic curve for a density and does not reflect one of the typical distributions, as we shall see in the next sections. Nevertheless, this is to demonstrate probability and proportionality.</p>
<p>We regard a bounded region as a proportion (or probable outcome) sliced between boundaries. The region or area between boundaries represents the range of probable outcomes. We see more of this topic when discussing <strong>cumulative distribution</strong>.</p>
</div>
<div id="probability-density-function-pdf" class="section level2 hasAnchor">
<h2><span class="header-section-number">5.5</span> Probability Density Function (PDF)  <a href="numericalprobability.html#probability-density-function-pdf" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Geometrically, the <strong>probability density function</strong> is a continuous function that describes the shape (or curvature) of a distribution. For example, in Figure <a href="numericalprobability.html#fig:gaussianpdf">5.8</a>, we see a bell shape <strong>density</strong> curve. Our <strong>probability density function</strong> generates this; hereafter, we use the term <strong>density function</strong>.</p>
<p>A <strong>density function</strong> is expressed in the below general form using a lower-case notation <strong>f(x)</strong>:</p>
<p><span class="math display">\[\begin{align}
f_X(x) = P(X = x)
\end{align}\]</span></p>
<p>An example of a <strong>density function</strong> is the normal (Gaussian) PDF expressed in the below equation:</p>
<p><span class="math display">\[\begin{align}
f(x; \mu, \sigma) = \frac{1}{\sigma \sqrt{2\pi}} exp\left[-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2\right]
\end{align}\]</span></p>
<p>with the following sample R code implementation:</p>

<div class="sourceCode" id="cb198"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb198-1" data-line-number="1">normal.pdf &lt;-<span class="st"> </span><span class="cf">function</span>(x, mean, sd ) {</a>
<a class="sourceLine" id="cb198-2" data-line-number="2">   <span class="co"># Gaussian / Normal Distribution</span></a>
<a class="sourceLine" id="cb198-3" data-line-number="3">   variance =<span class="st"> </span>sd<span class="op">^</span><span class="dv">2</span> </a>
<a class="sourceLine" id="cb198-4" data-line-number="4">   (<span class="dv">1</span> <span class="op">/</span><span class="st"> </span>(<span class="kw">sqrt</span>( <span class="dv">2</span> <span class="op">*</span><span class="st"> </span>pi <span class="op">*</span><span class="st"> </span>variance ))) <span class="op">*</span><span class="st">  </span></a>
<a class="sourceLine" id="cb198-5" data-line-number="5"><span class="st">     </span><span class="kw">exp</span>(<span class="op">-</span>(x <span class="op">-</span><span class="st"> </span>mean)<span class="op">^</span><span class="dv">2</span><span class="op">/</span>(<span class="dv">2</span> <span class="op">*</span><span class="st"> </span>variance))</a>
<a class="sourceLine" id="cb198-6" data-line-number="6">}</a>
<a class="sourceLine" id="cb198-7" data-line-number="7"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="op">-</span><span class="dv">3</span>,<span class="dv">3</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="fl">0.5</span>), </a>
<a class="sourceLine" id="cb198-8" data-line-number="8">     <span class="dt">xlab=</span><span class="st">&quot;spread (variance)&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;probability density&quot;</span>,</a>
<a class="sourceLine" id="cb198-9" data-line-number="9">     <span class="dt">main=</span><span class="st">&quot;Gaussian PDF&quot;</span>, <span class="dt">axes=</span><span class="ot">FALSE</span>, <span class="dt">frame=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb198-10" data-line-number="10"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb198-11" data-line-number="11"><span class="kw">abline</span>(<span class="dt">h=</span><span class="dv">0</span>, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">lwd=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb198-12" data-line-number="12"><span class="kw">curve</span>(<span class="kw">normal.pdf</span>(x, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span><span class="dv">1</span>), <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span>, <span class="dt">lwd=</span><span class="dv">2</span> )</a>
<a class="sourceLine" id="cb198-13" data-line-number="13"><span class="kw">axis</span>(<span class="dv">1</span>, <span class="dv">-3</span><span class="op">:</span><span class="dv">3</span>, <span class="kw">c</span>(<span class="kw">expression</span>(<span class="op">-</span><span class="dv">3</span><span class="op">*</span>sigma), <span class="kw">expression</span>(<span class="op">-</span><span class="dv">2</span><span class="op">*</span>sigma),</a>
<a class="sourceLine" id="cb198-14" data-line-number="14">               <span class="kw">expression</span>(sigma),<span class="dv">0</span>,<span class="kw">expression</span>(sigma),</a>
<a class="sourceLine" id="cb198-15" data-line-number="15">               <span class="kw">expression</span>(<span class="dv">2</span><span class="op">*</span>sigma),<span class="kw">expression</span>(<span class="dv">3</span><span class="op">*</span>sigma)))</a>
<a class="sourceLine" id="cb198-16" data-line-number="16"><span class="kw">axis</span>(<span class="dv">2</span>)</a>
<a class="sourceLine" id="cb198-17" data-line-number="17">y =<span class="st"> </span><span class="kw">normal.pdf</span>(<span class="dt">x=</span><span class="dv">0</span>, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb198-18" data-line-number="18"><span class="kw">segments</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, y, <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>, <span class="dt">lwd=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb198-19" data-line-number="19"><span class="kw">text</span>(<span class="dv">0</span>, y<span class="fl">+0.02</span>, <span class="dt">label=</span><span class="kw">paste</span>(<span class="st">&quot;probability density =&quot;</span>, <span class="kw">round</span>(y,<span class="dv">7</span>)) )</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:gaussianpdf"></span>
<img src="DS_files/figure-html/gaussianpdf-1.png" alt="Gaussian PDF" width="70%" />
<p class="caption">
Figure 5.8: Gaussian PDF
</p>
</div>

<p>Figure <a href="numericalprobability.html#fig:gaussianpdf">5.8</a> helps to visualize the <strong>probability density</strong> of observing data in a normal distribution in which x = 0. Using our implementation of the <strong>density function</strong>, we get the following result:</p>
<div class="sourceCode" id="cb199"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb199-1" data-line-number="1"><span class="kw">normal.pdf</span>(<span class="dt">x=</span><span class="dv">0</span>, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span><span class="dv">1</span>)</a></code></pre></div>
<pre><code>## [1] 0.3989423</code></pre>
<p>Alternatively, using a built-in R package <strong>dnorm()</strong>, we can obtain the same result:</p>
<div class="sourceCode" id="cb201"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb201-1" data-line-number="1"><span class="kw">dnorm</span>(<span class="dt">x=</span><span class="dv">0</span>, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span><span class="dv">1</span>)</a></code></pre></div>
<pre><code>## [1] 0.3989423</code></pre>
</div>
<div id="probability-mass-function-pmf" class="section level2 hasAnchor">
<h2><span class="header-section-number">5.6</span> Probability Mass function (PMF)  <a href="numericalprobability.html#probability-mass-function-pmf" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Geometrically, the <strong>probability mass function</strong> is a discrete function that describes the height of a distribution with respect to a discrete location (X-value). In an x-y coordinate system, given an <strong>X</strong> value, one can identify the corresponding <strong>Y</strong> value using the function similar to <strong>PDF</strong>, but only this time, we deal with <strong>discrete</strong> random variable, <strong>X</strong>.</p>
<p>A <strong>probability mass function</strong> is expressed in the below general form using a lower-case notation <strong>f(x)</strong>:</p>
<p><span class="math display">\[\begin{align}
f_X(x) = P(X = x)
\end{align}\]</span></p>
<p>Hereafter, we use the term <strong>mass function</strong>. A <strong>mass function</strong> is illustrated using a table or a histogram. For example, let us suppose we have the following discrete support, S:</p>
<p><span class="math display">\[
s \in S\ \ \ \rightarrow S = \{\ -3,-2,-1,\ 0,\ 1,\ 2,\ 3\ \}
\]</span>
In R code, we have the following graph:</p>

<div class="sourceCode" id="cb203"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb203-1" data-line-number="1">x =<span class="st"> </span><span class="dv">-3</span><span class="op">:</span><span class="dv">3</span></a>
<a class="sourceLine" id="cb203-2" data-line-number="2">y =<span class="st"> </span><span class="kw">normal.pdf</span>(x, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb203-3" data-line-number="3"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="op">-</span><span class="dv">3</span>,<span class="dv">3</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="fl">0.5</span>), </a>
<a class="sourceLine" id="cb203-4" data-line-number="4">     <span class="dt">xlab=</span><span class="st">&quot;support&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;probability mass&quot;</span>,</a>
<a class="sourceLine" id="cb203-5" data-line-number="5">     <span class="dt">main=</span><span class="st">&quot;Probability Mass Function (Histogram)&quot;</span>,  <span class="dt">frame=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb203-6" data-line-number="6"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb203-7" data-line-number="7"><span class="kw">abline</span>(<span class="dt">h=</span><span class="dv">0</span>, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb203-8" data-line-number="8"><span class="kw">curve</span>(<span class="kw">normal.pdf</span>(x, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span><span class="dv">1</span>), <span class="dt">col=</span><span class="st">&quot;grey&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span>, </a>
<a class="sourceLine" id="cb203-9" data-line-number="9">      <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">lwd=</span><span class="dv">2</span> )</a>
<a class="sourceLine" id="cb203-10" data-line-number="10"><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">7</span>) {</a>
<a class="sourceLine" id="cb203-11" data-line-number="11">    <span class="kw">segments</span>(x[i], <span class="dv">0</span>, x[i], y[i], <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>, <span class="dt">lwd=</span><span class="dv">7</span>)</a>
<a class="sourceLine" id="cb203-12" data-line-number="12">}</a>
<a class="sourceLine" id="cb203-13" data-line-number="13">y =<span class="st"> </span><span class="kw">normal.pdf</span>(<span class="dt">x=</span><span class="dv">0</span>, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb203-14" data-line-number="14"><span class="kw">text</span>(<span class="dv">0</span>, y<span class="fl">+0.02</span>, <span class="dt">label=</span><span class="kw">paste</span>(<span class="st">&quot;probability mass =&quot;</span>, <span class="kw">round</span>(y,<span class="dv">7</span>)) )</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:gaussianpmf"></span>
<img src="DS_files/figure-html/gaussianpmf-1.png" alt="Pobability Mass Function" width="70%" />
<p class="caption">
Figure 5.9: Pobability Mass Function
</p>
</div>

<p>To illustrate, let us calculate the <strong>probability mass</strong> of a normal distribution in which x = 0. Note that our x can only be within the range of our support, X.</p>
<p><span class="math display">\[\begin{align}
f_X(x) = P(X = x),\ \ \ \ \ where\ x \in \{\ -3,-2,-1,\ 0,\ 1,\ 2,\ 3\ \}.
\end{align}\]</span></p>
<p>We get the following result:</p>
<div class="sourceCode" id="cb204"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb204-1" data-line-number="1"><span class="kw">normal.pdf</span>(<span class="dt">x=</span><span class="dv">0</span>, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span><span class="dv">1</span>)</a></code></pre></div>
<pre><code>## [1] 0.3989423</code></pre>
<p>Alternatively, using the same built-in R package <strong>dnorm()</strong>, we can obtain the same result:</p>
<div class="sourceCode" id="cb206"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb206-1" data-line-number="1"><span class="kw">dnorm</span>(<span class="dt">x=</span><span class="dv">0</span>, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span><span class="dv">1</span>)</a></code></pre></div>
<pre><code>## [1] 0.3989423</code></pre>
</div>
<div id="cumulative-distribution-function-cdf" class="section level2 hasAnchor">
<h2><span class="header-section-number">5.7</span> Cumulative Distribution Function (CDF)  <a href="numericalprobability.html#cumulative-distribution-function-cdf" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>A <strong>cumulative distribution function</strong> computes the cumulative probability that a continuous random variable <strong>X</strong> falls under a value less than or equal to <strong>x</strong>; hereafter, we use the term <strong>distribution function</strong>.</p>
<p>A <strong>distribution function</strong> is expressed in the below general form using an upper-case notation <strong>F(x)</strong>:</p>
<p><span class="math display">\[\begin{align}
\mathcal{F}_X(x) = P(X \le x)
\end{align}\]</span></p>
<p>The cumulative distribution describes a monotonic <strong>distribution</strong> curve. See figure <a href="numericalprobability.html#fig:gaussiancdf">5.10</a>.</p>

<div class="sourceCode" id="cb208"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb208-1" data-line-number="1">normal.cdf &lt;-<span class="st"> </span><span class="cf">function</span>(x) {</a>
<a class="sourceLine" id="cb208-2" data-line-number="2">  <span class="kw">round</span>( <span class="kw">pnorm</span>(x, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span><span class="dv">1</span>), <span class="dv">2</span>)</a>
<a class="sourceLine" id="cb208-3" data-line-number="3">}</a>
<a class="sourceLine" id="cb208-4" data-line-number="4">q =<span class="st"> </span>x =<span class="st"> </span><span class="dv">1</span>  <span class="co"># one unit of standard deviation</span></a>
<a class="sourceLine" id="cb208-5" data-line-number="5">p =<span class="st"> </span><span class="kw">normal.cdf</span>(q)</a>
<a class="sourceLine" id="cb208-6" data-line-number="6"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="op">-</span><span class="dv">3</span>,<span class="dv">3</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="dv">1</span>), </a>
<a class="sourceLine" id="cb208-7" data-line-number="7">     <span class="dt">xlab=</span><span class="st">&quot;spread/variance (qnorm)&quot;</span>, </a>
<a class="sourceLine" id="cb208-8" data-line-number="8">     <span class="dt">ylab=</span><span class="st">&quot;cumulative probability (pnorm)&quot;</span>,</a>
<a class="sourceLine" id="cb208-9" data-line-number="9">     <span class="dt">main=</span><span class="st">&quot;Gaussian CDF&quot;</span>, <span class="dt">axes=</span><span class="ot">FALSE</span>, <span class="dt">frame=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb208-10" data-line-number="10"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb208-11" data-line-number="11"><span class="kw">curve</span>(<span class="kw">pnorm</span>(x, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span><span class="dv">1</span>), <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span>, <span class="dt">lwd=</span><span class="dv">2</span> )</a>
<a class="sourceLine" id="cb208-12" data-line-number="12"><span class="kw">segments</span>(<span class="kw">c</span>(<span class="dv">0</span>,<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>) , <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>), </a>
<a class="sourceLine" id="cb208-13" data-line-number="13">         <span class="kw">c</span>(<span class="dv">0</span>,<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>), <span class="kw">c</span>(<span class="kw">normal.cdf</span>(<span class="dv">0</span>), <span class="kw">normal.cdf</span>(<span class="op">-</span><span class="dv">1</span>), p), </a>
<a class="sourceLine" id="cb208-14" data-line-number="14">         <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb208-15" data-line-number="15"><span class="kw">abline</span>(<span class="dt">h=</span><span class="dv">0</span>, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb208-16" data-line-number="16"><span class="kw">axis</span>(<span class="dv">1</span>, <span class="dv">-3</span><span class="op">:</span><span class="dv">3</span>, <span class="kw">c</span>(<span class="kw">expression</span>(<span class="op">-</span><span class="dv">3</span><span class="op">*</span>sigma), <span class="kw">expression</span>(<span class="op">-</span><span class="dv">2</span><span class="op">*</span>sigma),</a>
<a class="sourceLine" id="cb208-17" data-line-number="17">               <span class="kw">expression</span>(<span class="op">-</span><span class="dv">1</span><span class="op">*</span>sigma),<span class="dv">0</span>,<span class="kw">expression</span>(<span class="dv">1</span><span class="op">*</span>sigma),</a>
<a class="sourceLine" id="cb208-18" data-line-number="18">               <span class="kw">expression</span>(<span class="dv">2</span><span class="op">*</span>sigma),<span class="kw">expression</span>(<span class="dv">3</span><span class="op">*</span>sigma)))</a>
<a class="sourceLine" id="cb208-19" data-line-number="19"><span class="kw">axis</span>(<span class="dv">2</span>)</a>
<a class="sourceLine" id="cb208-20" data-line-number="20"><span class="kw">text</span>(<span class="fl">2.5</span>, <span class="fl">0.95</span>, <span class="dt">label=</span><span class="st">&quot;cdf curve&quot;</span>, <span class="dt">ce=</span><span class="dv">1</span>, <span class="dt">col=</span><span class="st">&quot;blue&quot;</span>)</a>
<a class="sourceLine" id="cb208-21" data-line-number="21"><span class="kw">text</span>(<span class="dv">0</span> <span class="op">-</span><span class="st"> </span><span class="fl">0.65</span>,  <span class="kw">normal.cdf</span>(<span class="dv">0</span>), <span class="dt">label=</span><span class="kw">paste0</span>(<span class="st">&quot;(pnorm) = &quot;</span>, </a>
<a class="sourceLine" id="cb208-22" data-line-number="22">                <span class="kw">normal.cdf</span>(<span class="dv">0</span>)), <span class="dt">ce=</span><span class="dv">1</span>, <span class="dt">col=</span><span class="st">&quot;black&quot;</span>)</a>
<a class="sourceLine" id="cb208-23" data-line-number="23"><span class="kw">text</span>(<span class="op">-</span><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="fl">0.65</span>, <span class="kw">normal.cdf</span>(<span class="op">-</span><span class="dv">1</span>), <span class="dt">label=</span><span class="kw">paste0</span>(<span class="st">&quot;(pnorm) = &quot;</span>, </a>
<a class="sourceLine" id="cb208-24" data-line-number="24">                <span class="kw">normal.cdf</span>(<span class="op">-</span><span class="dv">1</span>)), <span class="dt">ce=</span><span class="dv">1</span>, <span class="dt">col=</span><span class="st">&quot;black&quot;</span>)</a>
<a class="sourceLine" id="cb208-25" data-line-number="25"><span class="kw">text</span>(q <span class="op">-</span><span class="st"> </span><span class="fl">0.65</span>,  <span class="kw">normal.cdf</span>(q), <span class="dt">label=</span><span class="kw">paste0</span>(<span class="st">&quot;(pnorm) = &quot;</span>, </a>
<a class="sourceLine" id="cb208-26" data-line-number="26">                <span class="kw">normal.cdf</span>(q)), <span class="dt">ce=</span><span class="dv">1</span>, <span class="dt">col=</span><span class="st">&quot;black&quot;</span>)</a>
<a class="sourceLine" id="cb208-27" data-line-number="27"><span class="kw">text</span>(x <span class="op">+</span><span class="st"> </span><span class="fl">0.5</span>, <span class="fl">0.03</span>, <span class="dt">label=</span><span class="kw">paste0</span>(<span class="st">&quot;(qnorm) = &quot;</span>, q), <span class="dt">ce=</span><span class="dv">1</span>, <span class="dt">col=</span><span class="st">&quot;black&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:gaussiancdf"></span>
<img src="DS_files/figure-html/gaussiancdf-1.png" alt="Gaussian CDF" width="70%" />
<p class="caption">
Figure 5.10: Gaussian CDF
</p>
</div>

<p>Base on figure <a href="numericalprobability.html#fig:gaussiancdf">5.10</a>, we notice three characteristics of a <strong>distribution</strong> curve:</p>
<ul>
<li>The curve is monotonically increasing to the right.</li>
<li>If we increase the support infinitely, we see that the curve flattens infinitely towards 1:</li>
</ul>
<p><span class="math display">\[\begin{align}
\underset{x \rightarrow \infty}{\mathrm{lim}}(\text{CDF}) = 1
\end{align}\]</span></p>
<ul>
<li>If we decrease the support, we see that the curve flattens infinitely towards 0:</li>
</ul>
<p><span class="math display">\[\begin{align}
\underset{x \rightarrow -\infty}{\mathrm{lim}}(\text{CDF}) = 0
\end{align}\]</span></p>
<p>Alternatively, a <strong>distribution function</strong> also computes for the area under the <strong>density</strong> curve. See figure <a href="numericalprobability.html#fig:gaussianq">5.11</a>.</p>

<div class="sourceCode" id="cb209"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb209-1" data-line-number="1">normal.cdf &lt;-<span class="st"> </span><span class="cf">function</span>(prob) {</a>
<a class="sourceLine" id="cb209-2" data-line-number="2">   <span class="kw">qnorm</span>(prob)</a>
<a class="sourceLine" id="cb209-3" data-line-number="3">}</a>
<a class="sourceLine" id="cb209-4" data-line-number="4">area &lt;-<span class="st"> </span><span class="cf">function</span>(prob) {</a>
<a class="sourceLine" id="cb209-5" data-line-number="5">    <span class="co"># boundaries</span></a>
<a class="sourceLine" id="cb209-6" data-line-number="6">    a =<span class="st"> </span><span class="dv">-3</span>; b =<span class="st"> </span><span class="kw">normal.cdf</span>(prob) <span class="co"># (quantile function)</span></a>
<a class="sourceLine" id="cb209-7" data-line-number="7">    <span class="co"># area</span></a>
<a class="sourceLine" id="cb209-8" data-line-number="8">    area =<span class="st"> </span><span class="kw">seq</span>(a, b, <span class="dt">length.out=</span><span class="dv">50</span>)</a>
<a class="sourceLine" id="cb209-9" data-line-number="9">    x =<span class="st"> </span><span class="kw">c</span>(a, area , b)</a>
<a class="sourceLine" id="cb209-10" data-line-number="10">    y =<span class="st"> </span><span class="kw">c</span>(<span class="dv">0</span>, <span class="kw">normal.pdf</span>(area, <span class="dv">0</span>, <span class="dv">1</span>), <span class="dv">0</span>)</a>
<a class="sourceLine" id="cb209-11" data-line-number="11">    <span class="kw">polygon</span>(x, y, <span class="dt">col=</span><span class="st">&quot;grey&quot;</span>)</a>
<a class="sourceLine" id="cb209-12" data-line-number="12">}</a>
<a class="sourceLine" id="cb209-13" data-line-number="13"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="op">-</span><span class="dv">3</span>,<span class="dv">3</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="fl">0.5</span>), </a>
<a class="sourceLine" id="cb209-14" data-line-number="14">     <span class="dt">xlab=</span><span class="st">&quot;spread/variance (qnorm)&quot;</span>, </a>
<a class="sourceLine" id="cb209-15" data-line-number="15">     <span class="dt">ylab=</span><span class="st">&quot;probability density (dnorm)&quot;</span>,</a>
<a class="sourceLine" id="cb209-16" data-line-number="16">     <span class="dt">main=</span><span class="st">&quot;Gaussian CDF&quot;</span>, <span class="dt">axes=</span><span class="ot">FALSE</span>, <span class="dt">frame=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb209-17" data-line-number="17"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb209-18" data-line-number="18"><span class="kw">abline</span>(<span class="dt">h=</span><span class="dv">0</span>, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb209-19" data-line-number="19"><span class="kw">curve</span>(<span class="kw">normal.pdf</span>(x, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span><span class="dv">1</span>), <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span>, <span class="dt">lwd=</span><span class="dv">2</span> )</a>
<a class="sourceLine" id="cb209-20" data-line-number="20"><span class="kw">axis</span>(<span class="dv">1</span>, <span class="dv">-3</span><span class="op">:</span><span class="dv">3</span>, <span class="kw">c</span>(<span class="kw">expression</span>(<span class="op">-</span><span class="dv">3</span><span class="op">*</span>sigma), <span class="kw">expression</span>(<span class="op">-</span><span class="dv">2</span><span class="op">*</span>sigma),</a>
<a class="sourceLine" id="cb209-21" data-line-number="21">               <span class="kw">expression</span>(<span class="op">-</span><span class="dv">1</span><span class="op">*</span>sigma),<span class="dv">0</span>,<span class="kw">expression</span>(<span class="dv">1</span><span class="op">*</span>sigma),</a>
<a class="sourceLine" id="cb209-22" data-line-number="22">               <span class="kw">expression</span>(<span class="dv">2</span><span class="op">*</span>sigma),<span class="kw">expression</span>(<span class="dv">3</span><span class="op">*</span>sigma)))</a>
<a class="sourceLine" id="cb209-23" data-line-number="23"><span class="kw">axis</span>(<span class="dv">2</span>)</a>
<a class="sourceLine" id="cb209-24" data-line-number="24"><span class="kw">area</span>(<span class="dt">prob=</span><span class="fl">0.5</span>)</a>
<a class="sourceLine" id="cb209-25" data-line-number="25"><span class="kw">text</span>(<span class="dv">0</span>, <span class="fl">0.42</span>, <span class="dt">label=</span><span class="st">&quot;pdf curve&quot;</span>, <span class="dt">ce=</span><span class="dv">1</span>, <span class="dt">col=</span><span class="st">&quot;blue&quot;</span>)</a>
<a class="sourceLine" id="cb209-26" data-line-number="26"><span class="kw">text</span>(<span class="op">-</span><span class="fl">0.6</span>, <span class="fl">0.14</span>, <span class="dt">label=</span><span class="st">&quot;cdf area = 0.5&quot;</span>, <span class="dt">ce=</span><span class="dv">1</span>, <span class="dt">col=</span><span class="st">&quot;black&quot;</span>)</a>
<a class="sourceLine" id="cb209-27" data-line-number="27"><span class="kw">text</span>(<span class="op">-</span><span class="fl">0.6</span>, <span class="fl">0.09</span>, <span class="dt">label=</span><span class="st">&quot;(pnorm)&quot;</span>, <span class="dt">ce=</span><span class="dv">1</span>, <span class="dt">col=</span><span class="st">&quot;black&quot;</span>)</a>
<a class="sourceLine" id="cb209-28" data-line-number="28"><span class="kw">text</span>(<span class="fl">0.50</span>, <span class="fl">0.02</span>, <span class="dt">label=</span><span class="st">&quot;(qnorm) q=0&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:gaussianq"></span>
<img src="DS_files/figure-html/gaussianq-1.png" alt="Gaussian CDF" width="70%" />
<p class="caption">
Figure 5.11: Gaussian CDF
</p>
</div>

<p>To illustrate, let us calculate the <strong>cumulative density</strong> (or <strong>cumulative distribution</strong> or <strong>probability distribution</strong>) of a normal distribution in which <span class="math inline">\(x = 0\)</span>:</p>
<p><span class="math display">\[\begin{align}
\mathcal{F}_X(x) = P(X \le x) = P(X \le 0) 
\end{align}\]</span></p>
<p>In R code, cumulative density can be computed using <strong>pnorm</strong>:</p>
<div class="sourceCode" id="cb210"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb210-1" data-line-number="1">(<span class="dt">p =</span> <span class="kw">pnorm</span>(<span class="dt">q=</span><span class="dv">0</span>, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span><span class="dv">1</span>)) <span class="co"># area under the curve, given quantile=0</span></a></code></pre></div>
<pre><code>## [1] 0.5</code></pre>
<p>In reverse, get the <strong>quantile value</strong> given the result of <strong>cdf</strong>:</p>
<div class="sourceCode" id="cb212"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb212-1" data-line-number="1">(<span class="dt">q =</span> <span class="kw">qnorm</span>(<span class="dt">p=</span><span class="fl">0.5</span>, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span><span class="dv">1</span>)) <span class="co"># inverse of cdf (or pnorm)</span></a></code></pre></div>
<pre><code>## [1] 0</code></pre>
</div>
<div id="special-functions" class="section level2 hasAnchor">
<h2><span class="header-section-number">5.8</span> Special Functions<a href="numericalprobability.html#special-functions" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Before we discuss the different types of distribution in this section, let us first introduce some <strong>special functions</strong> that are often used in numerical computing for <strong>PDFs</strong> and <strong>CDFs</strong>. Here, we exclude the derivation of the functions. We leave readers to investigate those derivations. Other references include Mathai A. M. <span class="citation">(<a href="bibliography.html#ref-ref714a">1993</a>)</span>] and Gautschi W. <span class="citation">(<a href="bibliography.html#ref-ref739w">1983</a>)</span>.</p>
<div id="gamma-function" class="section level3 hasAnchor">
<h3><span class="header-section-number">5.8.1</span> Gamma function <a href="numericalprobability.html#gamma-function" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Gamma</strong> function extends the scope of factorial function from non-negative integer to real numbers.</p>
<p><span class="math display">\[\begin{align}
\Gamma(z) = \int_0^\infty  x^{z-1} e^{-x} dx = (z-1)!\ \ \ \ \ \ \ \ \ \ \ \ \ \ \Gamma(z+1) = z\Gamma(z) =  z(z-1)!
\end{align}\]</span></p>
<p>The Gamma function can be split into two regions (see next section).</p>
<p><span class="math display">\[\begin{align}
\Gamma(z) = \gamma(z, \alpha) + \Gamma(z, \alpha) 
\end{align}\]</span></p>
</div>
<div id="incomplete-gamma-function" class="section level3 hasAnchor">
<h3><span class="header-section-number">5.8.2</span> Incomplete Gamma function <a href="numericalprobability.html#incomplete-gamma-function" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The term <strong>Incomplete</strong> refers to the bounded (only partial) region covered by the integration with respect to the parameter, <span class="math inline">\(\alpha\)</span>.</p>
<p>There are two regions:</p>
<p>The <strong>lower region</strong> defined by the following equation (where x &gt;=0):</p>
<p><span class="math display">\[\begin{align}
\gamma(z, \alpha) = \int_0^\alpha x^{z-1}e^{-x} dx,\ \ \ \ \ \ \ where\ z &gt; 0
\end{align}\]</span></p>
<p>The <strong>upper region</strong> defined by the following equation (where x &gt;= 0):</p>
<p><span class="math display">\[\begin{align}
\Gamma(z, \alpha) = \int_\alpha^\infty x^{z-1}e^{-x} dx,\ \ \ \ \ \ \ where\ z &gt; 0
\end{align}\]</span></p>
<p>Here, let us use one of a few numerical variations such as the <strong>power series</strong> to compute for the <strong>lower incomplete gamma function</strong> (Wikipedia - Incomplete Gamma Function):</p>
<p><span class="math display">\[\begin{align}
\gamma(z, \alpha) = \alpha^z e^{-\alpha} \sum_{k=0}^\infty \frac{\alpha^k}{\Gamma(z+k+1)}
\end{align}\]</span></p>
<p>With that, we have the following <strong>regularized Incomplete Gamma functions</strong>:</p>
<p><strong>lower tail</strong> in a distribution:</p>
<p><span class="math display">\[\begin{align}
P(z, \alpha) = \frac{\gamma(z, \alpha)}{\Gamma(z)} 
= \frac{1}{\Gamma(\alpha)}\int_0^\alpha x^{z-1}e^{-x}dx
= \frac{ \alpha^z e^{-\alpha} }{\Gamma(z)}
\sum_{k=0}^\infty \frac{\alpha^k}{\Gamma(z+k+1)},
\end{align}\]</span></p>
<p>and <strong>upper tail</strong> in a distribution:</p>
<p><span class="math display">\[\begin{align}
Q(z,\alpha) = \frac{\Gamma(z,\alpha)}{\Gamma(z)} 
= \frac{1}{\Gamma(\alpha)}\int_\alpha^\infty x^{z-1}e^{-x}dx
= 1 - P(z, \alpha)
\end{align}\]</span></p>
<p>Here is a naive implementation of <strong>Incomplete Gamma functions</strong> in R code:</p>

<div class="sourceCode" id="cb214"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb214-1" data-line-number="1"><span class="kw">library</span>(pracma)</a>
<a class="sourceLine" id="cb214-2" data-line-number="2">Gamma &lt;-<span class="st"> </span><span class="cf">function</span>(n) { <span class="kw">factorial</span>(n<span class="dv">-1</span>)}</a>
<a class="sourceLine" id="cb214-3" data-line-number="3">GammaInc &lt;-<span class="st"> </span><span class="cf">function</span>(alpha, z) {</a>
<a class="sourceLine" id="cb214-4" data-line-number="4">    s =<span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb214-5" data-line-number="5">    limit =<span class="st"> </span><span class="dv">300</span></a>
<a class="sourceLine" id="cb214-6" data-line-number="6">    flimit =<span class="st"> </span><span class="dv">172</span>  <span class="co"># R&#39;s gamma limit</span></a>
<a class="sourceLine" id="cb214-7" data-line-number="7">    <span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">0</span><span class="op">:</span>limit) {</a>
<a class="sourceLine" id="cb214-8" data-line-number="8">      <span class="cf">if</span> (z <span class="op">+</span><span class="st"> </span>k <span class="op">+</span><span class="st"> </span><span class="dv">1</span> <span class="op">&gt;</span><span class="st"> </span><span class="dv">171</span>) { <span class="cf">break</span> }</a>
<a class="sourceLine" id="cb214-9" data-line-number="9">      s =<span class="st"> </span>s <span class="op">+</span><span class="st"> </span>alpha<span class="op">^</span>k <span class="op">/</span><span class="st"> </span><span class="kw">Gamma</span>( z <span class="op">+</span><span class="st"> </span>k <span class="op">+</span><span class="st"> </span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb214-10" data-line-number="10">    }</a>
<a class="sourceLine" id="cb214-11" data-line-number="11">    lower =<span class="st"> </span>alpha<span class="op">^</span>z <span class="op">*</span><span class="st"> </span><span class="kw">Gamma</span>(z) <span class="op">*</span><span class="st"> </span><span class="kw">exp</span>(<span class="op">-</span>alpha) <span class="op">*</span><span class="st"> </span>s</a>
<a class="sourceLine" id="cb214-12" data-line-number="12">    upper =<span class="st"> </span><span class="kw">Gamma</span>(z) <span class="op">-</span><span class="st"> </span>lower</a>
<a class="sourceLine" id="cb214-13" data-line-number="13">    P =<span class="st"> </span>lower <span class="op">/</span><span class="st"> </span><span class="kw">Gamma</span>(z) <span class="co"># regular inc gamma</span></a>
<a class="sourceLine" id="cb214-14" data-line-number="14">    Q =<span class="st"> </span>upper <span class="op">/</span><span class="st"> </span><span class="kw">Gamma</span>(z)</a>
<a class="sourceLine" id="cb214-15" data-line-number="15">    <span class="kw">list</span>(<span class="st">&quot;lower&quot;</span>=<span class="st"> </span>lower, <span class="st">&quot;upper&quot;</span>=upper,  <span class="st">&quot;P&quot;</span>=P, <span class="st">&quot;Q&quot;</span>=Q )</a>
<a class="sourceLine" id="cb214-16" data-line-number="16">}</a>
<a class="sourceLine" id="cb214-17" data-line-number="17"><span class="co"># Naive implementation</span></a>
<a class="sourceLine" id="cb214-18" data-line-number="18"><span class="kw">t</span>(<span class="kw">GammaInc</span>(<span class="dv">2</span>,<span class="dv">1</span>))</a></code></pre></div>
<pre><code>##      lower     upper     P         Q        
## [1,] 0.8646647 0.1353353 0.8646647 0.1353353</code></pre>
<div class="sourceCode" id="cb216"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb216-1" data-line-number="1"><span class="co"># Built-in R package (pracma)</span></a>
<a class="sourceLine" id="cb216-2" data-line-number="2"><span class="kw">gammainc</span>(<span class="dv">2</span>,<span class="dv">1</span>)</a></code></pre></div>
<pre><code>##    lowinc    uppinc    reginc 
## 0.8646647 0.1353353 0.8646647</code></pre>

<p>Note that in R, the gamma function may not allow numbers over the range limit of 172. A way to work around that is using log gamma (lgamma) with additional adjustments in the expressions.</p>
</div>
<div id="digamma-function" class="section level3 hasAnchor">
<h3><span class="header-section-number">5.8.3</span> Digamma Function <a href="numericalprobability.html#digamma-function" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The <strong>Digamma</strong> function is the derivative of the log of Gamma function and is written as:</p>
<p><span class="math display">\[\begin{align}
\Psi(x) = \frac{d}{dx} \log_e \Gamma(x) = \frac{\Gamma&#39;(x)}{\Gamma(x)}
\end{align}\]</span></p>
<p>We also have <strong>Polygamma</strong> function as a general extension of <strong>Digamma</strong> function and written like so:</p>
<p><span class="math display">\[\begin{align}
\Psi(n,x) = \frac{d^n}{dx^n} \log_e \Gamma(x) = \frac{\Gamma^{(n)}(x)}{\Gamma(x)}
\end{align}\]</span></p>
</div>
<div id="beta-function" class="section level3 hasAnchor">
<h3><span class="header-section-number">5.8.4</span> Beta function <a href="numericalprobability.html#beta-function" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Beta</strong> function is named by <strong>Legendre</strong> for <strong>Eulerâs integral of the first kind</strong> which relies on <strong>Gamma</strong> function.</p>
<p><span class="math display">\[\begin{align}
\mathcal{B}(\alpha, \beta) \equiv \mathcal{B}(1; \alpha, \beta)  = \int_0^1 x^{\alpha-1}(1-x)^{\beta-1} dx 
= \frac{\Gamma(\alpha)\Gamma(\beta)}{\Gamma(\alpha + \beta)}
\end{align}\]</span></p>
<p>where <span class="math inline">\(\alpha &gt; 0\ and\ \beta &gt; 0\)</span>.</p>
<p>Note that if <strong>function</strong> is symmetric, then we have:</p>
<p><span class="math display">\[
\mathcal{B}(\alpha, \beta) = \mathcal{B}(\beta, \alpha)
\]</span></p>
</div>
<div id="incomplete-beta-function" class="section level3 hasAnchor">
<h3><span class="header-section-number">5.8.5</span> Incomplete Beta function <a href="numericalprobability.html#incomplete-beta-function" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Given the <strong>support</strong> as <span class="math inline">\(0 \le x \le 1\)</span>, we have the following function:</p>
<p><span class="math display">\[\begin{align}
\mathcal{B}_x(\alpha, \beta) \equiv \mathcal{B}(x; \alpha, \beta)  = \int_0^x x^{\alpha-1}(1-x)^{\beta-1} dx
\end{align}\]</span></p>
</div>
<div id="regularized-beta-function" class="section level3 hasAnchor">
<h3><span class="header-section-number">5.8.6</span> Regularized Beta function  <a href="numericalprobability.html#regularized-beta-function" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Regularized Beta function</strong> is also called the <strong>Normalized Incomplete Beta function</strong> and is written as.</p>
<p><span class="math display">\[\begin{align}
I_x(\alpha, \beta) \equiv I(x; \alpha, \beta) = 1 - I_{1-x}(\beta, \alpha)  = \frac{\mathcal{B}_x(\alpha, \beta)}{\mathcal{B}(\alpha, \beta)}
\end{align}\]</span></p>
<p>Equivalently, we have:</p>
<p><span class="math display">\[\begin{align}
I_x(\alpha, \beta) +  I_{1-x}(\beta, \alpha)  = 1
\end{align}\]</span></p>
<p>Also, for the derivations, we have:</p>
<p><span class="math display">\[\begin{align}
I_x(\alpha, \beta) \equiv I(x; \alpha, \beta)  = \frac{1}{\mathcal{B}(\alpha, \beta) } \int_0^x x^{\alpha-1}(1-x)^{\beta-1} dx
\end{align}\]</span></p>
<p>and</p>
<p><span class="math display">\[\begin{align}
I_{1-x}(\beta, \alpha) \equiv I(1-x; \beta, \alpha) = \frac{1}{\mathcal{B}(\alpha, \beta) } \int_{x}^1 x^{\alpha-1}(1-x)^{\beta-1} dx
\end{align}\]</span></p>
<p>For further discussion of <strong>Incomplete Beta functions</strong>, see <strong>CDF</strong> for <strong>T distribution</strong> in Chapter <strong>6</strong> (<strong>Statistical Computation</strong>).</p>
</div>
<div id="hypergeometric-function" class="section level3 hasAnchor">
<h3><span class="header-section-number">5.8.7</span> Hypergeometric function <a href="numericalprobability.html#hypergeometric-function" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Hypergeometric function</strong> is a special function that computes for the sum of <strong>hypergeometric series</strong>.</p>
<p><strong>Generalized form</strong>:</p>
<p><span class="math display">\[\begin{align}
{}_pF_q(\alpha_1,...,\alpha_p; \beta_1,...,\beta_q; x) = \sum_{n=0}^\infty \frac{(\alpha_1)_n\cdots(\alpha_p)_n}{\beta_1)_n\cdots(\beta_q)_n}\frac{x^n}{n!}
\end{align}\]</span></p>
<p><strong>Gauss form</strong>:</p>
<p><span class="math display">\[\begin{align}
{}_2F_1(a,b;c; x) = \sum_{n=0}^\infty \frac{(a)_n(b)_n}{(c)_n}\frac{x^n}{n!}
\end{align}\]</span></p>
<p>Note that <span class="math inline">\((x)_n\)</span> is a <strong>Pochhammer symbol</strong> which is expressed as: </p>
<ul>
<li><strong>Falling Factorial</strong> (where <span class="math inline">\(x \ge 0\)</span> and <span class="math inline">\(x \in \mathbb{R}\)</span>): </li>
</ul>
<p><span class="math display">\[\begin{align}
(x)_n = \frac{\Gamma(x+n)}{\Gamma(x - n + 1)}  = x(x-1)(x-2) ... (x- n +1) = \prod_{k=0}^{n-1} (x-k)
\end{align}\]</span></p>
<ul>
<li><strong>Rising Factorial</strong> (where <span class="math inline">\(x \ge 0\)</span> and <span class="math inline">\(x \in \mathbb{R}\)</span>): </li>
</ul>
<p><span class="math display">\[\begin{align}
(x)^n = \frac{\Gamma(x+n)}{\Gamma(x)}  = x(x+1)(x+2) ... (x+n-1) = \prod_{k=0}^{n-1}(x+k)
\end{align}\]</span></p>
<p>A rather expansion form of <strong>Hypergeometric function</strong> without the <strong>Pochhammer symbol</strong> is the following:</p>
<p><span class="math display">\[\begin{align}
{}_pF_q(\alpha_1,...,\alpha_p; \beta_1,...,\beta_q; x) = 
\sum_{k=0}^\infty 
\prod_{i=1}^p \frac{\Gamma(k+\alpha_i)}{\Gamma(\alpha_i)}
\prod_{j=1}^p  \frac{\Gamma(\beta_j)}{\Gamma(k+\beta_j)}
\frac{x^k}{k!}
\end{align}\]</span></p>
<p>and using that to form our <strong>Gauss Hypergeometric function</strong>:</p>
<p><span class="math display">\[\begin{align}
{}_2F_1(\alpha_1,\alpha_2; \beta_1; x) = 
\sum_{k=0}^\infty 
\prod_{i=1}^2 \frac{\Gamma(k+\alpha_i)}{\Gamma(\alpha_i)}
\prod_{j=1}^1 \frac{\Gamma(\beta_j)}{\Gamma(k+\beta_j)}
\frac{x^k}{k!}
\end{align}\]</span></p>
<p>The <strong>Gauss Hypergeometric function</strong> has other transformation formulas (<strong>Abramowitz and Stegun</strong> 1964):</p>
<p><span class="math display">\[\begin{align}
{}_2F_1(\alpha,\beta,c; x) &amp;= (1-x)^{-\beta} {}_2F_1\left(c-\alpha,\beta;c; \frac{x}{x-1}\right)\ \ \ \leftarrow\ \ \ Pfaff\\
&amp;= (1-x)^{-\alpha} {}_2F_1\left(\alpha,c-\beta;c; \frac{x}{x-1}\right)\ \ \ \leftarrow\ \ \ Pfaff\\
&amp;= (1-x)^{c-\alpha-\beta} {}_2F_1(c-\alpha,c-\beta;c; x)\ \ \ \leftarrow\ \ \ Euler
\end{align}\]</span></p>
<p>To illustrate the use of <strong>Gamma, Beta, and Hypergeometric functions</strong>, see the discussion of <strong>CDF</strong> in Chapter <strong>6</strong> (<strong>Statistical Computation</strong>) under <strong>t-Distribution</strong>.</p>
</div>
<div id="continued-fraction" class="section level3 hasAnchor">
<h3><span class="header-section-number">5.8.8</span> Continued Fraction <a href="numericalprobability.html#continued-fraction" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Continued Fraction</strong> is a finite representation of a rational number in the form of a fraction characterized by a repeating quotient. It has the following format (with <span class="math inline">\(\mathcal{K}\)</span> indicating a series of continued fractions):</p>
<p><span class="math display">\[\begin{align}
CF(a,b) = b_0 + \mathcal{K}_{n=1}^\infty \frac{a_n}{b_n} = b_0 + \frac{a_1}{b_1 + \frac{a_2}{b_2 + \frac{a_3}{b_3 + ...}}}
\end{align}\]</span></p>
<p>There are two notations we can use to represent <strong>Continued Fraction</strong>:</p>
<p><span class="math display">\[\begin{align}
CF(a,b) = ( b_0; b_1, b_2, b_3, ... )\ \ \ \ and\ \ \ \ 
CF(a,b) = \left[ b_0 + \frac{a_1}{b_1 +}\frac{a_2}{b_2 +}\frac{a_3}{b_3 +} ... \right]
\end{align}\]</span></p>
<p>Only for illustration purpose, here is a sample naive (recursive) implementation of <strong>Continued Fraction</strong> in R code:</p>

<div class="sourceCode" id="cb218"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb218-1" data-line-number="1">continued_fraction &lt;-<span class="st"> </span><span class="cf">function</span>(n, a, b) { <span class="co"># recursive</span></a>
<a class="sourceLine" id="cb218-2" data-line-number="2">    <span class="cf">if</span> (n <span class="op">==</span><span class="st"> </span><span class="dv">0</span>) <span class="kw">return</span>(a<span class="op">/</span>b)</a>
<a class="sourceLine" id="cb218-3" data-line-number="3">    b <span class="op">+</span><span class="st"> </span>a <span class="op">/</span><span class="st"> </span><span class="kw">continued_fraction</span>(n<span class="dv">-1</span>, a, b)</a>
<a class="sourceLine" id="cb218-4" data-line-number="4">}</a>
<a class="sourceLine" id="cb218-5" data-line-number="5"><span class="kw">continued_fraction</span>(<span class="dt">n=</span><span class="dv">20</span>,<span class="dt">a=</span><span class="dv">2</span>,<span class="dt">b=</span><span class="dv">1</span>)</a></code></pre></div>
<pre><code>## [1] 2</code></pre>


<p><span class="math display">\[\begin{align*}
CF(a,b) {}&amp;= b_0 + \mathcal{K}_{n=1}^\infty \frac{a_n}{b_n} 
= 1 + \mathcal{K}_{n=1}^{20} \frac{2}{1} 
&amp;= b_0 + \frac{a_1}{b_1 + \frac{a_2}{b_2 + \frac{a_3}{b_3 + ...}}}
&amp;= 1 + \frac{2}{1+ \frac{2}{1 + \frac{2}{1 + ...}}}
= 2
\end{align*}\]</span>
</p>
<p>We leave readers to investigate <strong>Lentzâs algorithm</strong> used to compute for continued fractions.</p>
<p>The next two functions may not necessarily be used in distribution functions; however, it helps to be familiar with them.</p>
</div>
<div id="dirac-delta-function" class="section level3 hasAnchor">
<h3><span class="header-section-number">5.8.9</span> Dirac Delta Function <a href="numericalprobability.html#dirac-delta-function" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The <strong>Dirac Delta</strong> function is also called the <strong>Impulse</strong> function. It characterizes a behavior such that it develops into a sudden spike from a prolonged constant state and immediately drops back to a constant state. For example, a sudden change of <strong>momentum</strong> because of an applied force creates such an <strong>impulse</strong>.</p>
<p><span class="math display">\[\begin{align}
\delta (x) = 
\begin{cases}
0 &amp; x \ne 0\\
\infty &amp; x = 0
\end{cases} \label{eqn:eqnnumber15}
\end{align}\]</span></p>
</div>
<div id="kronecker-delta-function" class="section level3 hasAnchor">
<h3><span class="header-section-number">5.8.10</span> Kronecker Delta Function <a href="numericalprobability.html#kronecker-delta-function" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The <strong>Kronecker delta</strong> has the likes of an <strong>indicator</strong> function in that it outputs one if a variable equals some given value; otherwise, it outputs zero.</p>
<p><span class="math display">\[\begin{align}
\delta (x) = 
\begin{cases}
0 &amp; x \ne 0\\
1 &amp; x = 0
\end{cases}
\ \ \ \ \ \ \ \
\delta (x) = 
\begin{cases}
0 &amp; x \ne m\\
1 &amp; x = m
\end{cases} \label{eqn:eqnnumber16}
\end{align}\]</span></p>
</div>
</div>
<div id="distributiontypes" class="section level2 hasAnchor">
<h2><span class="header-section-number">5.9</span> Types of Distribution<a href="numericalprobability.html#distributiontypes" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Apart from summarizing data based on quantifying its moments (mean, variance, skewness, kurtosis), it helps characterize the <strong>distribution</strong> of data based on the geometric shape, size, and thickness of its tails. This section shows the <strong>PDF</strong> and <strong>CDF</strong> to describe the distribution. Here, we reference the great works of Walck C. <span class="citation">(<a href="bibliography.html#ref-ref685c">2007</a>)</span>, Press W.H et al. <span class="citation">(<a href="bibliography.html#ref-ref215w">2007</a>)</span>, pp.Â 321-339, Ross S. <span class="citation">(<a href="bibliography.html#ref-ref695s">2010</a>)</span>, Murphy K.P. <span class="citation">(<a href="bibliography.html#ref-ref224k">2012</a>)</span>, pp.Â 34-43, and McLaughlin M.P. <span class="citation">(<a href="bibliography.html#ref-ref705m">2016</a>)</span>.</p>
<p>Let us start with <strong>Bernoulli distribution</strong> - a single trial <strong>Binomial distribution</strong>. </p>
<div id="bernoulli-distribution" class="section level3 hasAnchor">
<h3><span class="header-section-number">5.9.1</span> Bernoulli distribution <a href="numericalprobability.html#bernoulli-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A <strong>Bernoulli distribution</strong>, named after <strong>Jacob Bernoulli</strong>, is a <strong>discrete</strong> probability distribution of a random variable taking a <strong>binary outcome</strong> which can be 0 or 1, true or false, head or tail of a coin, and is written as:</p>
<p><span class="math display">\[\begin{align}
X \sim Bernoulli(\rho)\ \ \ or\ \ \ \ X \sim Ber(\rho)
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(\rho\)</span> is the approximate probability of success</li>
<li><strong>X</strong> is the data (random variable).</li>
</ul>
<p>Here, we continue to emphasize the idea of approximation. We give two cases where we show approximation for random events.</p>
<p>For example, suppose we make a single attempt to toss a coin with an approximate 50% chance that the coin lands on heads. Here, we have a probability outcome denoted as <span class="math inline">\(\rho\)</span>. If <span class="math inline">\(\rho\)</span> is the probable outcome of the head, then <span class="math inline">\(q = 1 - \rho\)</span> is the probable outcome of tails.</p>
<p>Being a discrete distribution, the <strong>PMF</strong>, probability mass function, where <span class="math inline">\(\rho=0.50\)</span> is written as:</p>
<p><span class="math display">\[\begin{align}
f(x) = 
\begin{cases}
\rho &amp; x = 1 \\
q = 1 - \rho &amp; x = 0
\end{cases} \label{eqn:eqnnumber17}
\end{align}\]</span></p>
<p>which can also be written as:</p>
<p><span class="math display">\[\begin{align}
f(x; \rho) = P(X=x|\rho) = \rho^xq^{1-x} = \rho^x(1-\rho)^{1-x}
\end{align}\]</span></p>
<p>For another example, suppose we make just one attempt to roll a six-sided die with a 16% probability that it lands on one side with the number four. Here, let us use <span class="math inline">\(\mathbf{x=1}\)</span> if the die lands on number four, and <span class="math inline">\(\mathbf{x=0}\)</span> if the die lands on other numbers. Also, let us consider the following:</p>
<p><span class="math display">\[
\rho_{\{4\}} = 0.16\ \ \ \ \ \ \ \ q_{\{1,2,3,5,6\}} = 0.84
\]</span>
Using the equation, we get the following:</p>
<p><span class="math display">\[\begin{align*}
f(x; \rho) {}&amp;= P(X=x|\rho) = \rho^xq^{1-x} = \rho^x(1-\rho)^{1-x}\\
f(x=1; \rho=0.16) &amp;= P(X=1|\rho=0.16) = (0.16)^{1}(0.84)^{1-1} = 0.16\\
f(x=0; \rho=0.16) &amp;= P(X=0|\rho=0.16) = (0.16)^{0}(0.84)^{1-0} = 0.84\\
\end{align*}\]</span></p>
</div>
<div id="binomial-distribution" class="section level3 hasAnchor">
<h3><span class="header-section-number">5.9.2</span> Binomial distribution <a href="numericalprobability.html#binomial-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>On the other hand, a <strong>Binomial distribution</strong> is the sum of <strong>Bernoulli</strong> trials and is written as:</p>
<p><span class="math display">\[\begin{align}
X \sim Bin(n, \rho)
\end{align}\]</span></p>
<p>Note that a <strong>Bernoulli distribution</strong> is characterized by a single trial (n=1) and a <strong>Binomial distribution</strong> is characterized by multiple trials (n &gt; 1).</p>
<p>The <strong>PMF</strong> - probability mass function - for a <strong>discrete Binomial distribution</strong> is expressed as:</p>
<p><span class="math display">\[\begin{align}
f(x; n, \rho)  = P(X = x|n,\rho) = \binom{n}{x}  \rho^xq^{n-x} = \binom{n}{x}  \rho^x(1-\rho)^{n-x}
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li><strong>n</strong> is the number of independent trials (independent observations)</li>
<li><span class="math inline">\(\rho\)</span> is the probability of a state, e.g.Â probability of a coin landing on heads.</li>
<li><strong>X</strong> is data (random variable), where X <span class="math inline">\(\in\)</span> {0,1}.</li>
</ul>
<p>and:</p>
<p><span class="math display">\[
\binom{n}{x} = \frac{n!}{(n-x)!x!}\ \ \ \ \text{(this is a constant)}
\]</span></p>
<p>and:</p>
<p><span class="math display">\[
\rho^x(1-\rho)^{n-x}\ \ \ \ \ \text{(this describes the shape of curve)}
\]</span></p>
<p>The <strong>PMF</strong> is read as <strong>a function of random variable x with n and <span class="math inline">\(\rho\)</span> parameters.</strong></p>
<p>The <strong>CMF</strong> - cumulative mass function - for a <strong>discrete Binomial distribution</strong> is expressed as:</p>
<p><span class="math display">\[\begin{align}
\mathcal{F}(x; n, \rho) = P( X \le x| n, \rho) = \sum_{k=0}^x \binom{n}{k}  \rho^k(1-\rho)^{n-k}
\end{align}\]</span></p>
<p>Because <strong>Binomial distribution</strong> is discrete, we use summation instead of integration.</p>
<p>Note that we use the lowercase <strong>f</strong> function to indicate PDF/PMF for the rest of this section, and we use the uppercase <strong>F</strong> function to indicate CDF/CMF.</p>
<p>Now to illustrate, suppose we toss a coin ten times. Each time we toss, we record the outcome. In the end, we will be able to record ten outcomes of mixed tails and heads. However, there are two possibilities for each outcome: either a T or an H. Therefore, if we toss a coin ten times, the possible outcome would end up 2^10 = 1024 possible outcomes. That are many possibilities.</p>
<p>Let us try to visualize some of the combinations and see what the possible outcome of flipping an H is:</p>
<ul>
<li>Possibility that all ten flips end up to be Tails = 1 count out of 1024 possibilities</li>
</ul>
<p><span class="math display">\[
T T T T T T T T T T 
\]</span></p>
<ul>
<li>Possibility that all 10 flips end up to be Heads = 1 count out of 1024 possibilities</li>
</ul>
<p><span class="math display">\[
H H H H H H H H H H
\]</span></p>
<ul>
<li>Possibility that all 10 flips end up to be Tails except the first = 1 count / 1024</li>
</ul>
<p><span class="math display">\[
H T T T T T T T T T
\]</span></p>
<ul>
<li>Possibility that all 10 flips end up to be Tails except the second = 1 count / 1024</li>
</ul>
<p><span class="math display">\[
T H T T T T T T T T
\]</span></p>
<p>If we continue this, we will have to do it for all 1024 possibilities. Let us use combination formula:</p>

<p><span class="math display">\[\begin{align*}
P(Outcome = \ \ 0\ H) {}&amp; = nCr / 1024 = {}_{10}C_0 / 1024 = 1 / 1024\\
P(Outcome = \ \ 1\ H) &amp;= nCr / 1024 = {}_{10}C_1 / 1024 = 10 / 1024\\
P(Outcome = \ \ 2\ H) &amp;= nCr / 1024 = {}_{10}C_2 / 1024 = 45 / 1024\\
P(Outcome = \ \ 3\ H) &amp;= nCr / 1024 = {}_{10}C_3 / 1024 = 120 / 1024\\
P(Outcome = \ \ 4\ H) &amp;= nCr / 1024 = {}_{10}C_4 / 1024 = 210 / 1024\\
P(Outcome = \ \ 5\ H) &amp;= nCr / 1024 = {}_{10}C_5 / 1024 = 252 / 1024\\
P(Outcome = \ \ 6\ H) &amp;= nCr / 1024 = {}_{10}C_6 / 1024 = 210 / 1024\\
P(Outcome = \ \ 7\ H) &amp;= nCr / 1024 = {}_{10}C_7 / 1024 = 120 / 1024\\
P(Outcome = \ \ 8\ H) &amp;= nCr / 1024 = {}_{10}C_8 / 1024 = 45 / 1024\\
P(Outcome = \ \ 9\ H) &amp;= nCr / 1024 = {}_{10}C_9 / 1024 = 10 / 1024\\
P(Outcome = 10\ H) &amp;= nCr / 1024 = {}_{10}C_{10} / 1024 = 1 / 1024
\end{align*}\]</span>
</p>
<p>Now let us plot the distribution of these probable outcomes â¦</p>

<div class="sourceCode" id="cb220"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb220-1" data-line-number="1">random_x &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">10</span>,<span class="dv">45</span>,<span class="dv">120</span>,<span class="dv">210</span>,<span class="dv">252</span>,<span class="dv">210</span>,<span class="dv">120</span>,<span class="dv">45</span>,<span class="dv">10</span>,<span class="dv">1</span>) <span class="op">/</span><span class="st"> </span><span class="dv">1024</span></a>
<a class="sourceLine" id="cb220-2" data-line-number="2"><span class="kw">names</span>(random_x) &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">10</span>,<span class="dv">1</span>)</a>
<a class="sourceLine" id="cb220-3" data-line-number="3"><span class="kw">barplot</span>(random_x, <span class="dt">density=</span>T, <span class="dt">col=</span><span class="dv">2</span>, <span class="dt">xlab=</span><span class="st">&quot;H Outcome&quot;</span>,</a>
<a class="sourceLine" id="cb220-4" data-line-number="4">        <span class="dt">ylim=</span><span class="kw">range</span>(<span class="dv">0</span>, <span class="fl">0.25</span>), <span class="dt">xlim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="dv">12</span>),</a>
<a class="sourceLine" id="cb220-5" data-line-number="5">        <span class="dt">ylab=</span><span class="st">&quot;Probability&quot;</span>, <span class="dt">main=</span><span class="st">&quot;Flip A Fair Coin&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:statistics3"></span>
<img src="DS_files/figure-html/statistics3-1.png" alt="Statistics" width="70%" />
<p class="caption">
Figure 5.12: Statistics
</p>
</div>

<p>We can derive the same probability of a binomial case using the <strong>dbinom(.)</strong> function. For example, we can write the probability of getting two heads successfully out of 10 trials given a 0.20 probability threshold as:</p>
<div class="sourceCode" id="cb221"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb221-1" data-line-number="1"><span class="kw">dbinom</span>(<span class="dt">x =</span> <span class="dv">2</span>, <span class="dt">size=</span><span class="dv">10</span>, <span class="dt">prob=</span><span class="fl">0.20</span>)</a></code></pre></div>
<pre><code>## [1] 0.3019899</code></pre>
<p>For the expected value and variance of <strong>Binomial distribution</strong>, we use the following equations:</p>
<p><strong>Expected value:</strong></p>
<p><span class="math display">\[\begin{align}
\mathbb{E}(X) {}&amp;= \sum_{x=0}^{n} x(fx) = x \binom{n}{x}  p^n(1-p)^{n-x}  = np\\
\mathbb{E}(X^2) &amp;= \sum_{x=0}^{n} x^2(fx) = x^2 \binom{n}{x}  p^n(1-p)^{n-x}  
= n(n-1)p^2 + np
\end{align}\]</span></p>
<p><strong>Variance:</strong></p>
<p><span class="math display">\[\begin{align}
Var(X) = \mathbb{E}(X^2) - \mathbb{E}(X)^2 = 
\left[ n(n-1)p^2 + np \right] - (np)^2 = np(1-p) = npq
\end{align}\]</span></p>
</div>
<div id="multinomial-distribution" class="section level3 hasAnchor">
<h3><span class="header-section-number">5.9.3</span> Multinomial distribution <a href="numericalprobability.html#multinomial-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A <strong>Multinomial distribution</strong>, also called <strong>Categorical distribution</strong>, models a <strong>discrete categorical</strong> probability distribution of a random variable taking an outcome with <strong>multiple categories</strong> which can be 0 to K states, e.g., a die has six possible states (or outcomes), and is written as:</p>
<p><span class="math display">\[\begin{align}
X \sim Multi(n,\rho)
\end{align}\]</span></p>
<p>The <strong>PMF</strong> for a <strong>Multinomial distribution</strong> is expressed as:</p>
<p><span class="math display">\[\begin{align}
f(x; n, \rho) = P(X= x|n, \rho) {}&amp;= 
\frac{n!}{x_1! \times ... \times x_k!} 
 \rho_1^{x_1} \times ... \times \rho_k^{x_k}\\
&amp;= \frac{n!}{\prod_{i=1}^k x_i!} \prod_{i=1}^k \rho_i^{x_i}
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li><strong>n</strong> is the number of independent trials (independent observations)</li>
<li><span class="math inline">\(\rho\)</span> is the probability of a state, e.g., the probability of a die landing on 4.</li>
<li><span class="math inline">\(k\)</span> is the number of possible states (or outcomes), e.g., a die has six sides.</li>
<li><strong>X</strong> is a random variable with list of occurrences, e.g.Â X = ( <span class="math inline">\(x_1, x_2,..., x_k\)</span> )</li>
<li><span class="math inline">\(x_i\)</span> is the number of occurrences of a state (i); e.g. âx_1 = 3â means there are three occurrences of drawing the first marble from an urn (assuming each marble is labeled with a number).</li>
<li><span class="math inline">\(\rho_i\)</span> is the probability of state (i), e.g., <span class="math inline">\(\rho_4 = 0.60\)</span> means a 60% probability of drawing the fourth marble from an urn (assuming each marble is labeled with a number).</li>
</ul>
<p>and:</p>
<p><span class="math display">\[
\frac{n!}{\prod_{i=1}^k x_i!}\ \ \ \ \  \ \text{( the number of possible arrangements)}
\]</span></p>
<p>Here are a few examples that allow a stochastic process to generate <strong>multinomial distribution</strong>:</p>
<ul>
<li>Probability of getting number 6 after rolling a 6-sided dice.</li>
<li>Probability of drawing a red marble out of 6 marbles from an urn.</li>
<li>Probability of drawing a blood type of âABâ out of four blood types (e.g., O, A, B, AB) from a list of patients.</li>
</ul>
<p>To illustrate, let us use a typical example. Suppose we draw five marbles - with replacement - from an urn with four marbles - one red marble, two green marbles, and one blue marble. Let us calculate the probability of selecting two red and three green marbles.</p>
<p>We have the following:</p>
<ul>
<li><strong>n</strong> = 5 draws (trials)</li>
<li><strong>k</strong> = 3 states (red, green, blue)</li>
<li><strong>X</strong> = (2 red marbles, 3 green marbles, 0 blue marbles); <span class="math inline">\(x_1\)</span> = 2, <span class="math inline">\(x_2\)</span> = 3, <span class="math inline">\(x_3\)</span> = 0</li>
<li><span class="math inline">\(\rho\)</span> = probabilities: (<span class="math inline">\(1/4\)</span> red, <span class="math inline">\(2/4\)</span> green, <span class="math inline">\(1/4\)</span> blue); <span class="math inline">\(\rho_1\)</span> = 0.25, <span class="math inline">\(\rho_2\)</span> = 0.50, <span class="math inline">\(\rho_3\)</span> = 0.25</li>
</ul>
<p>Using the <strong>Multinomial distribution</strong> formula:</p>
<p><span class="math display">\[
f(x; n,p) = P(X= x|n,\rho) = \frac{5!}{2! \times 3! \times 0!} \times \left( 0.25^2 \times 0.50^3 \times 0.25^0  \right) 
\]</span>
let us implement in R code:</p>
<div class="sourceCode" id="cb223"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb223-1" data-line-number="1">multinomial.pdf &lt;-<span class="st"> </span><span class="cf">function</span>(x, n, p) {</a>
<a class="sourceLine" id="cb223-2" data-line-number="2">  ( <span class="kw">factorial</span>(n) <span class="op">/</span><span class="st"> </span><span class="kw">prod</span>(<span class="kw">factorial</span>(x)) ) <span class="op">*</span><span class="st"> </span><span class="kw">prod</span> ( p<span class="op">^</span>x )</a>
<a class="sourceLine" id="cb223-3" data-line-number="3">}</a>
<a class="sourceLine" id="cb223-4" data-line-number="4">n =<span class="st"> </span><span class="dv">5</span></a>
<a class="sourceLine" id="cb223-5" data-line-number="5">x =<span class="st"> </span><span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">0</span>)</a>
<a class="sourceLine" id="cb223-6" data-line-number="6">p =<span class="st"> </span><span class="kw">c</span>(<span class="fl">0.25</span>, <span class="fl">0.50</span>, <span class="fl">0.25</span>)</a>
<a class="sourceLine" id="cb223-7" data-line-number="7"><span class="kw">c</span>(<span class="st">&quot;probability&quot;</span>=<span class="kw">multinomial.pdf</span>(x, n, p))</a></code></pre></div>
<pre><code>## probability 
##    0.078125</code></pre>
<p>We can validate using a built-in R function called <strong>dmultinom()</strong>.</p>
<div class="sourceCode" id="cb225"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb225-1" data-line-number="1"><span class="kw">dmultinom</span>(x, <span class="dt">size=</span>n, <span class="dt">prob=</span>p)</a></code></pre></div>
<pre><code>## [1] 0.078125</code></pre>
</div>
<div id="geometric-distribution" class="section level3 hasAnchor">
<h3><span class="header-section-number">5.9.4</span> Geometric distribution <a href="numericalprobability.html#geometric-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Geometric distribution</strong> models a <strong>discrete distribution</strong> of a random variable <strong>X</strong>, considering the number of failed <strong>Bernoulli</strong> attempts prior to a successful one. It is written as:</p>
<p><span class="math display">\[\begin{align}
X \sim Geo(\rho)
\end{align}\]</span></p>
<p>The <strong>PMF</strong> for a <strong>Geometric distribution</strong> is expressed as:</p>
<p><span class="math display">\[\begin{align}
f(x; \rho) = P(X=x|\rho) = q^{(x-1)}\rho = \rho(1-\rho)^{x-1}
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(\rho\)</span> is the probability of success</li>
<li>q is the probability of failure (1-p)</li>
</ul>
<p>The <strong>CMF</strong> for a <strong>Geometric distribution</strong> is expressed as:</p>
<p><span class="math display">\[\begin{align}
\mathcal{F}(x; \rho) = P(X \le x|\rho) = 
\begin{cases}
1 - (1-\rho)^{x} &amp; x \ge 0\\
0 &amp; x &lt; 0
\end{cases} \label{eqn:eqnnumber18}
\end{align}\]</span></p>
<p>Note that other literature may have the following equations for geometric <strong>PDF</strong> and <strong>CDF</strong> respectively instead:</p>
<p><span class="math display">\[\begin{align}
f(x; \rho)  = \rho(1-\rho)^{x}\ \ \ \ \ \ \ \ \
\mathcal{F}(x; \rho) = 1 - (1-\rho)^{x+1}
\end{align}\]</span></p>
<p>To illustrate, in tossing a coin, compute for the probability that we miss the first four attempts before a successful fifth attempt, granting the probability of a successful attempt is 0.60.</p>
<p><span class="math display">\[
P(X = 5) = P(X \le 5)^{4}P(X=5) = (0.40)^3(0.60) = 0.01536
\]</span></p>
<p>where:</p>
<p><span class="math display">\[\begin{align*}
{}&amp;P(X \le 5)^4 \ \ \ \leftarrow\ \text{first four failed attempts}\\
&amp;P(X = 5) \ \ \ \leftarrow\ \text{fifth successful attempt}\\
\end{align*}\]</span></p>
<p>The <strong>expected value</strong> and <strong>variance</strong> is written respectively as:</p>
<p><span class="math display">\[\begin{align}
\mathbb{E}(X) = 1/\rho\ \ \ \ \ \ \ \ \ \ \ Var(X) = \frac{q}{\rho^2}
\end{align}\]</span></p>
</div>
<div id="beta-distribution" class="section level3 hasAnchor">
<h3><span class="header-section-number">5.9.5</span> Beta distribution <a href="numericalprobability.html#beta-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Beta distribution</strong> models a <strong>continuous distribution</strong> which is a special kind of <strong>Binomial distribution</strong> written as:</p>
<p><span class="math display">\[\begin{align}
X \sim Beta(\alpha, \beta)
\end{align}\]</span></p>
<p>with the following <strong>Beta PDF</strong> where <strong>support</strong> is <span class="math inline">\(0 \le x \le 1\)</span>:</p>
<p><span class="math display">\[\begin{align}
f(x;\alpha,\beta) = P(X = x|\alpha,\beta)  = \frac{1}{\mathcal{B}(\alpha,\beta)} 
x ^{\alpha-1}(1-x)^{\beta - 1} 
\end{align}\]</span></p>
<p>where <strong>Beta function</strong> has the following:</p>
<p><span class="math display">\[\begin{align}
\mathcal{B}(\alpha,\beta) {}&amp;= \int_0^1 x^{\alpha-1}(1-x)^{\beta-1}dx \\
\mathcal{B}(\alpha,\beta) &amp;= \frac{\Gamma(\alpha)\Gamma(\beta)  }{\Gamma(\alpha + \beta) } 
\end{align}\]</span></p>
<p>and where the <strong>Gamma function</strong> is as follows:</p>
<p><span class="math display">\[\begin{align}
\Gamma(n) = (n-1)!\ \ \ \ \ \ \ \ \Gamma(n+1) = n\Gamma(n) = n(n-1)!
\end{align}\]</span></p>
<p>On the other hand, the <strong>CDF</strong> of <strong>Beta distribution</strong> is expressed as:</p>
<p><span class="math display">\[\begin{align}
f(x;\alpha,\beta) {}&amp;= P(X \le x|\alpha,\beta) = \frac{1}{\mathcal{B}(\alpha,\beta)} 
\int_0^x x^{\alpha-1}(1-x)^{\beta - 1} dx\\
\nonumber \\
&amp;= I_x(\alpha,\beta) = \frac{B_x(x; \alpha, \beta)}{\mathcal{B}(\alpha,\beta)}.
\end{align}\]</span></p>
<p>The <strong>CDF</strong> is a <strong>regularized beta function</strong> as introduced in the <strong>Special functions</strong> section.</p>
<p>Because <strong>Beta distribution</strong> is continuous, we use integration instead of summation (such as <strong>CMF</strong> for <strong>Binomial distribution</strong>).</p>
<p>Here is a naive implementation of <strong>PDF</strong> and <strong>CDF</strong> for <strong>Beta distribution</strong> with the different shapes, <span class="math inline">\(\{\alpha, \beta\}\)</span> (See also <strong>T-distribution</strong> in Chapter <strong>6</strong> (<strong>Statistical Computation</strong>) for an alternative implementation of <span class="math inline">\(\mathbf{Ix(\alpha,\beta)}\)</span>):</p>

<div class="sourceCode" id="cb227"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb227-1" data-line-number="1">Gamma &lt;-<span class="st"> </span><span class="cf">function</span>(n) { <span class="kw">factorial</span>(n<span class="dv">-1</span>)}</a>
<a class="sourceLine" id="cb227-2" data-line-number="2">B &lt;-<span class="st"> </span><span class="cf">function</span>(alpha, beta) { </a>
<a class="sourceLine" id="cb227-3" data-line-number="3">    <span class="co"># also can use built-in, beta(a,b)</span></a>
<a class="sourceLine" id="cb227-4" data-line-number="4">    (<span class="kw">Gamma</span>(alpha) <span class="op">*</span><span class="st"> </span><span class="kw">Gamma</span>(beta)) <span class="op">/</span><span class="st">  </span><span class="kw">Gamma</span>(alpha <span class="op">+</span><span class="st"> </span>beta )</a>
<a class="sourceLine" id="cb227-5" data-line-number="5">}</a>
<a class="sourceLine" id="cb227-6" data-line-number="6">incomplete_beta &lt;-<span class="st"> </span><span class="cf">function</span>(x,a,b) { </a>
<a class="sourceLine" id="cb227-7" data-line-number="7">    <span class="kw">pbeta</span>(x,a,b) <span class="op">*</span><span class="st"> </span><span class="kw">B</span>(a,b) </a>
<a class="sourceLine" id="cb227-8" data-line-number="8">}</a>
<a class="sourceLine" id="cb227-9" data-line-number="9">Ix &lt;-<span class="cf">function</span>(x, a, b) { <span class="co">#regulrized beta function, Ix(x; a, b)</span></a>
<a class="sourceLine" id="cb227-10" data-line-number="10">   <span class="kw">incomplete_beta</span>(x,a,b) <span class="op">/</span><span class="st"> </span><span class="kw">B</span>(a,b)</a>
<a class="sourceLine" id="cb227-11" data-line-number="11">}</a>
<a class="sourceLine" id="cb227-12" data-line-number="12">beta_pdf &lt;-<span class="st"> </span><span class="cf">function</span>(x, alpha, beta ) {</a>
<a class="sourceLine" id="cb227-13" data-line-number="13">   <span class="dv">1</span><span class="op">/</span><span class="kw">B</span>(alpha,beta) <span class="op">*</span><span class="st"> </span>( x<span class="op">^</span>(alpha<span class="dv">-1</span>) <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span><span class="op">-</span>x)<span class="op">^</span>(beta<span class="dv">-1</span>) )</a>
<a class="sourceLine" id="cb227-14" data-line-number="14">}</a>
<a class="sourceLine" id="cb227-15" data-line-number="15">beta_cdf &lt;-<span class="st"> </span><span class="cf">function</span>(x, alpha, beta ) {</a>
<a class="sourceLine" id="cb227-16" data-line-number="16">   <span class="kw">Ix</span>(x, alpha, beta)</a>
<a class="sourceLine" id="cb227-17" data-line-number="17">}</a>
<a class="sourceLine" id="cb227-18" data-line-number="18"></a>
<a class="sourceLine" id="cb227-19" data-line-number="19"><span class="co"># probability density</span></a>
<a class="sourceLine" id="cb227-20" data-line-number="20"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">1</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="dv">3</span>), </a>
<a class="sourceLine" id="cb227-21" data-line-number="21">     <span class="dt">xlab=</span><span class="st">&quot;support&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;probability density&quot;</span>,</a>
<a class="sourceLine" id="cb227-22" data-line-number="22">     <span class="dt">main=</span><span class="st">&quot;PDF (Beta Distribution)&quot;</span>,  <span class="dt">frame=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb227-23" data-line-number="23"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb227-24" data-line-number="24"><span class="kw">abline</span>(<span class="dt">h=</span><span class="dv">0</span>, <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb227-25" data-line-number="25">x =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>, <span class="dt">length.out=</span><span class="dv">20</span>)</a>
<a class="sourceLine" id="cb227-26" data-line-number="26"><span class="kw">curve</span>(<span class="kw">beta_pdf</span>(x, <span class="dt">alpha=</span><span class="dv">1</span>, <span class="dt">beta=</span><span class="dv">4</span>), <span class="dt">col=</span><span class="st">&quot;purple&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb227-27" data-line-number="27"><span class="kw">curve</span>(<span class="kw">beta_pdf</span>(x, <span class="dt">alpha=</span><span class="dv">2</span>, <span class="dt">beta=</span><span class="dv">2</span>), <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb227-28" data-line-number="28"><span class="kw">curve</span>(<span class="kw">beta_pdf</span>(x, <span class="dt">alpha=</span><span class="dv">2</span>, <span class="dt">beta=</span><span class="dv">4</span>), <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb227-29" data-line-number="29"><span class="kw">curve</span>(<span class="kw">beta_pdf</span>(x, <span class="dt">alpha=</span><span class="dv">5</span>, <span class="dt">beta=</span><span class="dv">1</span>), <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb227-30" data-line-number="30"><span class="kw">curve</span>(<span class="kw">beta_pdf</span>(x, <span class="dt">alpha=</span><span class="dv">5</span>, <span class="dt">beta=</span><span class="dv">3</span>), <span class="dt">col=</span><span class="st">&quot;brown&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:betadist1"></span>
<img src="DS_files/figure-html/betadist1-1.png" alt="Beta Distribution (Probability Density)" width="70%" />
<p class="caption">
Figure 5.13: Beta Distribution (Probability Density)
</p>
</div>
<div class="sourceCode" id="cb228"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb228-1" data-line-number="1"><span class="co"># cumulative density</span></a>
<a class="sourceLine" id="cb228-2" data-line-number="2"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">1</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="dv">1</span>), </a>
<a class="sourceLine" id="cb228-3" data-line-number="3">     <span class="dt">xlab=</span><span class="st">&quot;support&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;cumulative probability&quot;</span>,</a>
<a class="sourceLine" id="cb228-4" data-line-number="4">     <span class="dt">main=</span><span class="st">&quot;CDF (Beta Distribution)&quot;</span>,  <span class="dt">frame=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb228-5" data-line-number="5"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb228-6" data-line-number="6"><span class="kw">abline</span>(<span class="dt">h=</span><span class="dv">0</span>, <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb228-7" data-line-number="7">x =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>, <span class="dt">length.out=</span><span class="dv">20</span>)</a>
<a class="sourceLine" id="cb228-8" data-line-number="8"><span class="kw">curve</span>(<span class="kw">beta_cdf</span>(x, <span class="dt">alpha=</span><span class="dv">1</span>, <span class="dt">beta=</span><span class="dv">4</span>), <span class="dt">col=</span><span class="st">&quot;purple&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb228-9" data-line-number="9"><span class="kw">curve</span>(<span class="kw">beta_cdf</span>(x, <span class="dt">alpha=</span><span class="dv">2</span>, <span class="dt">beta=</span><span class="dv">2</span>), <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb228-10" data-line-number="10"><span class="kw">curve</span>(<span class="kw">beta_cdf</span>(x, <span class="dt">alpha=</span><span class="dv">2</span>, <span class="dt">beta=</span><span class="dv">4</span>), <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb228-11" data-line-number="11"><span class="kw">curve</span>(<span class="kw">beta_cdf</span>(x, <span class="dt">alpha=</span><span class="dv">5</span>, <span class="dt">beta=</span><span class="dv">1</span>), <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb228-12" data-line-number="12"><span class="kw">curve</span>(<span class="kw">beta_cdf</span>(x, <span class="dt">alpha=</span><span class="dv">5</span>, <span class="dt">beta=</span><span class="dv">3</span>), <span class="dt">col=</span><span class="st">&quot;brown&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:betadist2"></span>
<img src="DS_files/figure-html/betadist2-1.png" alt="Beta Distribution (Cumulative Density)" width="70%" />
<p class="caption">
Figure 5.14: Beta Distribution (Cumulative Density)
</p>
</div>

<p>Let us save further discussion of <strong>Beta distribution</strong> until we get to the <strong>Bayesian Computation</strong> to cover <strong>Conjugate and Joint distributions</strong> in which one distribution is chained to another.</p>
<p><span class="math display">\[\begin{align}
X_{Pr} \sim Beta(\alpha, \beta)\ \ \ \rightarrow \ \ \ \ \ X \sim Bin(n, X_{Pr})
\end{align}\]</span></p>
<p>Also, we leave readers to investigate on <strong>Pert</strong> distribution which requires a minimum and a maximum parameter for <strong>Beta distribution</strong>:</p>
<p><span class="math display">\[\begin{align}
X \sim Beta(min, max, \alpha, \beta) \equiv Pert(min, max, \alpha, \beta)
\end{align}\]</span></p>
</div>
<div id="dirichlet-distribution" class="section level3 hasAnchor">
<h3><span class="header-section-number">5.9.6</span> Dirichlet distribution <a href="numericalprobability.html#dirichlet-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Dirichlet distribution</strong> models a <strong>continuous distribution</strong> and is a special kind of <strong>Multinomial distribution</strong> written as:</p>
<p><span class="math display">\[\begin{align}
X_{Pr} \sim Dir(\alpha)
\end{align}\]</span></p>
<p>Like dealing with <strong>Beta distribution</strong>, which is related to <strong>Binomial distribution</strong>, the <strong>Dirichlet distribution</strong> is related to <strong>Multinomial distribution</strong>.</p>
<p>The <strong>PDF</strong> for <strong>Dirichlet distribution</strong> with <strong>support</strong> <span class="math inline">\(\{x_1,..., x_k\}\)</span> and <span class="math inline">\(0 \le x_i \le 1\)</span> and <span class="math inline">\(\sum(X) = 1\)</span> is expressed as:</p>
<p><span class="math display">\[\begin{align}
f(X_k;\alpha_k) = P(x_1,...,x_k|\alpha_1, ... \alpha_k)  = \frac{1}{\mathcal{B}(\alpha)}
\prod_{i=1}^k {x_i}^{\alpha_i-1} 
\end{align}\]</span></p>
<p>where the <strong>Beta function</strong>, <span class="math inline">\(\mathbf{\mathcal{B}(\vec{\alpha})}\)</span>, is equivalent to that of <strong>Beta distribution</strong> :</p>
<p><span class="math display">\[\begin{align}
\mathcal{B}(\alpha) &amp;= \frac{\prod_{i=1}^k \Gamma(\alpha_i)} {\Gamma(\sum_{i=1}^k \alpha_i)}
\ \ \ \ \ \ \leftarrow\ \ \ \ \ \ \ \ 
\mathcal{B}(\alpha_1, \alpha_2) = \frac{\Gamma(\alpha_1)\Gamma(\alpha_2)}{\Gamma(\alpha_1 + \alpha_2)}
\ \ \ \ \text{if k=2}
\end{align}\]</span></p>
<p>and where the <strong>Gamma function</strong> is as follows:</p>
<p><span class="math display">\[\begin{align}
\Gamma(n) = (n-1)!\ \ \ \ \ \ \ \ \Gamma(n+1) = n\Gamma(n) = n(n-1)!
\end{align}\]</span></p>
<p>Note that <strong>Dirichlet distribution</strong> is a generalization of <strong>Beta distribution</strong>.</p>
<p>To illustrate, we can continue to use <strong>Dirichlet PDF</strong> against <strong>Binomial distribution</strong> where <span class="math inline">\(\{\alpha,\beta\} = \{ \alpha, \alpha \} = \{\vec{ \alpha} \}\)</span></p>
<p>Figure <a href="numericalprobability.html#fig:betadist1">5.13</a> illustrates graphs of the different shapes, <span class="math inline">\(\{\vec{ \alpha} \}\)</span>, of <strong>Dirichlet distribution</strong>.</p>

<div class="sourceCode" id="cb229"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb229-1" data-line-number="1">Gamma &lt;-<span class="st"> </span><span class="cf">function</span>(n) { <span class="kw">factorial</span>(n<span class="dv">-1</span>)}</a>
<a class="sourceLine" id="cb229-2" data-line-number="2">dirichlet_B &lt;-<span class="st"> </span><span class="cf">function</span>(alpha) { </a>
<a class="sourceLine" id="cb229-3" data-line-number="3">    <span class="kw">prod</span>(<span class="kw">Gamma</span>(alpha)) <span class="op">/</span><span class="st"> </span><span class="kw">Gamma</span>( <span class="kw">sum</span> (alpha))  </a>
<a class="sourceLine" id="cb229-4" data-line-number="4">}</a>
<a class="sourceLine" id="cb229-5" data-line-number="5">dirichlet_pdf &lt;-<span class="st"> </span><span class="cf">function</span>(x, alpha) { <span class="co"># naive implementation</span></a>
<a class="sourceLine" id="cb229-6" data-line-number="6">  <span class="co"># using binomial distribution, e.g. x (%success), 1-x (%fail)</span></a>
<a class="sourceLine" id="cb229-7" data-line-number="7">   <span class="dv">1</span><span class="op">/</span><span class="kw">dirichlet_B</span>(alpha) <span class="op">*</span><span class="st"> </span>( x<span class="op">^</span>(alpha[<span class="dv">1</span>]<span class="op">-</span><span class="dv">1</span>) <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span><span class="op">-</span>x)<span class="op">^</span>(alpha[<span class="dv">2</span>]<span class="op">-</span><span class="dv">1</span>) )</a>
<a class="sourceLine" id="cb229-8" data-line-number="8">}</a>
<a class="sourceLine" id="cb229-9" data-line-number="9"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">1</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="dv">3</span>), </a>
<a class="sourceLine" id="cb229-10" data-line-number="10">     <span class="dt">xlab=</span><span class="st">&quot;support&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;probability density&quot;</span>,</a>
<a class="sourceLine" id="cb229-11" data-line-number="11">     <span class="dt">main=</span><span class="st">&quot;PDF (Dirichlet Distribution)&quot;</span>,  <span class="dt">frame=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb229-12" data-line-number="12"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb229-13" data-line-number="13"><span class="kw">abline</span>(<span class="dt">h=</span><span class="dv">0</span>, <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb229-14" data-line-number="14">x =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>, <span class="dt">length.out=</span><span class="dv">20</span>)</a>
<a class="sourceLine" id="cb229-15" data-line-number="15"><span class="kw">curve</span>(<span class="kw">dirichlet_pdf</span>(x, <span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">4</span>)), <span class="dt">col=</span><span class="st">&quot;purple&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb229-16" data-line-number="16"><span class="kw">curve</span>(<span class="kw">dirichlet_pdf</span>(x, <span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>)), <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb229-17" data-line-number="17"><span class="kw">curve</span>(<span class="kw">dirichlet_pdf</span>(x, <span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">4</span>)), <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb229-18" data-line-number="18"><span class="kw">curve</span>(<span class="kw">dirichlet_pdf</span>(x, <span class="kw">c</span>(<span class="dv">5</span>,<span class="dv">1</span>)), <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb229-19" data-line-number="19"><span class="kw">curve</span>(<span class="kw">dirichlet_pdf</span>(x, <span class="kw">c</span>(<span class="dv">5</span>,<span class="dv">3</span>)), <span class="dt">col=</span><span class="st">&quot;brown&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:dirichletdist"></span>
<img src="DS_files/figure-html/dirichletdist-1.png" alt="Dirichlet Distribution" width="70%" />
<p class="caption">
Figure 5.15: Dirichlet Distribution
</p>
</div>

<p>Similarly, we further cover <strong>Dirichlet distribution</strong> in Chapter <strong>7</strong> (<strong>Bayesian Computation I</strong>) when discussing <strong>Conjugate distribution</strong>. Also, the idea is about one distribution in which the parameters are based on the outcome of another distribution.</p>
<p><span class="math display">\[\begin{align}
X \sim Mult(n, \rho)\ \ \ \leftarrow \ \ \ \  \  \rho \sim Dir(\alpha)
\end{align}\]</span></p>
</div>
<div id="exponential-distribution" class="section level3 hasAnchor">
<h3><span class="header-section-number">5.9.7</span> Exponential distribution <a href="numericalprobability.html#exponential-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Exponential distribution</strong> models a <strong>continuous distribution</strong> of a random variable <strong>X</strong>, taking into account the <strong>waiting (or elapsed) time</strong> between events. It is written as:</p>
<p><span class="math display">\[\begin{align}
X \sim Expo(\lambda)
\end{align}\]</span></p>
<p>The <strong>PDF</strong> of an <strong>Exponential distribution</strong> has the <strong>support</strong> condition:</p>
<p><span class="math display">\[\begin{align}
f(x;\lambda) = \begin{cases} \lambda e^{-\lambda x} &amp; x \ge 0\\ 0 &amp; x &lt; 0 \end{cases}. \label{eqn:eqnnumber19}
\end{align}\]</span></p>
<p>Therefore, with <strong>support</strong> <span class="math inline">\(0 \le x \le \infty\)</span>, we get:</p>
<p><span class="math display">\[\begin{align}
 P(X = x|\lambda) =  \lambda e^{-\lambda x}
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(\lambda\)</span> is a shape parameter describing event rate, <span class="math inline">\(\lambda = 1/t\)</span>, e.g.Â 1 event per avg. time.</li>
<li>t is the average wait time (or average elapsed time prior to an event occurring)</li>
</ul>
<p>and the <strong>CDF</strong> of an <strong>Exponential distribution</strong> is expressed as:</p>
<p><span class="math display">\[\begin{align}
\mathcal{F}(x; \lambda) = P(X \le x|\lambda) =  1 - e^{-\lambda x}
\end{align}\]</span></p>
<p>Exponential growth and decay are two typical events in which we can use <strong>Exponential distribution</strong> to measure the expected time. To illustrate, here are three examples of events in which we can form an <strong>Exponential distribution</strong>:</p>
<ul>
<li>Suppose we plant a pumpkin seed about an inch into fertile soil. Then, we compute the time it takes for the seed to germinate. Hint: does a pumpkin seed germinate in a week?</li>
<li>Suppose we procure a piece of enterprise-grade computer equipment. Then, we compute the time it takes before the equipment starts to fail. Hint: does it take three to five years for equipment support to expire?</li>
<li>Suppose we arrive at a gas station but have to wait for our turn to fill up gas. Then, we compute the time it takes to wait.</li>
</ul>
<p>Here, <span class="math inline">\(\lambda\)</span> (lambda) is the expected time for events to occur. It answers the question: <strong>How long?</strong></p>
<p>Below is a naive implementation of <strong>PDF</strong> and <strong>CDF</strong> of <strong>Exponential distribution</strong> in R code. Here we use <span class="math inline">\(\lambda = 0.5\)</span> and <span class="math inline">\(x = 4\)</span> to show a larger area. See Figure <a href="numericalprobability.html#fig:expdist2">5.17</a>.</p>

<div class="sourceCode" id="cb230"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb230-1" data-line-number="1">exp_pdf &lt;-<span class="st"> </span><span class="cf">function</span>(x, lambda ) {</a>
<a class="sourceLine" id="cb230-2" data-line-number="2">    lambda <span class="op">*</span><span class="st"> </span><span class="kw">exp</span>(<span class="op">-</span>lambda <span class="op">*</span><span class="st"> </span>x)</a>
<a class="sourceLine" id="cb230-3" data-line-number="3">}</a>
<a class="sourceLine" id="cb230-4" data-line-number="4">exp_cdf &lt;-<span class="st"> </span><span class="cf">function</span>(x, lambda) {</a>
<a class="sourceLine" id="cb230-5" data-line-number="5">    <span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">exp</span>(<span class="op">-</span>lambda <span class="op">*</span><span class="st"> </span>x)</a>
<a class="sourceLine" id="cb230-6" data-line-number="6">}</a>
<a class="sourceLine" id="cb230-7" data-line-number="7">exp_area &lt;-<span class="st"> </span><span class="cf">function</span>(x, lambda) {</a>
<a class="sourceLine" id="cb230-8" data-line-number="8">    a =<span class="st"> </span><span class="dv">0</span>; b =<span class="st"> </span>x  <span class="co"># boundaries</span></a>
<a class="sourceLine" id="cb230-9" data-line-number="9">    area =<span class="st"> </span><span class="kw">seq</span>(a, b, <span class="dt">length.out=</span><span class="dv">50</span>) <span class="co"># area</span></a>
<a class="sourceLine" id="cb230-10" data-line-number="10">    x =<span class="st"> </span><span class="kw">c</span>(a, area , b)</a>
<a class="sourceLine" id="cb230-11" data-line-number="11">    y =<span class="st"> </span><span class="kw">c</span>(<span class="dv">0</span>, <span class="kw">exp_pdf</span>(area, lambda), <span class="dv">0</span>)</a>
<a class="sourceLine" id="cb230-12" data-line-number="12">    <span class="kw">polygon</span>(x, y, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>)    </a>
<a class="sourceLine" id="cb230-13" data-line-number="13">}</a>
<a class="sourceLine" id="cb230-14" data-line-number="14"><span class="co">#Plotting PDF and CDF (Area for lambda=0.5)</span></a>
<a class="sourceLine" id="cb230-15" data-line-number="15"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">5</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="fl">2.0</span>), </a>
<a class="sourceLine" id="cb230-16" data-line-number="16">     <span class="dt">xlab=</span><span class="st">&quot;support&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;probability density&quot;</span>,</a>
<a class="sourceLine" id="cb230-17" data-line-number="17">     <span class="dt">main=</span><span class="st">&quot;PDF (Exponential Distribution)&quot;</span>,  <span class="dt">frame=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb230-18" data-line-number="18"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb230-19" data-line-number="19"><span class="kw">abline</span>(<span class="dt">h=</span><span class="dv">0</span>, <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb230-20" data-line-number="20">p =<span class="st"> </span><span class="kw">exp_cdf</span>(<span class="dt">x=</span><span class="dv">4</span>, <span class="dt">lambda=</span><span class="fl">0.5</span>)</a>
<a class="sourceLine" id="cb230-21" data-line-number="21"><span class="kw">exp_area</span>(<span class="dt">x=</span><span class="dv">4</span>, <span class="dt">lambda=</span><span class="fl">0.5</span>)</a>
<a class="sourceLine" id="cb230-22" data-line-number="22"><span class="kw">curve</span>(<span class="kw">exp_pdf</span>(x, <span class="dt">lambda=</span><span class="fl">0.5</span>), <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb230-23" data-line-number="23"><span class="kw">curve</span>(<span class="kw">exp_pdf</span>(x, <span class="dt">lambda=</span><span class="fl">1.0</span>), <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb230-24" data-line-number="24"><span class="kw">curve</span>(<span class="kw">exp_pdf</span>(x, <span class="dt">lambda=</span><span class="fl">1.5</span>), <span class="dt">col=</span><span class="st">&quot;brown&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb230-25" data-line-number="25"><span class="kw">curve</span>(<span class="kw">exp_pdf</span>(x, <span class="dt">lambda=</span><span class="fl">2.0</span>), <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb230-26" data-line-number="26"><span class="kw">text</span>(<span class="dv">3</span>,<span class="fl">0.3</span>, <span class="dt">label=</span><span class="kw">expression</span>(<span class="kw">paste</span>(<span class="st">&quot;pdf=&quot;</span>, lambda <span class="op">*</span><span class="st"> </span>e<span class="op">^</span>(<span class="op">-</span>lambda <span class="op">*</span><span class="st"> </span>x))))</a>
<a class="sourceLine" id="cb230-27" data-line-number="27"><span class="kw">text</span>(<span class="fl">0.6</span>, <span class="fl">0.2</span>, <span class="dt">label=</span><span class="st">&quot;(cdf)&quot;</span>, <span class="dt">col=</span><span class="st">&quot;black&quot;</span>)</a>
<a class="sourceLine" id="cb230-28" data-line-number="28"><span class="kw">text</span>(<span class="fl">0.7</span>, <span class="fl">0.1</span>, <span class="dt">label=</span><span class="kw">paste</span>(<span class="st">&quot;Area = &quot;</span>, <span class="kw">round</span>(p,<span class="dv">5</span>), <span class="dt">sep=</span><span class="st">&quot;&quot;</span>), </a>
<a class="sourceLine" id="cb230-29" data-line-number="29">     <span class="dt">ce=</span><span class="dv">1</span>, <span class="dt">col=</span><span class="st">&quot;black&quot;</span>)</a>
<a class="sourceLine" id="cb230-30" data-line-number="30"><span class="kw">text</span>(<span class="fl">4.2</span>, <span class="fl">0.12</span>, <span class="dt">label=</span><span class="st">&quot;x=4&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:expdist1"></span>
<img src="DS_files/figure-html/expdist1-1.png" alt="Exponential Distribution (PDF)" width="70%" />
<p class="caption">
Figure 5.16: Exponential Distribution (PDF)
</p>
</div>
<div class="sourceCode" id="cb231"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb231-1" data-line-number="1"><span class="co">#Plotting CDF </span></a>
<a class="sourceLine" id="cb231-2" data-line-number="2"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">5</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="fl">1.0</span>), </a>
<a class="sourceLine" id="cb231-3" data-line-number="3">     <span class="dt">xlab=</span><span class="st">&quot;support&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;cumulative density&quot;</span>,</a>
<a class="sourceLine" id="cb231-4" data-line-number="4">     <span class="dt">main=</span><span class="st">&quot;CDF (Exponential Distribution)&quot;</span>,  <span class="dt">frame=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb231-5" data-line-number="5"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb231-6" data-line-number="6"><span class="kw">abline</span>(<span class="dt">h=</span><span class="dv">0</span>, <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb231-7" data-line-number="7">x =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">5</span>, <span class="dt">length.out=</span><span class="dv">500</span>)</a>
<a class="sourceLine" id="cb231-8" data-line-number="8"><span class="kw">curve</span>(<span class="kw">exp_cdf</span>(x, <span class="dt">lambda=</span><span class="fl">0.5</span>), <span class="dt">col=</span><span class="st">&quot;brown&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb231-9" data-line-number="9"><span class="kw">curve</span>(<span class="kw">exp_cdf</span>(x, <span class="dt">lambda=</span><span class="fl">1.0</span>), <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb231-10" data-line-number="10"><span class="kw">curve</span>(<span class="kw">exp_cdf</span>(x, <span class="dt">lambda=</span><span class="fl">1.5</span>), <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb231-11" data-line-number="11"><span class="kw">curve</span>(<span class="kw">exp_cdf</span>(x, <span class="dt">lambda=</span><span class="fl">2.0</span>), <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:expdist2"></span>
<img src="DS_files/figure-html/expdist2-1.png" alt="Exponential Distribution (CDF)" width="70%" />
<p class="caption">
Figure 5.17: Exponential Distribution (CDF)
</p>
</div>

<p>To illustrate further, let us use one of the examples given. Suppose we wait to fill up gas at a gas station. Let us compute the probability of waiting for less than 5 minutes given that <span class="math inline">\(\lambda = 1/2\)</span>. That gives us the following problem statement:</p>
<p><span class="math display">\[\begin{align}
P(X \le x) = P(X \le 5) = 1 - e^{-\lambda x}
\end{align}\]</span></p>
<p>were average time to wait = 2 minutes.</p>
<p>Here is the implementation of <strong>CDF</strong> in R code:</p>

<div class="sourceCode" id="cb232"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb232-1" data-line-number="1"><span class="kw">sum</span> ( <span class="kw">exp_cdf</span>(<span class="dt">x=</span><span class="kw">c</span>(<span class="dv">4</span>),<span class="dt">lambda=</span><span class="fl">0.5</span>) )  <span class="co"># our code</span></a></code></pre></div>
<pre><code>## [1] 0.8646647</code></pre>
<div class="sourceCode" id="cb234"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb234-1" data-line-number="1">(<span class="dt">p =</span> <span class="kw">sum</span>(<span class="kw">pexp</span>(<span class="dt">q=</span><span class="kw">c</span>(<span class="dv">4</span>), <span class="dt">rate=</span><span class="fl">0.5</span>))) <span class="co"># R&#39;s built-in package</span></a></code></pre></div>
<pre><code>## [1] 0.8646647</code></pre>

<p>Both outcomes give around 86.47% probability for us to wait for 4 minutes only.</p>
<p>On the other hand, if the average wait time is 10 minutes instead. Then we get:</p>

<div class="sourceCode" id="cb236"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb236-1" data-line-number="1"><span class="kw">sum</span> ( <span class="kw">exp_cdf</span>(<span class="dt">x=</span><span class="kw">c</span>(<span class="dv">4</span>),<span class="dt">lambda=</span><span class="fl">0.2</span>) )  <span class="co"># our code</span></a></code></pre></div>
<pre><code>## [1] 0.550671</code></pre>
<div class="sourceCode" id="cb238"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb238-1" data-line-number="1">(<span class="dt">p =</span> <span class="kw">sum</span>(<span class="kw">pexp</span>(<span class="dt">q=</span><span class="kw">c</span>(<span class="dv">4</span>), <span class="dt">rate=</span><span class="fl">0.2</span>))) <span class="co"># R&#39;s built-in package</span></a></code></pre></div>
<pre><code>## [1] 0.550671</code></pre>

<p>Both outcomes give around 55.07% probability for us to wait for 4 minutes only.</p>
<p>In terms of expected value and variance, we have the following expression:</p>
<p><strong>Expected value</strong>:</p>
<p><span class="math display">\[\begin{align}
\mathbb{E}(X) = \int_0^\infty x\lambda e^{-\lambda x} dx = 
\left[\frac{e^{-\lambda x}}{\lambda}\right]_0^\infty =
\frac{1}{\lambda}
\end{align}\]</span></p>
<p><strong>Variance:</strong></p>
<p><span class="math display">\[\begin{align}
Var(X) = \mathbb{E}({X}^2) - \mathbb{E}(X)^2 
= \frac{2}{\lambda^2} - \frac{1}{\lambda^2} = \frac{1}{\lambda^2}
\end{align}\]</span></p>
<p>We now discuss the next type of distribution - the <strong>Gamma distribution</strong>. It is notable to mention that <strong>Exponential distribution</strong> and <strong>Gamma distribution</strong> are somewhat related. While <strong>Exponential distribution</strong> is about <strong>waiting time</strong> between events of interest, <strong>Gamma distribution</strong> is <strong>waiting time</strong> taken for <strong>number of events</strong>.</p>
</div>
<div id="gamma-distribution" class="section level3 hasAnchor">
<h3><span class="header-section-number">5.9.8</span> Gamma distribution <a href="numericalprobability.html#gamma-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Gamma distribution</strong> models a <strong>continuous distribution</strong> of a random variable <strong>X</strong> taking into account the number of events that occurred after <strong>wait (or elapse) time</strong> and is written as:</p>
<p><span class="math display">\[\begin{align}
X \sim Gamma(\alpha, \beta)\ \ \ \ or\ \ \ \ \ X \sim \Gamma(\alpha, \beta) 
\end{align}\]</span></p>
<p>Any queueing system involving wait times or any events that can be measured in terms of elapsed time are two common examples in which using <strong>Gamma distribution</strong> is helpful.
The <strong>PDF</strong> of a <strong>Gamma distribution</strong> with <strong>support</strong> <span class="math inline">\(x \ge 0\)</span> is expressed as:</p>
<p><span class="math display">\[\begin{align}
f(x; \alpha,\beta) = P(X = x|\alpha, \beta) =  \frac{1}{\beta^{\alpha}\Gamma(\alpha)}x^{\alpha-1}e^{-\frac{x}{\beta}} =
\frac{\beta^{\alpha}}{\Gamma(\alpha)}x^{\alpha-1}e^{-\beta x}
\end{align}\]</span></p>
<p>where the <strong>Gamma function</strong> is expressed as:</p>
<p><span class="math display">\[\begin{align}
\Gamma(\alpha) {}&amp;= \int_0^\infty x^{\alpha-1} e^{-x} dx \\
\Gamma(n) &amp;= (n-1)! \\
\Gamma(n+1) &amp;= n\Gamma(n) = n(n-1)!
\end{align}\]</span></p>
<p>also where:</p>
<ul>
<li><span class="math inline">\(\alpha\)</span> is the number of events that occurred</li>
<li><span class="math inline">\(\beta\)</span> is the average number of events per time. It is equivalent to <span class="math inline">\(1/\lambda\)</span> in which <span class="math inline">\(\lambda\)</span> denotes the average time between events.</li>
</ul>
<p>The inverse of <strong>Gamma distribution</strong> is expressed as:</p>
<p><span class="math display">\[\begin{align}
g(x; \alpha,\beta) = P(X = x|\alpha, \beta) = 
\frac{\beta^{\alpha}}{\Gamma(\alpha)}x^{-(\alpha+1)}e^{-\frac{\beta}{ x}}\ \ \text{(inverse)}
\end{align}\]</span></p>
<p>Note that if the average time between events (e.g.Â bathroom breaks) is two hours <span class="math inline">\(\rightarrow \lambda = 2\ hrs\)</span>, then <span class="math inline">\(\beta = 1/2 = 0.5\)</span>.</p>
<p>The <strong>CDF</strong> of a <strong>Gamma distribution</strong> where <span class="math inline">\(x \ge 0\)</span> is expressed as:</p>
<p><span class="math display">\[\begin{align}
\mathcal{F}(x; \alpha, \beta) = P(X \le x|\alpha, \beta) = 1 - \sum_{i=0}^{\alpha-1} \frac{(\lambda x)^i}{i!}e^{-\lambda x} 
\end{align}\]</span></p>
<p>Below is a naive implementation of <strong>Gamma Distribution</strong> in R code:</p>

<div class="sourceCode" id="cb240"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb240-1" data-line-number="1">Gamma &lt;-<span class="st"> </span><span class="cf">function</span>(n) { <span class="kw">factorial</span>(n<span class="dv">-1</span>)}</a>
<a class="sourceLine" id="cb240-2" data-line-number="2">gamma_pdf &lt;-<span class="st"> </span><span class="cf">function</span>(x, alpha, beta ) {</a>
<a class="sourceLine" id="cb240-3" data-line-number="3">    <span class="dv">1</span> <span class="op">/</span><span class="st"> </span>(beta <span class="op">^</span>alpha <span class="op">*</span><span class="st"> </span><span class="kw">Gamma</span>(alpha)) <span class="op">*</span><span class="st"> </span>x<span class="op">^</span>(alpha <span class="op">-</span><span class="st"> </span><span class="dv">1</span>) <span class="op">*</span><span class="st"> </span><span class="kw">exp</span>(<span class="op">-</span>x<span class="op">/</span>beta)</a>
<a class="sourceLine" id="cb240-4" data-line-number="4">}</a>
<a class="sourceLine" id="cb240-5" data-line-number="5">gamma_cdf &lt;-<span class="st"> </span><span class="cf">function</span>(x, alpha, beta) {</a>
<a class="sourceLine" id="cb240-6" data-line-number="6">    constant =<span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb240-7" data-line-number="7">    lambda =<span class="st"> </span><span class="dv">1</span><span class="op">/</span>beta</a>
<a class="sourceLine" id="cb240-8" data-line-number="8">    <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">0</span><span class="op">:</span>(alpha<span class="dv">-1</span>)) { </a>
<a class="sourceLine" id="cb240-9" data-line-number="9">      constant =<span class="st"> </span>constant <span class="op">+</span><span class="st"> </span>((lambda<span class="op">*</span>x)<span class="op">^</span>i)<span class="op">/</span><span class="kw">factorial</span>(i)<span class="op">*</span><span class="kw">exp</span>(<span class="op">-</span>lambda<span class="op">*</span>x)</a>
<a class="sourceLine" id="cb240-10" data-line-number="10">    }</a>
<a class="sourceLine" id="cb240-11" data-line-number="11">    <span class="dv">1</span> <span class="op">-</span><span class="st"> </span>constant</a>
<a class="sourceLine" id="cb240-12" data-line-number="12">}</a>
<a class="sourceLine" id="cb240-13" data-line-number="13">gamma_area &lt;-<span class="st"> </span><span class="cf">function</span>(x, alpha, beta) {</a>
<a class="sourceLine" id="cb240-14" data-line-number="14">    a =<span class="st"> </span><span class="dv">0</span>; b =<span class="st"> </span>x     <span class="co"># boundaries</span></a>
<a class="sourceLine" id="cb240-15" data-line-number="15">    area =<span class="st"> </span><span class="kw">seq</span>(a, b, <span class="dt">length.out=</span><span class="dv">50</span>)     <span class="co"># area</span></a>
<a class="sourceLine" id="cb240-16" data-line-number="16">    x =<span class="st"> </span><span class="kw">c</span>(a, area , b)</a>
<a class="sourceLine" id="cb240-17" data-line-number="17">    y =<span class="st"> </span><span class="kw">c</span>(<span class="dv">0</span>, <span class="kw">gamma_pdf</span>(area, alpha, beta), <span class="dv">0</span>)</a>
<a class="sourceLine" id="cb240-18" data-line-number="18">    <span class="kw">polygon</span>(x, y, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>)    </a>
<a class="sourceLine" id="cb240-19" data-line-number="19">}</a>
<a class="sourceLine" id="cb240-20" data-line-number="20"></a>
<a class="sourceLine" id="cb240-21" data-line-number="21"><span class="co">#Plotting PDF and CDF(Area for alpha=5, beta=1)</span></a>
<a class="sourceLine" id="cb240-22" data-line-number="22"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">15</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="fl">0.5</span>), </a>
<a class="sourceLine" id="cb240-23" data-line-number="23">     <span class="dt">xlab=</span><span class="st">&quot;support&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;probability density&quot;</span>,</a>
<a class="sourceLine" id="cb240-24" data-line-number="24">     <span class="dt">main=</span><span class="st">&quot;PDF and CDF (Gamma Distribution)&quot;</span>,  <span class="dt">frame=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb240-25" data-line-number="25"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb240-26" data-line-number="26"><span class="kw">abline</span>(<span class="dt">h=</span><span class="dv">0</span>, <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb240-27" data-line-number="27">p =<span class="st"> </span><span class="kw">gamma_cdf</span>(<span class="dt">x=</span><span class="dv">6</span>, <span class="dt">alpha=</span><span class="dv">5</span>, <span class="dt">beta=</span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb240-28" data-line-number="28"><span class="kw">gamma_area</span>(<span class="dt">x=</span><span class="dv">6</span>, <span class="dt">alpha=</span><span class="dv">5</span>, <span class="dt">beta=</span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb240-29" data-line-number="29"><span class="kw">curve</span>(<span class="kw">gamma_pdf</span>(x, <span class="dt">alpha=</span><span class="dv">1</span>, <span class="dt">beta=</span><span class="dv">2</span>), <span class="dt">col=</span><span class="st">&quot;brown&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb240-30" data-line-number="30"><span class="kw">curve</span>(<span class="kw">gamma_pdf</span>(x, <span class="dt">alpha=</span><span class="dv">2</span>, <span class="dt">beta=</span><span class="dv">2</span>), <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb240-31" data-line-number="31"><span class="kw">curve</span>(<span class="kw">gamma_pdf</span>(x, <span class="dt">alpha=</span><span class="dv">5</span>, <span class="dt">beta=</span><span class="dv">1</span>), <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb240-32" data-line-number="32"><span class="kw">curve</span>(<span class="kw">gamma_pdf</span>(x, <span class="dt">alpha=</span><span class="dv">10</span>, <span class="dt">beta=</span><span class="fl">0.5</span>), <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb240-33" data-line-number="33"><span class="kw">text</span>(<span class="dv">4</span>,<span class="fl">0.06</span>, <span class="dt">label=</span><span class="st">&quot;(cdf)&quot;</span>, <span class="dt">col=</span><span class="st">&quot;black&quot;</span>)</a>
<a class="sourceLine" id="cb240-34" data-line-number="34"><span class="kw">text</span>(<span class="dv">4</span>, <span class="fl">0.02</span>, <span class="dt">label=</span><span class="kw">paste</span>(<span class="st">&quot;Area = &quot;</span>, <span class="kw">round</span>(p,<span class="dv">5</span>), <span class="dt">sep=</span><span class="st">&quot;&quot;</span>), </a>
<a class="sourceLine" id="cb240-35" data-line-number="35">     <span class="dt">ce=</span><span class="fl">0.80</span>, <span class="dt">col=</span><span class="st">&quot;black&quot;</span>)</a>
<a class="sourceLine" id="cb240-36" data-line-number="36"><span class="kw">text</span>(<span class="fl">6.5</span>, <span class="fl">0.04</span>, <span class="dt">label=</span><span class="st">&quot;x=6&quot;</span>)</a>
<a class="sourceLine" id="cb240-37" data-line-number="37"></a>
<a class="sourceLine" id="cb240-38" data-line-number="38"><span class="co">#Plotting CDF</span></a>
<a class="sourceLine" id="cb240-39" data-line-number="39"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">15</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="dv">1</span>), </a>
<a class="sourceLine" id="cb240-40" data-line-number="40">     <span class="dt">xlab=</span><span class="st">&quot;support&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;cumulative density&quot;</span>,</a>
<a class="sourceLine" id="cb240-41" data-line-number="41">     <span class="dt">main=</span><span class="st">&quot;CDF (Gamma Distribution)&quot;</span>,  <span class="dt">frame=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb240-42" data-line-number="42"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb240-43" data-line-number="43"><span class="kw">abline</span>(<span class="dt">h=</span><span class="dv">0</span>, <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb240-44" data-line-number="44">x =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">15</span>, <span class="dt">length.out=</span><span class="dv">500</span>)</a>
<a class="sourceLine" id="cb240-45" data-line-number="45"><span class="kw">curve</span>(<span class="kw">gamma_cdf</span>(x, <span class="dt">alpha=</span><span class="dv">1</span>, <span class="dt">beta=</span><span class="dv">2</span>), <span class="dt">col=</span><span class="st">&quot;brown&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb240-46" data-line-number="46"><span class="kw">curve</span>(<span class="kw">gamma_cdf</span>(x, <span class="dt">alpha=</span><span class="dv">2</span>, <span class="dt">beta=</span><span class="dv">2</span>), <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb240-47" data-line-number="47"><span class="kw">curve</span>(<span class="kw">gamma_cdf</span>(x, <span class="dt">alpha=</span><span class="dv">5</span>, <span class="dt">beta=</span><span class="dv">1</span>), <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb240-48" data-line-number="48"><span class="kw">curve</span>(<span class="kw">gamma_cdf</span>(x, <span class="dt">alpha=</span><span class="dv">10</span>, <span class="dt">beta=</span><span class="fl">0.5</span>), <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:gammapdf-1"></span>
<img src="DS_files/figure-html/gammapdf-1.png" alt="Gamma Distribution" width="70%" />
<p class="caption">
Figure 5.18: Gamma Distribution
</p>
</div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:gammapdf-2"></span>
<img src="DS_files/figure-html/gammapdf-2.png" alt="Gamma Distribution" width="70%" />
<p class="caption">
Figure 5.19: Gamma Distribution
</p>
</div>

<p>Note that if <span class="math inline">\(\alpha = 1\)</span>, the inverse of <span class="math inline">\(\beta\)</span> makes the <strong>Gamma distribution</strong> equivalent to <strong>Exponential distribution</strong>. Meaning, use <span class="math inline">\(\alpha=1, \beta=1/\lambda\)</span> to mimic <strong>Exponential distribution</strong> using <strong>Gamma PDF</strong>.</p>
<p>One way to illustrate the relation between <strong>Gamma and Exponential distribution</strong> is shown in figure <a href="numericalprobability.html#fig:gammadist">5.20</a>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:gammadist"></span>
<img src="gamma.png" alt="Gamma and Exponential Distribution" width="80%" />
<p class="caption">
Figure 5.20: Gamma and Exponential Distribution
</p>
</div>
<p>In Figure <a href="numericalprobability.html#fig:gammadist">5.20</a>, there are four events, <span class="math inline">\(\{ e1, e2, e3, e4\}\)</span>. Event <strong>e1</strong> happens between times 0 and 1. The time taken is one second, <strong>x1</strong>. Event <strong>e2</strong> happens between times 1 and 2. The time taken is also one second, <strong>x2</strong>. Event <strong>e3</strong> happens between times 2 and 4. The time taken is two seconds, <strong>x3</strong>. Moreover, event <strong>e4</strong> happens between times 4 and 7. The time taken is three seconds, <strong>x4</strong>. Here, <strong>Exponential distribution</strong> focuses on the time taken between events.</p>
<p>On the other hand, at time 1, event <strong>e1</strong> happens after waiting for one second, <strong>G1</strong>. There is only one event that happens after one second. At time 2, events <strong>e1, e2</strong> happen after two seconds elapsed, <strong>G2</strong>. Two events happen after two seconds. At time 4, after four seconds ,<strong>G3</strong>, events <strong>e1, e2, e3</strong> happen. Three events happen after four seconds. Finally, at time 7, seven seconds, <strong>G4</strong>, events <strong>e1, e2, e3, e4</strong> happen. Four events happen after seven seconds. Here, <strong>Gamma distribution</strong> focuses on the number of events after some <strong>elapsed time</strong>.</p>
<p>To illustrate practically, suppose a shuttle bus in an airportâs long-term parking lot arrives every 30 minutes at the airport to pick up travelers. Let us compute the probability of expecting three buses to arrive after waiting between 1 hour and 2 hours.</p>
<p>A shuttle bus arriving every 30 minutes means we expect to see <span class="math inline">\(\beta = 1/0.5= 2\)</span> buses arriving every hour on average.</p>
<p>Using <span class="math inline">\(\alpha = 3\)</span> and <span class="math inline">\(\beta = 2\)</span>, we can compute this as follows:</p>
<p><span class="math display">\[\begin{align}
P(1 \le X \le 2) = \sum_{x=1}^{\alpha-1} \frac {1}{\beta^\alpha\Gamma(\alpha)}x^{(\alpha-1)}e^{-\frac{x}{\beta}}
= \sum_{x=1}^{3-1} \frac {1}{\Gamma(3)2^3}x^{(3-1)}e^{-\frac{x}{2}}
= 0.129878
\end{align}\]</span></p>
<p>Here is the implementation of <strong>PDF</strong> in R code:</p>

<div class="sourceCode" id="cb241"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb241-1" data-line-number="1">gamma_pdf &lt;-<span class="st"> </span><span class="cf">function</span>(x, alpha, beta) { </a>
<a class="sourceLine" id="cb241-2" data-line-number="2">  <span class="dv">1</span><span class="op">/</span>( <span class="kw">factorial</span>(alpha<span class="dv">-1</span>)<span class="op">*</span><span class="st"> </span>beta<span class="op">^</span>alpha ) <span class="op">*</span><span class="st"> </span>x<span class="op">^</span>(alpha<span class="dv">-1</span>) <span class="op">*</span><span class="st"> </span><span class="kw">exp</span>(<span class="op">-</span>x<span class="op">/</span>beta)</a>
<a class="sourceLine" id="cb241-3" data-line-number="3">}</a>
<a class="sourceLine" id="cb241-4" data-line-number="4"><span class="kw">sum</span> ( <span class="kw">gamma_pdf</span>(<span class="dt">x=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>), <span class="dt">alpha=</span><span class="dv">3</span>, <span class="dt">beta=</span><span class="dv">2</span>) )  <span class="co"># our code</span></a></code></pre></div>
<pre><code>## [1] 0.129878</code></pre>
<div class="sourceCode" id="cb243"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb243-1" data-line-number="1"><span class="kw">sum</span>(<span class="kw">dgamma</span>(<span class="dt">x=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>), <span class="dt">shape=</span><span class="dv">3</span>, <span class="dt">rate=</span><span class="fl">0.5</span>)) <span class="co"># R&#39;s built-in package</span></a></code></pre></div>
<pre><code>## [1] 0.129878</code></pre>

<p>Note that <span class="math inline">\(\alpha = shape\)</span> and <span class="math inline">\(\beta = 1 / rate\)</span>.</p>
<p>In terms of expected value and variance, we have the following formulas:</p>
<p><strong>Expected value</strong>:</p>
<p><span class="math display">\[\begin{align}
\mathbb{E}(X) = \alpha \beta
\end{align}\]</span></p>
<p><strong>Variance:</strong></p>
<p><span class="math display">\[\begin{align}
Var(X) = \mathbb{E}({X}^2) - \mathbb{E}(X)^2   =  \alpha \beta^2
\end{align}\]</span></p>
</div>
<div id="inverse-gamma-distribution" class="section level3 hasAnchor">
<h3><span class="header-section-number">5.9.9</span> Inverse Gamma distribution <a href="numericalprobability.html#inverse-gamma-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Inverse Gamma distribution</strong> models a <strong>continuous distribution</strong> whose <strong>PDF</strong> is inverse of <strong>Gamma distribution</strong> where <strong>support</strong> <span class="math inline">\(x \ge 0\)</span> and is written as:</p>
<p><span class="math display">\[\begin{align}
f(x; \alpha,\beta) = P(X = x|\alpha, \beta) = \frac{1}{\beta^{\alpha}\Gamma(\alpha)}x^{-(\alpha+1)}e^{-\frac{1}{x\beta}}
\end{align}\]</span></p>
<p>and its <strong>CDF</strong> is:</p>
<p><span class="math display">\[\begin{align}
\mathcal{F}(x; \alpha,\beta) = P(X &lt;= x|\alpha, \beta) = \frac{\Gamma(\alpha, \frac{\beta}{x})}{\Gamma(\alpha)} 
\end{align}\]</span></p>
<p>where the upper <strong>incomplete Gamma function</strong> is written as:</p>
<p><span class="math display">\[\begin{align}
\Gamma(\alpha, \frac{\beta}{x}) = \int_0^x t^{\alpha - 1}e^{-t}dt
\end{align}\]</span></p>
<p><strong>Expected value</strong>:</p>
<p><span class="math display">\[\begin{align}
\mathbb{E}(X) = \frac{\beta}{(\alpha - 1 )}
\end{align}\]</span></p>
<p><strong>Variance:</strong></p>
<p><span class="math display">\[\begin{align}
Var(X) = \mathbb{E}({X}^2) - \mathbb{E}(X)^2   =  \frac{\beta^2}{(\alpha-1)^2(\alpha - 2)}
\end{align}\]</span></p>
</div>
<div id="weibull-distribution" class="section level3 hasAnchor">
<h3><span class="header-section-number">5.9.10</span> Weibull distribution <a href="numericalprobability.html#weibull-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>For an alternative to <strong>Gamma distribution</strong>, we leave readers to investigate <strong>Weibull distribution</strong>, which offers simplicity and reliability and is written as:</p>
<p><span class="math display">\[\begin{align}
X \sim Weib(\alpha, \beta)
\end{align}\]</span></p>
<p>with the following 2-parameter <strong>PDF</strong> for <strong>Weibull distribution</strong>, where <strong>support</strong> <span class="math inline">\(x \ge 0\)</span> :</p>
<p><span class="math display">\[\begin{align}
f(x; \tau, \lambda) = P(X = x|\tau, \lambda) =  \frac{\tau}{\lambda}\left(\frac{x}{\lambda}\right)^{\tau - 1} e^{ -\left(\frac{x}{\lambda}\right)^{\tau}}
\end{align}\]</span></p>
<p>and with the 2-parameter <strong>CDF</strong> for <strong>Weibull distribution</strong>:</p>
<p><span class="math display">\[\begin{align}
\mathcal{F}(x; \tau, \lambda) = P(X \le x| \tau, \lambda) = 1 - e^{ -\left(\frac{x}{\lambda}\right)^{\tau}}
\end{align}\]</span></p>
<p>We also note exploring the 3-parameter <strong>Weibull PDF</strong> and the 1-parameter <strong>Weibull PDF</strong>.</p>
<p>We now discuss the next type of distribution - the <strong>Poisson distribution</strong>. It is notable to mention that <strong>Gamma distribution</strong> and <strong>Poisson distribution</strong> are also somewhat interrelated. While <strong>Gamma distribution</strong> is about the number of events <strong>after wait time</strong>, <strong>Poisson distribution</strong> is about the number of events <strong>between fixed times</strong>.</p>
</div>
<div id="poisson-distribution" class="section level3 hasAnchor">
<h3><span class="header-section-number">5.9.11</span> Poisson distribution <a href="numericalprobability.html#poisson-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Poisson distribution</strong> is also called <strong>Count distribution</strong> as it describes a <strong>discrete distribution</strong> of data based on the number of times events are occurring in some given fixed time-intervals and is expressed as:</p>
<p><span class="math display">\[\begin{align}
X \sim Pois(\lambda )\ \ \ \ \ or \ \ \ \ \  \ X \sim Po(\lambda )
\end{align}\]</span></p>
<p>As examples:</p>
<ul>
<li>How many words are typed every minute?</li>
<li>How many drops of rainfall on a basin every second?</li>
<li>How many cars pass by the highway every minute?</li>
</ul>
<p>Here, the expected number of occurrences is <span class="math inline">\(\lambda\)</span> (lambda). It answers the question, <strong>How many?</strong>.</p>
<p>The <strong>PMF</strong> of a <strong>discrete Poisson distribution</strong> is expressed as:</p>
<p><span class="math display">\[\begin{align}
f(x; \lambda) = P(X = x|\lambda) = \frac{\lambda^xe^{-\lambda}}{x!} \label{eqn:eqnnumber6001}
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li>k is the number of events occurring successfully</li>
<li><span class="math inline">\(\lambda\)</span> is a shape parameter describing event rate, <span class="math inline">\(\lambda = rt\)</span>, e.g., number of events per fixed interval of time.</li>
<li>r is the number of occurrences.</li>
<li>t is the fixed interval time.</li>
</ul>
<p>The <strong>CMF</strong> of a <strong>discrete Poisson distribution</strong> is expressed as:</p>
<p><span class="math display">\[\begin{align}
\mathcal{F}(x; \lambda) = P(X \le x|\lambda) = \sum_{k=0}^{x} \frac{\lambda^k}{k!}e^{-\lambda}
\end{align}\]</span></p>
<p>Below is a naive implementation of <strong>Poisson Distribution</strong> in R code:</p>

<div class="sourceCode" id="cb245"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb245-1" data-line-number="1">poisson_pmf &lt;-<span class="st"> </span><span class="cf">function</span>(x, lambda ) {</a>
<a class="sourceLine" id="cb245-2" data-line-number="2">    lambda<span class="op">^</span>x <span class="op">*</span><span class="st"> </span><span class="kw">exp</span>(<span class="op">-</span>lambda) <span class="op">/</span><span class="st"> </span><span class="kw">factorial</span>(x)</a>
<a class="sourceLine" id="cb245-3" data-line-number="3">}</a>
<a class="sourceLine" id="cb245-4" data-line-number="4">poisson_cmf &lt;-<span class="st"> </span><span class="cf">function</span>(x, lambda) {</a>
<a class="sourceLine" id="cb245-5" data-line-number="5">    poisson =<span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb245-6" data-line-number="6">    <span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">0</span><span class="op">:</span>x) { </a>
<a class="sourceLine" id="cb245-7" data-line-number="7">      poisson =<span class="st"> </span>poisson <span class="op">+</span><span class="st"> </span>(lambda<span class="op">^</span>k)<span class="op">/</span><span class="kw">factorial</span>(k) <span class="op">*</span><span class="st"> </span><span class="kw">exp</span>(<span class="op">-</span>lambda)</a>
<a class="sourceLine" id="cb245-8" data-line-number="8">    }</a>
<a class="sourceLine" id="cb245-9" data-line-number="9">    poisson</a>
<a class="sourceLine" id="cb245-10" data-line-number="10">}</a>
<a class="sourceLine" id="cb245-11" data-line-number="11">poisson_area &lt;-<span class="st"> </span><span class="cf">function</span>(x, lambda) {</a>
<a class="sourceLine" id="cb245-12" data-line-number="12">    a =<span class="st"> </span><span class="dv">0</span>; b =<span class="st"> </span>x     <span class="co"># boundaries</span></a>
<a class="sourceLine" id="cb245-13" data-line-number="13">    area =<span class="st"> </span><span class="kw">seq</span>(a, b, <span class="dt">length.out=</span><span class="dv">50</span>) <span class="co"># area</span></a>
<a class="sourceLine" id="cb245-14" data-line-number="14">    x =<span class="st"> </span><span class="kw">c</span>(a, area , b)</a>
<a class="sourceLine" id="cb245-15" data-line-number="15">    y =<span class="st"> </span><span class="kw">c</span>(<span class="dv">0</span>, <span class="kw">poisson_pmf</span>(area, lambda), <span class="dv">0</span>)</a>
<a class="sourceLine" id="cb245-16" data-line-number="16">    <span class="kw">polygon</span>(x, y, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>)</a>
<a class="sourceLine" id="cb245-17" data-line-number="17">    bars =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">20</span>, <span class="dt">length.out=</span><span class="dv">21</span>)</a>
<a class="sourceLine" id="cb245-18" data-line-number="18">    y =<span class="st"> </span><span class="kw">poisson_pmf</span>(bars, lambda) </a>
<a class="sourceLine" id="cb245-19" data-line-number="19">}</a>
<a class="sourceLine" id="cb245-20" data-line-number="20"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">20</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="op">-</span><span class="fl">0.01</span>,<span class="fl">0.6</span>), </a>
<a class="sourceLine" id="cb245-21" data-line-number="21">     <span class="dt">xlab=</span><span class="st">&quot;support&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;probability mass&quot;</span>,</a>
<a class="sourceLine" id="cb245-22" data-line-number="22">     <span class="dt">main=</span><span class="st">&quot;PMF and CMF (Poisson Distribution)&quot;</span>,  <span class="dt">frame=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb245-23" data-line-number="23"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb245-24" data-line-number="24"><span class="kw">abline</span>(<span class="dt">h=</span><span class="dv">0</span>, <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb245-25" data-line-number="25">p =<span class="st"> </span><span class="kw">poisson_cmf</span>(<span class="dt">x=</span><span class="dv">10</span>, <span class="dt">lambda=</span><span class="dv">9</span>)</a>
<a class="sourceLine" id="cb245-26" data-line-number="26"><span class="kw">poisson_area</span>(<span class="dt">x=</span><span class="dv">10</span>, <span class="dt">lambda=</span><span class="dv">9</span>)</a>
<a class="sourceLine" id="cb245-27" data-line-number="27"><span class="co"># use n=550 to smoothen curves</span></a>
<a class="sourceLine" id="cb245-28" data-line-number="28"><span class="kw">curve</span>(<span class="kw">poisson_pmf</span>(x, <span class="dt">lambda=</span><span class="fl">0.5</span>), <span class="dt">n=</span><span class="dv">550</span>, <span class="dt">col=</span><span class="st">&quot;brown&quot;</span>, </a>
<a class="sourceLine" id="cb245-29" data-line-number="29">      <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb245-30" data-line-number="30"><span class="kw">curve</span>(<span class="kw">poisson_pmf</span>(x, <span class="dt">lambda=</span><span class="dv">1</span>), <span class="dt">n=</span><span class="dv">550</span>, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, </a>
<a class="sourceLine" id="cb245-31" data-line-number="31">      <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb245-32" data-line-number="32"><span class="kw">curve</span>(<span class="kw">poisson_pmf</span>(x, <span class="dt">lambda=</span><span class="dv">5</span>), <span class="dt">n=</span><span class="dv">550</span>, <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, </a>
<a class="sourceLine" id="cb245-33" data-line-number="33">      <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb245-34" data-line-number="34"><span class="kw">curve</span>(<span class="kw">poisson_pmf</span>(x, <span class="dt">lambda=</span><span class="dv">9</span>), <span class="dt">n=</span><span class="dv">550</span>, <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb245-35" data-line-number="35">x =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">20</span>, <span class="dt">length=</span><span class="dv">21</span>)</a>
<a class="sourceLine" id="cb245-36" data-line-number="36">y =<span class="st"> </span><span class="kw">poisson_pmf</span>(x, <span class="dt">lambda=</span><span class="dv">9</span>)</a>
<a class="sourceLine" id="cb245-37" data-line-number="37"><span class="kw">points</span>(x,y, <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>, <span class="dt">pch=</span><span class="dv">16</span>, <span class="dt">cex=</span><span class="fl">0.8</span>)</a>
<a class="sourceLine" id="cb245-38" data-line-number="38"><span class="kw">text</span>(<span class="dv">7</span>,<span class="fl">0.06</span>, <span class="dt">label=</span><span class="st">&quot;(cmf)&quot;</span>, <span class="dt">col=</span><span class="st">&quot;black&quot;</span>)</a>
<a class="sourceLine" id="cb245-39" data-line-number="39"><span class="kw">text</span>(<span class="dv">7</span>, <span class="fl">0.02</span>, <span class="dt">label=</span><span class="kw">paste</span>(<span class="st">&quot;Area = &quot;</span>, <span class="kw">round</span>(p,<span class="dv">5</span>), <span class="dt">sep=</span><span class="st">&quot;&quot;</span>), </a>
<a class="sourceLine" id="cb245-40" data-line-number="40">     <span class="dt">ce=</span><span class="fl">0.80</span>, <span class="dt">col=</span><span class="st">&quot;black&quot;</span>)</a>
<a class="sourceLine" id="cb245-41" data-line-number="41"><span class="kw">text</span>(<span class="dv">10</span>, <span class="fl">-0.01</span>, <span class="dt">label=</span><span class="st">&quot;x=10&quot;</span>, <span class="dt">cex=</span><span class="fl">0.8</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:poissonpdf"></span>
<img src="DS_files/figure-html/poissonpdf-1.png" alt="Poisson (PMF and CMF)" width="70%" />
<p class="caption">
Figure 5.21: Poisson (PMF and CMF)
</p>
</div>

<p>Our <strong>CMF</strong> for the <strong>Poisson distribution</strong> in figure <a href="numericalprobability.html#fig:poissonpdf">5.21</a> is 0.70599.</p>
<p>Note that the <strong>PMF</strong> and <strong>CMF</strong> may appear continuous in figure <a href="numericalprobability.html#fig:poissonpdf">5.21</a>. However, we focus more on the discrete points along the curves generated by <strong>PMF</strong>. Equivalently, <strong>CMF</strong> generates a set of discrete bars up to <span class="math inline">\(x\)</span> instead of a continuously filled region.</p>
<p>To illustrate further, suppose that a software developer types an average of 40 words per minute on a computer keyboard. Calculate the probability of k = (0,1,2,3,..6) in an interval of 1-minute.</p>
<p><span class="math display">\[
P(X\ \in\ \{0,1,2,3,4,5,6\}) = \frac{\lambda^x e^{-\lambda}}{x!}
\]</span></p>
<p>where:</p>
<ul>
<li><strong>r</strong> is 40 words typed on the average.</li>
<li><strong>t</strong> is 1 minute interval.</li>
<li><span class="math inline">\(\lambda\)</span> is 40 words / minute</li>
</ul>
<p>Here is the implementation of <strong>PMF</strong> in R code:</p>
<div class="sourceCode" id="cb246"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb246-1" data-line-number="1">k =<span class="st"> </span><span class="kw">c</span>(<span class="dv">30</span>,<span class="dv">35</span>,<span class="dv">40</span>,<span class="dv">45</span>,<span class="dv">50</span>)</a>
<a class="sourceLine" id="cb246-2" data-line-number="2"><span class="kw">round</span>(<span class="kw">poisson_pmf</span>(<span class="dt">x=</span>k,<span class="dt">lambda=</span><span class="dv">40</span>), <span class="dv">5</span>)   <span class="co"># our code</span></a></code></pre></div>
<pre><code>## [1] 0.01847 0.04854 0.06295 0.04397 0.01771</code></pre>
<div class="sourceCode" id="cb248"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb248-1" data-line-number="1">(<span class="dt">p =</span> <span class="kw">round</span>(<span class="kw">dpois</span>(<span class="dt">x=</span>k, <span class="dt">lambda=</span><span class="dv">40</span>), <span class="dv">5</span>)) <span class="co"># R&#39;s built-in package</span></a></code></pre></div>
<pre><code>## [1] 0.01847 0.04854 0.06295 0.04397 0.01771</code></pre>
<div class="sourceCode" id="cb250"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb250-1" data-line-number="1"><span class="kw">names</span>(p) &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">4</span>,<span class="dv">1</span>)</a>
<a class="sourceLine" id="cb250-2" data-line-number="2"><span class="kw">barplot</span>(p, <span class="dt">density=</span>T, <span class="dt">col=</span><span class="dv">2</span>, <span class="dt">xlab=</span><span class="st">&quot;Events&quot;</span>,</a>
<a class="sourceLine" id="cb250-3" data-line-number="3">        <span class="dt">ylab=</span><span class="st">&quot;Probability&quot;</span>, <span class="dt">main=</span><span class="st">&quot;Rate of Typed Words&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:rpoipmf1"></span>
<img src="DS_files/figure-html/rpoipmf1-1.png" alt="(PMF) Poisson Distribution" width="60%" />
<p class="caption">
Figure 5.22: (PMF) Poisson Distribution
</p>
</div>
<p>Here, the probability of typing 30 words per minute with an average of 40 words per minute is 1.85%. The probability of typing 40 words per minute is 6.30% if the average is 40 words per minute.</p>
<p>For the <strong>expected value</strong> and <strong>variance</strong>, respectively, we have:</p>
<p><span class="math display">\[\begin{align}
\mathbb{E}(X) = Var(X) = \lambda = rt
\end{align}\]</span></p>
</div>
<div id="pareto-distribution" class="section level3 hasAnchor">
<h3><span class="header-section-number">5.9.12</span> Pareto distribution <a href="numericalprobability.html#pareto-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Pareto distribution</strong> models a skewed and heavy-tailed <strong>continuous distribution</strong> written as:</p>
<p><span class="math display">\[\begin{align}
X \sim Pareto(\lambda, \alpha)
\end{align}\]</span></p>
<p>This distribution is commonly known to model the distribution of incomes.
The <strong>Pareto PDF</strong> of a <strong>Pareto distribution</strong> with <strong>support</strong>, <span class="math inline">\(x &gt; \lambda\)</span>, is expressed as:</p>
<p><span class="math display">\[\begin{align}
f(x; \lambda, \alpha) = P(X = x) = \frac{\alpha \cdot \lambda^\alpha}{X^{\alpha+1}}
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(\lambda\)</span> represents the minimum wage</li>
<li><span class="math inline">\(\alpha\)</span> is the <strong>shape parameter</strong> modeling an income distribution</li>
</ul>
<p>The <strong>Pareto CDF</strong> is expressed in the below equation, where <span class="math inline">\(x &gt; \lambda\)</span>:</p>
<p><span class="math display">\[\begin{align}
f(x; \lambda, \alpha) = P(X \le x) = 1 - \left(\frac{\lambda}{x}^\alpha\right)
\end{align}\]</span></p>
<p>The mean and variance are expressed as such:</p>
<p><span class="math display">\[\begin{align}
\mathbb{E}(X) = \frac{\alpha\lambda}{\alpha - 1}, \alpha &gt; 1
\ \ \ \ \ \ \ \ \ \ \ \
VAR(X) = \frac{\alpha\lambda^2}{(\alpha - 1)^2(\alpha - 2)}, \alpha &gt; 2
\end{align}\]</span></p>
<p>Below is a naive implementation of <strong>Pareto Distribution</strong> in R code (See Figures <a href="numericalprobability.html#fig:paretopdf1">5.23</a> and <a href="numericalprobability.html#fig:paretopdf2">5.24</a>):</p>

<div class="sourceCode" id="cb251"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb251-1" data-line-number="1">pareto_pdf &lt;-<span class="st"> </span><span class="cf">function</span>(x, lambda,  alpha ) {</a>
<a class="sourceLine" id="cb251-2" data-line-number="2">    (alpha <span class="op">*</span><span class="st"> </span>lambda<span class="op">^</span>alpha) <span class="op">/</span><span class="st"> </span>(x<span class="op">^</span>(alpha <span class="op">+</span><span class="st"> </span><span class="dv">1</span>))</a>
<a class="sourceLine" id="cb251-3" data-line-number="3">}</a>
<a class="sourceLine" id="cb251-4" data-line-number="4">pareto_cdf &lt;-<span class="st"> </span><span class="cf">function</span>(x, lambda, alpha) {</a>
<a class="sourceLine" id="cb251-5" data-line-number="5">    <span class="dv">1</span> <span class="op">-</span><span class="st"> </span>(lambda<span class="op">^</span>alpha <span class="op">/</span><span class="st"> </span>x)</a>
<a class="sourceLine" id="cb251-6" data-line-number="6">}</a>
<a class="sourceLine" id="cb251-7" data-line-number="7">pareto_area &lt;-<span class="st"> </span><span class="cf">function</span>(x, lambda, alpha) {</a>
<a class="sourceLine" id="cb251-8" data-line-number="8">    a =<span class="st"> </span><span class="dv">1</span>; b =<span class="st"> </span>x     <span class="co"># boundaries</span></a>
<a class="sourceLine" id="cb251-9" data-line-number="9">    area =<span class="st"> </span><span class="kw">seq</span>(a, b, <span class="dt">length.out=</span><span class="dv">50</span>)     <span class="co"># area</span></a>
<a class="sourceLine" id="cb251-10" data-line-number="10">    x =<span class="st"> </span><span class="kw">c</span>(a, area , b)</a>
<a class="sourceLine" id="cb251-11" data-line-number="11">    y =<span class="st"> </span><span class="kw">c</span>(<span class="dv">0</span>, <span class="kw">pareto_pdf</span>(area, lambda, alpha), <span class="dv">0</span>)</a>
<a class="sourceLine" id="cb251-12" data-line-number="12">    <span class="kw">polygon</span>(x, y, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>)    </a>
<a class="sourceLine" id="cb251-13" data-line-number="13">}</a>
<a class="sourceLine" id="cb251-14" data-line-number="14"><span class="co">#Plotting PDF and CDF (Area for alpha=1, beta=1)</span></a>
<a class="sourceLine" id="cb251-15" data-line-number="15"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">8</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="dv">2</span>), </a>
<a class="sourceLine" id="cb251-16" data-line-number="16">     <span class="dt">xlab=</span><span class="st">&quot;support&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;probability density&quot;</span>,</a>
<a class="sourceLine" id="cb251-17" data-line-number="17">     <span class="dt">main=</span><span class="st">&quot;PDF (Pareto Distribution)&quot;</span>,  <span class="dt">frame=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb251-18" data-line-number="18"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb251-19" data-line-number="19"><span class="kw">abline</span>(<span class="dt">h=</span><span class="dv">0</span>, <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb251-20" data-line-number="20">p =<span class="st"> </span><span class="kw">pareto_cdf</span>(<span class="dt">x=</span><span class="dv">2</span>, <span class="dt">lambda=</span><span class="fl">0.5</span>, <span class="dt">alpha=</span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb251-21" data-line-number="21"><span class="kw">pareto_area</span>(<span class="dt">x=</span><span class="dv">2</span>, <span class="dt">lambda=</span><span class="fl">0.5</span>, <span class="dt">alpha=</span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb251-22" data-line-number="22"><span class="kw">curve</span>(<span class="kw">pareto_pdf</span>(x, <span class="dt">lambda=</span><span class="fl">0.5</span>, <span class="dt">alpha=</span><span class="dv">1</span>), <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb251-23" data-line-number="23"><span class="kw">curve</span>(<span class="kw">pareto_pdf</span>(x, <span class="dt">lambda=</span><span class="dv">1</span>, <span class="dt">alpha=</span><span class="dv">1</span>),   <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, </a>
<a class="sourceLine" id="cb251-24" data-line-number="24">      <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb251-25" data-line-number="25"><span class="kw">curve</span>(<span class="kw">pareto_pdf</span>(x, <span class="dt">lambda=</span><span class="fl">1.5</span>, <span class="dt">alpha=</span><span class="dv">1</span>), <span class="dt">col=</span><span class="st">&quot;brown&quot;</span>, </a>
<a class="sourceLine" id="cb251-26" data-line-number="26">      <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb251-27" data-line-number="27"><span class="kw">curve</span>(<span class="kw">pareto_pdf</span>(x, <span class="dt">lambda=</span><span class="dv">2</span>, <span class="dt">alpha=</span><span class="dv">1</span>),   <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb251-28" data-line-number="28"></a>
<a class="sourceLine" id="cb251-29" data-line-number="29"><span class="kw">text</span>(<span class="fl">1.2</span>,<span class="fl">0.2</span>, <span class="dt">label=</span><span class="st">&quot;(cdf)&quot;</span>, <span class="dt">col=</span><span class="st">&quot;black&quot;</span>)</a>
<a class="sourceLine" id="cb251-30" data-line-number="30"><span class="kw">text</span>(<span class="fl">1.5</span>, <span class="fl">0.1</span>, <span class="dt">label=</span><span class="kw">paste</span>(<span class="st">&quot;Area = &quot;</span>, <span class="kw">round</span>(p,<span class="dv">5</span>), <span class="dt">sep=</span><span class="st">&quot;&quot;</span>), </a>
<a class="sourceLine" id="cb251-31" data-line-number="31">     <span class="dt">ce=</span><span class="fl">0.80</span>, <span class="dt">col=</span><span class="st">&quot;black&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:paretopdf1"></span>
<img src="DS_files/figure-html/paretopdf1-1.png" alt="Pareto Distribution (PDF)" width="70%" />
<p class="caption">
Figure 5.23: Pareto Distribution (PDF)
</p>
</div>
<div class="sourceCode" id="cb252"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb252-1" data-line-number="1"><span class="co">#Plotting CDF</span></a>
<a class="sourceLine" id="cb252-2" data-line-number="2"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="dv">2</span><span class="op">:</span><span class="dv">30</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="dv">1</span>), </a>
<a class="sourceLine" id="cb252-3" data-line-number="3">     <span class="dt">xlab=</span><span class="st">&quot;support&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;cumulative density&quot;</span>,</a>
<a class="sourceLine" id="cb252-4" data-line-number="4">     <span class="dt">main=</span><span class="st">&quot;CDF (Pareto Distribution)&quot;</span>,  <span class="dt">frame=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb252-5" data-line-number="5"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb252-6" data-line-number="6"><span class="kw">abline</span>(<span class="dt">h=</span><span class="dv">0</span>, <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb252-7" data-line-number="7">x =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">15</span>, <span class="dt">length.out=</span><span class="dv">500</span>)</a>
<a class="sourceLine" id="cb252-8" data-line-number="8"><span class="kw">curve</span>(<span class="kw">pareto_cdf</span>(x, <span class="dt">lambda=</span><span class="fl">0.5</span>, <span class="dt">alpha=</span><span class="dv">1</span>), <span class="dt">col=</span><span class="st">&quot;brown&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb252-9" data-line-number="9"><span class="kw">curve</span>(<span class="kw">pareto_cdf</span>(x, <span class="dt">lambda=</span><span class="dv">1</span>, <span class="dt">alpha=</span><span class="dv">1</span>), <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>,   <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb252-10" data-line-number="10"><span class="kw">curve</span>(<span class="kw">pareto_cdf</span>(x, <span class="dt">lambda=</span><span class="fl">1.5</span>, <span class="dt">alpha=</span><span class="dv">1</span>), <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb252-11" data-line-number="11"><span class="kw">curve</span>(<span class="kw">pareto_cdf</span>(x, <span class="dt">lambda=</span><span class="dv">2</span>, <span class="dt">alpha=</span><span class="dv">1</span>), <span class="dt">col=</span><span class="st">&quot;red&quot;</span>,   <span class="dt">add=</span><span class="ot">TRUE</span> )</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:paretopdf2"></span>
<img src="DS_files/figure-html/paretopdf2-1.png" alt="Pareto Distribution (CDF)" width="70%" />
<p class="caption">
Figure 5.24: Pareto Distribution (CDF)
</p>
</div>

</div>
<div id="normal-distribution" class="section level3 hasAnchor">
<h3><span class="header-section-number">5.9.13</span> Normal distribution <a href="numericalprobability.html#normal-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Normal distribution</strong>, also called <strong>Gaussian distribution</strong>, models a <strong>continuous distribution</strong> written as:</p>
<p><span class="math display">\[\begin{align}
X \sim \mathcal{N}(\mu, \sigma^2)
\end{align}\]</span></p>
<p>The <strong>Normal PDF</strong> of a <strong>Normal distribution</strong> with <strong>support</strong> <span class="math inline">\(x \in \mathbb{R}\)</span> is expressed as:</p>
<p><span class="math display">\[\begin{align}
f(x; \mu, \sigma) = P(X =  x) = \frac{1}{\sigma \sqrt{2\pi}} exp\left[-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2\right]
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(\mu\)</span> is the average or mean of the distribution, where <span class="math inline">\(-\infty &lt; \mu &lt; \infty\)</span></li>
<li><span class="math inline">\(\sigma^2\)</span> is the variance</li>
<li><span class="math inline">\(\sigma\)</span> is the standard deviation.</li>
</ul>
<p>Note that, geometrically, <span class="math inline">\(\mu\)</span> controls the location of the <strong>bell-shaped</strong> curve, and <span class="math inline">\(\sigma\)</span> controls the shape or scale of the curve. We discuss this further in Chapter <strong>7</strong> (<strong>Bayesian Computation I</strong>) under <strong>Likelihood</strong> Subsection under <strong>Bayes Theorem</strong> Section.</p>
<p>See Figure <a href="numericalprobability.html#fig:gaussianpdf">5.8</a> for the bell-shaped curve of standard normal distribution.</p>
<p>The <span class="math inline">\(\frac{1}{\sqrt{2\pi}}\)</span> is a normalizing constant that helps bring the probability equal to one. That is because if we remove the normalizing constant, then the <strong>probability area</strong> will not integrate into one; instead, we get (<span class="math inline">\(\sqrt{2\pi}\)</span>):</p>
<p><span class="math display">\[\begin{align}
\int_{-\infty}^\infty  exp\left[-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2\right] dx = \sqrt{2\pi}
\end{align}\]</span></p>
<p>To understand the derivation, investigate <strong>Gaussian integrals with polar coordinates</strong>.</p>
<p>Now, if we add the normalizing constant based on the following integration (for continuous distribution), we get:</p>
<p><span class="math display">\[\begin{align}
\frac{1}{\sqrt{2\pi}} \int_{-\infty}^\infty exp\left[-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2\right] dx =
\frac{1}{\sqrt{2\pi}} \left(\sqrt{2\pi}\right) = 1
\end{align}\]</span></p>
<p>On the other hand, the fraction <span class="math inline">\(\frac{1}{2}\)</span> in the exponent exists to transform the variance into a unit variance (and effectively into a unit standard deviation).</p>
<p>Additionally, the negative sign in the exponent exists to flip the quadratic parabola so that its vertex points upwards geometrically, making the shape a bell shape.</p>
<p>Finally, the exponent expression describes the shape of the curve (e.g., bell shape). If we drop the constant, this does not affect the shape or proportionality described by the exponent.</p>
<p>The <strong>Normal CDF</strong> is expressed in the below equation (wikipedia 2020), where <span class="math inline">\(x \ge 0\)</span> and <span class="math inline">\(\sigma &gt; 0\)</span>:</p>
<p><span class="math display">\[\begin{align}
\mathcal{F}(x; \mu, \sigma^2) = P(X \le x) = \frac{1}{2} + \frac{1}{2} 
erf\left(  \frac{( x-\mu)}{2\sqrt{\sigma}} \right)
\end{align}\]</span></p>
<p>where <strong>erf</strong>, <strong>error function</strong>, is written as:</p>
<p><span class="math display">\[\begin{align}
erf(x) = \frac{2}{\sqrt{\pi}}\int_0^x e^{-t^2} dt
\end{align}\]</span></p>
<p>here we can use an approximation for <strong>erf</strong>:</p>
<p><span class="math display">\[\begin{align}
erf(x) \approx tanh\left(\frac{x\pi}{\sqrt{6}}\right)
\end{align}\]</span></p>
<p>See Figure <a href="numericalprobability.html#fig:erf">5.28</a> for <strong>Gauss error function</strong>.</p>
<p>The R code below draws a scattered plot and normal distribution. See Figure <a href="numericalprobability.html#fig:statistics1">5.25</a>.</p>

<div class="sourceCode" id="cb253"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb253-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">142</span>)</a>
<a class="sourceLine" id="cb253-2" data-line-number="2"><span class="co"># Generate random values for random variable x </span></a>
<a class="sourceLine" id="cb253-3" data-line-number="3"><span class="co"># using standard normal distribution.</span></a>
<a class="sourceLine" id="cb253-4" data-line-number="4">size=<span class="dv">500</span></a>
<a class="sourceLine" id="cb253-5" data-line-number="5">x =<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n=</span>size, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb253-6" data-line-number="6"><span class="co"># Draw the scattered plot.</span></a>
<a class="sourceLine" id="cb253-7" data-line-number="7"><span class="kw">plot</span>(x, <span class="dt">lwd=</span><span class="dv">1</span>, <span class="dt">pch=</span><span class="dv">16</span>, <span class="dt">col=</span><span class="st">&quot;black&quot;</span>, <span class="dt">main=</span><span class="st">&quot;Scattered Plot&quot;</span>,</a>
<a class="sourceLine" id="cb253-8" data-line-number="8"><span class="dt">ylab=</span><span class="st">&quot;Response (Y)&quot;</span>, <span class="dt">xlab=</span><span class="st">&quot;Predictor (X)&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:statistics1"></span>
<img src="DS_files/figure-html/statistics1-1.png" alt="Normal Distribution" width="60%" />
<p class="caption">
Figure 5.25: Normal Distribution
</p>
</div>
<div class="sourceCode" id="cb254"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb254-1" data-line-number="1">breaks=<span class="dv">20</span></a>
<a class="sourceLine" id="cb254-2" data-line-number="2"><span class="co"># Draw the standard normal distribution.</span></a>
<a class="sourceLine" id="cb254-3" data-line-number="3"><span class="kw">hist</span>(x, <span class="dt">breaks=</span>breaks, <span class="dt">prob=</span><span class="ot">TRUE</span>,   <span class="dt">xlim=</span><span class="kw">range</span>(<span class="op">-</span><span class="dv">4</span>,<span class="dv">4</span>),</a>
<a class="sourceLine" id="cb254-4" data-line-number="4">       <span class="dt">main=</span><span class="st">&#39;Standard Normal Distribution&#39;</span>, <span class="dt">xlab=</span><span class="st">&#39;Standard Deviation&#39;</span>)</a>
<a class="sourceLine" id="cb254-5" data-line-number="5"><span class="kw">curve</span>(<span class="kw">dnorm</span>(x, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span><span class="dv">1</span>), <span class="dt">add=</span><span class="ot">TRUE</span>, <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:statistics2"></span>
<img src="DS_files/figure-html/statistics2-1.png" alt="Normal Distribution" width="60%" />
<p class="caption">
Figure 5.26: Normal Distribution
</p>
</div>

<p>Note that a normal distribution with mean = 0 and standard deviation = 1 is also called a <strong>unit normal</strong>.</p>
<p>For <strong>multivariate normal distribution (MVN)</strong>, we can use the following similar notation but with vectorized parameters:</p>
<p><span class="math display">\[\begin{align}
X_{(p)} \sim \mathcal{N}\left(\mu_{(p)}, \Sigma_{(pxp)}\right)
\end{align}\]</span></p>
<p><span class="math display">\[\begin{align*}
\mu_{(p)} = \left(\begin{array}{cc}\mu_1 \\ \mu_2 \\ \vdots \\ \mu_p \end{array}\right)
\ \ \ \ \ \ \
\Sigma_{(pxp)} = 
\left(\begin{array}{cccc}
\sigma^2_{11} &amp; \sigma^2_{12} &amp; \cdots &amp;\sigma^2_{1p} \\ 
\sigma^2_{21} &amp; \sigma^2_{22} &amp; \cdots &amp;\sigma^2_{2p} \\ 
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ 
\sigma^2_{p1} &amp; \sigma^2_{p2} &amp; \cdots &amp;\sigma^2_{pp} \\ 
\end{array}\right)_{pxp}
\end{align*}\]</span></p>
<p>where: <span class="math inline">\(\Sigma_{(pxp)}\)</span> is <strong>symmetric positive-definite</strong>.</p>
<p>An <strong>MVN PDF</strong> is written as:</p>
<p><span class="math display">\[\begin{align}
f(x_{(p)}; \mu_{(p)}, \Sigma_{(pxp)}) 
&amp;= P(X = x_{(p)})\\
&amp;=  \frac{1}{|\Sigma_{(pxp)}|^\frac{1}{2} (2\pi)^{\frac{p}{2}}} exp\left[-\frac{1}{2}(x-\mu)^T\Sigma^{-1}_{(pxp)}( x - \mu)\right]
\end{align}\]</span></p>
<p>For example, given a bivariate normal distribution:</p>
<p><span class="math display">\[\begin{align}
f(x_{(p)}; \mu_{(p)}, \Sigma_{(pxp)}) &amp;= 
\frac{1}{2\pi \left[\begin{array}{llll} \sigma_{11}^2 &amp; \sigma_{12}^2 \\ \sigma_{21}^2 &amp; \sigma_{22}^2 \end{array}\right]_{(2x1)}^{\frac{1}{2}}} \times \nonumber \\
&amp;\exp\left[-\frac{1}{2}
 \left[\begin{array}{l} x_1 - \mu_1 \\ x_2 - \mu_2 \end{array}\right]^T_{(2x1)}
 \left[\begin{array}{ll} \sigma_{11}^2 &amp; \sigma_{12}^2 \\ \sigma_{21}^2 &amp; \sigma_{22}^2 \end{array}\right]^{-1}_{(2x2)}
 \left[\begin{array}{l} x_1 - \mu_1 \\ x_2 - \mu_2 \end{array}\right]_{(2x1)}
\right]  \nonumber
\end{align}\]</span></p>
<p>Note that a vector <strong>x</strong> may follow a set of independent Gaussian normal distributions. Thus, we also can write this way:</p>
<p><span class="math display">\[\begin{align}
f(x_{(p)}; \mu_{(p)}, \Sigma_{(pxp)}) = 
\prod_{i=1}^n
\frac{1}{ \sqrt{2\pi\sigma_i}} exp\left[-\frac{1}{2}\frac{(x_1-\mu_1)^2}{\sigma_i^2}\right]
\end{align}\]</span></p>
<p>Here is a simple implementation of multivariate normal (MVN) distribution (specifically, bivariate):</p>

<div class="sourceCode" id="cb255"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb255-1" data-line-number="1"><span class="kw">library</span>(mvtnorm)</a>
<a class="sourceLine" id="cb255-2" data-line-number="2"><span class="kw">set.seed</span>(<span class="dv">142</span>)</a>
<a class="sourceLine" id="cb255-3" data-line-number="3">sample_size =<span class="st"> </span>n =<span class="st"> </span><span class="dv">40</span></a>
<a class="sourceLine" id="cb255-4" data-line-number="4">x =<span class="st"> </span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">5</span>,<span class="dv">5</span>, <span class="dt">length.out =</span> <span class="dv">40</span>)</a>
<a class="sourceLine" id="cb255-5" data-line-number="5">y =<span class="st"> </span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">5</span>,<span class="dv">5</span>, <span class="dt">length.out =</span> <span class="dv">40</span>)</a>
<a class="sourceLine" id="cb255-6" data-line-number="6">mu =<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>,<span class="dv">2</span>); sigma =<span class="st"> </span><span class="kw">diag</span>(<span class="dv">1</span>,<span class="dv">2</span>)</a>
<a class="sourceLine" id="cb255-7" data-line-number="7">g =<span class="st"> </span><span class="kw">expand.grid</span>(x, y)</a>
<a class="sourceLine" id="cb255-8" data-line-number="8">z &lt;-<span class="st"> </span><span class="kw">matrix</span> ( <span class="kw">dmvnorm</span>(<span class="kw">as.matrix</span>(g), <span class="dt">mean=</span>mu, <span class="dt">sigma=</span>sigma), <span class="dt">nrow =</span> n )</a>
<a class="sourceLine" id="cb255-9" data-line-number="9"><span class="kw">persp</span>(x,y,z, <span class="dt">phi=</span><span class="dv">30</span>, <span class="dt">theta=</span><span class="dv">25</span>,</a>
<a class="sourceLine" id="cb255-10" data-line-number="10">      <span class="dt">expand =</span> <span class="fl">0.5</span>, <span class="dt">shade =</span> <span class="fl">0.10</span>,</a>
<a class="sourceLine" id="cb255-11" data-line-number="11">      <span class="dt">main=</span><span class="st">&quot;Bivariate Normal Distribution&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:multinormal"></span>
<img src="embed0069.1.png" alt="Bivariate Normal Distribution" width="80%" />
<p class="caption">
Figure 5.27: Bivariate Normal Distribution
</p>
</div>

</div>
<div id="wald-distribution" class="section level3 hasAnchor">
<h3><span class="header-section-number">5.9.14</span> Wald Distribution <a href="numericalprobability.html#wald-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Wald Distribution</strong> is also known as <strong>Inverse Gaussian Distribution</strong> and is written as:</p>
<p><span class="math display">\[\begin{align}
X \sim  \mathcal{IG}(\mu, \lambda)
\end{align}\]</span></p>
<p>The <strong>Wald PDF</strong> of a <strong>Normal distribution</strong> with <strong>support</strong> <span class="math inline">\((0, \infty)\)</span> is expressed as:</p>
<p><span class="math display">\[\begin{align}
f(x; \mu, \lambda) = P(X =  x) = \sqrt{\frac{\lambda}{2\pi x^3}} exp\left(-\frac{\lambda(x-\mu)^2}{2\mu^2 x}\right)
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(\mu\)</span> is the average or mean of the distribution (location),</li>
<li><span class="math inline">\(\lambda\)</span> is the standard deviation (shape).</li>
</ul>
<p>The <strong>Wald CDF</strong> is expressed in the below equation:</p>
<p><span class="math display">\[\begin{align}
\mathcal{F}(x; \mu, \lambda) = 
\Phi \left(\sqrt{\frac{\lambda}{x}}\left(\frac{x}{\mu} - 1\right) \right)
+ exp\left(\frac{2\lambda}{\mu}\right)\Phi \left(
\sqrt{\frac{\lambda}{x}}\left(\frac{x}{\mu} + 1\right)
\right)
\end{align}\]</span></p>
<p><strong>Wald distribution</strong> tends to be a skewed <strong>Gaussian</strong> distribution, such that if <span class="math inline">\(\lambda\)</span> increases to infinity, the <strong>Wald</strong> distribution eventually becomes a <strong>Gaussian</strong> distribution.</p>
</div>
<div id="log-normal-distribution" class="section level3 hasAnchor">
<h3><span class="header-section-number">5.9.15</span> Log-normal Distribution <a href="numericalprobability.html#log-normal-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A <strong>Log-normal distribution</strong> models a <strong>continuous distribution</strong> in which the logarithm of its random variable models a <strong>Normal (Gaussian) distribution</strong> and is written as:</p>
<p><span class="math display">\[\begin{align}
X \sim ln\ \mathcal{N}(\mu, \sigma^2)
\end{align}\]</span></p>
<p>The <strong>Log-normal PDF</strong> is expressed in the below equation, where <span class="math inline">\(x \ge 0\)</span>:</p>
<p><span class="math display">\[\begin{align}
f(x; \mu, \sigma^2) = \frac{1}{x\sqrt{2\pi\sigma^2}} e^{-\frac{(ln\ x-\mu)^2}{2\sigma^2}}
\end{align}\]</span></p>
<p>The <strong>Log-normal CDF</strong> is expressed in the below equation:</p>
<p><span class="math display">\[\begin{align}
\mathcal{F}(x; \mu, \sigma^2) = P(X \le x) = \frac{1}{2} + \frac{1}{2} erf\left(  \frac{ln\ x-\mu}{\sigma\sqrt{2}} \right)
\end{align}\]</span></p>
<p>where <strong>erf</strong>, <strong>error function</strong>, is written as:</p>
<p><span class="math display">\[\begin{align}
erf(x) {}&amp;= \frac{2}{\sqrt{\pi}}\int_0^x e^{-t^2} dt \\
&amp;\approx tanh\left(\frac{x\pi}{\sqrt{6}}\right)
\end{align}\]</span></p>
<p><strong>ERF</strong> is a sigmoid function as shown in Figure <a href="numericalprobability.html#fig:erf">5.28</a>. Note that we use <strong>tanh</strong> as an approximation only to the integral equation.</p>

<div class="sourceCode" id="cb256"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb256-1" data-line-number="1">erf &lt;-<span class="st"> </span><span class="cf">function</span>(x) {</a>
<a class="sourceLine" id="cb256-2" data-line-number="2">    <span class="kw">tanh</span>(x<span class="op">*</span>pi<span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">6</span>))</a>
<a class="sourceLine" id="cb256-3" data-line-number="3">}</a>
<a class="sourceLine" id="cb256-4" data-line-number="4">x =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">length.out=</span><span class="dv">100</span>)</a>
<a class="sourceLine" id="cb256-5" data-line-number="5"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="op">-</span><span class="dv">2</span>,<span class="dv">2</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>), </a>
<a class="sourceLine" id="cb256-6" data-line-number="6">     <span class="dt">xlab=</span><span class="st">&quot;x&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;y&quot;</span>,</a>
<a class="sourceLine" id="cb256-7" data-line-number="7">     <span class="dt">main=</span><span class="st">&quot;Gauss Error Function&quot;</span>)</a>
<a class="sourceLine" id="cb256-8" data-line-number="8"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb256-9" data-line-number="9"><span class="kw">curve</span>(<span class="kw">erf</span>(x), <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>, <span class="dt">lwd=</span><span class="dv">2</span>,<span class="dt">add=</span><span class="ot">TRUE</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:erf"></span>
<img src="DS_files/figure-html/erf-1.png" alt="Gauss Error Function" width="70%" />
<p class="caption">
Figure 5.28: Gauss Error Function
</p>
</div>

<p>Note that <strong>Log-normal distribution</strong> is more advantageous over <strong>Normal distribution</strong> for situations where the distribution cannot take a negative value.</p>
<p>Below is a naive implementation of <strong>Log-normal distribution</strong> in R code:</p>

<div class="sourceCode" id="cb257"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb257-1" data-line-number="1">erf &lt;-<span class="st"> </span><span class="cf">function</span>(x, a, b ) { </a>
<a class="sourceLine" id="cb257-2" data-line-number="2">    <span class="kw">tanh</span>(x<span class="op">*</span>pi<span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">6</span>)) <span class="co"># an approximation.</span></a>
<a class="sourceLine" id="cb257-3" data-line-number="3">}</a>
<a class="sourceLine" id="cb257-4" data-line-number="4">logpdf &lt;-<span class="st"> </span><span class="cf">function</span>(x, mean, sd ) {</a>
<a class="sourceLine" id="cb257-5" data-line-number="5">    <span class="co"># Log-normal Distribution</span></a>
<a class="sourceLine" id="cb257-6" data-line-number="6">    ( <span class="dv">1</span> <span class="op">/</span><span class="st"> </span>(x<span class="op">*</span><span class="kw">sqrt</span>(<span class="dv">2</span><span class="op">*</span>pi<span class="op">*</span>sd))) <span class="op">*</span><span class="st"> </span><span class="kw">exp</span>( <span class="op">-</span><span class="st"> </span>(<span class="kw">log</span>(x)<span class="op">-</span>mean)<span class="op">^</span><span class="dv">2</span><span class="op">/</span>(<span class="dv">2</span><span class="op">*</span>sd))</a>
<a class="sourceLine" id="cb257-7" data-line-number="7">}</a>
<a class="sourceLine" id="cb257-8" data-line-number="8">logcdf &lt;-<span class="st"> </span><span class="cf">function</span>(x, mean, sd) {</a>
<a class="sourceLine" id="cb257-9" data-line-number="9">    <span class="dv">1</span><span class="op">/</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span><span class="dv">1</span><span class="op">/</span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="kw">erf</span>((<span class="kw">log</span>(x) <span class="op">-</span><span class="st"> </span>mean)<span class="op">/</span>(<span class="kw">sqrt</span>(<span class="dv">2</span><span class="op">*</span>sd)))</a>
<a class="sourceLine" id="cb257-10" data-line-number="10">}</a>
<a class="sourceLine" id="cb257-11" data-line-number="11">logarea &lt;-<span class="st"> </span><span class="cf">function</span>(x, mean, sd) {</a>
<a class="sourceLine" id="cb257-12" data-line-number="12">    a =<span class="st"> </span><span class="fl">0.01</span>; b =<span class="st"> </span>x <span class="co"># boundaries</span></a>
<a class="sourceLine" id="cb257-13" data-line-number="13">    area =<span class="st"> </span><span class="kw">seq</span>(a, b, <span class="dt">length.out=</span><span class="dv">50</span>) <span class="co"># area</span></a>
<a class="sourceLine" id="cb257-14" data-line-number="14">    x =<span class="st"> </span><span class="kw">c</span>(a, area , b)</a>
<a class="sourceLine" id="cb257-15" data-line-number="15">    y =<span class="st"> </span><span class="kw">c</span>(<span class="dv">0</span>, <span class="kw">logpdf</span>(area, <span class="dv">0</span>, <span class="dv">1</span>), <span class="dv">0</span>)</a>
<a class="sourceLine" id="cb257-16" data-line-number="16">    <span class="kw">polygon</span>(x, y, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>)</a>
<a class="sourceLine" id="cb257-17" data-line-number="17">}</a></code></pre></div>
<p>And we plot the distribution as shown in Figure <a href="numericalprobability.html#fig:lognormal">5.29</a>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:lognormal"></span>
<img src="DS_files/figure-html/lognormal-1.png" alt="Log-normal Distribution" width="70%" />
<p class="caption">
Figure 5.29: Log-normal Distribution
</p>
</div>
<div class="sourceCode" id="cb258"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb258-1" data-line-number="1"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="dv">10</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="op">-</span><span class="fl">0.01</span>,<span class="fl">0.8</span>), </a>
<a class="sourceLine" id="cb258-2" data-line-number="2">     <span class="dt">xlab=</span><span class="st">&quot;spread (variance)&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;probability density&quot;</span>,</a>
<a class="sourceLine" id="cb258-3" data-line-number="3">     <span class="dt">main=</span><span class="st">&quot;Log-normal Distribution&quot;</span> )</a>
<a class="sourceLine" id="cb258-4" data-line-number="4"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb258-5" data-line-number="5"><span class="kw">abline</span>(<span class="dt">h=</span><span class="dv">0</span>, <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>)</a>
<a class="sourceLine" id="cb258-6" data-line-number="6">p =<span class="st"> </span><span class="kw">logcdf</span>(<span class="dt">x=</span><span class="dv">4</span>, <span class="dv">0</span>, <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb258-7" data-line-number="7"><span class="kw">logarea</span>(<span class="dt">x=</span><span class="dv">4</span>, <span class="dv">0</span>, <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb258-8" data-line-number="8"><span class="kw">curve</span>(<span class="kw">logpdf</span>(x, <span class="dv">0</span>, <span class="fl">1.0</span>), <span class="dt">n=</span><span class="dv">500</span>, <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb258-9" data-line-number="9"><span class="kw">curve</span>(<span class="kw">logpdf</span>(x, <span class="dv">1</span>, <span class="fl">0.7</span>), <span class="dt">n=</span><span class="dv">500</span>, <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb258-10" data-line-number="10"><span class="kw">curve</span>(<span class="kw">logpdf</span>(x, <span class="dv">2</span>, <span class="fl">0.5</span>), <span class="dt">n=</span><span class="dv">500</span>, <span class="dt">col=</span><span class="st">&quot;brown&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb258-11" data-line-number="11"><span class="kw">text</span>(<span class="fl">1.5</span>,<span class="fl">0.09</span>, <span class="dt">label=</span><span class="st">&quot;(cdf)&quot;</span>, <span class="dt">col=</span><span class="st">&quot;black&quot;</span>)</a>
<a class="sourceLine" id="cb258-12" data-line-number="12"><span class="kw">text</span>(<span class="fl">1.5</span>, <span class="fl">0.05</span>, <span class="dt">label=</span><span class="kw">paste</span>(<span class="st">&quot;Area = &quot;</span>, <span class="kw">round</span>(p, <span class="dv">5</span>), <span class="dt">sep=</span><span class="st">&quot;&quot;</span>), </a>
<a class="sourceLine" id="cb258-13" data-line-number="13">     <span class="dt">ce=</span><span class="dv">1</span>, <span class="dt">col=</span><span class="st">&quot;black&quot;</span>)</a>
<a class="sourceLine" id="cb258-14" data-line-number="14"><span class="kw">text</span>(<span class="dv">4</span>, <span class="fl">-0.01</span>, <span class="dt">label=</span><span class="st">&quot;q=2&quot;</span>)</a></code></pre></div>

</div>
<div id="uniform-distribution" class="section level3 hasAnchor">
<h3><span class="header-section-number">5.9.16</span> Uniform Distribution <a href="numericalprobability.html#uniform-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A <strong>Uniform distribution</strong> models a <strong>continuous distribution</strong> and is written as:</p>
<p><span class="math display">\[\begin{align}
X \sim U(a,b)
\end{align}\]</span></p>
<p>The <strong>PDF</strong> for a <strong>Uniform distribution</strong> with <strong>support</strong> <span class="math inline">\(\{a,b\} \in \mathbb{R}\)</span> and <span class="math inline">\(a &lt; b\)</span> is expressed as:</p>
<p><span class="math display">\[\begin{align}
f(x) = \begin{cases}
\frac{1}{b - a} &amp; a \le x \le b \\
0 &amp; otherwise
\end{cases} \label{eqn:eqnnumber20}
\end{align}\]</span></p>
<p>The <strong>CDF</strong> for a <strong>Uniform distribution</strong> is expressed as:</p>
<p><span class="math display">\[\begin{align}
F(x) = \begin{cases}
0 &amp; x &lt; a \\
1 &amp; x &gt; b \\
\frac{x-a}{b - a} &amp; otherwise
\end{cases} \label{eqn:eqnnumber21}
\end{align}\]</span></p>
<p>For the <strong>expected value</strong> and <strong>variance</strong> respectively, we have:</p>
<p><span class="math display">\[\begin{align}
\mu = \frac{a+b}{2}\ \ \ \ \ \ \ \ \ \ \ \ \ \sigma = \sqrt{\frac{(b-a)^2}{12}}
\end{align}\]</span></p>
<p>Given the simple formula above, the <strong>PDF</strong> and <strong>CDF</strong> for <strong>Uniform distribution</strong> should be simple to implement in R code (we skip the implementation).</p>
<p>The next few sections cover <strong>T-distribution</strong>, <strong>F-distribution</strong>, <strong>Chi-Square distribution</strong>, <strong>Wishart distribution</strong>, and <strong>Mixture distribution</strong> among a few others. We introduce the <strong>CDF</strong> of the subsequent distributions, which come with complexity because of special functions such as <strong>Gamma, Beta, Continued Fraction, and HyperGeometric functions</strong>. While these complex <strong>CDFs</strong> are known or used in practice, continued efforts may still be ongoing to explore better alternatives.</p>
</div>
<div id="t-distribution" class="section level3 hasAnchor">
<h3><span class="header-section-number">5.9.17</span> T-Distribution <a href="numericalprobability.html#t-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A <strong>T-distribution</strong>, also called <strong>Studentâs distribution</strong>, models a <strong>continuous distribution</strong> sampled from a <strong>Normal distribution</strong> and is written as:</p>
<p><span class="math display">\[\begin{align}
X_s \sim T(\nu)\ \ \ \ \leftarrow\ \ \ \ \ X_p \sim iid\ N(\mu, \sigma^2)
\end{align}\]</span></p>
<p>The <strong>T-distribution</strong> is used for <strong>T-statistic tests</strong> to analyze samples of data with smaller sample size - typical suggested size is 30 or less. We discuss the <strong>T-Test</strong> in later sections.  </p>
<p>It can be said that a <strong>T-distribution</strong> is independently and identically distributed as a <strong>normal distribution</strong> whose <strong>PDF</strong> follows a much shorter and fatter curve.</p>
<p>The <strong>PDF</strong> for a <strong>T-distribution</strong> with <strong>support</strong> <span class="math inline">\(x \in \mathbb{R}\)</span> is expressed as:</p>
<p><span class="math display">\[\begin{align}
f(x; \nu) = \frac{1} {\Gamma(\frac{\nu}{2})\sqrt{\nu\pi}} 
\Gamma\left(\frac{\nu+1}{2}\right) \left(1 + \frac{x^2}{\nu}\right)^{-\frac{\nu+1}{2}}
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(\nu\)</span> is the degrees of freedom.</li>
</ul>
<p>Here is a naive implementation of <strong>PDF</strong> for a symmetric (central) <strong>T-Distribution</strong> in R code:</p>

<div class="sourceCode" id="cb259"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb259-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">1</span>)</a>
<a class="sourceLine" id="cb259-2" data-line-number="2">Gamma &lt;-<span class="st"> </span><span class="cf">function</span>(n) { <span class="kw">factorial</span>(n<span class="dv">-1</span>) }</a>
<a class="sourceLine" id="cb259-3" data-line-number="3">t_pdf &lt;-<span class="st"> </span><span class="cf">function</span>(x, df) {</a>
<a class="sourceLine" id="cb259-4" data-line-number="4">    <span class="kw">Gamma</span>((df<span class="op">+</span><span class="dv">1</span>)<span class="op">/</span><span class="dv">2</span>) <span class="op">/</span><span class="st"> </span>( <span class="kw">Gamma</span>(df<span class="op">/</span><span class="dv">2</span>) <span class="op">*</span><span class="st"> </span><span class="kw">sqrt</span>(df <span class="op">*</span><span class="st"> </span>pi) ) <span class="op">*</span><span class="st"> </span></a>
<a class="sourceLine" id="cb259-5" data-line-number="5"><span class="st">    </span>( <span class="dv">1</span> <span class="op">+</span><span class="st"> </span>x<span class="op">^</span><span class="dv">2</span><span class="op">/</span>df )<span class="op">^</span>(<span class="op">-</span>(df<span class="op">+</span><span class="dv">1</span>)<span class="op">/</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb259-6" data-line-number="6">}</a>
<a class="sourceLine" id="cb259-7" data-line-number="7">population =<span class="st"> </span><span class="kw">round</span>(<span class="kw">seq</span>(<span class="dv">4</span>,<span class="dv">7</span>, <span class="dt">length.out=</span><span class="dv">10</span>),<span class="dv">1</span>)</a>
<a class="sourceLine" id="cb259-8" data-line-number="8">x =<span class="st"> </span><span class="kw">sample</span>(population, <span class="dt">size=</span><span class="dv">20</span>, <span class="dt">replace=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb259-9" data-line-number="9"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="op">-</span><span class="dv">4</span>,<span class="dv">4</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="fl">0.5</span>), </a>
<a class="sourceLine" id="cb259-10" data-line-number="10">     <span class="dt">xlab=</span><span class="st">&quot;T value&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;probability density&quot;</span>,</a>
<a class="sourceLine" id="cb259-11" data-line-number="11">     <span class="dt">main=</span><span class="st">&quot;T Distribution (PDF)&quot;</span>)</a>
<a class="sourceLine" id="cb259-12" data-line-number="12"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb259-13" data-line-number="13"><span class="kw">curve</span>(<span class="kw">dnorm</span>(x, <span class="dv">0</span>, <span class="dv">1</span>), <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb259-14" data-line-number="14"><span class="kw">curve</span>(<span class="kw">t_pdf</span>(x, <span class="dv">10</span>), <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb259-15" data-line-number="15"><span class="kw">curve</span>(<span class="kw">t_pdf</span>(x, <span class="dv">2</span>), <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb259-16" data-line-number="16"><span class="kw">curve</span>(<span class="kw">t_pdf</span>(x, <span class="dv">1</span>), <span class="dt">col=</span><span class="st">&quot;brown&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">add=</span><span class="ot">TRUE</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:tdist"></span>
<img src="DS_files/figure-html/tdist-1.png" alt="T-Distribution (PDF)" width="70%" />
<p class="caption">
Figure 5.30: T-Distribution (PDF)
</p>
</div>

<p>It can be noticed that as the degree of freedom, <span class="math inline">\(\mathbf{\nu}\)</span>, gets larger, the <strong>T-distribution</strong> gets closer to that of a <strong>Normal distribution</strong> based on <strong>PDF</strong>.</p>
<p>The <strong>CDF</strong> for a symmetric (central) <strong>T-distribution</strong> is expressed as:</p>
<p><span class="math display">\[\begin{align}
F(x; \nu) = \frac{1}{2} + \frac{1}{2} sign(x) \left[
I\left(1; \frac{\nu}{2},\frac{1}{2}\right) -  
I\left(\frac{\nu}{\nu + x^2}; \frac{\nu}{2},\frac{1}{2}\right) \right]
\end{align}\]</span></p>
<p>where:</p>
<p><span class="math display">\[\begin{align}
I_x(\alpha,\beta) = \frac{\mathcal{B}_x(\alpha,\beta)}{\mathcal{B}(\alpha,\beta)}\ \ \leftarrow\ \ \text{regularized beta function}
\end{align}\]</span></p>
<p>Moreover, as complementary, we can explore the use of <strong>continued fraction</strong> for <strong>regularized beta function</strong> instead of <strong>hypergeometric function</strong>.</p>
<p>Example, if x &lt; (a+1) / (a+b+2):</p>
<p><span class="math display">\[\begin{align}
Bx(\alpha,\beta) = \frac{ Kx(\alpha,\beta) }{a} \left[1+\frac{d_1}{1+}\frac{d_2}{1+}\frac{d_3}{1+}...\right]
\end{align}\]</span></p>
<p>where:</p>
<p><span class="math display">\[\begin{align}
Kx(\alpha,\beta) = \frac{1}{\mathcal{B}(\alpha,\beta)}x^\alpha(1-x)^\beta 
\end{align}\]</span></p>
<p>and</p>
<p><span class="math display">\[\begin{align}
d_{2m} = \frac{m(\beta-m)x}{(\alpha+2m - 1)(\alpha+2m)}\ \ \ \ \ \ \ \ \
d_{2m+1} =  -\frac{(\alpha+m)(\alpha+\beta+m)x}{(\alpha+2m)(\alpha+2m+1)}
\end{align}\]</span></p>
<p>Let us first show an implementation of <strong>continued fraction</strong> in R code (see Numerical Recipes (W.H. Press et al., 1992) in C code): </p>

<div class="sourceCode" id="cb260"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb260-1" data-line-number="1">Gamma &lt;-<span class="st"> </span><span class="cf">function</span>(n) { <span class="kw">factorial</span>(n<span class="dv">-1</span>) }</a>
<a class="sourceLine" id="cb260-2" data-line-number="2">Beta &lt;-<span class="st"> </span><span class="cf">function</span>(a,b) { <span class="kw">Gamma</span>(a)<span class="op">*</span><span class="kw">Gamma</span>(b) <span class="op">/</span><span class="st"> </span><span class="kw">Gamma</span>(a<span class="op">+</span>b)}</a>
<a class="sourceLine" id="cb260-3" data-line-number="3">even &lt;-<span class="st"> </span><span class="cf">function</span>(x, a, b, m) {</a>
<a class="sourceLine" id="cb260-4" data-line-number="4">  (m<span class="op">*</span>(b<span class="op">-</span>m)<span class="op">*</span>x) <span class="op">/</span><span class="st"> </span>((a <span class="op">+</span><span class="st"> </span><span class="dv">2</span><span class="op">*</span>m <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)<span class="op">*</span>(a<span class="op">+</span><span class="dv">2</span><span class="op">*</span>m))</a>
<a class="sourceLine" id="cb260-5" data-line-number="5">}</a>
<a class="sourceLine" id="cb260-6" data-line-number="6">odd &lt;-<span class="st"> </span><span class="cf">function</span>(x, a, b, m) {</a>
<a class="sourceLine" id="cb260-7" data-line-number="7">  <span class="op">-</span>((a<span class="op">+</span>m)<span class="op">*</span>(a<span class="op">+</span>b<span class="op">+</span>m)<span class="op">*</span>x) <span class="op">/</span><span class="st"> </span>((a<span class="op">+</span><span class="dv">2</span><span class="op">*</span>m)<span class="op">*</span>(a<span class="op">+</span><span class="dv">2</span><span class="op">*</span>m<span class="op">+</span><span class="dv">1</span>))</a>
<a class="sourceLine" id="cb260-8" data-line-number="8">}</a>
<a class="sourceLine" id="cb260-9" data-line-number="9">tiny &lt;-<span class="st"> </span><span class="cf">function</span>(z) {</a>
<a class="sourceLine" id="cb260-10" data-line-number="10">    eps =<span class="st"> </span><span class="fl">1e-30</span></a>
<a class="sourceLine" id="cb260-11" data-line-number="11">    <span class="cf">if</span> (z <span class="op">&lt;</span><span class="st"> </span>eps) { <span class="kw">return</span>(eps) }</a>
<a class="sourceLine" id="cb260-12" data-line-number="12">    z</a>
<a class="sourceLine" id="cb260-13" data-line-number="13">}</a>
<a class="sourceLine" id="cb260-14" data-line-number="14">betacf &lt;-<span class="st"> </span><span class="cf">function</span>(x, a, b, m) {</a>
<a class="sourceLine" id="cb260-15" data-line-number="15">    limit =<span class="st"> </span><span class="dv">200</span></a>
<a class="sourceLine" id="cb260-16" data-line-number="16">    epsilon =<span class="st"> </span><span class="fl">3e-14</span></a>
<a class="sourceLine" id="cb260-17" data-line-number="17">    c =<span class="st"> </span><span class="dv">1</span></a>
<a class="sourceLine" id="cb260-18" data-line-number="18">    d =<span class="st"> </span><span class="dv">1</span> <span class="op">/</span><span class="st"> </span><span class="kw">tiny</span>(<span class="dv">1</span><span class="op">-</span>(a<span class="op">+</span>b)<span class="op">*</span>x<span class="op">/</span>(a<span class="op">+</span><span class="dv">1</span>)) </a>
<a class="sourceLine" id="cb260-19" data-line-number="19">    cf =<span class="st"> </span>d</a>
<a class="sourceLine" id="cb260-20" data-line-number="20">    <span class="cf">for</span> (m <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>limit) {</a>
<a class="sourceLine" id="cb260-21" data-line-number="21">       num =<span class="st"> </span><span class="kw">even</span>(x, a, b, m)</a>
<a class="sourceLine" id="cb260-22" data-line-number="22">       d =<span class="st"> </span><span class="dv">1</span> <span class="op">/</span><span class="st"> </span><span class="kw">tiny</span>(<span class="dv">1</span><span class="op">+</span>num <span class="op">*</span><span class="st"> </span>d ) </a>
<a class="sourceLine" id="cb260-23" data-line-number="23">       c =<span class="st"> </span><span class="kw">tiny</span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>num <span class="op">/</span><span class="st"> </span>c)</a>
<a class="sourceLine" id="cb260-24" data-line-number="24">       cf =<span class="st"> </span>cf <span class="op">*</span><span class="st"> </span>d<span class="op">*</span>c</a>
<a class="sourceLine" id="cb260-25" data-line-number="25">       num =<span class="st"> </span><span class="kw">odd</span>(x, a, b, m)</a>
<a class="sourceLine" id="cb260-26" data-line-number="26">       d =<span class="st"> </span><span class="dv">1</span> <span class="op">/</span><span class="st"> </span><span class="kw">tiny</span>(<span class="dv">1</span><span class="op">+</span>num <span class="op">*</span><span class="st"> </span>d ) </a>
<a class="sourceLine" id="cb260-27" data-line-number="27">       c =<span class="st"> </span><span class="kw">tiny</span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>num<span class="op">/</span>c)</a>
<a class="sourceLine" id="cb260-28" data-line-number="28">       cf =<span class="st"> </span>cf <span class="op">*</span><span class="st"> </span>d<span class="op">*</span>c</a>
<a class="sourceLine" id="cb260-29" data-line-number="29">       <span class="cf">if</span> (<span class="kw">abs</span>(d<span class="op">*</span>c<span class="dv">-1</span>) <span class="op">&lt;</span><span class="st"> </span>epsilon) {</a>
<a class="sourceLine" id="cb260-30" data-line-number="30">           <span class="kw">return</span>(cf)</a>
<a class="sourceLine" id="cb260-31" data-line-number="31">       }</a>
<a class="sourceLine" id="cb260-32" data-line-number="32">    }</a>
<a class="sourceLine" id="cb260-33" data-line-number="33">    <span class="kw">return</span> (<span class="ot">Inf</span>)</a>
<a class="sourceLine" id="cb260-34" data-line-number="34">}</a>
<a class="sourceLine" id="cb260-35" data-line-number="35">Bx &lt;-<span class="st"> </span><span class="cf">function</span>(x, a, b) {</a>
<a class="sourceLine" id="cb260-36" data-line-number="36">   n =<span class="st"> </span><span class="kw">length</span>(x)</a>
<a class="sourceLine" id="cb260-37" data-line-number="37">   bx =<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, n)</a>
<a class="sourceLine" id="cb260-38" data-line-number="38">   <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n) {</a>
<a class="sourceLine" id="cb260-39" data-line-number="39">     <span class="cf">if</span> (x[i] <span class="op">&lt;</span><span class="st"> </span><span class="dv">0</span> <span class="op">||</span><span class="st"> </span>x[i] <span class="op">&gt;</span><span class="st"> </span><span class="dv">1</span>) {bx[i] =<span class="st"> </span><span class="dv">0</span>; <span class="cf">next</span>  }</a>
<a class="sourceLine" id="cb260-40" data-line-number="40">     k =<span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb260-41" data-line-number="41">     <span class="cf">if</span> ( <span class="dv">0</span> <span class="op">&lt;</span><span class="st"> </span>x[i] <span class="op">&amp;&amp;</span><span class="st"> </span>x[i] <span class="op">&lt;</span><span class="st"> </span><span class="dv">1</span> ) {</a>
<a class="sourceLine" id="cb260-42" data-line-number="42">        k =<span class="st"> </span><span class="dv">1</span> <span class="op">/</span><span class="st"> </span><span class="kw">Beta</span>(a,b) <span class="op">*</span><span class="st"> </span>(x[i]<span class="op">^</span>a <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span><span class="op">-</span>x[i])<span class="op">^</span>(b) )</a>
<a class="sourceLine" id="cb260-43" data-line-number="43">     }</a>
<a class="sourceLine" id="cb260-44" data-line-number="44">     <span class="cf">if</span> (x[i] <span class="op">&lt;</span><span class="st"> </span>(a<span class="op">+</span><span class="dv">1</span>) <span class="op">/</span><span class="st"> </span>(a<span class="op">+</span>b<span class="op">+</span><span class="dv">2</span>)) {</a>
<a class="sourceLine" id="cb260-45" data-line-number="45">        <span class="co"># For I(x, a, b)</span></a>
<a class="sourceLine" id="cb260-46" data-line-number="46">        bx[i] =<span class="st"> </span>(k <span class="op">/</span><span class="st"> </span>a <span class="op">*</span><span class="st"> </span><span class="kw">betacf</span>( x[i], a, b, <span class="dv">1</span>))<span class="op">*</span><span class="kw">Beta</span>(a,b)</a>
<a class="sourceLine" id="cb260-47" data-line-number="47">     } <span class="cf">else</span> {</a>
<a class="sourceLine" id="cb260-48" data-line-number="48">        <span class="co"># For I(1-x, b, a)</span></a>
<a class="sourceLine" id="cb260-49" data-line-number="49">        bx[i] =<span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>k <span class="op">/</span><span class="st"> </span>b <span class="op">*</span><span class="st"> </span><span class="kw">betacf</span>( <span class="dv">1</span><span class="op">-</span>x[i], b, a, <span class="dv">1</span>))<span class="op">*</span><span class="kw">Beta</span>(a,b)</a>
<a class="sourceLine" id="cb260-50" data-line-number="50">     }</a>
<a class="sourceLine" id="cb260-51" data-line-number="51">   }</a>
<a class="sourceLine" id="cb260-52" data-line-number="52">   <span class="kw">return</span>(bx)</a>
<a class="sourceLine" id="cb260-53" data-line-number="53">}</a>
<a class="sourceLine" id="cb260-54" data-line-number="54"><span class="co"># replaces original implementation from beta distribution section</span></a>
<a class="sourceLine" id="cb260-55" data-line-number="55">Ix &lt;-<span class="st"> </span><span class="cf">function</span>(x, a, b) { </a>
<a class="sourceLine" id="cb260-56" data-line-number="56">   <span class="kw">Bx</span>(x, a, b) <span class="op">/</span><span class="st"> </span><span class="kw">Beta</span>(a, b)</a>
<a class="sourceLine" id="cb260-57" data-line-number="57">}</a>
<a class="sourceLine" id="cb260-58" data-line-number="58">incomplete_beta &lt;-<span class="st"> </span><span class="cf">function</span>(x,a,b) { </a>
<a class="sourceLine" id="cb260-59" data-line-number="59">    <span class="kw">pbeta</span>(x,a,b) <span class="op">*</span><span class="st"> </span><span class="kw">beta</span>(a,b) <span class="co"># using built-in R package &quot;pbeta&quot;.</span></a>
<a class="sourceLine" id="cb260-60" data-line-number="60">}</a>
<a class="sourceLine" id="cb260-61" data-line-number="61">Ix_alt &lt;-<span class="cf">function</span>(x, a, b) { <span class="co"># see beta distribution chapter</span></a>
<a class="sourceLine" id="cb260-62" data-line-number="62">   <span class="kw">incomplete_beta</span>(x,a,b) <span class="op">/</span><span class="st"> </span><span class="kw">Beta</span>(a,b)</a>
<a class="sourceLine" id="cb260-63" data-line-number="63">}</a>
<a class="sourceLine" id="cb260-64" data-line-number="64">x =<span class="st"> </span><span class="kw">c</span>(<span class="fl">0.50</span>, <span class="fl">-0.50</span>)</a>
<a class="sourceLine" id="cb260-65" data-line-number="65"><span class="kw">list</span>(<span class="st">&quot;Ix&quot;</span>=<span class="kw">Ix</span>(x, <span class="dv">3</span>, <span class="dv">2</span>), <span class="st">&quot;pbeta&quot;</span>=<span class="kw">pbeta</span>(x, <span class="dv">3</span>, <span class="dv">2</span>))</a></code></pre></div>
<pre><code>## $Ix
## [1] 0.3125 0.0000
## 
## $pbeta
## [1] 0.3125 0.0000</code></pre>
<div class="sourceCode" id="cb262"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb262-1" data-line-number="1"><span class="kw">list</span>(<span class="st">&quot;Ix&quot;</span>=<span class="kw">Ix</span>(x, <span class="dv">2</span>, <span class="dv">3</span>), <span class="st">&quot;pbeta&quot;</span>=<span class="kw">pbeta</span>(x, <span class="dv">2</span>, <span class="dv">3</span>))</a></code></pre></div>
<pre><code>## $Ix
## [1] 0.6875 0.0000
## 
## $pbeta
## [1] 0.6875 0.0000</code></pre>

<p>Note that to avoid overflows or underflows, or to avoid using multiplication and division, we use exponential and logarithmic functions (as shown in the original C code from Numerical Recipes). So that for the constant, K, we have:</p>
<p><span class="math display">\[\begin{align}
Kx(\alpha,\beta) {}&amp;= exp( log(\Gamma(\alpha)) -  log(\Gamma(\beta)) 
- log(\Gamma(\alpha +\beta)) \nonumber \\
&amp;+ a \times log(x) + b \times log(1-x))
\end{align}\]</span></p>
<p>However, in our R code, we intentionally use the original beta function instead of the exponential and logarithmic function to focus on the notation.</p>
<p><span class="math display">\[\begin{align}
\mathcal{K}x(\alpha,\beta) = \frac{1}{\mathcal{B}(\alpha,\beta)}x^\alpha(1-x)^\beta 
\end{align}\]</span></p>
<p>Also, the <strong>regular beta function</strong> keeps the common notation in the R code:</p>
<p><span class="math display">\[\begin{align}
\mathcal{I}_x(\alpha,\beta) = \frac{ \mathcal{B}_x(\alpha,\beta) }{ \mathcal{B}(\alpha, \beta)}
\end{align}\]</span></p>
<p>Given all that, here is a naive implementation of <strong>CDF</strong> for <strong>T-Distribution</strong> in R code:</p>

<div class="sourceCode" id="cb264"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb264-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">1</span>)</a>
<a class="sourceLine" id="cb264-2" data-line-number="2">t_cdf  &lt;-<span class="st"> </span><span class="cf">function</span>(x, df) {</a>
<a class="sourceLine" id="cb264-3" data-line-number="3">  <span class="dv">1</span><span class="op">/</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span><span class="dv">1</span><span class="op">/</span><span class="dv">2</span> <span class="op">*</span><span class="st">  </span><span class="kw">sign</span>(x) <span class="op">*</span><span class="st"> </span></a>
<a class="sourceLine" id="cb264-4" data-line-number="4"><span class="st">               </span>( <span class="kw">Ix</span>(<span class="dv">1</span>,df<span class="op">/</span><span class="dv">2</span>, <span class="dv">1</span><span class="op">/</span><span class="dv">2</span>) <span class="op">-</span><span class="st"> </span><span class="kw">Ix</span>(df<span class="op">/</span>(df<span class="op">+</span>x<span class="op">^</span><span class="dv">2</span>), df<span class="op">/</span><span class="dv">2</span>, <span class="dv">1</span><span class="op">/</span><span class="dv">2</span>) ) </a>
<a class="sourceLine" id="cb264-5" data-line-number="5">}</a>
<a class="sourceLine" id="cb264-6" data-line-number="6">population =<span class="st"> </span><span class="kw">round</span>(<span class="kw">seq</span>(<span class="dv">4</span>,<span class="dv">7</span>, <span class="dt">length.out=</span><span class="dv">10</span>),<span class="dv">1</span>)</a>
<a class="sourceLine" id="cb264-7" data-line-number="7">x =<span class="st"> </span><span class="kw">sample</span>(population, <span class="dt">size=</span><span class="dv">20</span>, <span class="dt">replace=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb264-8" data-line-number="8"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="op">-</span><span class="dv">5</span>,<span class="dv">5</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="dv">1</span>), </a>
<a class="sourceLine" id="cb264-9" data-line-number="9">     <span class="dt">xlab=</span><span class="st">&quot;T value&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;cumulative probability&quot;</span>,</a>
<a class="sourceLine" id="cb264-10" data-line-number="10">     <span class="dt">main=</span><span class="st">&quot;T Distribution (CDF)&quot;</span>)</a>
<a class="sourceLine" id="cb264-11" data-line-number="11"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb264-12" data-line-number="12"><span class="kw">curve</span>(<span class="kw">pnorm</span>(x, <span class="dv">0</span>, <span class="dv">1</span>), <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb264-13" data-line-number="13"><span class="kw">curve</span>(<span class="kw">t_cdf</span>(x, <span class="dv">10</span>), <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb264-14" data-line-number="14"><span class="kw">curve</span>(<span class="kw">t_cdf</span>(x, <span class="dv">2</span>), <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb264-15" data-line-number="15"><span class="kw">curve</span>(<span class="kw">t_cdf</span>(x, <span class="dv">1</span>), <span class="dt">col=</span><span class="st">&quot;brown&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">add=</span><span class="ot">TRUE</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:ptdist"></span>
<img src="DS_files/figure-html/ptdist-1.png" alt="T-Distribution (CDF)" width="70%" />
<p class="caption">
Figure 5.31: T-Distribution (CDF)
</p>
</div>

<p>An alternative solution to the <strong>CDF</strong> for the <strong>T-distribution</strong> uses the <strong>Hypergeometric function</strong> as follows:</p>
<p><span class="math display">\[\begin{align}
{}_2F_1(a,b;c; x) {}&amp;= (1-x)^{-b} {}_2F_1\left(c-a,b;c; z\right)
\ \ \ \ \ where\ \ \ z = \frac{x}{x-1}\\
&amp;= 
\frac{1}{(1-x)^{b}}\sum_{n=0}^\infty\frac{(c-a)_n (b)_n}{(c)_n} \frac{z^n}{n!}
\end{align}\]</span></p>
<p>Note that we use the first transformation form of the <strong>Hypergeometric function</strong> as listed in Chapter <strong>5</strong> (<strong>Probability and Distribution</strong>) under the <strong>Special Functions</strong> Section:</p>
<p>Also, note that we use the <strong>Rising Factorial</strong> for the symbol <span class="math inline">\((...)_n\)</span>. </p>
<p>Here is a naive implementation of the <strong>Hypergeometric function</strong> for our t-distribution <strong>CDF</strong> (Note that in this implementation, the alternative function, <strong>t_cdf_alt</strong>, is limited to the t-distribution support range, <span class="math inline">\(-4 \le x \le 4\)</span>): </p>

<div class="sourceCode" id="cb265"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb265-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">1</span>)</a>
<a class="sourceLine" id="cb265-2" data-line-number="2">Gamma &lt;-<span class="st"> </span><span class="cf">function</span>(n) { <span class="kw">factorial</span>(n<span class="dv">-1</span>) }</a>
<a class="sourceLine" id="cb265-3" data-line-number="3">rise_factorial &lt;-<span class="st"> </span><span class="cf">function</span>(x, n) {</a>
<a class="sourceLine" id="cb265-4" data-line-number="4">    <span class="cf">if</span> (n<span class="op">==</span><span class="dv">0</span>) <span class="kw">return</span>(<span class="dv">1</span>)</a>
<a class="sourceLine" id="cb265-5" data-line-number="5">    prod =<span class="st"> </span><span class="dv">1</span></a>
<a class="sourceLine" id="cb265-6" data-line-number="6">    <span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">0</span><span class="op">:</span>(n<span class="dv">-1</span>)) {</a>
<a class="sourceLine" id="cb265-7" data-line-number="7">        prod =<span class="st"> </span>prod <span class="op">*</span><span class="st"> </span>(x <span class="op">+</span><span class="st"> </span>k)</a>
<a class="sourceLine" id="cb265-8" data-line-number="8">    }</a>
<a class="sourceLine" id="cb265-9" data-line-number="9">    prod</a>
<a class="sourceLine" id="cb265-10" data-line-number="10">}</a>
<a class="sourceLine" id="cb265-11" data-line-number="11">hypergeometric  &lt;-<span class="st"> </span><span class="cf">function</span>(a, b, c, x) { <span class="co"># only for 2F1(a,b;c;x)</span></a>
<a class="sourceLine" id="cb265-12" data-line-number="12">    hyperG_1st_form =<span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb265-13" data-line-number="13">    limit =<span class="st"> </span><span class="dv">50</span></a>
<a class="sourceLine" id="cb265-14" data-line-number="14">    z =<span class="st"> </span>x <span class="op">/</span><span class="st"> </span>( x <span class="op">-</span><span class="st"> </span><span class="dv">1</span>) </a>
<a class="sourceLine" id="cb265-15" data-line-number="15">    <span class="cf">for</span> (n <span class="cf">in</span>  <span class="dv">0</span><span class="op">:</span>limit) {</a>
<a class="sourceLine" id="cb265-16" data-line-number="16">        hyperG_1st_form =<span class="st"> </span>hyperG_1st_form <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb265-17" data-line-number="17"><span class="st">        </span>(( <span class="kw">rise_factorial</span>(c<span class="op">-</span>a , n) <span class="op">*</span><span class="st"> </span><span class="kw">rise_factorial</span>(b, n) ) <span class="op">/</span><span class="st"> </span></a>
<a class="sourceLine" id="cb265-18" data-line-number="18"><span class="st">           </span><span class="kw">rise_factorial</span>(c, n)) <span class="op">*</span><span class="st"> </span>( z<span class="op">^</span>n <span class="op">/</span><span class="st"> </span><span class="kw">factorial</span>(n))</a>
<a class="sourceLine" id="cb265-19" data-line-number="19">    }</a>
<a class="sourceLine" id="cb265-20" data-line-number="20">    hyperG_1st_form <span class="op">/</span><span class="st"> </span>(<span class="dv">1</span><span class="op">-</span>x)<span class="op">^</span>b</a>
<a class="sourceLine" id="cb265-21" data-line-number="21">}</a>
<a class="sourceLine" id="cb265-22" data-line-number="22">t_cdf_alt &lt;-<span class="st"> </span><span class="cf">function</span>(x, df) {</a>
<a class="sourceLine" id="cb265-23" data-line-number="23">   <span class="dv">1</span><span class="op">/</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span>x <span class="op">*</span><span class="st"> </span><span class="kw">Gamma</span>((df<span class="op">+</span><span class="dv">1</span>)<span class="op">/</span><span class="dv">2</span>) <span class="op">/</span><span class="st"> </span>( <span class="kw">Gamma</span>(df<span class="op">/</span><span class="dv">2</span>) <span class="op">*</span><span class="st"> </span><span class="kw">sqrt</span>(df <span class="op">*</span><span class="st"> </span>pi) ) <span class="op">*</span><span class="st"> </span></a>
<a class="sourceLine" id="cb265-24" data-line-number="24"><span class="st">   </span><span class="kw">hypergeometric</span>(<span class="dv">1</span><span class="op">/</span><span class="dv">2</span>, (df<span class="op">+</span><span class="dv">1</span>)<span class="op">/</span><span class="dv">2</span>, <span class="dv">3</span><span class="op">/</span><span class="dv">2</span>, <span class="op">-</span>(x<span class="op">^</span><span class="dv">2</span><span class="op">/</span>df)) </a>
<a class="sourceLine" id="cb265-25" data-line-number="25">}</a></code></pre></div>

<p>Now in terms of the <strong>expected value</strong> and <strong>variance</strong> respectively, we have:</p>
<p><span class="math display">\[\begin{align}
\mu = 0\ \ \ \ \ \ \ \ \ \ \ \ \ \sigma = \frac{v}{v-2}
\end{align}\]</span></p>
<p>We leave readers to investigate the non-central (asymmetric) <strong>T-distribution</strong>.</p>
</div>
<div id="f-distribution" class="section level3 hasAnchor">
<h3><span class="header-section-number">5.9.18</span> F-Distribution <a href="numericalprobability.html#f-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>An <strong>F-distribution</strong>, also known as <strong>Fisher-Snedecor distribution</strong>, models a <strong>continuous distribution</strong> and is written as:</p>
<p><span class="math display">\[\begin{align}
X \sim F(\nu_1, \nu_2)
\end{align}\]</span></p>
<p>The distribution is used for <strong>F-statistic test</strong> by comparing two populations which we discuss in later section.  </p>
<p>The <strong>PDF</strong> for an <strong>F-distribution</strong> with <strong>support</strong> <span class="math inline">\(x \ge 0\)</span> is expressed as:</p>
<p><span class="math display">\[\begin{align}
f(x; \nu_1, \nu_2) {}&amp;= 
\left[
\Gamma\left(\frac{\nu_1 + \nu_2}{2}\right)
\nu_1^{\frac{\nu_1}{2}}  \nu_2^{\frac{\nu_2}{2}}  x^{\frac{\nu_1}{2} - 1}
 \right]
\left[
\Gamma\left(\frac{\nu_1}{2}\right) \Gamma\left(\frac{\nu_2}{2}\right) 
( \nu_1  x + \nu_2)^{\frac{\nu1 + \nu_2}{2}}
\right]^{-1} \\
&amp;=\left[
\nu_1^{\frac{\nu_1}{2}}  \nu_2^{\frac{\nu_2}{2}}  x^{\frac{\nu_1}{2} - 1}
 \right]
\left[
B\left(\frac{\nu_1}{2},  \frac{\nu_2}{2} \right) 
( \nu_1  x + \nu_2)^{\frac{\nu1 + \nu_2}{2}}
\right]^{-1} 
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(\nu_1\ and\ \nu_2\)</span> are the degrees of freedom.</li>
</ul>
<p>The <strong>CDF</strong> for an <strong>F-distribution</strong> with <strong>support</strong> <span class="math inline">\(x \ge 0\)</span> is expressed as:</p>
<p><span class="math display">\[\begin{align}
F(x; \nu_1, \nu_2)  = I_z(\alpha, \beta) = I(z; \alpha, \beta)\ \ \rightarrow\ \ \text{regularized beta function}
\end{align}\]</span></p>
<p>where:</p>
<p><span class="math display">\[\begin{align}
z = \left(\frac{\nu_1 x}{\nu_1 x + \nu_2}\right)
\end{align}\]</span></p>
<p>Here is a naive implementation of <strong>PDF</strong> and <strong>CDF</strong> for <strong>F-distribution</strong> in R code (Note that we use the built-in R package <strong>pbeta()</strong> for the regularized beta function):</p>

<div class="sourceCode" id="cb266"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb266-1" data-line-number="1">Gamma &lt;-<span class="st"> </span><span class="cf">function</span>(n) {<span class="kw">factorial</span>(n<span class="dv">-1</span>)}</a>
<a class="sourceLine" id="cb266-2" data-line-number="2">Beta &lt;-<span class="st"> </span><span class="cf">function</span>(a, b) {</a>
<a class="sourceLine" id="cb266-3" data-line-number="3">    ( <span class="kw">Gamma</span>(a) <span class="op">*</span><span class="st"> </span><span class="kw">Gamma</span>(b)) <span class="op">/</span><span class="st"> </span><span class="kw">Gamma</span>(a<span class="op">+</span>b)</a>
<a class="sourceLine" id="cb266-4" data-line-number="4">}</a>
<a class="sourceLine" id="cb266-5" data-line-number="5">f_pdf &lt;-<span class="st"> </span><span class="cf">function</span>(x, df1, df2) {</a>
<a class="sourceLine" id="cb266-6" data-line-number="6">   n =<span class="st">  </span>df1<span class="op">^</span>(df1<span class="op">/</span><span class="dv">2</span>) <span class="op">*</span><span class="st"> </span>df2<span class="op">^</span>(df2<span class="op">/</span><span class="dv">2</span>) <span class="op">*</span><span class="st"> </span>x<span class="op">^</span>((df1<span class="op">/</span><span class="dv">2</span>) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb266-7" data-line-number="7">   d =<span class="st">  </span>(df1<span class="op">*</span>x <span class="op">+</span><span class="st"> </span>df2)<span class="op">^</span>((df1<span class="op">+</span>df2)<span class="op">/</span><span class="dv">2</span>)  </a>
<a class="sourceLine" id="cb266-8" data-line-number="8">   n <span class="op">/</span><span class="st"> </span>( <span class="kw">Beta</span>(df1<span class="op">/</span><span class="dv">2</span>, df2<span class="op">/</span><span class="dv">2</span>) <span class="op">*</span><span class="st"> </span>d )</a>
<a class="sourceLine" id="cb266-9" data-line-number="9">}</a>
<a class="sourceLine" id="cb266-10" data-line-number="10">f_cdf &lt;-<span class="st"> </span><span class="cf">function</span>(x, df1, df2) {</a>
<a class="sourceLine" id="cb266-11" data-line-number="11">   z =<span class="st"> </span>(df1 <span class="op">*</span><span class="st"> </span>x) <span class="op">/</span><span class="st"> </span>( df1 <span class="op">*</span><span class="st"> </span>x <span class="op">+</span><span class="st"> </span>df2)</a>
<a class="sourceLine" id="cb266-12" data-line-number="12">   <span class="kw">pbeta</span> ( z, df1<span class="op">/</span><span class="dv">2</span>, df2<span class="op">/</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb266-13" data-line-number="13">}</a></code></pre></div>
<p>And we plot the distribution as shown in Figures <a href="numericalprobability.html#fig:pfdist1">5.32</a> and <a href="numericalprobability.html#fig:pfdist2">5.33</a>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:pfdist1"></span>
<img src="DS_files/figure-html/pfdist1-1.png" alt="F-Distribution (PDF)" width="70%" />
<p class="caption">
Figure 5.32: F-Distribution (PDF)
</p>
</div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:pfdist2"></span>
<img src="DS_files/figure-html/pfdist2-1.png" alt="F-Distribution (CDF)" width="70%" />
<p class="caption">
Figure 5.33: F-Distribution (CDF)
</p>
</div>
<div class="sourceCode" id="cb267"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb267-1" data-line-number="1"><span class="co"># Probability Density</span></a>
<a class="sourceLine" id="cb267-2" data-line-number="2">x =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">6</span>)</a>
<a class="sourceLine" id="cb267-3" data-line-number="3"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="dv">6</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="dv">1</span>), </a>
<a class="sourceLine" id="cb267-4" data-line-number="4">     <span class="dt">xlab=</span><span class="st">&quot;F value&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;probability density&quot;</span>,</a>
<a class="sourceLine" id="cb267-5" data-line-number="5">     <span class="dt">main=</span><span class="st">&quot;F Distribution (PDF)&quot;</span>)</a>
<a class="sourceLine" id="cb267-6" data-line-number="6"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb267-7" data-line-number="7"><span class="kw">curve</span>(<span class="kw">f_pdf</span>(x, <span class="dv">2</span>, <span class="dv">5</span>), <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>,  <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb267-8" data-line-number="8"><span class="kw">curve</span>(<span class="kw">f_pdf</span>(x, <span class="dv">10</span>, <span class="dv">5</span>), <span class="dt">col=</span><span class="st">&quot;brown&quot;</span>,  <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb267-9" data-line-number="9"><span class="kw">curve</span>(<span class="kw">f_pdf</span>(x, <span class="dv">50</span>, <span class="dv">10</span>), <span class="dt">col=</span><span class="st">&quot;red&quot;</span>,  <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb267-10" data-line-number="10"></a>
<a class="sourceLine" id="cb267-11" data-line-number="11"><span class="co"># Cumulative Density</span></a>
<a class="sourceLine" id="cb267-12" data-line-number="12">x =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">6</span>)</a>
<a class="sourceLine" id="cb267-13" data-line-number="13"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="dv">6</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="dv">1</span>), </a>
<a class="sourceLine" id="cb267-14" data-line-number="14">     <span class="dt">xlab=</span><span class="st">&quot;F value&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;cumulative probability&quot;</span>,</a>
<a class="sourceLine" id="cb267-15" data-line-number="15">     <span class="dt">main=</span><span class="st">&quot;F Distribution (CDF)&quot;</span>)</a>
<a class="sourceLine" id="cb267-16" data-line-number="16"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb267-17" data-line-number="17"><span class="kw">curve</span>(<span class="kw">f_cdf</span>(x, <span class="dv">2</span>, <span class="dv">5</span>), <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>,  <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb267-18" data-line-number="18"><span class="kw">curve</span>(<span class="kw">f_cdf</span>(x, <span class="dv">10</span>, <span class="dv">5</span>), <span class="dt">col=</span><span class="st">&quot;brown&quot;</span>,  <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb267-19" data-line-number="19"><span class="kw">curve</span>(<span class="kw">f_cdf</span>(x, <span class="dv">50</span>, <span class="dv">10</span>), <span class="dt">col=</span><span class="st">&quot;red&quot;</span>,  <span class="dt">add=</span><span class="ot">TRUE</span>)</a></code></pre></div>

</div>
<div id="chi-square-distribution" class="section level3 hasAnchor">
<h3><span class="header-section-number">5.9.19</span> Chi-square Distribution <a href="numericalprobability.html#chi-square-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A <strong>Chi-square distribution</strong>, also called <span class="math inline">\(X^2\)</span><strong>-distribution</strong>, models a <strong>continuous distribution</strong> formed by squaring and summing the <strong>standard normal deviation</strong> of <span class="math inline">\(\mathbf{\nu}\)</span> independent variables that follow a standard normal distribution. The distribution can be expressed as follows:</p>
<p><span class="math display">\[\begin{align}
Q \sim X^2(\nu)\ \ \ \ \ \ \ where\ \mathbf{\nu}\ = \text{degrees of freedom}
\end{align}\]</span></p>
<p>The <strong>PDF</strong> for a <strong>Chi-squared distribution</strong> with <strong>support</strong> <span class="math inline">\(x \ge 0\)</span> is expressed as:</p>
<p><span class="math display">\[\begin{align}
f(x; \nu) = \frac{1}{2^{\frac{\nu}{2}}\Gamma\left(\frac{\nu}{2}\right)} 
x^{\frac{\nu}{2}-1} e^{-\frac{x}{2}}
\end{align}\]</span></p>
<p>The <strong>CDF</strong> for a <strong>Chi-square distribution</strong> with <strong>support</strong> <span class="math inline">\(x \ge 0\)</span> is expressed as:</p>
<p><span class="math display">\[\begin{align}
F(x; \nu) = \frac{1}{\Gamma\left(\frac{\nu}{2}\right)} \gamma \left(\frac{\nu}{2},\frac{x}{2}\right) = P(\frac{\nu}{2},\frac{x}{2})
\end{align}\]</span></p>
<p>where <span class="math inline">\(\gamma(\nu, x)\)</span> is the <strong>lower incomplete gamma function</strong> and <span class="math inline">\(P(\nu, x)\)</span> is the <strong>lower regularized gamma function</strong>.</p>
<p>Here is a naive implementation of <strong>PDF and CDF</strong> for <strong>Chi-square distribution</strong> in R code:</p>

<div class="sourceCode" id="cb268"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb268-1" data-line-number="1">Gamma &lt;-<span class="st"> </span><span class="cf">function</span>(n) {<span class="kw">factorial</span>(n<span class="dv">-1</span>)}</a>
<a class="sourceLine" id="cb268-2" data-line-number="2">Beta &lt;-<span class="st"> </span><span class="cf">function</span>(a, b) {</a>
<a class="sourceLine" id="cb268-3" data-line-number="3">    ( <span class="kw">Gamma</span>(a) <span class="op">*</span><span class="st"> </span><span class="kw">Gamma</span>(b)) <span class="op">/</span><span class="st"> </span><span class="kw">Gamma</span>(a<span class="op">+</span>b)</a>
<a class="sourceLine" id="cb268-4" data-line-number="4">}</a>
<a class="sourceLine" id="cb268-5" data-line-number="5">chi_pdf &lt;-<span class="st"> </span><span class="cf">function</span>(x, df) {</a>
<a class="sourceLine" id="cb268-6" data-line-number="6">   <span class="dv">1</span> <span class="op">/</span><span class="st"> </span>( <span class="dv">2</span><span class="op">^</span>(df<span class="op">/</span><span class="dv">2</span>) <span class="op">*</span><span class="st"> </span><span class="kw">Gamma</span>(df<span class="op">/</span><span class="dv">2</span>)) <span class="op">*</span><span class="st"> </span>x<span class="op">^</span>(df<span class="op">/</span><span class="dv">2-1</span>) <span class="op">*</span><span class="st"> </span><span class="kw">exp</span>(<span class="op">-</span>x<span class="op">/</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb268-7" data-line-number="7">}</a>
<a class="sourceLine" id="cb268-8" data-line-number="8"><span class="co"># Probability Density</span></a>
<a class="sourceLine" id="cb268-9" data-line-number="9">x =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">10</span>)</a>
<a class="sourceLine" id="cb268-10" data-line-number="10"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="dv">10</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="dv">1</span>), </a>
<a class="sourceLine" id="cb268-11" data-line-number="11">     <span class="dt">xlab=</span><span class="st">&quot;Chi-square value&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;probability density&quot;</span>,</a>
<a class="sourceLine" id="cb268-12" data-line-number="12">     <span class="dt">main=</span><span class="st">&quot;Chi-squared Distribution (PDF)&quot;</span>)</a>
<a class="sourceLine" id="cb268-13" data-line-number="13"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb268-14" data-line-number="14"><span class="kw">curve</span>(<span class="kw">chi_pdf</span>(x, <span class="dv">1</span>), <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>,  <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb268-15" data-line-number="15"><span class="kw">curve</span>(<span class="kw">chi_pdf</span>(x, <span class="dv">2</span>), <span class="dt">col=</span><span class="st">&quot;brown&quot;</span>,  <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb268-16" data-line-number="16"><span class="kw">curve</span>(<span class="kw">chi_pdf</span>(x, <span class="dv">4</span>), <span class="dt">col=</span><span class="st">&quot;red&quot;</span>,  <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb268-17" data-line-number="17"><span class="kw">curve</span>(<span class="kw">chi_pdf</span>(x, <span class="dv">6</span>), <span class="dt">col=</span><span class="st">&quot;purple&quot;</span>,  <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb268-18" data-line-number="18"><span class="kw">curve</span>(<span class="kw">chi_pdf</span>(x, <span class="dv">9</span>), <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>,  <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb268-19" data-line-number="19"></a>
<a class="sourceLine" id="cb268-20" data-line-number="20">GammaInc &lt;-<span class="st"> </span><span class="cf">function</span>(alpha, z) {</a>
<a class="sourceLine" id="cb268-21" data-line-number="21">    s =<span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb268-22" data-line-number="22">    limit =<span class="st"> </span><span class="dv">300</span></a>
<a class="sourceLine" id="cb268-23" data-line-number="23">    flimit =<span class="st"> </span><span class="dv">172</span>  <span class="co"># R&#39;s gamma limit</span></a>
<a class="sourceLine" id="cb268-24" data-line-number="24">    <span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">0</span><span class="op">:</span>limit) {</a>
<a class="sourceLine" id="cb268-25" data-line-number="25">      <span class="cf">if</span> (z <span class="op">+</span><span class="st"> </span>k <span class="op">+</span><span class="st"> </span><span class="dv">1</span> <span class="op">&gt;</span><span class="st"> </span><span class="dv">171</span>) { <span class="cf">break</span> }</a>
<a class="sourceLine" id="cb268-26" data-line-number="26">      s =<span class="st"> </span>s <span class="op">+</span><span class="st"> </span>alpha<span class="op">^</span>k <span class="op">/</span><span class="st"> </span><span class="kw">Gamma</span>( z <span class="op">+</span><span class="st"> </span>k <span class="op">+</span><span class="st"> </span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb268-27" data-line-number="27">    }</a>
<a class="sourceLine" id="cb268-28" data-line-number="28">    lower =<span class="st"> </span>alpha<span class="op">^</span>z <span class="op">*</span><span class="st"> </span><span class="kw">Gamma</span>(z) <span class="op">*</span><span class="st"> </span><span class="kw">exp</span>(<span class="op">-</span>alpha) <span class="op">*</span><span class="st"> </span>s</a>
<a class="sourceLine" id="cb268-29" data-line-number="29">    upper =<span class="st"> </span><span class="kw">Gamma</span>(z) <span class="op">-</span><span class="st"> </span>lower</a>
<a class="sourceLine" id="cb268-30" data-line-number="30">    P =<span class="st"> </span>lower <span class="op">/</span><span class="st"> </span><span class="kw">Gamma</span>(z) <span class="co"># regular inc gamma</span></a>
<a class="sourceLine" id="cb268-31" data-line-number="31">    Q =<span class="st"> </span>upper <span class="op">/</span><span class="st"> </span><span class="kw">Gamma</span>(z)</a>
<a class="sourceLine" id="cb268-32" data-line-number="32">    <span class="kw">list</span>(<span class="st">&quot;lower&quot;</span>=<span class="st"> </span>lower, <span class="st">&quot;upper&quot;</span>=upper,  <span class="st">&quot;P&quot;</span>=P, <span class="st">&quot;Q&quot;</span>=Q )</a>
<a class="sourceLine" id="cb268-33" data-line-number="33">}</a>
<a class="sourceLine" id="cb268-34" data-line-number="34">chi_cdf &lt;-<span class="st"> </span><span class="cf">function</span>(x, v) {</a>
<a class="sourceLine" id="cb268-35" data-line-number="35">  <span class="dv">1</span> <span class="op">/</span><span class="st"> </span><span class="kw">Gamma</span>(v<span class="op">/</span><span class="dv">2</span>) <span class="op">*</span><span class="st"> </span><span class="kw">GammaInc</span>(x<span class="op">/</span><span class="dv">2</span>, v<span class="op">/</span><span class="dv">2</span>)<span class="op">$</span>lower</a>
<a class="sourceLine" id="cb268-36" data-line-number="36">}</a>
<a class="sourceLine" id="cb268-37" data-line-number="37"><span class="co"># Cumulative Density</span></a>
<a class="sourceLine" id="cb268-38" data-line-number="38">x =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">10</span>)</a>
<a class="sourceLine" id="cb268-39" data-line-number="39"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="dv">20</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="dv">1</span>), </a>
<a class="sourceLine" id="cb268-40" data-line-number="40">     <span class="dt">xlab=</span><span class="st">&quot;Chi-square value&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;cumulative probability&quot;</span>,</a>
<a class="sourceLine" id="cb268-41" data-line-number="41">     <span class="dt">main=</span><span class="st">&quot;Chi-squared Distribution (CDF)&quot;</span>)</a>
<a class="sourceLine" id="cb268-42" data-line-number="42"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb268-43" data-line-number="43"><span class="kw">curve</span>(<span class="kw">chi_cdf</span>(x, <span class="dv">1</span>), <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>,  <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb268-44" data-line-number="44"><span class="kw">curve</span>(<span class="kw">chi_cdf</span>(x, <span class="dv">2</span>), <span class="dt">col=</span><span class="st">&quot;brown&quot;</span>,  <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb268-45" data-line-number="45"><span class="kw">curve</span>(<span class="kw">chi_cdf</span>(x, <span class="dv">4</span>), <span class="dt">col=</span><span class="st">&quot;red&quot;</span>,  <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb268-46" data-line-number="46"><span class="kw">curve</span>(<span class="kw">chi_cdf</span>(x, <span class="dv">6</span>), <span class="dt">col=</span><span class="st">&quot;purple&quot;</span>,  <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb268-47" data-line-number="47"><span class="kw">curve</span>(<span class="kw">chi_cdf</span>(x, <span class="dv">9</span>), <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>,  <span class="dt">add=</span><span class="ot">TRUE</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:pchidist-1"></span>
<img src="DS_files/figure-html/pchidist-1.png" alt="Chi-square Distribution (PDF and CDF)" width="70%" />
<p class="caption">
Figure 5.34: Chi-square Distribution (PDF and CDF)
</p>
</div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:pchidist-2"></span>
<img src="DS_files/figure-html/pchidist-2.png" alt="Chi-square Distribution (PDF and CDF)" width="70%" />
<p class="caption">
Figure 5.35: Chi-square Distribution (PDF and CDF)
</p>
</div>

<p>It helps to also reference the <strong>Chi-square table</strong> in the Appendix.</p>
<p><span class="math display">\[
\underbrace{P(x &gt; 2.7055, 1) = 0.100}_\text{df=1}\ \ \ \ \ \ \ \ \ \ \ \ \
\underbrace{P(x &gt; 4.6052, 2) = 0.100}_\text{df=2}
\]</span></p>
<div class="sourceCode" id="cb269"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb269-1" data-line-number="1"><span class="kw">c</span>(<span class="st">&quot;df=1&quot;</span>=<span class="kw">round</span>( <span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">pchisq</span>(<span class="fl">2.7055</span>,<span class="dv">1</span>),<span class="dv">3</span>), </a>
<a class="sourceLine" id="cb269-2" data-line-number="2">  <span class="st">&quot;df=2&quot;</span>=<span class="kw">round</span>( <span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">pchisq</span>(<span class="fl">4.6052</span>,<span class="dv">2</span>),<span class="dv">3</span>))</a></code></pre></div>
<pre><code>## df=1 df=2 
##  0.1  0.1</code></pre>
<p>Now in terms of the <strong>expected value</strong> and <strong>variance</strong> respectively, we have:</p>
<p><span class="math display">\[\begin{align}
\mathbb{E}(X) = n\ \ \ \ \ \ \ \ \ \ \ \ \ Var(X) = 2n
\end{align}\]</span></p>
<p>See <strong>Chi-square Test</strong> section for sample application of the distribution.</p>
</div>
<div id="wishartdistribution" class="section level3 hasAnchor">
<h3><span class="header-section-number">5.9.20</span> Wishart distribution<a href="numericalprobability.html#wishartdistribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Wishart distribution</strong> models a covariance <strong>continuous</strong> distribution drawn or sampled (as a <strong>precision</strong> or <strong>inverse covariance</strong> matrix, namely <strong>V</strong> ) from a <strong>multivariate normal distribution (MVN)</strong>. It is both an extension of gamma distribution and a generalization of the Chi-Square <span class="math inline">\(\mathcal{X}^2\)</span> distribution. To compare Chi-Square and Wishart structure in terms of multivariate distribution, see below <span class="citation">(Mathew T. <a href="bibliography.html#ref-ref1298t">1997</a>)</span>: </p>
<p><span class="math display">\[\begin{align}
\underbrace{V = \sum_{i=1}^n X_i^2}_{
   \begin{array}{c}\text{chi-square}\ (V \in \mathbb{R}^n)\ dist\\ \ V\sim\ \mathcal{X}^2(\ \nu\ )\\ from \\ \text{univariate dist}\\ X \sim\  \mathcal{N}(\mu, \sigma^2)\end{array}
  }\ \ \ \ \ \ \ \ \ \ \
\underbrace{V = \sum_{i=1}^n X_i X_i^T}_{
   \begin{array}{c}\text{wishart} (V \in \mathbb{R}^{pxp})\ dist\\ \ \Sigma\ \sim\ \mathcal{W}(\ \nu, V)\\ from \\\text{multivariate dist}\\ X \sim\  \mathcal{N}_p(\mu, \Sigma)\end{array}
  } \label{eqn:eqnnumber22}
\end{align}\]</span></p>
<p>Below is the structure of a <strong>multivariate distribution</strong>, namely <strong>X</strong>, with a corresponding <strong>covariance</strong> matrix, namely <span class="math inline">\(\Sigma\)</span>:</p>
<p><span class="math display">\[
X = \left[\begin{array}{rrrr}
    x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1p}\\ 
    x_{21} &amp; x_{22} &amp; \cdots &amp; x_{2p} \\ 
    \vdots &amp;  \vdots &amp; \ddots &amp;  \vdots \\ 
    x_{n1} &amp; x_{n2} &amp; \cdots &amp; x_{np} 
    \end{array}\right]_\text{(nxp)}
 \ \ \ 
\mu = \left[\begin{array}{c}\bar{x}_1 \\ \bar{x}_2 \\ \vdots \\ \bar{x}_p \end{array}\right]
= \left[\begin{array}{c}\mu_1 \\ \mu_2 \\ \vdots \\ \mu_p \end{array}\right]_\text{(1xp)}
\]</span></p>
<p><span class="math display">\[
\Sigma_{(pxp)} = \left[\begin{array}{rrrr}
   \sigma^2_{1} &amp; \sigma_{12} &amp; \cdots &amp; \sigma_{1p}\\
   \sigma_{21} &amp; \sigma^2_{2} &amp; \cdots &amp; \sigma_{2p} \\ 
   \vdots &amp;  \vdots &amp;  \ddots &amp;  \vdots \\ 
   \sigma_{p1} &amp; \sigma_{p2} &amp; \cdots &amp; \sigma^2_{p} 
   \end{array}\right]_\text{(pxp)} 
\]</span></p>
<p>Here, we cover three types of <strong>Wishart distributions</strong> using the following illustration:</p>
<p>The first distribution type is the <strong>Central Wishart distribution</strong> which is written as:</p>
<p><span class="math display">\[\begin{align}
V \sim W_p \left(\nu, \Sigma_{(pxp)}\right) \equiv Wishart_p \left(\nu, \Sigma_{(pxp)} \right) 
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li><strong>V</strong> is a <strong>precision</strong> or <strong>inverse</strong> covariance <strong>positive-definite</strong> matrix.</li>
<li><span class="math inline">\(\Sigma_{(pxp)}\)</span> is upper sigma describing a pxp <strong>non-inverse</strong> covariance <strong>positive-definite scale</strong> matrix</li>
<li><strong>p</strong> is number of random variables, e.g.Â p-variate distribution.</li>
<li><span class="math inline">\(\mathbf{\nu}\)</span> is degrees of freedom, where <span class="math inline">\(\nu\)</span> &gt; <strong>p</strong> - 1. Also, <span class="math inline">\(\nu = n\)</span>.</li>
</ul>
<p>The <strong>X</strong> is drawn from a multivariate normal distribution of which its covariance matrix is a positive-definite scale matrix with <strong>p</strong> random variables. We use a bivariate normal distribution for a shorter illustration where <strong>p</strong> = 2.</p>
<p><span class="math display">\[\begin{align}
X \sim \mathcal{N}_2(\mu_{(2)}, \Sigma_{(2x2)}),\ \ \ \ \ \ 
\mu_{(2)} = \left[\begin{array}{cc}\mu_1 \\ \mu_2  \end{array}\right],\ \ \ \ \ \ 
\Sigma_{(2x2)} = 
\underbrace{\left[\begin{array}{cc}
\sigma^2_{11} &amp; \sigma^2_{12} \\ 
\sigma^2_{21} &amp; \sigma^2_{22}  \\ 
\end{array}\right]_{2x2}}_\text{scale matrix} \label{eqn:eqnnumber23}
\end{align}\]</span></p>
<p>Given <strong>X</strong>, we generate a sum square covariance <strong>V</strong> distribution written as:</p>
<p><span class="math display">\[\begin{align}
V = \sum_{i=1}^n\left(x_i -\mu)(x_i - \mu\right)^T \ \ \ \ \ where\ \mu = \bar{x}
\end{align}\]</span></p>
<p>The <strong>PDF</strong> for a <strong>Central Wishart distribution</strong> is expressed as:</p>
<p><span class="math display">\[\begin{align}
f_p(V; \nu, \Sigma_{(pxp)}) = 
    \frac{|V|^{\frac{\nu-p-1}{2}} exp\left[-\frac{1}{2}tr(\Sigma^{-1}V)\right]}
    {2^{\frac{\nu p}{2}}|\Sigma|^{\frac{\nu}{2}}\ \Gamma_p\left(\frac{\nu}{2}\right)}\ \ \ 
\begin{array}{ll}
\text{(see matrix trace in Linear}\\
\text{ Algebra chapter)}\\
\end{array} \label{eqn:eqnnumber24}
\end{align}\]</span></p>
<p>where <strong>multivariate Gamma function</strong> is:</p>
<p><span class="math display">\[\begin{align}
\Gamma_p\left(\frac{\nu}{2}\right) = \pi^{\frac{p(p-1)}{4}} \prod_{i=1}^p \Gamma\left[\frac{\nu - (i - 1)}{2}\right]
\end{align}\]</span></p>
<p>and</p>
<p><span class="math display">\[\begin{align}
mean =  n \times \Sigma_{(pxp)}\ \ \ \ \ \ \ |V| = \text{det}(V)
\end{align}\]</span></p>
<p>The second distribution type is the <strong>Non-Central Wishart distribution</strong> which is written as:</p>
<p><span class="math display">\[\begin{align}
U \sim W_p(\nu, \Sigma_{(pxp)}, \Upsilon) \equiv Wishart_p(\nu, \Sigma_{(pxp)}, \Upsilon) 
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li><strong>U</strong> is a <strong>precision</strong> or <strong>inverse</strong> covariance <strong>positive-definite</strong> matrix.</li>
<li><span class="math inline">\(\Sigma_{(pxp)}\)</span> is a pxp <strong>non-inverse</strong> covariance <strong>positive-definite scale</strong> matrix</li>
<li><strong>p</strong> is the number of random variables, e.g.Â p-variate distribution.</li>
<li><span class="math inline">\(\mathbf{\nu}\)</span> is degrees of freedom, where <span class="math inline">\(\nu\)</span> &gt; <strong>p</strong> - 1.</li>
</ul>
<p>The <strong>X</strong> is drawn from a multivariate normal distribution of which its covariance matrix is a positive-definite scale matrix with <strong>p</strong> random variables. For illustration, we use bivariate normal distribution where <strong>p</strong> = 2.</p>
<p><span class="math display">\[\begin{align}
X \sim \mathcal{N}(\mu_{(2)}, \Sigma_{(2x2)}),\ \ \ \ \ \ 
\mu_{(2)} = \left(\begin{array}{cc}\mu_1 \\ \mu_2  \end{array}\right),\ \ \ \ \ \ 
\Sigma_{(2x2)} = 
\underbrace{\left(\begin{array}{cc}
\sigma^2_{11} &amp; \sigma^2_{12} \\  
\sigma^2_{21} &amp; \sigma^2_{22}  \\ 
\end{array}\right)_{2x2}}_\text{scale matrix} \label{eqn:eqnnumber25}
\end{align}\]</span></p>
<p>Here we extend the <strong>Central Wishart</strong> equation with two other factors:</p>
<p><span class="math display">\[\begin{align}
U = \sum_{i=1}^n X_i X_k^T\ \ \ \ \ \ \ \ \ \ \ \ \ \Upsilon = N\Sigma^{-1}\mu\mu^T
\end{align}\]</span></p>
<p>The <strong>PDF</strong> for a <strong>Non-Central Wishart distribution</strong> is expressed as:</p>
<p><span class="math display">\[\begin{align}
f_p(U; \nu, \Sigma_{(pxp)}, \Upsilon) = 
    \frac{|U|^{\frac{\nu-p-1}{2}} exp\left[-\frac{1}{2}tr(\Sigma^{-1}U)\right]}
    {2^{\frac{\nu p}{2}}|\Sigma|^{\frac{\nu}{2}}\ \Gamma_p\left(\frac{\nu}{2}\right)}exp\left[-\frac{1}{2}\Upsilon\right]{}_0F_1\left(\frac{\nu}{1}; \frac{1}{4}\Upsilon \Sigma^{-1} U\right)
\end{align}\]</span></p>
<p>The third distribution type is the <strong>Inverse Wishart distribution</strong> which is written as:</p>
<p><span class="math display">\[\begin{align}
\Sigma_{pxp} =  \sim \mathcal{IW}_p(\nu, V) \equiv \mathcal{W}_p^{-1}(\nu, V) 
\end{align}\]</span></p>
<p>where</p>
<ul>
<li><strong>V</strong> is a <strong>inverse</strong> covariance <strong>positive-definite scale</strong> matrix.</li>
<li><span class="math inline">\(\Sigma_{(pxp)}\)</span> is a pxp <strong>non-inverse</strong> covariance <strong>positive-definite</strong> matrix</li>
<li><strong>p</strong> is the number of random variables, e.g.Â p-variate distribution.</li>
<li><span class="math inline">\(\mathbf{\nu}\)</span> is degrees of freedom, where <span class="math inline">\(\nu\)</span> &gt; <strong>p</strong> - 1.</li>
</ul>
<p>The <strong>PDF</strong> for an <strong>Inverse Wishart distribution</strong> is expressed as:</p>
<p><span class="math display">\[\begin{align}
f_p(\Sigma_{(pxp)}; \nu,  V) = 
    \frac{ |\Sigma|^{-\frac{\nu +p+1}{2}}  exp\left[-\frac{1}{2}tr(\Sigma^{-1}V)\right]}
    {2^{\frac{\nu p}{2}}|V|^{-\frac{\nu}{2}}\ \Gamma_p\left(\frac{\nu}{2}\right)}
\end{align}\]</span></p>
<p>and</p>
<p><span class="math display">\[\begin{align}
mean = \frac{V}{v - p - 1}
\end{align}\]</span></p>
<p>It may help to point out that to optimize matrix computation, recall <strong>Cholesky factorization</strong> in Chapter <strong>2</strong> (<strong>Numerical Linear Algebra I</strong>) for <strong>invertible positive definite square matrix</strong> using the upper Cholesky factor. We leave readers to investigate this topic. </p>
</div>
<div id="lkj-distribution" class="section level3 hasAnchor">
<h3><span class="header-section-number">5.9.21</span> LKJ distribution <a href="numericalprobability.html#lkj-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Lewandowski-Kurowicka-Joe (LKJ) distribution</strong> models a distribution around correlations of parameters, treated as random variables. In <strong>Bayesian inference</strong>, we often deal with events as uncertainty (and thus are treated as random). Such correlation is formed as a positive definite correlation matrix.</p>
<p>We leave readers to investigate this distribution as a modern alternative to <strong>Wishart distribution</strong>.</p>
</div>
<div id="mixture-distribution" class="section level3 hasAnchor">
<h3><span class="header-section-number">5.9.22</span> Mixture distribution <a href="numericalprobability.html#mixture-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A <strong>Mixture distribution</strong> is a parent distribution formed from the weighted <span class="math inline">\(\lambda k\)</span> combination of more than one child distribution called components of the parent distribution.</p>
<p>Note that it is possible to plot the individual components. Figure <a href="numericalprobability.html#fig:mixture1b">5.36</a> illustrates 3 components (K=3). The overall mixing proportions, <span class="math inline">\(\pi_{k}\)</span>, equates to 1, e.g., (<span class="math inline">\(\sum_{k}\pi_k = 1\)</span>).</p>
<p>A mixture model has the following <strong>PDF</strong> formula:</p>
<p><span class="math display">\[\begin{align}
f(x) = \sum_k \pi_k f(x|\theta_k)
\end{align}\]</span></p>
<p>where <span class="math inline">\(\pi_k\)</span> is the mixing proportion.</p>
<p>Below is a sample implementation of a <strong>Mixture distribution</strong> using a built-in <strong>KDE</strong> function called <strong>density()</strong> which we briefly introduce under <strong>Non-parametric distribution</strong> section (See Figure <a href="numericalprobability.html#fig:mixture1b">5.36</a>).</p>

<div class="sourceCode" id="cb271"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb271-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">142</span>)</a>
<a class="sourceLine" id="cb271-2" data-line-number="2">n=<span class="dv">500</span></a>
<a class="sourceLine" id="cb271-3" data-line-number="3">x =<span class="st"> </span><span class="kw">c</span>( <span class="kw">rnorm</span>(<span class="dt">n=</span>n<span class="op">/</span><span class="fl">2.5</span>,  <span class="dv">4</span>,  <span class="fl">1.5</span>),</a>
<a class="sourceLine" id="cb271-4" data-line-number="4">           <span class="kw">rnorm</span>(<span class="dt">n=</span>n<span class="op">/</span><span class="fl">2.5</span>, <span class="fl">7.5</span>, <span class="fl">0.4</span>),</a>
<a class="sourceLine" id="cb271-5" data-line-number="5">           <span class="kw">rnorm</span>(<span class="dt">n=</span>n<span class="op">/</span><span class="fl">2.5</span>, <span class="dv">8</span>, <span class="dv">1</span>))</a>
<a class="sourceLine" id="cb271-6" data-line-number="6"></a>
<a class="sourceLine" id="cb271-7" data-line-number="7"><span class="co"># Plotting the main (parent) mixture distribution</span></a>
<a class="sourceLine" id="cb271-8" data-line-number="8"><span class="kw">plot</span>(<span class="kw">density</span>(x),  </a>
<a class="sourceLine" id="cb271-9" data-line-number="9">     <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>, <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">main=</span><span class="st">&quot;Mixture Density&quot;</span>,</a>
<a class="sourceLine" id="cb271-10" data-line-number="10">     <span class="dt">xlab=</span><span class="st">&quot;Three Independent Normal Distributions&quot;</span>)</a>
<a class="sourceLine" id="cb271-11" data-line-number="11"><span class="kw">grid</span>()</a>
<a class="sourceLine" id="cb271-12" data-line-number="12"></a>
<a class="sourceLine" id="cb271-13" data-line-number="13"><span class="co"># Let us use scale for plotting convenience only</span></a>
<a class="sourceLine" id="cb271-14" data-line-number="14"><span class="co"># to fit the components along the mixture distribution</span></a>
<a class="sourceLine" id="cb271-15" data-line-number="15">scale=<span class="fl">3.5</span></a>
<a class="sourceLine" id="cb271-16" data-line-number="16"></a>
<a class="sourceLine" id="cb271-17" data-line-number="17"><span class="co"># Plotting the 1st component distribution</span></a>
<a class="sourceLine" id="cb271-18" data-line-number="18">x =<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n=</span>n<span class="op">/</span><span class="fl">2.5</span>,  <span class="dv">4</span>,  <span class="fl">1.5</span>)</a>
<a class="sourceLine" id="cb271-19" data-line-number="19">c1 =<span class="st"> </span><span class="kw">curve</span>(<span class="kw">dnorm</span>(x, <span class="dv">4</span>, <span class="fl">1.5</span>)<span class="op">/</span>scale, <span class="dt">add=</span><span class="ot">TRUE</span>, <span class="dt">col=</span><span class="st">&quot;green&quot;</span> )</a>
<a class="sourceLine" id="cb271-20" data-line-number="20"></a>
<a class="sourceLine" id="cb271-21" data-line-number="21"><span class="co"># Plotting the 2nd component distribution</span></a>
<a class="sourceLine" id="cb271-22" data-line-number="22">x =<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n=</span>n<span class="op">/</span><span class="fl">2.5</span>, <span class="fl">7.5</span> , <span class="fl">0.4</span>)</a>
<a class="sourceLine" id="cb271-23" data-line-number="23">c2 =<span class="kw">curve</span>(<span class="kw">dnorm</span>(x, <span class="fl">7.5</span>, <span class="fl">0.4</span>)<span class="op">/</span>scale, <span class="dt">add=</span><span class="ot">TRUE</span>, <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>  )</a>
<a class="sourceLine" id="cb271-24" data-line-number="24"></a>
<a class="sourceLine" id="cb271-25" data-line-number="25"><span class="co"># Plotting the 3rd component distribution</span></a>
<a class="sourceLine" id="cb271-26" data-line-number="26">x =<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n=</span>n<span class="op">/</span><span class="fl">2.5</span>, <span class="dv">8</span>, <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb271-27" data-line-number="27">c3 =<span class="st"> </span><span class="kw">curve</span>(<span class="kw">dnorm</span>(x, <span class="dv">8</span>, <span class="dv">1</span>)<span class="op">/</span>scale, <span class="dt">add=</span><span class="ot">TRUE</span>, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>  )</a>
<a class="sourceLine" id="cb271-28" data-line-number="28"></a>
<a class="sourceLine" id="cb271-29" data-line-number="29"><span class="kw">rug</span>(<span class="kw">rnorm</span>(<span class="dt">n=</span><span class="dv">15</span>,  <span class="dv">4</span>,  <span class="fl">1.5</span>), <span class="dt">col=</span><span class="st">&quot;brown&quot;</span>)</a>
<a class="sourceLine" id="cb271-30" data-line-number="30"><span class="kw">rug</span>(<span class="kw">rnorm</span>(<span class="dt">n=</span><span class="dv">15</span>,  <span class="fl">7.5</span>,  <span class="fl">0.4</span>), <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>)</a>
<a class="sourceLine" id="cb271-31" data-line-number="31"><span class="kw">rug</span>(<span class="kw">rnorm</span>(<span class="dt">n=</span><span class="dv">15</span>,  <span class="dv">8</span>,  <span class="dv">1</span>), <span class="dt">col=</span><span class="st">&quot;red&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:mixture1b"></span>
<img src="DS_files/figure-html/mixture1b-1.png" alt="Mixture Distribution" width="80%" />
<p class="caption">
Figure 5.36: Mixture Distribution
</p>
</div>

<p>Note that <strong>mixture gaussian models</strong> are covered under <strong>Expectation-Maximization (EM)</strong> section in Chapter <strong>7</strong> (<strong>Bayesian Computation I</strong>) as extension to <strong>mixture distribution</strong> discussion.</p>
</div>
<div id="non-parametric-distribution" class="section level3 hasAnchor">
<h3><span class="header-section-number">5.9.23</span> Non-parametric distribution <a href="numericalprobability.html#non-parametric-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The previous section discusses about common <strong>PDFs</strong> and <strong>CDFs</strong>. For example, recall the following normal <strong>PDF</strong> function.</p>
<p><span class="math display">\[\begin{align}
f(x; \mu, \sigma) = \frac{1}{\sqrt{2 \pi \sigma^2 }}e^{\frac{(x-\mu)^2}{2\sigma^2}}
\end{align}\]</span></p>
<p>The function is parametric, e.g.Â for <strong>normal</strong> distribution, we use the <strong>mean</strong> and <strong>variance</strong> parameters. In a case in which our data set cannot follow any of the formal distributions that we discussed to represent specific <strong>PDFs</strong> and <strong>CDFs</strong>, we then resort to an estimation of a distribution. We want to simulate a <strong>non-parametric</strong> density function by which our data set can follow some <strong>estimated</strong> distribution. To do that, we use what we call <strong>Kernel Density Estimators (KDE)</strong>. <strong>KDE</strong> and the math involved are introduced in Chapter <strong>3</strong> (<strong>Numerical Linear Algebra II</strong>) under <strong>Kernel Smoothing</strong> Subsection along with a list of <strong>kernel functions and kernel estimators</strong>.</p>
<p>Our guide to being able to construct such an estimated <strong>PDF</strong> is by visualizing a histogram and perhaps drawing a curve that matches it.</p>
<p>Here is a naive implementation of <strong>KDE</strong> (see Figure <a href="numericalprobability.html#fig:kde">5.37</a>) to show the curve and histogram. For our function <strong>K()</strong> implementation, refer to Chapter <strong>3</strong> (<strong>Numerical Linear Algebra II</strong>) under <strong>Kernel Smoothing</strong> Subsection.</p>

<div class="sourceCode" id="cb272"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb272-1" data-line-number="1">kde &lt;-<span class="st"> </span><span class="cf">function</span>( x,  h, kernel) {</a>
<a class="sourceLine" id="cb272-2" data-line-number="2">      X =<span class="st"> </span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">10</span>, <span class="dv">15</span>, <span class="dt">length.out =</span> <span class="dv">200</span>)</a>
<a class="sourceLine" id="cb272-3" data-line-number="3">      m =<span class="st"> </span><span class="kw">length</span>(X); n =<span class="st"> </span><span class="kw">length</span>(x)</a>
<a class="sourceLine" id="cb272-4" data-line-number="4">      y =<span class="st"> </span><span class="kw">c</span>()</a>
<a class="sourceLine" id="cb272-5" data-line-number="5">      <span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>m) {</a>
<a class="sourceLine" id="cb272-6" data-line-number="6">          w =<span class="st"> </span><span class="kw">c</span>()</a>
<a class="sourceLine" id="cb272-7" data-line-number="7">          <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n) {</a>
<a class="sourceLine" id="cb272-8" data-line-number="8">              x_ =<span class="st"> </span>(<span class="dv">1</span> <span class="op">/</span><span class="st"> </span>h) <span class="op">*</span><span class="st"> </span><span class="kw">K</span> ( ( X[k] <span class="op">-</span><span class="st"> </span>x[i] ) <span class="op">/</span><span class="st"> </span>h , kernel )</a>
<a class="sourceLine" id="cb272-9" data-line-number="9">              w =<span class="st"> </span><span class="kw">c</span>(w, x_ )</a>
<a class="sourceLine" id="cb272-10" data-line-number="10">          }</a>
<a class="sourceLine" id="cb272-11" data-line-number="11">          y =<span class="st"> </span><span class="kw">c</span>(y, <span class="kw">sum</span>(w) <span class="op">/</span><span class="st"> </span>n  )</a>
<a class="sourceLine" id="cb272-12" data-line-number="12">      }</a>
<a class="sourceLine" id="cb272-13" data-line-number="13">      <span class="kw">list</span>(<span class="st">&quot;x&quot;</span>=X, <span class="st">&quot;y&quot;</span> =<span class="st"> </span>y)  </a>
<a class="sourceLine" id="cb272-14" data-line-number="14">}</a>
<a class="sourceLine" id="cb272-15" data-line-number="15">x =<span class="st"> </span><span class="kw">c</span>(  <span class="fl">-3.0</span>, <span class="fl">1.0</span>, <span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">7</span>, <span class="dv">9</span>, <span class="dv">10</span> )</a>
<a class="sourceLine" id="cb272-16" data-line-number="16"><span class="co"># Silverman Rule of Thumb (optimal bandwidth)</span></a>
<a class="sourceLine" id="cb272-17" data-line-number="17">h =<span class="st"> </span><span class="kw">bw.nrd</span>(x) <span class="op">-</span><span class="st"> </span><span class="fl">0.2</span></a>
<a class="sourceLine" id="cb272-18" data-line-number="18">kde.our.model =<span class="st"> </span><span class="kw">kde</span>( x, h, <span class="st">&quot;normal&quot;</span>) </a>
<a class="sourceLine" id="cb272-19" data-line-number="19">kde.sj.model =<span class="st"> </span><span class="kw">density</span>(x, <span class="dt">bw=</span><span class="st">&quot;sj&quot;</span>) <span class="co"># Sheather and Jones (1991)</span></a>
<a class="sourceLine" id="cb272-20" data-line-number="20">kde.nrd.model =<span class="st"> </span><span class="kw">density</span>(x, <span class="dt">bw=</span><span class="st">&quot;nrd&quot;</span>) <span class="co"># silverman rule</span></a>
<a class="sourceLine" id="cb272-21" data-line-number="21"></a>
<a class="sourceLine" id="cb272-22" data-line-number="22"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim =</span> <span class="kw">range</span>(<span class="op">-</span><span class="dv">6</span>, <span class="dv">12</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="dv">0</span>, <span class="fl">3.2</span> ),</a>
<a class="sourceLine" id="cb272-23" data-line-number="23">     <span class="dt">xlab=</span><span class="st">&quot;x-axis&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;y-axis&quot;</span>,</a>
<a class="sourceLine" id="cb272-24" data-line-number="24">     <span class="dt">main=</span><span class="st">&quot;Kernel Density Estimation&quot;</span>)</a>
<a class="sourceLine" id="cb272-25" data-line-number="25"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>)</a>
<a class="sourceLine" id="cb272-26" data-line-number="26"></a>
<a class="sourceLine" id="cb272-27" data-line-number="27"><span class="kw">hist</span>(x, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb272-28" data-line-number="28">scale =<span class="st"> </span><span class="dv">28</span></a>
<a class="sourceLine" id="cb272-29" data-line-number="29"><span class="kw">lines</span>(kde.our.model<span class="op">$</span>x, kde.our.model<span class="op">$</span>y <span class="op">*</span><span class="st"> </span>scale, <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>, </a>
<a class="sourceLine" id="cb272-30" data-line-number="30">      <span class="dt">lwd=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb272-31" data-line-number="31"><span class="kw">lines</span>(kde.sj.model<span class="op">$</span>x, kde.sj.model<span class="op">$</span>y <span class="op">*</span><span class="st"> </span>scale, <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, </a>
<a class="sourceLine" id="cb272-32" data-line-number="32">      <span class="dt">lwd=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb272-33" data-line-number="33"><span class="kw">lines</span>(kde.nrd.model<span class="op">$</span>x, kde.nrd.model<span class="op">$</span>y <span class="op">*</span><span class="st"> </span>scale, <span class="dt">col=</span><span class="st">&quot;brown&quot;</span>, </a>
<a class="sourceLine" id="cb272-34" data-line-number="34">      <span class="dt">lwd=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb272-35" data-line-number="35"></a>
<a class="sourceLine" id="cb272-36" data-line-number="36">n =<span class="st"> </span><span class="kw">length</span>(x)</a>
<a class="sourceLine" id="cb272-37" data-line-number="37"><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n) {</a>
<a class="sourceLine" id="cb272-38" data-line-number="38">    mu =<span class="st"> </span>x[i]</a>
<a class="sourceLine" id="cb272-39" data-line-number="39">    x_ =<span class="st"> </span><span class="kw">seq</span>( mu <span class="op">-</span><span class="st"> </span><span class="dv">3</span>, mu <span class="op">+</span><span class="st"> </span><span class="dv">3</span>, <span class="dt">length.out =</span> <span class="dv">50</span>)</a>
<a class="sourceLine" id="cb272-40" data-line-number="40">    y_ =<span class="st"> </span><span class="kw">dnorm</span>(x_, <span class="dt">mean=</span>mu, <span class="dt">sd =</span> <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb272-41" data-line-number="41">    <span class="kw">lines</span>(x_, y_, <span class="dt">col=</span><span class="st">&quot;brown&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb272-42" data-line-number="42">}</a>
<a class="sourceLine" id="cb272-43" data-line-number="43"><span class="kw">rug</span>(x, <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>)</a>
<a class="sourceLine" id="cb272-44" data-line-number="44"><span class="kw">legend</span>(<span class="op">-</span><span class="dv">6</span>, <span class="dv">3</span>, </a>
<a class="sourceLine" id="cb272-45" data-line-number="45">    <span class="dt">legend=</span><span class="kw">c</span>( <span class="st">&quot;our kde (h=1.5)&quot;</span>, </a>
<a class="sourceLine" id="cb272-46" data-line-number="46">              <span class="st">&quot;built-in density(bw=sj)&quot;</span>,</a>
<a class="sourceLine" id="cb272-47" data-line-number="47">              <span class="st">&quot;build-in density(bw=nrd)&quot;</span>),</a>
<a class="sourceLine" id="cb272-48" data-line-number="48">    <span class="dt">col=</span><span class="kw">c</span>( <span class="st">&quot;navyblue&quot;</span>, <span class="st">&quot;darksalmon&quot;</span>, <span class="st">&quot;brown&quot;</span>), <span class="dt">lty=</span><span class="dv">1</span>,  <span class="dt">cex=</span><span class="fl">0.7</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:kde"></span>
<img src="DS_files/figure-html/kde-1.png" alt="Kernel Density Estimation" width="80%" />
<p class="caption">
Figure 5.37: Kernel Density Estimation
</p>
</div>

<p>Notice that our implementation of KDE exactly matches the output of the built-in R function <strong>density()</strong>. The bandwidth is intentionally adjusted with an offset of 0.2 so that the curve produced by our KDE implementation is demonstratively visible and does not overlap with the built-in estimate.</p>
<p>For <strong>bandwidth selection</strong>, we can use the built-in R function <strong>bw.&lt;choices&gt;()</strong>:</p>
<div class="sourceCode" id="cb273"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb273-1" data-line-number="1">(<span class="dt">optimal_bandwidth =</span> <span class="kw">bw.nrd</span>(x)) <span class="co"># Silverman&#39;s Rule of Thumb</span></a></code></pre></div>
<pre><code>## [1] 2.038978</code></pre>
<p>Alternatively, we can use <strong>unbiased cross-validation</strong> with a list of random bandwidths between 2 and 5. With that, we use a tolerance scaled at 0.1 (using the sample provided in the documentation of the built-in R function <strong>bw.ucv()</strong>):</p>
<div class="sourceCode" id="cb275"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb275-1" data-line-number="1"><span class="co"># unbiased cross-validation </span></a>
<a class="sourceLine" id="cb275-2" data-line-number="2">lower =<span class="st"> </span><span class="dv">2</span>; upper =<span class="st"> </span><span class="dv">5</span></a>
<a class="sourceLine" id="cb275-3" data-line-number="3">(<span class="dt">optimal_h =</span> <span class="kw">bw.ucv</span>(x, <span class="dt">nb =</span> <span class="dv">1000</span>, <span class="dt">lower =</span> <span class="fl">0.1</span> <span class="op">*</span><span class="st"> </span>upper, <span class="dt">upper =</span> upper, </a>
<a class="sourceLine" id="cb275-4" data-line-number="4">                    <span class="dt">tol =</span> <span class="fl">0.1</span> <span class="op">*</span><span class="st"> </span>lower))</a></code></pre></div>
<pre><code>## [1] 4.730645</code></pre>
</div>
<div id="multi-dimensional-density" class="section level3 hasAnchor">
<h3><span class="header-section-number">5.9.24</span> Multi-dimensional Density <a href="numericalprobability.html#multi-dimensional-density" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Most of the <strong>parametric</strong> distributions discussed are <strong>unimodal</strong> - a distribution with only one peak. In <strong>mixture distribution</strong>, we begin to show <strong>multimodal</strong> characteristics of the distribution in which we see multiple peaks. The individual peak follows an individual normal distribution. Then finally, in <strong>KDE</strong>, we continue to show <strong>multimodal</strong> behavior; however, high peaks represent stacks of weights (summation of weights) computed based on a choice of <strong>kernel functions</strong>. </p>
<p>Whether the distribution is <strong>unimodal</strong> or <strong>multimodal</strong>, it represents a <strong>univariate</strong> distribution - meaning, we deal with only one random independent variable.</p>
<p>In this section, we show two examples of <strong>multivariate</strong> distribution:</p>
<p><strong>First</strong>, we introduce <strong>multivariate unimodal distribution</strong>, which deals with multiple independent variables with one peak.</p>
<p>We start by using a 3rd-party library called <strong>mvtnorm</strong> and then generate a data set that follows a <strong>multivariate normal distribution</strong> with noise:</p>

<div class="sourceCode" id="cb277"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb277-1" data-line-number="1"><span class="kw">library</span>(mvtnorm)</a>
<a class="sourceLine" id="cb277-2" data-line-number="2"><span class="kw">set.seed</span>(<span class="dv">142</span>)</a>
<a class="sourceLine" id="cb277-3" data-line-number="3">sample_size =<span class="st"> </span>n =<span class="st"> </span><span class="dv">200</span></a>
<a class="sourceLine" id="cb277-4" data-line-number="4">e =<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n=</span>sample_size, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span><span class="dv">1</span>) <span class="op">/</span><span class="st"> </span><span class="dv">30</span>  <span class="co"># Noise/Gaussian Residual</span></a>
<a class="sourceLine" id="cb277-5" data-line-number="5">x =<span class="st">  </span><span class="kw">sample</span>(<span class="kw">seq</span>(<span class="op">-</span><span class="dv">5</span>,<span class="dv">5</span>), <span class="dt">size=</span>n, <span class="dt">replace=</span><span class="ot">TRUE</span>) </a>
<a class="sourceLine" id="cb277-6" data-line-number="6">y =<span class="st">  </span><span class="kw">sample</span>(<span class="kw">seq</span>(<span class="op">-</span><span class="dv">5</span>,<span class="dv">5</span>), <span class="dt">size=</span>n, <span class="dt">replace=</span><span class="ot">TRUE</span>) </a>
<a class="sourceLine" id="cb277-7" data-line-number="7">mu =<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>,<span class="dv">2</span>); sigma =<span class="st"> </span><span class="kw">diag</span>(<span class="dv">1</span>,<span class="dv">2</span>)</a>
<a class="sourceLine" id="cb277-8" data-line-number="8">z =<span class="st"> </span><span class="kw">dmvnorm</span>(<span class="kw">cbind</span>(x, y), <span class="dt">mean =</span> mu,  <span class="dt">sigma=</span>sigma ) <span class="op">+</span><span class="st"> </span>e</a></code></pre></div>

<p>We then use an R function called <strong>loess()</strong> to fit a two-dimensional model to our data using a span of 0.5 and a polynomial degree of 2 - a parabolic polynomial.</p>

<div class="sourceCode" id="cb278"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb278-1" data-line-number="1"><span class="co"># Because we added noise, our goal is to demonstrate how to fit</span></a>
<a class="sourceLine" id="cb278-2" data-line-number="2"><span class="co"># a 2D loess model.</span></a>
<a class="sourceLine" id="cb278-3" data-line-number="3">loess.model =<span class="st"> </span><span class="kw">loess</span>(z <span class="op">~</span><span class="st"> </span>x <span class="op">+</span><span class="st"> </span>y, <span class="dt">degree=</span><span class="dv">2</span>, <span class="dt">span=</span><span class="fl">0.5</span>)</a>
<a class="sourceLine" id="cb278-4" data-line-number="4"><span class="co"># Perform smooth fit by prediction</span></a>
<a class="sourceLine" id="cb278-5" data-line-number="5">x =<span class="st"> </span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">5</span>,<span class="dv">5</span>, <span class="dt">length.out =</span> <span class="dv">50</span>)</a>
<a class="sourceLine" id="cb278-6" data-line-number="6">y =<span class="st"> </span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">5</span>,<span class="dv">5</span>, <span class="dt">length.out =</span> <span class="dv">50</span>)</a>
<a class="sourceLine" id="cb278-7" data-line-number="7">xy.grid =<span class="st"> </span><span class="kw">as.matrix</span>( <span class="kw">expand.grid</span>(x,y))</a>
<a class="sourceLine" id="cb278-8" data-line-number="8">z.fit =<span class="st"> </span>stats<span class="op">::</span><span class="kw">predict</span>(loess.model, <span class="dt">newdata =</span> xy.grid)</a>
<a class="sourceLine" id="cb278-9" data-line-number="9">z.fit =<span class="st"> </span><span class="kw">matrix</span>(<span class="dt">data =</span> z.fit, <span class="dt">nrow=</span><span class="kw">length</span>(x), <span class="dt">ncol=</span><span class="kw">length</span>(y))</a></code></pre></div>

<p>Finally, we plot a <strong>3D perspective view</strong> (See Figure <a href="numericalprobability.html#fig:multiloess">5.38</a>).</p>
<div class="sourceCode" id="cb279"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb279-1" data-line-number="1"><span class="kw">persp</span>(x, y, z.fit, <span class="dt">phi=</span><span class="dv">30</span>, <span class="dt">theta=</span><span class="dv">25</span>, </a>
<a class="sourceLine" id="cb279-2" data-line-number="2">      <span class="dt">xlim=</span><span class="kw">range</span>(<span class="op">-</span><span class="dv">5</span>,<span class="dv">5</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="op">-</span><span class="dv">5</span>,<span class="dv">5</span>),</a>
<a class="sourceLine" id="cb279-3" data-line-number="3">      <span class="dt">main=</span><span class="st">&quot;Fitting LOESS with Multi-Dimensional data&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:multiloess"></span>
<img src="embed0080.1.png" alt="Fitting LOESS with Multi-Dimensional data" width="80%" />
<p class="caption">
Figure 5.38: Fitting LOESS with Multi-Dimensional data
</p>
</div>
<p>In <strong>Statistical Computation</strong>, we extend our discussion on <strong>LOESS</strong> under <strong>Statistical Regression and Statistical Inference</strong>.</p>
<p><strong>Second</strong>, we introduce <strong>multivariate multimodal distribution</strong>, which deals with multiple independent variables with multiple peaks.</p>
<p>We start by using a 3rd-party library called <strong>KernSmooth</strong> and then construct some random sample datasets.</p>
<div class="sourceCode" id="cb280"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb280-1" data-line-number="1"><span class="kw">library</span>(KernSmooth)</a></code></pre></div>
<pre><code>## KernSmooth 2.23 loaded
## Copyright M. P. Wand 1997-2009</code></pre>
<div class="sourceCode" id="cb282"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb282-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">142</span>)</a>
<a class="sourceLine" id="cb282-2" data-line-number="2">sample_size =<span class="st"> </span>n =<span class="st"> </span><span class="dv">40</span> </a>
<a class="sourceLine" id="cb282-3" data-line-number="3">y =<span class="st">  </span><span class="kw">sample</span>(<span class="kw">seq</span>(<span class="dv">1</span>,<span class="dv">9</span>), <span class="dt">size=</span>sample_size, <span class="dt">replace=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb282-4" data-line-number="4">x =<span class="st">  </span><span class="kw">sample</span>(<span class="kw">seq</span>(<span class="dv">1</span>,<span class="dv">9</span>), <span class="dt">size=</span>sample_size, <span class="dt">replace=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb282-5" data-line-number="5">data =<span class="st"> </span><span class="kw">cbind</span>(x, y)</a></code></pre></div>
<p>We then use an R function called <strong>bkde2d()</strong> to fit a two-dimensional <strong>KDE</strong> model to our data with an optimal bandwidth obtained from <strong>bw.nrd()</strong>. Note that <strong>bkde2d()</strong> uses a <strong>bivariate gaussian kernel</strong>. </p>
<div class="sourceCode" id="cb283"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb283-1" data-line-number="1">h =<span class="st"> </span><span class="kw">bw.nrd</span>(x)</a>
<a class="sourceLine" id="cb283-2" data-line-number="2">kde.grid =<span class="st"> </span><span class="kw">bkde2D</span>(<span class="dt">x =</span> data, <span class="dt">bandwidth=</span> h)</a></code></pre></div>
<p>Finally, let us plot a <strong>3D perspective view</strong> of our <strong>multi-dimensional KDE</strong> distribution (See Figure <a href="numericalprobability.html#fig:kde2dpersp">5.39</a>).</p>
<div class="sourceCode" id="cb284"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb284-1" data-line-number="1"><span class="kw">persp</span>(kde.grid<span class="op">$</span>fhat, </a>
<a class="sourceLine" id="cb284-2" data-line-number="2">       <span class="dt">phi=</span><span class="dv">30</span>, <span class="dt">theta=</span><span class="dv">25</span>,</a>
<a class="sourceLine" id="cb284-3" data-line-number="3">       <span class="dt">zlab =</span> <span class="st">&quot;z-axis&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;y-axis&quot;</span>, <span class="dt">xlab =</span> <span class="st">&quot;x-axis&quot;</span>,</a>
<a class="sourceLine" id="cb284-4" data-line-number="4">       <span class="dt">main=</span><span class="st">&quot;Multi-dimensional density estimate (3D perspective)&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:kde2dpersp"></span>
<img src="embed0081.1.png" alt="Multi-dimensional KDE (3D Perspective)" width="80%" />
<p class="caption">
Figure 5.39: Multi-dimensional KDE (3D Perspective)
</p>
</div>
<p>Additionally, we also can show the <strong>contour</strong> of our <strong>3D view</strong> (See Figure <a href="numericalprobability.html#fig:kde2dcontour">5.40</a>).</p>
<div class="sourceCode" id="cb285"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb285-1" data-line-number="1"><span class="kw">contour</span>(kde.grid<span class="op">$</span>x1, kde.grid<span class="op">$</span>x2, kde.grid<span class="op">$</span>fhat,</a>
<a class="sourceLine" id="cb285-2" data-line-number="2">        <span class="dt">xlab=</span><span class="st">&quot;x-axis&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;y-axis&quot;</span>,</a>
<a class="sourceLine" id="cb285-3" data-line-number="3">        <span class="dt">main=</span><span class="st">&quot;Multi-dimensional density estimate (Contour)&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:kde2dcontour"></span>
<img src="DS_files/figure-html/kde2dcontour-1.png" alt="Multi-dimensional KDE (Contour)" width="70%" />
<p class="caption">
Figure 5.40: Multi-dimensional KDE (Contour)
</p>
</div>
</div>
</div>
<div id="summary-3" class="section level2 hasAnchor">
<h2><span class="header-section-number">5.10</span> Summary<a href="numericalprobability.html#summary-3" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Let us review the distributions we covered in this chapter and the built-in R packages that we can use in practice later.</p>

<table>
<caption><span id="tab:sumdist">Table 5.1: </span>Stochastic Distribution (R functions)</caption>
<thead>
<tr class="header">
<th align="left">Distribution</th>
<th align="left">Sampling</th>
<th align="left">Density</th>
<th align="left">Cumulative</th>
<th align="left">Quartile</th>
<th align="left">Notation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Binomial</td>
<td align="left">rbinom</td>
<td align="left">dbinom</td>
<td align="left">pbinom</td>
<td align="left">qbinom</td>
<td align="left">X<span class="math inline">\(\sim\)</span>Bin(n, <span class="math inline">\(\rho\)</span>)</td>
</tr>
<tr class="even">
<td align="left">Multinomial</td>
<td align="left">rmultinom</td>
<td align="left">dmultinom</td>
<td align="left">pmultinom</td>
<td align="left">qmultinom</td>
<td align="left">X<span class="math inline">\(\sim\)</span>Multi(n, <span class="math inline">\(\rho\)</span>)</td>
</tr>
<tr class="odd">
<td align="left">Geometric</td>
<td align="left">rgeom</td>
<td align="left">dgeom</td>
<td align="left">pgeom</td>
<td align="left">qgeom</td>
<td align="left">X<span class="math inline">\(\sim\)</span>Geo(<span class="math inline">\(\rho\)</span>)</td>
</tr>
<tr class="even">
<td align="left">Beta</td>
<td align="left">rbeta</td>
<td align="left">dbeta</td>
<td align="left">pbeta</td>
<td align="left">qbeta</td>
<td align="left">X<span class="math inline">\(\sim\)</span>Beta(<span class="math inline">\(\alpha\)</span>, <span class="math inline">\(\beta\)</span>)</td>
</tr>
<tr class="odd">
<td align="left">Exponential</td>
<td align="left">rexp</td>
<td align="left">dexp</td>
<td align="left">pexp</td>
<td align="left">qexp</td>
<td align="left">X<span class="math inline">\(\sim\)</span>Expo(<span class="math inline">\(\lambda\)</span>)</td>
</tr>
<tr class="even">
<td align="left">Gamma</td>
<td align="left">rgamma</td>
<td align="left">dgamma</td>
<td align="left">pgamma</td>
<td align="left">qgamma</td>
<td align="left">X<span class="math inline">\(\sim\)</span>Gamma(<span class="math inline">\(\alpha\)</span>, <span class="math inline">\(\beta\)</span>)</td>
</tr>
<tr class="odd">
<td align="left">Weibull</td>
<td align="left">rweibull</td>
<td align="left">dweibull</td>
<td align="left">pweibull</td>
<td align="left">qweibull</td>
<td align="left">X<span class="math inline">\(\sim\)</span>Weib(<span class="math inline">\(\alpha\)</span>, <span class="math inline">\(\beta\)</span>)</td>
</tr>
<tr class="even">
<td align="left">Poisson</td>
<td align="left">rpois</td>
<td align="left">dpois</td>
<td align="left">ppois</td>
<td align="left">qpois</td>
<td align="left">X<span class="math inline">\(\sim\)</span>Pois(<span class="math inline">\(\lambda\)</span>)</td>
</tr>
<tr class="odd">
<td align="left">Normal</td>
<td align="left">rnorm</td>
<td align="left">dnorm</td>
<td align="left">pnorm</td>
<td align="left">qrnorm</td>
<td align="left">X<span class="math inline">\(\sim\)</span>N(<span class="math inline">\(\mu\)</span>, <span class="math inline">\(\sigma^2\)</span>)</td>
</tr>
<tr class="even">
<td align="left">Log-normal</td>
<td align="left">rlnorm</td>
<td align="left">dlnorm</td>
<td align="left">plnorm</td>
<td align="left">qlnorm</td>
<td align="left">X<span class="math inline">\(\sim\)</span>ln N(<span class="math inline">\(\mu\)</span>, <span class="math inline">\(\sigma^2\)</span>)</td>
</tr>
<tr class="odd">
<td align="left">T</td>
<td align="left">rt</td>
<td align="left">dt</td>
<td align="left">pt</td>
<td align="left">qt</td>
<td align="left">X<span class="math inline">\(\sim\)</span>T(<span class="math inline">\(\nu\)</span>)</td>
</tr>
<tr class="even">
<td align="left">F</td>
<td align="left">rf</td>
<td align="left">df</td>
<td align="left">pf</td>
<td align="left">qf</td>
<td align="left">X<span class="math inline">\(\sim\)</span><span class="math inline">\(F(\nu_1, \nu_2)\)</span></td>
</tr>
<tr class="odd">
<td align="left">Chi-Squared</td>
<td align="left">rchisq</td>
<td align="left">dchisq</td>
<td align="left">pchisq</td>
<td align="left">qchisq</td>
<td align="left">X<span class="math inline">\(\sim\)</span>X^2(k)$</td>
</tr>
<tr class="even">
<td align="left">Uniform</td>
<td align="left">runif</td>
<td align="left">dunif</td>
<td align="left">punif</td>
<td align="left">qunif</td>
<td align="left">X<span class="math inline">\(\sim\)</span>U(a,b)$</td>
</tr>
<tr class="odd">
<td align="left">Wilcoxon</td>
<td align="left">rwilcox</td>
<td align="left">dwilcox</td>
<td align="left">pwilcox</td>
<td align="left">qwilcox</td>
<td align="left">X<span class="math inline">\(\sim\)</span>RankSum(m,n)</td>
</tr>
<tr class="even">
<td align="left">Wilcoxon</td>
<td align="left">rsignrank</td>
<td align="left">dsignrank</td>
<td align="left">psignrank</td>
<td align="left">qsignrank</td>
<td align="left">X<span class="math inline">\(\sim\)</span>SignRank(n)</td>
</tr>
<tr class="odd">
<td align="left">Logis</td>
<td align="left">rlogis</td>
<td align="left">dlogis</td>
<td align="left">plogis</td>
<td align="left">qlogis</td>
<td align="left">X<span class="math inline">\(\sim\)</span>Logis(l,s)</td>
</tr>
</tbody>
</table>

<p>The build-in R functions allow us to analyze the different distributions. Each distribution is prefixed with the following letters: r, d, p q.</p>
<ul>
<li>r stands for random values.</li>
<li>d stands for density/mass.</li>
<li>p stands for probability distribution corresponding to its quartile (q).</li>
<li>q stands for quartile, corresponding to a probability distribution (p).</li>
</ul>
<p>Therefore, to generate random values for a <strong>Binomial distribution</strong>, we use <strong>rbinom</strong>. We use <strong>dbinom</strong> to get the <strong>PDF</strong>. We use <strong>pbinom</strong> to get the <strong>CDF</strong>. Moreover, we use <strong>qbinom</strong> to get the value <strong>x</strong> (or the quartile).</p>
<p>Note that four distributions (T-distribution, F-distribution, Chi-Squared distribution, Uniform) are covered in Chapter <strong>6</strong> (<strong>Statistical Computation</strong>).</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="numericalcalculus.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="statistics.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "sepia",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["DS.pdf", "DS.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
