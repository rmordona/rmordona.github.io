<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 8 Bayesian Computation II | The Power and Art of Approximation</title>
  <meta name="description" content="Enthused by the promising future of self-learning machines and the continuous advancement of technology, we write this book to cover a compendium of analytical and numerical techniques conflated into a common idea that highlights the fundamental requirements of Data Science and Machine Learning (ML) Engineering. In this book, we review and give brief insights into numerous fundamental ideas around methods of approximation conceived by great experts. We aim to share them with those new to Data Science who are just beginning to develop an inclination toward this field but may not know where to begin. In addition, we hope to introduce some essential aspects of Data Science in a more progressive and possibly structured manner. This book avoids being specific to a target audience depending on interest. The premise is that Data Science can be for everybody, whether one is an engineer, a researcher within a particular domain, or, for that matter, an undergraduate student just trying to get into this field. While we note that our common theme across the book is intuition, contemplating more on basic operations than mathematical rigor, it is essential to revive our understanding of mathematical concepts first. That is founded upon the idea that we express most of what we do in Data Science in the language of mathematics, more numerically inclined in fact than analytical - meaning, we live to decide based on close approximation in many situations. Therefore, it is just right to have a historical perspective of the mathematical foundations which Machine Learning algorithms may have come about - if not at least what they depend upon fundamentally. For that reason, we cover a list of mathematical concepts that are no doubt valuable to eventually get us to Machine Learning concepts. However, only a particular elementary and introductory portion of each field of mathematics is covered as we emphasize only relevant and essential areas. That said, this book comes in three volumes. Volumes I and II of this book briefly cover common topics in Linear Algebra, Numerical Analysis, Statistical Analysis, and Bayesian Analysis. The third part (or volume III) of this book covers Machine Learning and Deep Learning in detail." />
  <meta name="generator" content="bookdown 0.32 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 8 Bayesian Computation II | The Power and Art of Approximation" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Enthused by the promising future of self-learning machines and the continuous advancement of technology, we write this book to cover a compendium of analytical and numerical techniques conflated into a common idea that highlights the fundamental requirements of Data Science and Machine Learning (ML) Engineering. In this book, we review and give brief insights into numerous fundamental ideas around methods of approximation conceived by great experts. We aim to share them with those new to Data Science who are just beginning to develop an inclination toward this field but may not know where to begin. In addition, we hope to introduce some essential aspects of Data Science in a more progressive and possibly structured manner. This book avoids being specific to a target audience depending on interest. The premise is that Data Science can be for everybody, whether one is an engineer, a researcher within a particular domain, or, for that matter, an undergraduate student just trying to get into this field. While we note that our common theme across the book is intuition, contemplating more on basic operations than mathematical rigor, it is essential to revive our understanding of mathematical concepts first. That is founded upon the idea that we express most of what we do in Data Science in the language of mathematics, more numerically inclined in fact than analytical - meaning, we live to decide based on close approximation in many situations. Therefore, it is just right to have a historical perspective of the mathematical foundations which Machine Learning algorithms may have come about - if not at least what they depend upon fundamentally. For that reason, we cover a list of mathematical concepts that are no doubt valuable to eventually get us to Machine Learning concepts. However, only a particular elementary and introductory portion of each field of mathematics is covered as we emphasize only relevant and essential areas. That said, this book comes in three volumes. Volumes I and II of this book briefly cover common topics in Linear Algebra, Numerical Analysis, Statistical Analysis, and Bayesian Analysis. The third part (or volume III) of this book covers Machine Learning and Deep Learning in detail." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 8 Bayesian Computation II | The Power and Art of Approximation" />
  
  <meta name="twitter:description" content="Enthused by the promising future of self-learning machines and the continuous advancement of technology, we write this book to cover a compendium of analytical and numerical techniques conflated into a common idea that highlights the fundamental requirements of Data Science and Machine Learning (ML) Engineering. In this book, we review and give brief insights into numerous fundamental ideas around methods of approximation conceived by great experts. We aim to share them with those new to Data Science who are just beginning to develop an inclination toward this field but may not know where to begin. In addition, we hope to introduce some essential aspects of Data Science in a more progressive and possibly structured manner. This book avoids being specific to a target audience depending on interest. The premise is that Data Science can be for everybody, whether one is an engineer, a researcher within a particular domain, or, for that matter, an undergraduate student just trying to get into this field. While we note that our common theme across the book is intuition, contemplating more on basic operations than mathematical rigor, it is essential to revive our understanding of mathematical concepts first. That is founded upon the idea that we express most of what we do in Data Science in the language of mathematics, more numerically inclined in fact than analytical - meaning, we live to decide based on close approximation in many situations. Therefore, it is just right to have a historical perspective of the mathematical foundations which Machine Learning algorithms may have come about - if not at least what they depend upon fundamentally. For that reason, we cover a list of mathematical concepts that are no doubt valuable to eventually get us to Machine Learning concepts. However, only a particular elementary and introductory portion of each field of mathematics is covered as we emphasize only relevant and essential areas. That said, this book comes in three volumes. Volumes I and II of this book briefly cover common topics in Linear Algebra, Numerical Analysis, Statistical Analysis, and Bayesian Analysis. The third part (or volume III) of this book covers Machine Learning and Deep Learning in detail." />
  

<meta name="author" content="Raymond Michael Ofiaza OrdoÃ±a" />


<meta name="date" content="2023-02-14" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="bayesian.html"/>
<link rel="next" href="machinelearning1.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">The Power and Art of Approximation</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="0.1" data-path="index.html"><a href="index.html#acknowledgment-and-motivations"><i class="fa fa-check"></i><b>0.1</b> Acknowledgment and Motivations</a></li>
<li class="chapter" data-level="0.2" data-path="index.html"><a href="index.html#caveat"><i class="fa fa-check"></i><b>0.2</b> Caveat</a></li>
<li class="chapter" data-level="0.3" data-path="index.html"><a href="index.html#about-the-author"><i class="fa fa-check"></i><b>0.3</b> About the Author</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="" data-path="mathematical-notation.html"><a href="mathematical-notation.html"><i class="fa fa-check"></i>Mathematical Notation</a><ul>
<li class="chapter" data-level="0.4" data-path="mathematical-notation.html"><a href="mathematical-notation.html#notation"><i class="fa fa-check"></i><b>0.4</b> Notation</a></li>
<li class="chapter" data-level="0.5" data-path="mathematical-notation.html"><a href="mathematical-notation.html#number-system"><i class="fa fa-check"></i><b>0.5</b> Number System</a></li>
<li class="chapter" data-level="0.6" data-path="mathematical-notation.html"><a href="mathematical-notation.html#implementation"><i class="fa fa-check"></i><b>0.6</b> Implementation</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="numericalmethods.html"><a href="numericalmethods.html"><i class="fa fa-check"></i><b>1</b> Direct and Indirect Methods</a><ul>
<li class="chapter" data-level="1.1" data-path="numericalmethods.html"><a href="numericalmethods.html#closed-form-equation"><i class="fa fa-check"></i><b>1.1</b> Closed-form equation</a></li>
<li class="chapter" data-level="1.2" data-path="numericalmethods.html"><a href="numericalmethods.html#analytical-and-numerical-solutions"><i class="fa fa-check"></i><b>1.2</b> Analytical and Numerical solutions  </a></li>
<li class="chapter" data-level="1.3" data-path="numericalmethods.html"><a href="numericalmethods.html#significant-figures"><i class="fa fa-check"></i><b>1.3</b> Significant figures</a></li>
<li class="chapter" data-level="1.4" data-path="numericalmethods.html"><a href="numericalmethods.html#accuracy"><i class="fa fa-check"></i><b>1.4</b> Accuracy</a></li>
<li class="chapter" data-level="1.5" data-path="numericalmethods.html"><a href="numericalmethods.html#precision"><i class="fa fa-check"></i><b>1.5</b> Precision </a></li>
<li class="chapter" data-level="1.6" data-path="numericalmethods.html"><a href="numericalmethods.html#stability-and-sensitivity"><i class="fa fa-check"></i><b>1.6</b> Stability and Sensitivity  </a></li>
<li class="chapter" data-level="1.7" data-path="numericalmethods.html"><a href="numericalmethods.html#stiffness-and-implicitness"><i class="fa fa-check"></i><b>1.7</b> Stiffness and Implicitness  </a></li>
<li class="chapter" data-level="1.8" data-path="numericalmethods.html"><a href="numericalmethods.html#conditioning-and-posedness"><i class="fa fa-check"></i><b>1.8</b> Conditioning and Posedness  </a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="linearalgebra.html"><a href="linearalgebra.html"><i class="fa fa-check"></i><b>2</b> Numerical Linear Algebra I</a><ul>
<li class="chapter" data-level="2.1" data-path="linearalgebra.html"><a href="linearalgebra.html#system-of-linear-equations"><i class="fa fa-check"></i><b>2.1</b> System of Linear Equations</a></li>
<li class="chapter" data-level="2.2" data-path="linearalgebra.html"><a href="linearalgebra.html#scalar-vector-and-matrix-tensor"><i class="fa fa-check"></i><b>2.2</b> Scalar, Vector, and Matrix, Tensor</a></li>
<li class="chapter" data-level="2.3" data-path="linearalgebra.html"><a href="linearalgebra.html#transposition-and-multiplication"><i class="fa fa-check"></i><b>2.3</b> Transposition and Multiplication</a><ul>
<li class="chapter" data-level="2.3.1" data-path="linearalgebra.html"><a href="linearalgebra.html#transposition"><i class="fa fa-check"></i><b>2.3.1</b> Transposition</a></li>
<li class="chapter" data-level="2.3.2" data-path="linearalgebra.html"><a href="linearalgebra.html#dot-product"><i class="fa fa-check"></i><b>2.3.2</b> Dot Product</a></li>
<li class="chapter" data-level="2.3.3" data-path="linearalgebra.html"><a href="linearalgebra.html#hadamard-product"><i class="fa fa-check"></i><b>2.3.3</b> Hadamard Product</a></li>
<li class="chapter" data-level="2.3.4" data-path="linearalgebra.html"><a href="linearalgebra.html#kronecker-product"><i class="fa fa-check"></i><b>2.3.4</b> Kronecker Product</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="linearalgebra.html"><a href="linearalgebra.html#magnitude-direction-unit-vectors"><i class="fa fa-check"></i><b>2.4</b> Magnitude, Direction, Unit Vectors</a></li>
<li class="chapter" data-level="2.5" data-path="linearalgebra.html"><a href="linearalgebra.html#linear-combination-and-independence"><i class="fa fa-check"></i><b>2.5</b> Linear Combination and Independence</a></li>
<li class="chapter" data-level="2.6" data-path="linearalgebra.html"><a href="linearalgebra.html#space-span-and-basis"><i class="fa fa-check"></i><b>2.6</b> Space, Span, and Basis</a></li>
<li class="chapter" data-level="2.7" data-path="linearalgebra.html"><a href="linearalgebra.html#determinants"><i class="fa fa-check"></i><b>2.7</b> Determinants </a></li>
<li class="chapter" data-level="2.8" data-path="linearalgebra.html"><a href="linearalgebra.html#minors-cofactors-and-adjugate-forms"><i class="fa fa-check"></i><b>2.8</b> Minors, Cofactors, and Adjugate Forms</a></li>
<li class="chapter" data-level="2.9" data-path="linearalgebra.html"><a href="linearalgebra.html#inverse-form-and-row-echelon-form"><i class="fa fa-check"></i><b>2.9</b> Inverse Form and Row-Echelon Form</a></li>
<li class="chapter" data-level="2.10" data-path="linearalgebra.html"><a href="linearalgebra.html#linear-transformations"><i class="fa fa-check"></i><b>2.10</b> Linear Transformations</a><ul>
<li class="chapter" data-level="2.10.1" data-path="linearalgebra.html"><a href="linearalgebra.html#scaling"><i class="fa fa-check"></i><b>2.10.1</b> Scaling </a></li>
<li class="chapter" data-level="2.10.2" data-path="linearalgebra.html"><a href="linearalgebra.html#transvection-shearing"><i class="fa fa-check"></i><b>2.10.2</b> Transvection (Shearing)  </a></li>
<li class="chapter" data-level="2.10.3" data-path="linearalgebra.html"><a href="linearalgebra.html#rotation"><i class="fa fa-check"></i><b>2.10.3</b> Rotation </a></li>
<li class="chapter" data-level="2.10.4" data-path="linearalgebra.html"><a href="linearalgebra.html#reflection"><i class="fa fa-check"></i><b>2.10.4</b> Reflection </a></li>
<li class="chapter" data-level="2.10.5" data-path="linearalgebra.html"><a href="linearalgebra.html#projection"><i class="fa fa-check"></i><b>2.10.5</b> Projection </a></li>
<li class="chapter" data-level="2.10.6" data-path="linearalgebra.html"><a href="linearalgebra.html#translation"><i class="fa fa-check"></i><b>2.10.6</b> Translation </a></li>
<li class="chapter" data-level="2.10.7" data-path="linearalgebra.html"><a href="linearalgebra.html#dilation-and-composition"><i class="fa fa-check"></i><b>2.10.7</b> Dilation and Composition  </a></li>
</ul></li>
<li class="chapter" data-level="2.11" data-path="linearalgebra.html"><a href="linearalgebra.html#rank-and-nullity"><i class="fa fa-check"></i><b>2.11</b> Rank and Nullity  </a></li>
<li class="chapter" data-level="2.12" data-path="linearalgebra.html"><a href="linearalgebra.html#singularity-and-triviality"><i class="fa fa-check"></i><b>2.12</b> Singularity and Triviality  </a></li>
<li class="chapter" data-level="2.13" data-path="linearalgebra.html"><a href="linearalgebra.html#orthogonality-and-orthonormality"><i class="fa fa-check"></i><b>2.13</b> Orthogonality and Orthonormality  </a></li>
<li class="chapter" data-level="2.14" data-path="linearalgebra.html"><a href="linearalgebra.html#eigenvectors-and-eigenvalues"><i class="fa fa-check"></i><b>2.14</b> Eigenvectors and Eigenvalues  </a></li>
<li class="chapter" data-level="2.15" data-path="linearalgebra.html"><a href="linearalgebra.html#matrix-reconstruction-using-eigenvalues-and-eigenvectors"><i class="fa fa-check"></i><b>2.15</b> Matrix Reconstruction using Eigenvalues and Eigenvectors</a></li>
<li class="chapter" data-level="2.16" data-path="linearalgebra.html"><a href="linearalgebra.html#diagonalizability-of-a-matrix"><i class="fa fa-check"></i><b>2.16</b> Diagonalizability of a Matrix </a></li>
<li class="chapter" data-level="2.17" data-path="linearalgebra.html"><a href="linearalgebra.html#trace-of-a-square-matrix"><i class="fa fa-check"></i><b>2.17</b> Trace of a Square Matrix </a></li>
<li class="chapter" data-level="2.18" data-path="linearalgebra.html"><a href="linearalgebra.html#algebraic-and-geometric-multiplicity"><i class="fa fa-check"></i><b>2.18</b> Algebraic and Geometric Multiplicity</a></li>
<li class="chapter" data-level="2.19" data-path="linearalgebra.html"><a href="linearalgebra.html#types-of-matrices"><i class="fa fa-check"></i><b>2.19</b> Types of Matrices</a></li>
<li class="chapter" data-level="2.20" data-path="linearalgebra.html"><a href="linearalgebra.html#matrix-factorization"><i class="fa fa-check"></i><b>2.20</b> Matrix Factorization </a><ul>
<li class="chapter" data-level="2.20.1" data-path="linearalgebra.html"><a href="linearalgebra.html#eigen-spectral-decomposition"><i class="fa fa-check"></i><b>2.20.1</b> Eigen (Spectral) Decomposition  </a></li>
<li class="chapter" data-level="2.20.2" data-path="linearalgebra.html"><a href="linearalgebra.html#ludecomposition"><i class="fa fa-check"></i><b>2.20.2</b> LU Decomposition (Doolittle Algorithm)</a></li>
<li class="chapter" data-level="2.20.3" data-path="linearalgebra.html"><a href="linearalgebra.html#ldu-factorization"><i class="fa fa-check"></i><b>2.20.3</b> LDU Factorization </a></li>
<li class="chapter" data-level="2.20.4" data-path="linearalgebra.html"><a href="linearalgebra.html#qr-factorization-gram-schmidt-householder-and-givens"><i class="fa fa-check"></i><b>2.20.4</b> QR Factorization (Gram-Schmidt, Householder, and Givens) </a></li>
<li class="chapter" data-level="2.20.5" data-path="linearalgebra.html"><a href="linearalgebra.html#cholesky-factorization"><i class="fa fa-check"></i><b>2.20.5</b> Cholesky Factorization </a></li>
<li class="chapter" data-level="2.20.6" data-path="linearalgebra.html"><a href="linearalgebra.html#svd-factorization"><i class="fa fa-check"></i><b>2.20.6</b> SVD Factorization </a></li>
<li class="chapter" data-level="2.20.7" data-path="linearalgebra.html"><a href="linearalgebra.html#jordan-decomposition"><i class="fa fa-check"></i><b>2.20.7</b> Jordan Decomposition </a></li>
<li class="chapter" data-level="2.20.8" data-path="linearalgebra.html"><a href="linearalgebra.html#other-decomposition"><i class="fa fa-check"></i><b>2.20.8</b> Other Decomposition</a></li>
</ul></li>
<li class="chapter" data-level="2.21" data-path="linearalgebra.html"><a href="linearalgebra.html#software-libraries"><i class="fa fa-check"></i><b>2.21</b> Software libraries    </a></li>
<li class="chapter" data-level="2.22" data-path="linearalgebra.html"><a href="linearalgebra.html#summary"><i class="fa fa-check"></i><b>2.22</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html"><i class="fa fa-check"></i><b>3</b> Numerical Linear Algebra II</a><ul>
<li class="chapter" data-level="3.1" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#iteration-and-convergence"><i class="fa fa-check"></i><b>3.1</b> Iteration and Convergence </a></li>
<li class="chapter" data-level="3.2" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#approximating-eigenvalues-and-eigenvectors-by-iteration-av-lambda-v"><i class="fa fa-check"></i><b>3.2</b> Approximating Eigenvalues and EigenVectors by Iteration (<span class="math inline">\(Av = \lambda v\)</span>)</a><ul>
<li class="chapter" data-level="3.2.1" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#power-method"><i class="fa fa-check"></i><b>3.2.1</b> Power Method </a></li>
<li class="chapter" data-level="3.2.2" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#inverse-power-method-using-lu-decomposition"><i class="fa fa-check"></i><b>3.2.2</b> Inverse Power Method (using LU Decomposition)</a></li>
<li class="chapter" data-level="3.2.3" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#rayleigh-quotient-method-using-lu-decomposition"><i class="fa fa-check"></i><b>3.2.3</b> Rayleigh Quotient Method (using LU Decomposition)</a></li>
<li class="chapter" data-level="3.2.4" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#qr-method-using-qr-decomposition-by-givens"><i class="fa fa-check"></i><b>3.2.4</b> QR Method (using QR Decomposition by Givens)</a></li>
<li class="chapter" data-level="3.2.5" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#jacobi-eigenvalue-method-using-jacobi-rotation"><i class="fa fa-check"></i><b>3.2.5</b> Jacobi Eigenvalue Method (using Jacobi Rotation)</a></li>
<li class="chapter" data-level="3.2.6" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#arnoldi-method-using-gram-schmidt-in-krylov-subspace"><i class="fa fa-check"></i><b>3.2.6</b> Arnoldi Method (using Gram-Schmidt in Krylov Subspace) </a></li>
<li class="chapter" data-level="3.2.7" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#lanczos-method-using-gram-schmidt-in-krylov-subspace"><i class="fa fa-check"></i><b>3.2.7</b> Lanczos Method (using Gram-Schmidt in Krylov Subspace)</a></li>
<li class="chapter" data-level="3.2.8" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#fine-tuning-of-iteration-and-convergence"><i class="fa fa-check"></i><b>3.2.8</b> Fine-Tuning of Iteration and Convergence</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#approximating-root-and-fixed-point-by-iteration"><i class="fa fa-check"></i><b>3.3</b> Approximating Root and Fixed-Point by Iteration</a><ul>
<li class="chapter" data-level="3.3.1" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#root-finding-method-fx-0"><i class="fa fa-check"></i><b>3.3.1</b> Root-Finding Method (<span class="math inline">\(f(x) = 0\)</span>) </a></li>
<li class="chapter" data-level="3.3.2" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#fixed-point-method-fx-x"><i class="fa fa-check"></i><b>3.3.2</b> Fixed-Point Method (<span class="math inline">\(f(x) = x\)</span>) </a></li>
<li class="chapter" data-level="3.3.3" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#bisection-method"><i class="fa fa-check"></i><b>3.3.3</b> Bisection Method </a></li>
<li class="chapter" data-level="3.3.4" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#newton-raphson-method-using-the-tangent-line"><i class="fa fa-check"></i><b>3.3.4</b> Newton-Raphson Method (using the Tangent Line)</a></li>
<li class="chapter" data-level="3.3.5" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#secant-method-using-the-secant-line"><i class="fa fa-check"></i><b>3.3.5</b> Secant Method (using the Secant Line)</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#approximating-solutions-to-systems-of-eqs-by-iteration-ax-b"><i class="fa fa-check"></i><b>3.4</b> Approximating Solutions to Systems of Eqs by Iteration (<span class="math inline">\(Ax = b\)</span>)</a><ul>
<li class="chapter" data-level="3.4.1" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#krylovmethods"><i class="fa fa-check"></i><b>3.4.1</b> Krylov Methods</a></li>
<li class="chapter" data-level="3.4.2" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#gmres-generalized-minimal-residual"><i class="fa fa-check"></i><b>3.4.2</b> GMRES (Generalized Minimal Residual)  </a></li>
<li class="chapter" data-level="3.4.3" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#conjugate-gradient-method-cg"><i class="fa fa-check"></i><b>3.4.3</b> Conjugate Gradient Method (CG)  </a></li>
<li class="chapter" data-level="3.4.4" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#jacobi-and-gauss-seidel-method"><i class="fa fa-check"></i><b>3.4.4</b> Jacobi and Gauss-Seidel Method </a></li>
<li class="chapter" data-level="3.4.5" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#successive-over-relaxation-sor-method"><i class="fa fa-check"></i><b>3.4.5</b> Successive Over-Relaxation (SOR) Method  </a></li>
<li class="chapter" data-level="3.4.6" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#newtons-method"><i class="fa fa-check"></i><b>3.4.6</b> Newtonâs Method </a></li>
<li class="chapter" data-level="3.4.7" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#broydens-method"><i class="fa fa-check"></i><b>3.4.7</b> Broydenâs Method </a></li>
<li class="chapter" data-level="3.4.8" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#bfgs-broyden-fletcher-goldfarb-shanno-method"><i class="fa fa-check"></i><b>3.4.8</b> BFGS (Broyden-Fletcher-Goldfarb-Shanno) method </a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#polynomialregression"><i class="fa fa-check"></i><b>3.5</b> Approximating Polynomial Functions by Regression</a><ul>
<li class="chapter" data-level="3.5.1" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#least-squares"><i class="fa fa-check"></i><b>3.5.1</b> Least-Squares </a></li>
<li class="chapter" data-level="3.5.2" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#linear-regression"><i class="fa fa-check"></i><b>3.5.2</b> Linear Regression </a></li>
<li class="chapter" data-level="3.5.3" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#higherdegreepolynomials"><i class="fa fa-check"></i><b>3.5.3</b> Higher Degree Polynomials</a></li>
<li class="chapter" data-level="3.5.4" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#non-linear-regression"><i class="fa fa-check"></i><b>3.5.4</b> Non-Linear Regression </a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#approximating-polynomial-functions-by-series-expansion"><i class="fa fa-check"></i><b>3.6</b> Approximating Polynomial Functions by Series Expansion </a></li>
<li class="chapter" data-level="3.7" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#polynomialinterpolation"><i class="fa fa-check"></i><b>3.7</b> Approximating Polynomial Functions by Interpolation</a><ul>
<li class="chapter" data-level="3.7.1" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#polynomial-interpolation"><i class="fa fa-check"></i><b>3.7.1</b> Polynomial interpolation </a></li>
<li class="chapter" data-level="3.7.2" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#lagrange-interpolation"><i class="fa fa-check"></i><b>3.7.2</b> Lagrange interpolation </a></li>
<li class="chapter" data-level="3.7.3" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#newton-interpolation"><i class="fa fa-check"></i><b>3.7.3</b> Newton interpolation </a></li>
<li class="chapter" data-level="3.7.4" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#newton-forward-interpolation"><i class="fa fa-check"></i><b>3.7.4</b> Newton Forward interpolation </a></li>
<li class="chapter" data-level="3.7.5" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#newton-backward-interpolation"><i class="fa fa-check"></i><b>3.7.5</b> Newton Backward interpolation </a></li>
<li class="chapter" data-level="3.7.6" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#interpolation-considerations"><i class="fa fa-check"></i><b>3.7.6</b> Interpolation Considerations</a></li>
<li class="chapter" data-level="3.7.7" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#lebesque-constant"><i class="fa fa-check"></i><b>3.7.7</b> Lebesque Constant </a></li>
<li class="chapter" data-level="3.7.8" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#horners-method"><i class="fa fa-check"></i><b>3.7.8</b> Hornerâs method </a></li>
<li class="chapter" data-level="3.7.9" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#piecewise-polynomial-interpolation"><i class="fa fa-check"></i><b>3.7.9</b> Piecewise Polynomial Interpolation </a></li>
<li class="chapter" data-level="3.7.10" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#b-spline-interpolation"><i class="fa fa-check"></i><b>3.7.10</b> B-Spline interpolation </a></li>
<li class="chapter" data-level="3.7.11" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#bspline"><i class="fa fa-check"></i><b>3.7.11</b> B-Spline Regression</a></li>
<li class="chapter" data-level="3.7.12" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#p-spline-regression"><i class="fa fa-check"></i><b>3.7.12</b> P-Spline Regression </a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#polynomialsmoothing"><i class="fa fa-check"></i><b>3.8</b> Approximating Polynomial Functions by Smoothing</a><ul>
<li class="chapter" data-level="3.8.1" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#bin-smoothing"><i class="fa fa-check"></i><b>3.8.1</b> Bin Smoothing </a></li>
<li class="chapter" data-level="3.8.2" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#kernel-smoothing"><i class="fa fa-check"></i><b>3.8.2</b> Kernel Smoothing </a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#polynomial-optimization"><i class="fa fa-check"></i><b>3.9</b> Polynomial Optimization </a><ul>
<li class="chapter" data-level="3.9.1" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#simplexmethod"><i class="fa fa-check"></i><b>3.9.1</b> Simplex Method</a></li>
<li class="chapter" data-level="3.9.2" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#dualsimplex"><i class="fa fa-check"></i><b>3.9.2</b> Dual Simplex</a></li>
<li class="chapter" data-level="3.9.3" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#primaldual"><i class="fa fa-check"></i><b>3.9.3</b> Primal-Dual Formulation</a></li>
<li class="chapter" data-level="3.9.4" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#lagrange-multiplier"><i class="fa fa-check"></i><b>3.9.4</b> Lagrange Multiplier </a></li>
<li class="chapter" data-level="3.9.5" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#karush-khun-tucker-conditions"><i class="fa fa-check"></i><b>3.9.5</b> Karush-Khun-Tucker Conditions </a></li>
</ul></li>
<li class="chapter" data-level="3.10" data-path="numericallinearalgebra.html"><a href="numericallinearalgebra.html#summary-1"><i class="fa fa-check"></i><b>3.10</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="numericalcalculus.html"><a href="numericalcalculus.html"><i class="fa fa-check"></i><b>4</b> Numerical Calculus</a><ul>
<li class="chapter" data-level="4.1" data-path="numericalcalculus.html"><a href="numericalcalculus.html#introductory-calculus"><i class="fa fa-check"></i><b>4.1</b> Introductory Calculus</a><ul>
<li class="chapter" data-level="4.1.1" data-path="numericalcalculus.html"><a href="numericalcalculus.html#function"><i class="fa fa-check"></i><b>4.1.1</b> Function</a></li>
<li class="chapter" data-level="4.1.2" data-path="numericalcalculus.html"><a href="numericalcalculus.html#slopes"><i class="fa fa-check"></i><b>4.1.2</b> Slopes</a></li>
<li class="chapter" data-level="4.1.3" data-path="numericalcalculus.html"><a href="numericalcalculus.html#limits"><i class="fa fa-check"></i><b>4.1.3</b> Limits</a></li>
<li class="chapter" data-level="4.1.4" data-path="numericalcalculus.html"><a href="numericalcalculus.html#derivatives"><i class="fa fa-check"></i><b>4.1.4</b> Derivatives</a></li>
<li class="chapter" data-level="4.1.5" data-path="numericalcalculus.html"><a href="numericalcalculus.html#integrals"><i class="fa fa-check"></i><b>4.1.5</b> Integrals </a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="numericalcalculus.html"><a href="numericalcalculus.html#approximation-by-numerical-integration"><i class="fa fa-check"></i><b>4.2</b> Approximation by Numerical Integration </a><ul>
<li class="chapter" data-level="4.2.1" data-path="numericalcalculus.html"><a href="numericalcalculus.html#newton-cotes-quadrature"><i class="fa fa-check"></i><b>4.2.1</b> Newton-Cotes Quadrature </a></li>
<li class="chapter" data-level="4.2.2" data-path="numericalcalculus.html"><a href="numericalcalculus.html#composite-and-adaptive-quadrature"><i class="fa fa-check"></i><b>4.2.2</b> Composite and Adaptive Quadrature </a></li>
<li class="chapter" data-level="4.2.3" data-path="numericalcalculus.html"><a href="numericalcalculus.html#gaussianquadrature"><i class="fa fa-check"></i><b>4.2.3</b> Gaussian Quadrature</a></li>
<li class="chapter" data-level="4.2.4" data-path="numericalcalculus.html"><a href="numericalcalculus.html#romberg-integration"><i class="fa fa-check"></i><b>4.2.4</b> Romberg integration </a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="numericalcalculus.html"><a href="numericalcalculus.html#approximation-by-numerical-differentiation"><i class="fa fa-check"></i><b>4.3</b> Approximation by Numerical Differentiation </a><ul>
<li class="chapter" data-level="4.3.1" data-path="numericalcalculus.html"><a href="numericalcalculus.html#order-of-accuracy"><i class="fa fa-check"></i><b>4.3.1</b> Order of Accuracy</a></li>
<li class="chapter" data-level="4.3.2" data-path="numericalcalculus.html"><a href="numericalcalculus.html#finite-difference"><i class="fa fa-check"></i><b>4.3.2</b> Finite Difference </a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="numericalcalculus.html"><a href="numericalcalculus.html#approximation-using-ordinary-differential-equations"><i class="fa fa-check"></i><b>4.4</b> Approximation using Ordinary Differential Equations  </a><ul>
<li class="chapter" data-level="4.4.1" data-path="numericalcalculus.html"><a href="numericalcalculus.html#eulers-method-explicit"><i class="fa fa-check"></i><b>4.4.1</b> Eulerâs Method (Explicit) </a></li>
<li class="chapter" data-level="4.4.2" data-path="numericalcalculus.html"><a href="numericalcalculus.html#eulers-method-implicit"><i class="fa fa-check"></i><b>4.4.2</b> Eulerâs Method (Implicit)</a></li>
<li class="chapter" data-level="4.4.3" data-path="numericalcalculus.html"><a href="numericalcalculus.html#heuns-method"><i class="fa fa-check"></i><b>4.4.3</b> Heunâs Method </a></li>
<li class="chapter" data-level="4.4.4" data-path="numericalcalculus.html"><a href="numericalcalculus.html#runge-kutta-method"><i class="fa fa-check"></i><b>4.4.4</b> Runge-Kutta Method </a></li>
<li class="chapter" data-level="4.4.5" data-path="numericalcalculus.html"><a href="numericalcalculus.html#shooting-method"><i class="fa fa-check"></i><b>4.4.5</b> Shooting Method </a></li>
<li class="chapter" data-level="4.4.6" data-path="numericalcalculus.html"><a href="numericalcalculus.html#finite-difference-method"><i class="fa fa-check"></i><b>4.4.6</b> Finite Difference Method  </a></li>
<li class="chapter" data-level="4.4.7" data-path="numericalcalculus.html"><a href="numericalcalculus.html#finite-element-method-based-on-wrm-and-vm"><i class="fa fa-check"></i><b>4.4.7</b> Finite Element Method (based on WRM and VM) </a></li>
<li class="chapter" data-level="4.4.8" data-path="numericalcalculus.html"><a href="numericalcalculus.html#least-square-method-using-wrm"><i class="fa fa-check"></i><b>4.4.8</b> Least-Square Method (using WRM)</a></li>
<li class="chapter" data-level="4.4.9" data-path="numericalcalculus.html"><a href="numericalcalculus.html#galerkin-method-using-wrm"><i class="fa fa-check"></i><b>4.4.9</b> Galerkin Method (using WRM)</a></li>
<li class="chapter" data-level="4.4.10" data-path="numericalcalculus.html"><a href="numericalcalculus.html#petrov-galerkin-method-using-wrm"><i class="fa fa-check"></i><b>4.4.10</b> Petrov-Galerkin Method (using WRM)</a></li>
<li class="chapter" data-level="4.4.11" data-path="numericalcalculus.html"><a href="numericalcalculus.html#rayleigh-ritz-method-using-wrm"><i class="fa fa-check"></i><b>4.4.11</b> Rayleigh-Ritz Method (using WRM)</a></li>
<li class="chapter" data-level="4.4.12" data-path="numericalcalculus.html"><a href="numericalcalculus.html#subdomain-method-using-subdomains"><i class="fa fa-check"></i><b>4.4.12</b> Subdomain Method (using subdomains)</a></li>
<li class="chapter" data-level="4.4.13" data-path="numericalcalculus.html"><a href="numericalcalculus.html#collocation-method-using-direct-location-points"><i class="fa fa-check"></i><b>4.4.13</b> Collocation Method (using direct location points) </a></li>
<li class="chapter" data-level="4.4.14" data-path="numericalcalculus.html"><a href="numericalcalculus.html#weighted-residual-summary"><i class="fa fa-check"></i><b>4.4.14</b> Weighted Residual Summary </a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="numericalcalculus.html"><a href="numericalcalculus.html#approximation-using-functional-differential-equations"><i class="fa fa-check"></i><b>4.5</b> Approximation using Functional Differential Equations </a><ul>
<li class="chapter" data-level="4.5.1" data-path="numericalcalculus.html"><a href="numericalcalculus.html#variational-functions"><i class="fa fa-check"></i><b>4.5.1</b> Variational Functions </a></li>
<li class="chapter" data-level="4.5.2" data-path="numericalcalculus.html"><a href="numericalcalculus.html#variational-methods"><i class="fa fa-check"></i><b>4.5.2</b> Variational Methods </a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="numericalcalculus.html"><a href="numericalcalculus.html#approximation-using-partial-differential-equations"><i class="fa fa-check"></i><b>4.6</b> Approximation using Partial Differential Equations </a><ul>
<li class="chapter" data-level="4.6.1" data-path="numericalcalculus.html"><a href="numericalcalculus.html#the-laplace-equation-elliptic-pde"><i class="fa fa-check"></i><b>4.6.1</b> The Laplace Equation (Elliptic PDE)  </a></li>
<li class="chapter" data-level="4.6.2" data-path="numericalcalculus.html"><a href="numericalcalculus.html#the-heat-equation-parabolic-pde"><i class="fa fa-check"></i><b>4.6.2</b> The Heat equation (Parabolic PDE)  </a></li>
<li class="chapter" data-level="4.6.3" data-path="numericalcalculus.html"><a href="numericalcalculus.html#the-wave-equation-hyperbolic-pde"><i class="fa fa-check"></i><b>4.6.3</b> The Wave equation (Hyperbolic PDE)  </a></li>
<li class="chapter" data-level="4.6.4" data-path="numericalcalculus.html"><a href="numericalcalculus.html#the-crank-nicolson-equation"><i class="fa fa-check"></i><b>4.6.4</b> The Crank-Nicolson Equation </a></li>
<li class="chapter" data-level="4.6.5" data-path="numericalcalculus.html"><a href="numericalcalculus.html#the-burgers-equation"><i class="fa fa-check"></i><b>4.6.5</b> The Burgerâs Equation </a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="numericalcalculus.html"><a href="numericalcalculus.html#approximation-using-fourier-series-and-transform"><i class="fa fa-check"></i><b>4.7</b> Approximation using Fourier Series And Transform </a><ul>
<li class="chapter" data-level="4.7.1" data-path="numericalcalculus.html"><a href="numericalcalculus.html#discrete-fourier-transform-dft"><i class="fa fa-check"></i><b>4.7.1</b> Discrete Fourier Transform (DFT)  </a></li>
<li class="chapter" data-level="4.7.2" data-path="numericalcalculus.html"><a href="numericalcalculus.html#inverse-discrete-fourier-transformation-idft"><i class="fa fa-check"></i><b>4.7.2</b> Inverse Discrete Fourier Transformation (IDFT)  </a></li>
<li class="chapter" data-level="4.7.3" data-path="numericalcalculus.html"><a href="numericalcalculus.html#fast-fourier-transform-fft"><i class="fa fa-check"></i><b>4.7.3</b> Fast Fourier Transform (FFT)  </a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="numericalcalculus.html"><a href="numericalcalculus.html#summary-2"><i class="fa fa-check"></i><b>4.8</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="numericalprobability.html"><a href="numericalprobability.html"><i class="fa fa-check"></i><b>5</b> Probability and Distribution</a><ul>
<li class="chapter" data-level="5.1" data-path="numericalprobability.html"><a href="numericalprobability.html#approximation-based-on-random-chances"><i class="fa fa-check"></i><b>5.1</b> Approximation based on Random Chances </a></li>
<li class="chapter" data-level="5.2" data-path="numericalprobability.html"><a href="numericalprobability.html#distribution"><i class="fa fa-check"></i><b>5.2</b> Distribution</a></li>
<li class="chapter" data-level="5.3" data-path="numericalprobability.html"><a href="numericalprobability.html#mass-and-density"><i class="fa fa-check"></i><b>5.3</b> Mass and Density  </a></li>
<li class="chapter" data-level="5.4" data-path="numericalprobability.html"><a href="numericalprobability.html#probability"><i class="fa fa-check"></i><b>5.4</b> Probability  </a></li>
<li class="chapter" data-level="5.5" data-path="numericalprobability.html"><a href="numericalprobability.html#probability-density-function-pdf"><i class="fa fa-check"></i><b>5.5</b> Probability Density Function (PDF)  </a></li>
<li class="chapter" data-level="5.6" data-path="numericalprobability.html"><a href="numericalprobability.html#probability-mass-function-pmf"><i class="fa fa-check"></i><b>5.6</b> Probability Mass function (PMF)  </a></li>
<li class="chapter" data-level="5.7" data-path="numericalprobability.html"><a href="numericalprobability.html#cumulative-distribution-function-cdf"><i class="fa fa-check"></i><b>5.7</b> Cumulative Distribution Function (CDF)  </a></li>
<li class="chapter" data-level="5.8" data-path="numericalprobability.html"><a href="numericalprobability.html#special-functions"><i class="fa fa-check"></i><b>5.8</b> Special Functions</a><ul>
<li class="chapter" data-level="5.8.1" data-path="numericalprobability.html"><a href="numericalprobability.html#gamma-function"><i class="fa fa-check"></i><b>5.8.1</b> Gamma function </a></li>
<li class="chapter" data-level="5.8.2" data-path="numericalprobability.html"><a href="numericalprobability.html#incomplete-gamma-function"><i class="fa fa-check"></i><b>5.8.2</b> Incomplete Gamma function </a></li>
<li class="chapter" data-level="5.8.3" data-path="numericalprobability.html"><a href="numericalprobability.html#digamma-function"><i class="fa fa-check"></i><b>5.8.3</b> Digamma Function </a></li>
<li class="chapter" data-level="5.8.4" data-path="numericalprobability.html"><a href="numericalprobability.html#beta-function"><i class="fa fa-check"></i><b>5.8.4</b> Beta function </a></li>
<li class="chapter" data-level="5.8.5" data-path="numericalprobability.html"><a href="numericalprobability.html#incomplete-beta-function"><i class="fa fa-check"></i><b>5.8.5</b> Incomplete Beta function </a></li>
<li class="chapter" data-level="5.8.6" data-path="numericalprobability.html"><a href="numericalprobability.html#regularized-beta-function"><i class="fa fa-check"></i><b>5.8.6</b> Regularized Beta function  </a></li>
<li class="chapter" data-level="5.8.7" data-path="numericalprobability.html"><a href="numericalprobability.html#hypergeometric-function"><i class="fa fa-check"></i><b>5.8.7</b> Hypergeometric function </a></li>
<li class="chapter" data-level="5.8.8" data-path="numericalprobability.html"><a href="numericalprobability.html#continued-fraction"><i class="fa fa-check"></i><b>5.8.8</b> Continued Fraction </a></li>
<li class="chapter" data-level="5.8.9" data-path="numericalprobability.html"><a href="numericalprobability.html#dirac-delta-function"><i class="fa fa-check"></i><b>5.8.9</b> Dirac Delta Function </a></li>
<li class="chapter" data-level="5.8.10" data-path="numericalprobability.html"><a href="numericalprobability.html#kronecker-delta-function"><i class="fa fa-check"></i><b>5.8.10</b> Kronecker Delta Function </a></li>
</ul></li>
<li class="chapter" data-level="5.9" data-path="numericalprobability.html"><a href="numericalprobability.html#distributiontypes"><i class="fa fa-check"></i><b>5.9</b> Types of Distribution</a><ul>
<li class="chapter" data-level="5.9.1" data-path="numericalprobability.html"><a href="numericalprobability.html#bernoulli-distribution"><i class="fa fa-check"></i><b>5.9.1</b> Bernoulli distribution </a></li>
<li class="chapter" data-level="5.9.2" data-path="numericalprobability.html"><a href="numericalprobability.html#binomial-distribution"><i class="fa fa-check"></i><b>5.9.2</b> Binomial distribution </a></li>
<li class="chapter" data-level="5.9.3" data-path="numericalprobability.html"><a href="numericalprobability.html#multinomial-distribution"><i class="fa fa-check"></i><b>5.9.3</b> Multinomial distribution </a></li>
<li class="chapter" data-level="5.9.4" data-path="numericalprobability.html"><a href="numericalprobability.html#geometric-distribution"><i class="fa fa-check"></i><b>5.9.4</b> Geometric distribution </a></li>
<li class="chapter" data-level="5.9.5" data-path="numericalprobability.html"><a href="numericalprobability.html#beta-distribution"><i class="fa fa-check"></i><b>5.9.5</b> Beta distribution </a></li>
<li class="chapter" data-level="5.9.6" data-path="numericalprobability.html"><a href="numericalprobability.html#dirichlet-distribution"><i class="fa fa-check"></i><b>5.9.6</b> Dirichlet distribution </a></li>
<li class="chapter" data-level="5.9.7" data-path="numericalprobability.html"><a href="numericalprobability.html#exponential-distribution"><i class="fa fa-check"></i><b>5.9.7</b> Exponential distribution </a></li>
<li class="chapter" data-level="5.9.8" data-path="numericalprobability.html"><a href="numericalprobability.html#gamma-distribution"><i class="fa fa-check"></i><b>5.9.8</b> Gamma distribution </a></li>
<li class="chapter" data-level="5.9.9" data-path="numericalprobability.html"><a href="numericalprobability.html#inverse-gamma-distribution"><i class="fa fa-check"></i><b>5.9.9</b> Inverse Gamma distribution </a></li>
<li class="chapter" data-level="5.9.10" data-path="numericalprobability.html"><a href="numericalprobability.html#weibull-distribution"><i class="fa fa-check"></i><b>5.9.10</b> Weibull distribution </a></li>
<li class="chapter" data-level="5.9.11" data-path="numericalprobability.html"><a href="numericalprobability.html#poisson-distribution"><i class="fa fa-check"></i><b>5.9.11</b> Poisson distribution </a></li>
<li class="chapter" data-level="5.9.12" data-path="numericalprobability.html"><a href="numericalprobability.html#pareto-distribution"><i class="fa fa-check"></i><b>5.9.12</b> Pareto distribution </a></li>
<li class="chapter" data-level="5.9.13" data-path="numericalprobability.html"><a href="numericalprobability.html#normal-distribution"><i class="fa fa-check"></i><b>5.9.13</b> Normal distribution </a></li>
<li class="chapter" data-level="5.9.14" data-path="numericalprobability.html"><a href="numericalprobability.html#wald-distribution"><i class="fa fa-check"></i><b>5.9.14</b> Wald Distribution </a></li>
<li class="chapter" data-level="5.9.15" data-path="numericalprobability.html"><a href="numericalprobability.html#log-normal-distribution"><i class="fa fa-check"></i><b>5.9.15</b> Log-normal Distribution </a></li>
<li class="chapter" data-level="5.9.16" data-path="numericalprobability.html"><a href="numericalprobability.html#uniform-distribution"><i class="fa fa-check"></i><b>5.9.16</b> Uniform Distribution </a></li>
<li class="chapter" data-level="5.9.17" data-path="numericalprobability.html"><a href="numericalprobability.html#t-distribution"><i class="fa fa-check"></i><b>5.9.17</b> T-Distribution </a></li>
<li class="chapter" data-level="5.9.18" data-path="numericalprobability.html"><a href="numericalprobability.html#f-distribution"><i class="fa fa-check"></i><b>5.9.18</b> F-Distribution </a></li>
<li class="chapter" data-level="5.9.19" data-path="numericalprobability.html"><a href="numericalprobability.html#chi-square-distribution"><i class="fa fa-check"></i><b>5.9.19</b> Chi-square Distribution </a></li>
<li class="chapter" data-level="5.9.20" data-path="numericalprobability.html"><a href="numericalprobability.html#wishartdistribution"><i class="fa fa-check"></i><b>5.9.20</b> Wishart distribution</a></li>
<li class="chapter" data-level="5.9.21" data-path="numericalprobability.html"><a href="numericalprobability.html#lkj-distribution"><i class="fa fa-check"></i><b>5.9.21</b> LKJ distribution </a></li>
<li class="chapter" data-level="5.9.22" data-path="numericalprobability.html"><a href="numericalprobability.html#mixture-distribution"><i class="fa fa-check"></i><b>5.9.22</b> Mixture distribution </a></li>
<li class="chapter" data-level="5.9.23" data-path="numericalprobability.html"><a href="numericalprobability.html#non-parametric-distribution"><i class="fa fa-check"></i><b>5.9.23</b> Non-parametric distribution </a></li>
<li class="chapter" data-level="5.9.24" data-path="numericalprobability.html"><a href="numericalprobability.html#multi-dimensional-density"><i class="fa fa-check"></i><b>5.9.24</b> Multi-dimensional Density </a></li>
</ul></li>
<li class="chapter" data-level="5.10" data-path="numericalprobability.html"><a href="numericalprobability.html#summary-3"><i class="fa fa-check"></i><b>5.10</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="statistics.html"><a href="statistics.html"><i class="fa fa-check"></i><b>6</b> Statistical Computation</a><ul>
<li class="chapter" data-level="6.1" data-path="statistics.html"><a href="statistics.html#descriptive-statistics"><i class="fa fa-check"></i><b>6.1</b> Descriptive Statistics</a><ul>
<li class="chapter" data-level="6.1.1" data-path="statistics.html"><a href="statistics.html#visual-representation"><i class="fa fa-check"></i><b>6.1.1</b> Visual Representation</a></li>
<li class="chapter" data-level="6.1.2" data-path="statistics.html"><a href="statistics.html#central-tendency"><i class="fa fa-check"></i><b>6.1.2</b> Central Tendency </a></li>
<li class="chapter" data-level="6.1.3" data-path="statistics.html"><a href="statistics.html#variability"><i class="fa fa-check"></i><b>6.1.3</b> Variability </a></li>
<li class="chapter" data-level="6.1.4" data-path="statistics.html"><a href="statistics.html#kurtosis-and-skewness"><i class="fa fa-check"></i><b>6.1.4</b> Kurtosis and Skewness  </a></li>
<li class="chapter" data-level="6.1.5" data-path="statistics.html"><a href="statistics.html#five-number-summary"><i class="fa fa-check"></i><b>6.1.5</b> Five Number Summary  </a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="statistics.html"><a href="statistics.html#inferential-statistics"><i class="fa fa-check"></i><b>6.2</b> Inferential Statistics</a></li>
<li class="chapter" data-level="6.3" data-path="statistics.html"><a href="statistics.html#the-significance-of-difference"><i class="fa fa-check"></i><b>6.3</b> The Significance of Difference </a><ul>
<li class="chapter" data-level="6.3.1" data-path="statistics.html"><a href="statistics.html#hypothesis"><i class="fa fa-check"></i><b>6.3.1</b> Hypothesis</a></li>
<li class="chapter" data-level="6.3.2" data-path="statistics.html"><a href="statistics.html#t-test-true-variance-unknown"><i class="fa fa-check"></i><b>6.3.2</b> T-Test (True Variance unknown) </a></li>
<li class="chapter" data-level="6.3.3" data-path="statistics.html"><a href="statistics.html#z-test-true-variance-known"><i class="fa fa-check"></i><b>6.3.3</b> Z-Test (True Variance known)</a></li>
<li class="chapter" data-level="6.3.4" data-path="statistics.html"><a href="statistics.html#f-test-using-f-ratio"><i class="fa fa-check"></i><b>6.3.4</b> F-Test using F-ratio  </a></li>
<li class="chapter" data-level="6.3.5" data-path="statistics.html"><a href="statistics.html#f-test-with-one-way-anova"><i class="fa fa-check"></i><b>6.3.5</b> F-Test with One-Way ANOVA </a></li>
<li class="chapter" data-level="6.3.6" data-path="statistics.html"><a href="statistics.html#f-test-with-two-way-anova"><i class="fa fa-check"></i><b>6.3.6</b> F-Test with Two-Way ANOVA </a></li>
<li class="chapter" data-level="6.3.7" data-path="statistics.html"><a href="statistics.html#pearsons-chi-square-test"><i class="fa fa-check"></i><b>6.3.7</b> Pearsonâs Chi-square Test </a></li>
<li class="chapter" data-level="6.3.8" data-path="statistics.html"><a href="statistics.html#wilcoxon-test"><i class="fa fa-check"></i><b>6.3.8</b> Wilcoxon Test  </a></li>
<li class="chapter" data-level="6.3.9" data-path="statistics.html"><a href="statistics.html#kruskal-wallis-test"><i class="fa fa-check"></i><b>6.3.9</b> Kruskal-Wallis Test </a></li>
<li class="chapter" data-level="6.3.10" data-path="statistics.html"><a href="statistics.html#friedman-test"><i class="fa fa-check"></i><b>6.3.10</b> Friedman Test </a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="statistics.html"><a href="statistics.html#post-hoc-analysis"><i class="fa fa-check"></i><b>6.4</b> Post-HOC Analysis </a><ul>
<li class="chapter" data-level="6.4.1" data-path="statistics.html"><a href="statistics.html#bonferroni-correction"><i class="fa fa-check"></i><b>6.4.1</b> Bonferroni Correction </a></li>
<li class="chapter" data-level="6.4.2" data-path="statistics.html"><a href="statistics.html#benjamini-hochberg-correction"><i class="fa fa-check"></i><b>6.4.2</b> Benjamini-Hochberg Correction </a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="statistics.html"><a href="statistics.html#multiple-comparison-tests"><i class="fa fa-check"></i><b>6.5</b> Multiple Comparison Tests </a><ul>
<li class="chapter" data-level="6.5.1" data-path="statistics.html"><a href="statistics.html#scheffes-test"><i class="fa fa-check"></i><b>6.5.1</b> Scheffeâs Test </a></li>
<li class="chapter" data-level="6.5.2" data-path="statistics.html"><a href="statistics.html#fishers-test"><i class="fa fa-check"></i><b>6.5.2</b> Fisherâs Test </a></li>
<li class="chapter" data-level="6.5.3" data-path="statistics.html"><a href="statistics.html#tukeys-test"><i class="fa fa-check"></i><b>6.5.3</b> Tukeyâs Test </a></li>
<li class="chapter" data-level="6.5.4" data-path="statistics.html"><a href="statistics.html#newman-keul-test"><i class="fa fa-check"></i><b>6.5.4</b> Newman-Keul Test  </a></li>
<li class="chapter" data-level="6.5.5" data-path="statistics.html"><a href="statistics.html#games-howell-test"><i class="fa fa-check"></i><b>6.5.5</b> Games-Howell Test </a></li>
<li class="chapter" data-level="6.5.6" data-path="statistics.html"><a href="statistics.html#dunnetts-test"><i class="fa fa-check"></i><b>6.5.6</b> Dunnettâs Test </a></li>
<li class="chapter" data-level="6.5.7" data-path="statistics.html"><a href="statistics.html#duncans-test"><i class="fa fa-check"></i><b>6.5.7</b> Duncanâs Test </a></li>
<li class="chapter" data-level="6.5.8" data-path="statistics.html"><a href="statistics.html#meta-analysis-test"><i class="fa fa-check"></i><b>6.5.8</b> Meta-Analysis Test </a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="statistics.html"><a href="statistics.html#statistical-modeling"><i class="fa fa-check"></i><b>6.6</b> Statistical Modeling </a><ul>
<li class="chapter" data-level="6.6.1" data-path="statistics.html"><a href="statistics.html#model-specification"><i class="fa fa-check"></i><b>6.6.1</b> Model Specification </a></li>
<li class="chapter" data-level="6.6.2" data-path="statistics.html"><a href="statistics.html#statistical-interaction"><i class="fa fa-check"></i><b>6.6.2</b> Statistical Interaction </a></li>
<li class="chapter" data-level="6.6.3" data-path="statistics.html"><a href="statistics.html#dummy-variables"><i class="fa fa-check"></i><b>6.6.3</b> Dummy Variables </a></li>
<li class="chapter" data-level="6.6.4" data-path="statistics.html"><a href="statistics.html#model-selection"><i class="fa fa-check"></i><b>6.6.4</b> Model Selection </a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="statistics.html"><a href="statistics.html#regression-analysis"><i class="fa fa-check"></i><b>6.7</b> Regression Analysis </a><ul>
<li class="chapter" data-level="6.7.1" data-path="statistics.html"><a href="statistics.html#assumptions"><i class="fa fa-check"></i><b>6.7.1</b> Assumptions</a></li>
<li class="chapter" data-level="6.7.2" data-path="statistics.html"><a href="statistics.html#correlation-coefficients"><i class="fa fa-check"></i><b>6.7.2</b> Correlation Coefficients </a></li>
<li class="chapter" data-level="6.7.3" data-path="statistics.html"><a href="statistics.html#homoscedasticity-and-heteroscedasticity"><i class="fa fa-check"></i><b>6.7.3</b> Homoscedasticity and Heteroscedasticity  </a></li>
<li class="chapter" data-level="6.7.4" data-path="statistics.html"><a href="statistics.html#normality-and-leverage"><i class="fa fa-check"></i><b>6.7.4</b> Normality and Leverage  </a></li>
<li class="chapter" data-level="6.7.5" data-path="statistics.html"><a href="statistics.html#collinearity"><i class="fa fa-check"></i><b>6.7.5</b> Collinearity </a></li>
<li class="chapter" data-level="6.7.6" data-path="statistics.html"><a href="statistics.html#dispersion"><i class="fa fa-check"></i><b>6.7.6</b> Dispersion </a></li>
<li class="chapter" data-level="6.7.7" data-path="statistics.html"><a href="statistics.html#diagnostic-plots"><i class="fa fa-check"></i><b>6.7.7</b> Diagnostic Plots</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="statistics.html"><a href="statistics.html#the-significance-of-regression"><i class="fa fa-check"></i><b>6.8</b> The Significance of Regression </a><ul>
<li class="chapter" data-level="6.8.1" data-path="statistics.html"><a href="statistics.html#simple-linear-regression"><i class="fa fa-check"></i><b>6.8.1</b> Simple Linear Regression</a></li>
<li class="chapter" data-level="6.8.2" data-path="statistics.html"><a href="statistics.html#multilinear-regression"><i class="fa fa-check"></i><b>6.8.2</b> Multilinear Regression </a></li>
<li class="chapter" data-level="6.8.3" data-path="statistics.html"><a href="statistics.html#logistic-regression"><i class="fa fa-check"></i><b>6.8.3</b> Logistic Regression </a></li>
<li class="chapter" data-level="6.8.4" data-path="statistics.html"><a href="statistics.html#poisson-regression"><i class="fa fa-check"></i><b>6.8.4</b> Poisson Regression </a></li>
<li class="chapter" data-level="6.8.5" data-path="statistics.html"><a href="statistics.html#cox-regression"><i class="fa fa-check"></i><b>6.8.5</b> Cox Regression </a></li>
<li class="chapter" data-level="6.8.6" data-path="statistics.html"><a href="statistics.html#polynomial-regression"><i class="fa fa-check"></i><b>6.8.6</b> Polynomial Regression </a></li>
<li class="chapter" data-level="6.8.7" data-path="statistics.html"><a href="statistics.html#b-splines-and-natural-splines"><i class="fa fa-check"></i><b>6.8.7</b> B-Splines and Natural Splines  </a></li>
<li class="chapter" data-level="6.8.8" data-path="statistics.html"><a href="statistics.html#spline-smoothing"><i class="fa fa-check"></i><b>6.8.8</b> Spline Smoothing </a></li>
<li class="chapter" data-level="6.8.9" data-path="statistics.html"><a href="statistics.html#loess-and-lowess"><i class="fa fa-check"></i><b>6.8.9</b> LOESS and LOWESS  </a></li>
</ul></li>
<li class="chapter" data-level="6.9" data-path="statistics.html"><a href="statistics.html#inference-for-regression"><i class="fa fa-check"></i><b>6.9</b> Inference for Regression</a><ul>
<li class="chapter" data-level="6.9.1" data-path="statistics.html"><a href="statistics.html#goodness-of-fit-linear-regression"><i class="fa fa-check"></i><b>6.9.1</b> Goodness of Fit (Linear Regression) </a></li>
<li class="chapter" data-level="6.9.2" data-path="statistics.html"><a href="statistics.html#goodness-of-fit-non-linear-regression"><i class="fa fa-check"></i><b>6.9.2</b> Goodness of Fit (Non-Linear Regression) </a></li>
<li class="chapter" data-level="6.9.3" data-path="statistics.html"><a href="statistics.html#confidence-interval"><i class="fa fa-check"></i><b>6.9.3</b> Confidence interval </a></li>
</ul></li>
<li class="chapter" data-level="6.10" data-path="statistics.html"><a href="statistics.html#summary-4"><i class="fa fa-check"></i><b>6.10</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="bayesian.html"><a href="bayesian.html"><i class="fa fa-check"></i><b>7</b> Bayesian Computation I</a><ul>
<li class="chapter" data-level="7.1" data-path="bayesian.html"><a href="bayesian.html#probability-1"><i class="fa fa-check"></i><b>7.1</b> Probability </a><ul>
<li class="chapter" data-level="7.1.1" data-path="bayesian.html"><a href="bayesian.html#marginal-probability"><i class="fa fa-check"></i><b>7.1.1</b> Marginal Probability </a></li>
<li class="chapter" data-level="7.1.2" data-path="bayesian.html"><a href="bayesian.html#joint-probability"><i class="fa fa-check"></i><b>7.1.2</b> Joint Probability </a></li>
<li class="chapter" data-level="7.1.3" data-path="bayesian.html"><a href="bayesian.html#conditional-probability"><i class="fa fa-check"></i><b>7.1.3</b> Conditional Probability </a></li>
<li class="chapter" data-level="7.1.4" data-path="bayesian.html"><a href="bayesian.html#negation-probability"><i class="fa fa-check"></i><b>7.1.4</b> Negation Probability </a></li>
<li class="chapter" data-level="7.1.5" data-path="bayesian.html"><a href="bayesian.html#combination-of-probabilities"><i class="fa fa-check"></i><b>7.1.5</b> Combination of Probabilities</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="bayesian.html"><a href="bayesian.html#probability-rules"><i class="fa fa-check"></i><b>7.2</b> Probability Rules</a><ul>
<li class="chapter" data-level="7.2.1" data-path="bayesian.html"><a href="bayesian.html#law-of-total-probability"><i class="fa fa-check"></i><b>7.2.1</b> Law of Total Probability</a></li>
<li class="chapter" data-level="7.2.2" data-path="bayesian.html"><a href="bayesian.html#law-of-total-expectation"><i class="fa fa-check"></i><b>7.2.2</b> Law of Total Expectation </a></li>
<li class="chapter" data-level="7.2.3" data-path="bayesian.html"><a href="bayesian.html#law-of-total-variance"><i class="fa fa-check"></i><b>7.2.3</b> Law of Total Variance </a></li>
<li class="chapter" data-level="7.2.4" data-path="bayesian.html"><a href="bayesian.html#law-of-total-covariance"><i class="fa fa-check"></i><b>7.2.4</b> Law of Total Covariance </a></li>
<li class="chapter" data-level="7.2.5" data-path="bayesian.html"><a href="bayesian.html#law-of-large-numbers"><i class="fa fa-check"></i><b>7.2.5</b> Law of Large Numbers </a></li>
<li class="chapter" data-level="7.2.6" data-path="bayesian.html"><a href="bayesian.html#central-limit-theorem"><i class="fa fa-check"></i><b>7.2.6</b> Central Limit Theorem </a></li>
<li class="chapter" data-level="7.2.7" data-path="bayesian.html"><a href="bayesian.html#rule-of-independence"><i class="fa fa-check"></i><b>7.2.7</b> Rule of Independence </a></li>
<li class="chapter" data-level="7.2.8" data-path="bayesian.html"><a href="bayesian.html#rule-of-exchangeability"><i class="fa fa-check"></i><b>7.2.8</b> Rule of Exchangeability </a></li>
<li class="chapter" data-level="7.2.9" data-path="bayesian.html"><a href="bayesian.html#rule-of-expectation-and-variance"><i class="fa fa-check"></i><b>7.2.9</b> Rule of Expectation and Variance</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="bayesian.html"><a href="bayesian.html#bayes-theorem"><i class="fa fa-check"></i><b>7.3</b> Bayes Theorem </a><ul>
<li class="chapter" data-level="7.3.1" data-path="bayesian.html"><a href="bayesian.html#naÃ¯ve-bayes"><i class="fa fa-check"></i><b>7.3.1</b> NaÃ¯ve Bayes </a></li>
<li class="chapter" data-level="7.3.2" data-path="bayesian.html"><a href="bayesian.html#likelihood"><i class="fa fa-check"></i><b>7.3.2</b> Likelihood</a></li>
<li class="chapter" data-level="7.3.3" data-path="bayesian.html"><a href="bayesian.html#posterior-probability"><i class="fa fa-check"></i><b>7.3.3</b> Posterior Probability  </a></li>
<li class="chapter" data-level="7.3.4" data-path="bayesian.html"><a href="bayesian.html#prior-probability"><i class="fa fa-check"></i><b>7.3.4</b> Prior Probability  </a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="bayesian.html"><a href="bayesian.html#conjugacy"><i class="fa fa-check"></i><b>7.4</b> Conjugacy</a><ul>
<li class="chapter" data-level="7.4.1" data-path="bayesian.html"><a href="bayesian.html#precision-1"><i class="fa fa-check"></i><b>7.4.1</b> Precision </a></li>
<li class="chapter" data-level="7.4.2" data-path="bayesian.html"><a href="bayesian.html#conjugate-prior"><i class="fa fa-check"></i><b>7.4.2</b> Conjugate Prior </a></li>
<li class="chapter" data-level="7.4.3" data-path="bayesian.html"><a href="bayesian.html#normal-normal-conjugacy"><i class="fa fa-check"></i><b>7.4.3</b> Normal-Normal Conjugacy </a></li>
<li class="chapter" data-level="7.4.4" data-path="bayesian.html"><a href="bayesian.html#normal-inverse-gamma-conjugacy"><i class="fa fa-check"></i><b>7.4.4</b> Normal-Inverse Gamma Conjugacy </a></li>
<li class="chapter" data-level="7.4.5" data-path="bayesian.html"><a href="bayesian.html#multivariate-normal-conjugacy"><i class="fa fa-check"></i><b>7.4.5</b> Multivariate Normal Conjugacy </a></li>
<li class="chapter" data-level="7.4.6" data-path="bayesian.html"><a href="bayesian.html#normal-wishart-conjugacy"><i class="fa fa-check"></i><b>7.4.6</b> Normal Wishart Conjugacy </a></li>
<li class="chapter" data-level="7.4.7" data-path="bayesian.html"><a href="bayesian.html#normal-inverse-wishart-conjugacy"><i class="fa fa-check"></i><b>7.4.7</b> Normal-Inverse Wishart Conjugacy </a></li>
<li class="chapter" data-level="7.4.8" data-path="bayesian.html"><a href="bayesian.html#normal-lkj-conjugacy"><i class="fa fa-check"></i><b>7.4.8</b> Normal-LKJ Conjugacy </a></li>
<li class="chapter" data-level="7.4.9" data-path="bayesian.html"><a href="bayesian.html#binomial-beta-conjugacy"><i class="fa fa-check"></i><b>7.4.9</b> Binomial-Beta Conjugacy </a></li>
<li class="chapter" data-level="7.4.10" data-path="bayesian.html"><a href="bayesian.html#geometric-beta-conjugacy"><i class="fa fa-check"></i><b>7.4.10</b> Geometric-Beta Conjugacy </a></li>
<li class="chapter" data-level="7.4.11" data-path="bayesian.html"><a href="bayesian.html#poisson-gamma-conjugacy"><i class="fa fa-check"></i><b>7.4.11</b> Poisson-Gamma Conjugacy </a></li>
<li class="chapter" data-level="7.4.12" data-path="bayesian.html"><a href="bayesian.html#exponential-gamma-conjugacy"><i class="fa fa-check"></i><b>7.4.12</b> Exponential-Gamma Conjugacy </a></li>
<li class="chapter" data-level="7.4.13" data-path="bayesian.html"><a href="bayesian.html#multinomial-dirichlet-conjugacy"><i class="fa fa-check"></i><b>7.4.13</b> Multinomial-Dirichlet Conjugacy </a></li>
<li class="chapter" data-level="7.4.14" data-path="bayesian.html"><a href="bayesian.html#hyperparameters"><i class="fa fa-check"></i><b>7.4.14</b> Hyperparameters </a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="bayesian.html"><a href="bayesian.html#information-theory"><i class="fa fa-check"></i><b>7.5</b> Information Theory </a><ul>
<li class="chapter" data-level="7.5.1" data-path="bayesian.html"><a href="bayesian.html#information"><i class="fa fa-check"></i><b>7.5.1</b> Information </a></li>
<li class="chapter" data-level="7.5.2" data-path="bayesian.html"><a href="bayesian.html#entropy"><i class="fa fa-check"></i><b>7.5.2</b> Entropy </a></li>
<li class="chapter" data-level="7.5.3" data-path="bayesian.html"><a href="bayesian.html#gini-index"><i class="fa fa-check"></i><b>7.5.3</b> Gini Index </a></li>
<li class="chapter" data-level="7.5.4" data-path="bayesian.html"><a href="bayesian.html#information-gain"><i class="fa fa-check"></i><b>7.5.4</b> Information Gain </a></li>
<li class="chapter" data-level="7.5.5" data-path="bayesian.html"><a href="bayesian.html#mutual-information"><i class="fa fa-check"></i><b>7.5.5</b> Mutual Information </a></li>
<li class="chapter" data-level="7.5.6" data-path="bayesian.html"><a href="bayesian.html#kullback-leibler-divergence"><i class="fa fa-check"></i><b>7.5.6</b> Kullback-Leibler Divergence  </a></li>
<li class="chapter" data-level="7.5.7" data-path="bayesian.html"><a href="bayesian.html#jensens-inequality"><i class="fa fa-check"></i><b>7.5.7</b> Jensenâs Inequality</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="bayesian.html"><a href="bayesian.html#bayesianinference"><i class="fa fa-check"></i><b>7.6</b> Bayesian Inference</a><ul>
<li class="chapter" data-level="7.6.1" data-path="bayesian.html"><a href="bayesian.html#maximum-likelihood-mle"><i class="fa fa-check"></i><b>7.6.1</b> Maximum Likelihood (MLE)  </a></li>
<li class="chapter" data-level="7.6.2" data-path="bayesian.html"><a href="bayesian.html#maximum-a-posteriori-map"><i class="fa fa-check"></i><b>7.6.2</b> Maximum A-posteriori (MAP)  </a></li>
<li class="chapter" data-level="7.6.3" data-path="bayesian.html"><a href="bayesian.html#laplace-approximation"><i class="fa fa-check"></i><b>7.6.3</b> Laplace Approximation </a></li>
<li class="chapter" data-level="7.6.4" data-path="bayesian.html"><a href="bayesian.html#expectation-maximization-em"><i class="fa fa-check"></i><b>7.6.4</b> Expectation-Maximization (EM)  </a></li>
<li class="chapter" data-level="7.6.5" data-path="bayesian.html"><a href="bayesian.html#variational-inference"><i class="fa fa-check"></i><b>7.6.5</b> Variational Inference </a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="bayesian2.html"><a href="bayesian2.html"><i class="fa fa-check"></i><b>8</b> Bayesian Computation II</a><ul>
<li class="chapter" data-level="8.1" data-path="bayesian2.html"><a href="bayesian2.html#bayesian-models"><i class="fa fa-check"></i><b>8.1</b> Bayesian Models </a><ul>
<li class="chapter" data-level="8.1.1" data-path="bayesian2.html"><a href="bayesian2.html#belief-propagation"><i class="fa fa-check"></i><b>8.1.1</b> Belief Propagation </a></li>
<li class="chapter" data-level="8.1.2" data-path="bayesian2.html"><a href="bayesian2.html#expectation-propagation"><i class="fa fa-check"></i><b>8.1.2</b> Expectation Propagation </a></li>
<li class="chapter" data-level="8.1.3" data-path="bayesian2.html"><a href="bayesian2.html#markov-chain"><i class="fa fa-check"></i><b>8.1.3</b> Markov Chain </a></li>
<li class="chapter" data-level="8.1.4" data-path="bayesian2.html"><a href="bayesian2.html#hidden-markov-model"><i class="fa fa-check"></i><b>8.1.4</b> Hidden Markov Model  </a></li>
<li class="chapter" data-level="8.1.5" data-path="bayesian2.html"><a href="bayesian2.html#dynamic-system-model"><i class="fa fa-check"></i><b>8.1.5</b> Dynamic System Model</a></li>
<li class="chapter" data-level="8.1.6" data-path="bayesian2.html"><a href="bayesian2.html#bayes-filter"><i class="fa fa-check"></i><b>8.1.6</b> Bayes Filter </a></li>
<li class="chapter" data-level="8.1.7" data-path="bayesian2.html"><a href="bayesian2.html#kalman-filter"><i class="fa fa-check"></i><b>8.1.7</b> Kalman Filter </a></li>
<li class="chapter" data-level="8.1.8" data-path="bayesian2.html"><a href="bayesian2.html#extended-kalman-filter"><i class="fa fa-check"></i><b>8.1.8</b> Extended Kalman Filter </a></li>
<li class="chapter" data-level="8.1.9" data-path="bayesian2.html"><a href="bayesian2.html#unscented-kalman-filter"><i class="fa fa-check"></i><b>8.1.9</b> Unscented Kalman Filter </a></li>
<li class="chapter" data-level="8.1.10" data-path="bayesian2.html"><a href="bayesian2.html#particle-filter"><i class="fa fa-check"></i><b>8.1.10</b> Particle Filter </a></li>
<li class="chapter" data-level="8.1.11" data-path="bayesian2.html"><a href="bayesian2.html#ensemble-kalman-filter"><i class="fa fa-check"></i><b>8.1.11</b> Ensemble Kalman Filter </a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="bayesian2.html"><a href="bayesian2.html#simulation-and-sampling"><i class="fa fa-check"></i><b>8.2</b> Simulation and Sampling</a><ul>
<li class="chapter" data-level="8.2.1" data-path="bayesian2.html"><a href="bayesian2.html#monte-carlo-estimation"><i class="fa fa-check"></i><b>8.2.1</b> Monte Carlo Estimation </a></li>
<li class="chapter" data-level="8.2.2" data-path="bayesian2.html"><a href="bayesian2.html#monte-carlo-simulation"><i class="fa fa-check"></i><b>8.2.2</b> Monte Carlo Simulation </a></li>
<li class="chapter" data-level="8.2.3" data-path="bayesian2.html"><a href="bayesian2.html#markov-chain-monte-carlo"><i class="fa fa-check"></i><b>8.2.3</b> Markov Chain Monte Carlo  </a></li>
<li class="chapter" data-level="8.2.4" data-path="bayesian2.html"><a href="bayesian2.html#metropolis-hastings-monte-carlo"><i class="fa fa-check"></i><b>8.2.4</b> Metropolis-Hastings Monte Carlo  </a></li>
<li class="chapter" data-level="8.2.5" data-path="bayesian2.html"><a href="bayesian2.html#hamiltonian-monte-carlo"><i class="fa fa-check"></i><b>8.2.5</b> Hamiltonian Monte Carlo  </a></li>
<li class="chapter" data-level="8.2.6" data-path="bayesian2.html"><a href="bayesian2.html#gibbs-sampling"><i class="fa fa-check"></i><b>8.2.6</b> Gibbs Sampling </a></li>
<li class="chapter" data-level="8.2.7" data-path="bayesian2.html"><a href="bayesian2.html#importance-sampling"><i class="fa fa-check"></i><b>8.2.7</b> Importance Sampling </a></li>
<li class="chapter" data-level="8.2.8" data-path="bayesian2.html"><a href="bayesian2.html#rejection-sampling"><i class="fa fa-check"></i><b>8.2.8</b> Rejection Sampling </a></li>
<li class="chapter" data-level="8.2.9" data-path="bayesian2.html"><a href="bayesian2.html#jags-modeling"><i class="fa fa-check"></i><b>8.2.9</b> JAGS Modeling </a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="bayesian2.html"><a href="bayesian2.html#bayesian-analysis"><i class="fa fa-check"></i><b>8.3</b> Bayesian Analysis</a><ul>
<li class="chapter" data-level="8.3.1" data-path="bayesian2.html"><a href="bayesian2.html#autocorrelation"><i class="fa fa-check"></i><b>8.3.1</b> Autocorrelation </a></li>
<li class="chapter" data-level="8.3.2" data-path="bayesian2.html"><a href="bayesian2.html#predictive-probability"><i class="fa fa-check"></i><b>8.3.2</b> Predictive Probability </a></li>
<li class="chapter" data-level="8.3.3" data-path="bayesian2.html"><a href="bayesian2.html#posterior-interval"><i class="fa fa-check"></i><b>8.3.3</b> Posterior Interval </a></li>
<li class="chapter" data-level="8.3.4" data-path="bayesian2.html"><a href="bayesian2.html#bayes-factor"><i class="fa fa-check"></i><b>8.3.4</b> Bayes Factor </a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="bayesian2.html"><a href="bayesian2.html#summary-5"><i class="fa fa-check"></i><b>8.4</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="machinelearning1.html"><a href="machinelearning1.html"><i class="fa fa-check"></i><b>9</b> Computational Learning I</a><ul>
<li class="chapter" data-level="9.1" data-path="machinelearning1.html"><a href="machinelearning1.html#observation-and-measurement"><i class="fa fa-check"></i><b>9.1</b> Observation and Measurement</a><ul>
<li class="chapter" data-level="9.1.1" data-path="machinelearning1.html"><a href="machinelearning1.html#levels-of-measurements"><i class="fa fa-check"></i><b>9.1.1</b> Levels of Measurements</a></li>
<li class="chapter" data-level="9.1.2" data-path="machinelearning1.html"><a href="machinelearning1.html#levels-of-categorical-measurements"><i class="fa fa-check"></i><b>9.1.2</b> Levels of Categorical measurements</a></li>
<li class="chapter" data-level="9.1.3" data-path="machinelearning1.html"><a href="machinelearning1.html#levels-of-continuous-measurements"><i class="fa fa-check"></i><b>9.1.3</b> Levels of Continuous measurements</a></li>
<li class="chapter" data-level="9.1.4" data-path="machinelearning1.html"><a href="machinelearning1.html#discrete-vs-continuous-measurements"><i class="fa fa-check"></i><b>9.1.4</b> Discrete vs Continuous measurements</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="machinelearning1.html"><a href="machinelearning1.html#input-data"><i class="fa fa-check"></i><b>9.2</b> Input Data</a><ul>
<li class="chapter" data-level="9.2.1" data-path="machinelearning1.html"><a href="machinelearning1.html#structured-data"><i class="fa fa-check"></i><b>9.2.1</b> Structured Data</a></li>
<li class="chapter" data-level="9.2.2" data-path="machinelearning1.html"><a href="machinelearning1.html#non-structured-data"><i class="fa fa-check"></i><b>9.2.2</b> Non-Structured Data</a></li>
<li class="chapter" data-level="9.2.3" data-path="machinelearning1.html"><a href="machinelearning1.html#statistical-data"><i class="fa fa-check"></i><b>9.2.3</b> Statistical Data</a></li>
<li class="chapter" data-level="9.2.4" data-path="machinelearning1.html"><a href="machinelearning1.html#real-time-and-near-real-time-data"><i class="fa fa-check"></i><b>9.2.4</b> Real-Time and Near Real-Time Data</a></li>
<li class="chapter" data-level="9.2.5" data-path="machinelearning1.html"><a href="machinelearning1.html#oltp-and-datawarehouse"><i class="fa fa-check"></i><b>9.2.5</b> OLTP and Datawarehouse</a></li>
<li class="chapter" data-level="9.2.6" data-path="machinelearning1.html"><a href="machinelearning1.html#data-lake"><i class="fa fa-check"></i><b>9.2.6</b> Data lake</a></li>
<li class="chapter" data-level="9.2.7" data-path="machinelearning1.html"><a href="machinelearning1.html#natural-language-nl"><i class="fa fa-check"></i><b>9.2.7</b> Natural Language (NL)</a></li>
<li class="chapter" data-level="9.2.8" data-path="machinelearning1.html"><a href="machinelearning1.html#multimedia-md"><i class="fa fa-check"></i><b>9.2.8</b> Multimedia (MD)</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="machinelearning1.html"><a href="machinelearning1.html#primitive-methods"><i class="fa fa-check"></i><b>9.3</b> Primitive Methods</a><ul>
<li class="chapter" data-level="9.3.1" data-path="machinelearning1.html"><a href="machinelearning1.html#weighting"><i class="fa fa-check"></i><b>9.3.1</b> Weighting</a></li>
<li class="chapter" data-level="9.3.2" data-path="machinelearning1.html"><a href="machinelearning1.html#smoothing"><i class="fa fa-check"></i><b>9.3.2</b> Smoothing</a></li>
<li class="chapter" data-level="9.3.3" data-path="machinelearning1.html"><a href="machinelearning1.html#normalizing"><i class="fa fa-check"></i><b>9.3.3</b> Normalizing</a></li>
<li class="chapter" data-level="9.3.4" data-path="machinelearning1.html"><a href="machinelearning1.html#standardizing"><i class="fa fa-check"></i><b>9.3.4</b> Standardizing </a></li>
<li class="chapter" data-level="9.3.5" data-path="machinelearning1.html"><a href="machinelearning1.html#centering"><i class="fa fa-check"></i><b>9.3.5</b> Centering </a></li>
<li class="chapter" data-level="9.3.6" data-path="machinelearning1.html"><a href="machinelearning1.html#scaling-1"><i class="fa fa-check"></i><b>9.3.6</b> Scaling </a></li>
<li class="chapter" data-level="9.3.7" data-path="machinelearning1.html"><a href="machinelearning1.html#transforming"><i class="fa fa-check"></i><b>9.3.7</b> Transforming</a></li>
<li class="chapter" data-level="9.3.8" data-path="machinelearning1.html"><a href="machinelearning1.html#clipping"><i class="fa fa-check"></i><b>9.3.8</b> Clipping </a></li>
<li class="chapter" data-level="9.3.9" data-path="machinelearning1.html"><a href="machinelearning1.html#regularizing"><i class="fa fa-check"></i><b>9.3.9</b> Regularizing</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="machinelearning1.html"><a href="machinelearning1.html#distance-metrics"><i class="fa fa-check"></i><b>9.4</b> Distance Metrics</a><ul>
<li class="chapter" data-level="9.4.1" data-path="machinelearning1.html"><a href="machinelearning1.html#cosine-similarity"><i class="fa fa-check"></i><b>9.4.1</b> Cosine Similarity</a></li>
<li class="chapter" data-level="9.4.2" data-path="machinelearning1.html"><a href="machinelearning1.html#manhattan-and-euclidean-distance"><i class="fa fa-check"></i><b>9.4.2</b> Manhattan and Euclidean Distance  </a></li>
<li class="chapter" data-level="9.4.3" data-path="machinelearning1.html"><a href="machinelearning1.html#minkowski-and-chebyshev-supremum-distance"><i class="fa fa-check"></i><b>9.4.3</b> Minkowski and Chebyshev (Supremum) Distance  </a></li>
<li class="chapter" data-level="9.4.4" data-path="machinelearning1.html"><a href="machinelearning1.html#jaccard-similarity-and-distance"><i class="fa fa-check"></i><b>9.4.4</b> Jaccard (Similarity and Distance) </a></li>
<li class="chapter" data-level="9.4.5" data-path="machinelearning1.html"><a href="machinelearning1.html#hamming-distance"><i class="fa fa-check"></i><b>9.4.5</b> Hamming Distance </a></li>
<li class="chapter" data-level="9.4.6" data-path="machinelearning1.html"><a href="machinelearning1.html#mahalanobis-distance"><i class="fa fa-check"></i><b>9.4.6</b> Mahalanobis Distance </a></li>
<li class="chapter" data-level="9.4.7" data-path="machinelearning1.html"><a href="machinelearning1.html#precision-and-accuracy"><i class="fa fa-check"></i><b>9.4.7</b> Precision and Accuracy  </a></li>
<li class="chapter" data-level="9.4.8" data-path="machinelearning1.html"><a href="machinelearning1.html#auc-on-roc"><i class="fa fa-check"></i><b>9.4.8</b> AUC on ROC </a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="machinelearning1.html"><a href="machinelearning1.html#exploratory-data-analysis"><i class="fa fa-check"></i><b>9.5</b> Exploratory Data Analysis</a><ul>
<li class="chapter" data-level="9.5.1" data-path="machinelearning1.html"><a href="machinelearning1.html#data-cleaning-wrangling"><i class="fa fa-check"></i><b>9.5.1</b> Data Cleaning (Wrangling)  </a></li>
<li class="chapter" data-level="9.5.2" data-path="machinelearning1.html"><a href="machinelearning1.html#association"><i class="fa fa-check"></i><b>9.5.2</b> Association</a></li>
<li class="chapter" data-level="9.5.3" data-path="machinelearning1.html"><a href="machinelearning1.html#pattern-discovery"><i class="fa fa-check"></i><b>9.5.3</b> Pattern Discovery</a></li>
<li class="chapter" data-level="9.5.4" data-path="machinelearning1.html"><a href="machinelearning1.html#null-invariance"><i class="fa fa-check"></i><b>9.5.4</b> Null Invariance </a></li>
<li class="chapter" data-level="9.5.5" data-path="machinelearning1.html"><a href="machinelearning1.html#correlation-and-collinearity"><i class="fa fa-check"></i><b>9.5.5</b> Correlation and Collinearity  </a></li>
<li class="chapter" data-level="9.5.6" data-path="machinelearning1.html"><a href="machinelearning1.html#covariance"><i class="fa fa-check"></i><b>9.5.6</b> Covariance </a></li>
<li class="chapter" data-level="9.5.7" data-path="machinelearning1.html"><a href="machinelearning1.html#outliers-leverage-influence"><i class="fa fa-check"></i><b>9.5.7</b> Outliers, Leverage, Influence   </a></li>
<li class="chapter" data-level="9.5.8" data-path="machinelearning1.html"><a href="machinelearning1.html#dominating-factors"><i class="fa fa-check"></i><b>9.5.8</b> Dominating Factors </a></li>
<li class="chapter" data-level="9.5.9" data-path="machinelearning1.html"><a href="machinelearning1.html#missingness-and-imputation"><i class="fa fa-check"></i><b>9.5.9</b> Missingness and Imputation  </a></li>
<li class="chapter" data-level="9.5.10" data-path="machinelearning1.html"><a href="machinelearning1.html#confounding-variable"><i class="fa fa-check"></i><b>9.5.10</b> Confounding Variable </a></li>
<li class="chapter" data-level="9.5.11" data-path="machinelearning1.html"><a href="machinelearning1.html#data-leakage"><i class="fa fa-check"></i><b>9.5.11</b> Data Leakage </a></li>
<li class="chapter" data-level="9.5.12" data-path="machinelearning1.html"><a href="machinelearning1.html#one-hot-encoding"><i class="fa fa-check"></i><b>9.5.12</b> One Hot Encoding </a></li>
<li class="chapter" data-level="9.5.13" data-path="machinelearning1.html"><a href="machinelearning1.html#winsorization-and-trimming"><i class="fa fa-check"></i><b>9.5.13</b> Winsorization and Trimming  </a></li>
<li class="chapter" data-level="9.5.14" data-path="machinelearning1.html"><a href="machinelearning1.html#discretization"><i class="fa fa-check"></i><b>9.5.14</b> Discretization </a></li>
<li class="chapter" data-level="9.5.15" data-path="machinelearning1.html"><a href="machinelearning1.html#stratification"><i class="fa fa-check"></i><b>9.5.15</b> Stratification </a></li>
<li class="chapter" data-level="9.5.16" data-path="machinelearning1.html"><a href="machinelearning1.html#fine-and-coarse-classing"><i class="fa fa-check"></i><b>9.5.16</b> Fine and Coarse Classing</a></li>
<li class="chapter" data-level="9.5.17" data-path="machinelearning1.html"><a href="machinelearning1.html#embedding"><i class="fa fa-check"></i><b>9.5.17</b> Embedding </a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="machinelearning1.html"><a href="machinelearning1.html#featureengineering"><i class="fa fa-check"></i><b>9.6</b> Feature Engineering</a><ul>
<li class="chapter" data-level="9.6.1" data-path="machinelearning1.html"><a href="machinelearning1.html#machine-learning-features"><i class="fa fa-check"></i><b>9.6.1</b> Machine Learning Features</a></li>
<li class="chapter" data-level="9.6.2" data-path="machinelearning1.html"><a href="machinelearning1.html#dimensionality-reduction"><i class="fa fa-check"></i><b>9.6.2</b> Dimensionality Reduction </a></li>
<li class="chapter" data-level="9.6.3" data-path="machinelearning1.html"><a href="machinelearning1.html#principal-component-analysis"><i class="fa fa-check"></i><b>9.6.3</b> Principal Component Analysis  </a></li>
<li class="chapter" data-level="9.6.4" data-path="machinelearning1.html"><a href="machinelearning1.html#linear-discriminant-analysis-lda"><i class="fa fa-check"></i><b>9.6.4</b> Linear Discriminant Analysis (LDA)  </a></li>
<li class="chapter" data-level="9.6.5" data-path="machinelearning1.html"><a href="machinelearning1.html#feature-construction"><i class="fa fa-check"></i><b>9.6.5</b> Feature Construction </a></li>
<li class="chapter" data-level="9.6.6" data-path="machinelearning1.html"><a href="machinelearning1.html#featureselection"><i class="fa fa-check"></i><b>9.6.6</b> Feature Selection</a></li>
<li class="chapter" data-level="9.6.7" data-path="machinelearning1.html"><a href="machinelearning1.html#feature-transformation"><i class="fa fa-check"></i><b>9.6.7</b> Feature Transformation </a></li>
<li class="chapter" data-level="9.6.8" data-path="machinelearning1.html"><a href="machinelearning1.html#model-specification-1"><i class="fa fa-check"></i><b>9.6.8</b> Model Specification </a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="machinelearning1.html"><a href="machinelearning1.html#general-modeling"><i class="fa fa-check"></i><b>9.7</b> General Modeling</a><ul>
<li class="chapter" data-level="9.7.1" data-path="machinelearning1.html"><a href="machinelearning1.html#training-learning"><i class="fa fa-check"></i><b>9.7.1</b> Training (Learning)</a></li>
<li class="chapter" data-level="9.7.2" data-path="machinelearning1.html"><a href="machinelearning1.html#validation-tuning"><i class="fa fa-check"></i><b>9.7.2</b> Validation (Tuning) </a></li>
<li class="chapter" data-level="9.7.3" data-path="machinelearning1.html"><a href="machinelearning1.html#testing-assessing"><i class="fa fa-check"></i><b>9.7.3</b> Testing (Assessing) </a></li>
<li class="chapter" data-level="9.7.4" data-path="machinelearning1.html"><a href="machinelearning1.html#cross-validation-cv"><i class="fa fa-check"></i><b>9.7.4</b> Cross-Validation (CV)  </a></li>
<li class="chapter" data-level="9.7.5" data-path="machinelearning1.html"><a href="machinelearning1.html#bias-and-variance"><i class="fa fa-check"></i><b>9.7.5</b> Bias and Variance </a></li>
<li class="chapter" data-level="9.7.6" data-path="machinelearning1.html"><a href="machinelearning1.html#loss-and-cost-functions"><i class="fa fa-check"></i><b>9.7.6</b> Loss and Cost Functions  </a></li>
<li class="chapter" data-level="9.7.7" data-path="machinelearning1.html"><a href="machinelearning1.html#global-and-local-minima"><i class="fa fa-check"></i><b>9.7.7</b> Global and Local Minima  </a></li>
<li class="chapter" data-level="9.7.8" data-path="machinelearning1.html"><a href="machinelearning1.html#regularization"><i class="fa fa-check"></i><b>9.7.8</b> Regularization</a></li>
</ul></li>
<li class="chapter" data-level="9.8" data-path="machinelearning1.html"><a href="machinelearning1.html#supervised-vs.unsupervised-learning"><i class="fa fa-check"></i><b>9.8</b> Supervised vs.Â Unsupervised Learning  </a></li>
<li class="chapter" data-level="9.9" data-path="machinelearning1.html"><a href="machinelearning1.html#summary-6"><i class="fa fa-check"></i><b>9.9</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="machinelearning2.html"><a href="machinelearning2.html"><i class="fa fa-check"></i><b>10</b> Computational Learning II</a><ul>
<li class="chapter" data-level="10.1" data-path="machinelearning2.html"><a href="machinelearning2.html#regression"><i class="fa fa-check"></i><b>10.1</b> Regression (Supervised)</a><ul>
<li class="chapter" data-level="10.1.1" data-path="machinelearning2.html"><a href="machinelearning2.html#regression-trees"><i class="fa fa-check"></i><b>10.1.1</b> Regression Trees </a></li>
<li class="chapter" data-level="10.1.2" data-path="machinelearning2.html"><a href="machinelearning2.html#ensemble-methods"><i class="fa fa-check"></i><b>10.1.2</b> Ensemble Methods </a></li>
<li class="chapter" data-level="10.1.3" data-path="machinelearning2.html"><a href="machinelearning2.html#random-forest"><i class="fa fa-check"></i><b>10.1.3</b> Random Forest </a></li>
<li class="chapter" data-level="10.1.4" data-path="machinelearning2.html"><a href="machinelearning2.html#Adaoost"><i class="fa fa-check"></i><b>10.1.4</b> AdaBoost</a></li>
<li class="chapter" data-level="10.1.5" data-path="machinelearning2.html"><a href="machinelearning2.html#gradient-boost"><i class="fa fa-check"></i><b>10.1.5</b> Gradient Boost </a></li>
<li class="chapter" data-level="10.1.6" data-path="machinelearning2.html"><a href="machinelearning2.html#xgboost"><i class="fa fa-check"></i><b>10.1.6</b> XGBoost </a></li>
<li class="chapter" data-level="10.1.7" data-path="machinelearning2.html"><a href="machinelearning2.html#generalized-linear-modeling-glm"><i class="fa fa-check"></i><b>10.1.7</b> Generalized Linear Modeling (GLM)  </a></li>
<li class="chapter" data-level="10.1.8" data-path="machinelearning2.html"><a href="machinelearning2.html#logisticregression"><i class="fa fa-check"></i><b>10.1.8</b> Logistic Regression (GLM)</a></li>
<li class="chapter" data-level="10.1.9" data-path="machinelearning2.html"><a href="machinelearning2.html#poisson"><i class="fa fa-check"></i><b>10.1.9</b> Poisson Regression (GLM)</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="machinelearning2.html"><a href="machinelearning2.html#binary-classification-supervised"><i class="fa fa-check"></i><b>10.2</b> Binary Classification (Supervised)</a><ul>
<li class="chapter" data-level="10.2.1" data-path="machinelearning2.html"><a href="machinelearning2.html#linear-svm-sgdpegasos"><i class="fa fa-check"></i><b>10.2.1</b> Linear SVM (SGD/PEGASOS)  </a></li>
<li class="chapter" data-level="10.2.2" data-path="machinelearning2.html"><a href="machinelearning2.html#kernel-svm-smo"><i class="fa fa-check"></i><b>10.2.2</b> Kernel SVM (SMO)  </a></li>
<li class="chapter" data-level="10.2.3" data-path="machinelearning2.html"><a href="machinelearning2.html#sdca-based-svm"><i class="fa fa-check"></i><b>10.2.3</b> SDCA-based SVM </a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="machinelearning2.html"><a href="machinelearning2.html#multi-class-classification-supervised"><i class="fa fa-check"></i><b>10.3</b> Multi-class Classification (Supervised) </a><ul>
<li class="chapter" data-level="10.3.1" data-path="machinelearning2.html"><a href="machinelearning2.html#bayesian-classification"><i class="fa fa-check"></i><b>10.3.1</b> Bayesian Classification </a></li>
<li class="chapter" data-level="10.3.2" data-path="machinelearning2.html"><a href="machinelearning2.html#classification-trees"><i class="fa fa-check"></i><b>10.3.2</b> Classification Trees </a></li>
<li class="chapter" data-level="10.3.3" data-path="machinelearning2.html"><a href="machinelearning2.html#ensemble-methods-1"><i class="fa fa-check"></i><b>10.3.3</b> Ensemble Methods </a></li>
<li class="chapter" data-level="10.3.4" data-path="machinelearning2.html"><a href="machinelearning2.html#random-forest-1"><i class="fa fa-check"></i><b>10.3.4</b> Random Forest </a></li>
<li class="chapter" data-level="10.3.5" data-path="machinelearning2.html"><a href="machinelearning2.html#AdaBoost"><i class="fa fa-check"></i><b>10.3.5</b> AdaBoost &amp; SAMME</a></li>
<li class="chapter" data-level="10.3.6" data-path="machinelearning2.html"><a href="machinelearning2.html#logitboost-j-classes"><i class="fa fa-check"></i><b>10.3.6</b> LogitBoost (J Classes)</a></li>
<li class="chapter" data-level="10.3.7" data-path="machinelearning2.html"><a href="machinelearning2.html#gradient-boost-1"><i class="fa fa-check"></i><b>10.3.7</b> Gradient Boost </a></li>
<li class="chapter" data-level="10.3.8" data-path="machinelearning2.html"><a href="machinelearning2.html#k-next-neighbors-knn"><i class="fa fa-check"></i><b>10.3.8</b> K-Next Neighbors (KNN)  </a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="machinelearning3.html"><a href="machinelearning3.html"><i class="fa fa-check"></i><b>11</b> Computational Learning III</a><ul>
<li class="chapter" data-level="11.1" data-path="machinelearning3.html"><a href="machinelearning3.html#clustering-unsupervised"><i class="fa fa-check"></i><b>11.1</b> Clustering (Unsupervised) </a><ul>
<li class="chapter" data-level="11.1.1" data-path="machinelearning3.html"><a href="machinelearning3.html#k-means-clustering"><i class="fa fa-check"></i><b>11.1.1</b> K-means (clustering) </a></li>
<li class="chapter" data-level="11.1.2" data-path="machinelearning3.html"><a href="machinelearning3.html#hierarchical-clustering"><i class="fa fa-check"></i><b>11.1.2</b> Hierarchical (clustering) </a></li>
<li class="chapter" data-level="11.1.3" data-path="machinelearning3.html"><a href="machinelearning3.html#dbscan-clustering"><i class="fa fa-check"></i><b>11.1.3</b> DBSCAN (clustering) </a></li>
<li class="chapter" data-level="11.1.4" data-path="machinelearning3.html"><a href="machinelearning3.html#quality-of-clustering"><i class="fa fa-check"></i><b>11.1.4</b> Quality of Clustering</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="machinelearning3.html"><a href="machinelearning3.html#meta-learning"><i class="fa fa-check"></i><b>11.2</b> Meta-Learning </a></li>
<li class="chapter" data-level="11.3" data-path="machinelearning3.html"><a href="machinelearning3.html#natural-language-processing-nlp"><i class="fa fa-check"></i><b>11.3</b> Natural Language Processing (NLP)  </a><ul>
<li class="chapter" data-level="11.3.1" data-path="machinelearning3.html"><a href="machinelearning3.html#pre-processing-texts"><i class="fa fa-check"></i><b>11.3.1</b> Pre-Processing Texts</a></li>
<li class="chapter" data-level="11.3.2" data-path="machinelearning3.html"><a href="machinelearning3.html#ranking-and-scoring"><i class="fa fa-check"></i><b>11.3.2</b> Ranking and Scoring </a></li>
<li class="chapter" data-level="11.3.3" data-path="machinelearning3.html"><a href="machinelearning3.html#document-similarity"><i class="fa fa-check"></i><b>11.3.3</b> Document Similarity </a></li>
<li class="chapter" data-level="11.3.4" data-path="machinelearning3.html"><a href="machinelearning3.html#linguistic-analysis"><i class="fa fa-check"></i><b>11.3.4</b> Linguistic Analysis </a></li>
<li class="chapter" data-level="11.3.5" data-path="machinelearning3.html"><a href="machinelearning3.html#lexical-analysis"><i class="fa fa-check"></i><b>11.3.5</b> Lexical Analysis </a></li>
<li class="chapter" data-level="11.3.6" data-path="machinelearning3.html"><a href="machinelearning3.html#semantic-analysis"><i class="fa fa-check"></i><b>11.3.6</b> Semantic Analysis </a></li>
<li class="chapter" data-level="11.3.7" data-path="machinelearning3.html"><a href="machinelearning3.html#named-entity-recognition-ner"><i class="fa fa-check"></i><b>11.3.7</b> Named Entity Recognition (NER)  </a></li>
<li class="chapter" data-level="11.3.8" data-path="machinelearning3.html"><a href="machinelearning3.html#sentiment-and-opinion-analysis"><i class="fa fa-check"></i><b>11.3.8</b> Sentiment and Opinion Analysis  </a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="machinelearning3.html"><a href="machinelearning3.html#time-series-forecasting"><i class="fa fa-check"></i><b>11.4</b> Time-Series Forecasting </a><ul>
<li class="chapter" data-level="11.4.1" data-path="machinelearning3.html"><a href="machinelearning3.html#seasonal-trend-decomposition-using-loess-stl"><i class="fa fa-check"></i><b>11.4.1</b> Seasonal Trend Decomposition using LOESS (STL)  </a></li>
<li class="chapter" data-level="11.4.2" data-path="machinelearning3.html"><a href="machinelearning3.html#forecasting-models"><i class="fa fa-check"></i><b>11.4.2</b> Forecasting Models </a></li>
<li class="chapter" data-level="11.4.3" data-path="machinelearning3.html"><a href="machinelearning3.html#time-series-linear-model-tslm"><i class="fa fa-check"></i><b>11.4.3</b> Time-Series Linear Model (TSLM)  </a></li>
<li class="chapter" data-level="11.4.4" data-path="machinelearning3.html"><a href="machinelearning3.html#autoregressive-integrated-moving-average-arima"><i class="fa fa-check"></i><b>11.4.4</b> AutoRegressive Integrated Moving Average (ARIMA)  </a></li>
<li class="chapter" data-level="11.4.5" data-path="machinelearning3.html"><a href="machinelearning3.html#multiplicative-seasonal-arima-sarima"><i class="fa fa-check"></i><b>11.4.5</b> Multiplicative Seasonal ARIMA (SARIMA) </a></li>
<li class="chapter" data-level="11.4.6" data-path="machinelearning3.html"><a href="machinelearning3.html#time-series-decomposition"><i class="fa fa-check"></i><b>11.4.6</b> Time-Series Decomposition </a></li>
<li class="chapter" data-level="11.4.7" data-path="machinelearning3.html"><a href="machinelearning3.html#stl-with-aicbic"><i class="fa fa-check"></i><b>11.4.7</b> STL with AIC/BIC</a></li>
<li class="chapter" data-level="11.4.8" data-path="machinelearning3.html"><a href="machinelearning3.html#multivariate-time-series"><i class="fa fa-check"></i><b>11.4.8</b> Multivariate Time-Series</a></li>
<li class="chapter" data-level="11.4.9" data-path="machinelearning3.html"><a href="machinelearning3.html#forecasting-considerations"><i class="fa fa-check"></i><b>11.4.9</b> Forecasting Considerations</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="machinelearning3.html"><a href="machinelearning3.html#recommender-systems"><i class="fa fa-check"></i><b>11.5</b> Recommender Systems </a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="deeplearning1.html"><a href="deeplearning1.html"><i class="fa fa-check"></i><b>12</b> Computational Deep Learning I</a><ul>
<li class="chapter" data-level="12.1" data-path="deeplearning1.html"><a href="deeplearning1.html#simple-perceptron"><i class="fa fa-check"></i><b>12.1</b> Simple Perceptron  </a></li>
<li class="chapter" data-level="12.2" data-path="deeplearning1.html"><a href="deeplearning1.html#adaptive-linear-neuron-adaline"><i class="fa fa-check"></i><b>12.2</b> Adaptive Linear Neuron (ADALINE)  </a></li>
<li class="chapter" data-level="12.3" data-path="deeplearning1.html"><a href="deeplearning1.html#multi-layer-perceptron-mlp"><i class="fa fa-check"></i><b>12.3</b> Multi Layer Perceptron (MLP)  </a><ul>
<li class="chapter" data-level="12.3.1" data-path="deeplearning1.html"><a href="deeplearning1.html#forward-feed"><i class="fa fa-check"></i><b>12.3.1</b> Forward Feed </a></li>
<li class="chapter" data-level="12.3.2" data-path="deeplearning1.html"><a href="deeplearning1.html#backward-feed"><i class="fa fa-check"></i><b>12.3.2</b> Backward Feed </a></li>
<li class="chapter" data-level="12.3.3" data-path="deeplearning1.html"><a href="deeplearning1.html#backpropagation"><i class="fa fa-check"></i><b>12.3.3</b> BackPropagation </a></li>
<li class="chapter" data-level="12.3.4" data-path="deeplearning1.html"><a href="deeplearning1.html#mlp-example"><i class="fa fa-check"></i><b>12.3.4</b> MLP Example</a></li>
<li class="chapter" data-level="12.3.5" data-path="deeplearning1.html"><a href="deeplearning1.html#activation-function"><i class="fa fa-check"></i><b>12.3.5</b> Activation Function </a></li>
<li class="chapter" data-level="12.3.6" data-path="deeplearning1.html"><a href="deeplearning1.html#mlp-implementation"><i class="fa fa-check"></i><b>12.3.6</b> MLP Implementation</a></li>
<li class="chapter" data-level="12.3.7" data-path="deeplearning1.html"><a href="deeplearning1.html#deep-neural-network-dnn"><i class="fa fa-check"></i><b>12.3.7</b> Deep Neural Network (DNN)  </a></li>
<li class="chapter" data-level="12.3.8" data-path="deeplearning1.html"><a href="deeplearning1.html#vanishing-and-exploding-gradient"><i class="fa fa-check"></i><b>12.3.8</b> Vanishing and Exploding Gradient  </a></li>
<li class="chapter" data-level="12.3.9" data-path="deeplearning1.html"><a href="deeplearning1.html#dead-relu"><i class="fa fa-check"></i><b>12.3.9</b> Dead Relu </a></li>
<li class="chapter" data-level="12.3.10" data-path="deeplearning1.html"><a href="deeplearning1.html#gradient-clipping-gc"><i class="fa fa-check"></i><b>12.3.10</b> Gradient Clipping (GC) </a></li>
<li class="chapter" data-level="12.3.11" data-path="deeplearning1.html"><a href="deeplearning1.html#parameter-initialization"><i class="fa fa-check"></i><b>12.3.11</b> Parameter Initialization </a></li>
<li class="chapter" data-level="12.3.12" data-path="deeplearning1.html"><a href="deeplearning1.html#regularization-by-dropouts"><i class="fa fa-check"></i><b>12.3.12</b> Regularization by Dropouts </a></li>
<li class="chapter" data-level="12.3.13" data-path="deeplearning1.html"><a href="deeplearning1.html#batch-normalization"><i class="fa fa-check"></i><b>12.3.13</b> Batch Normalization </a></li>
<li class="chapter" data-level="12.3.14" data-path="deeplearning1.html"><a href="deeplearning1.html#optimization"><i class="fa fa-check"></i><b>12.3.14</b> Optimization </a></li>
<li class="chapter" data-level="12.3.15" data-path="deeplearning1.html"><a href="deeplearning1.html#interpretability"><i class="fa fa-check"></i><b>12.3.15</b> Interpretability</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="deeplearning1.html"><a href="deeplearning1.html#convolutional-neural-network-cnn"><i class="fa fa-check"></i><b>12.4</b> Convolutional Neural Network (CNN)  </a><ul>
<li class="chapter" data-level="12.4.1" data-path="deeplearning1.html"><a href="deeplearning1.html#computer-graphics"><i class="fa fa-check"></i><b>12.4.1</b> Computer Graphics</a></li>
<li class="chapter" data-level="12.4.2" data-path="deeplearning1.html"><a href="deeplearning1.html#convolution"><i class="fa fa-check"></i><b>12.4.2</b> Convolution </a></li>
<li class="chapter" data-level="12.4.3" data-path="deeplearning1.html"><a href="deeplearning1.html#stride-and-padding"><i class="fa fa-check"></i><b>12.4.3</b> Stride and Padding  </a></li>
<li class="chapter" data-level="12.4.4" data-path="deeplearning1.html"><a href="deeplearning1.html#kernels-and-filters"><i class="fa fa-check"></i><b>12.4.4</b> Kernels And Filters</a></li>
<li class="chapter" data-level="12.4.5" data-path="deeplearning1.html"><a href="deeplearning1.html#dilation"><i class="fa fa-check"></i><b>12.4.5</b> Dilation </a></li>
<li class="chapter" data-level="12.4.6" data-path="deeplearning1.html"><a href="deeplearning1.html#pooling"><i class="fa fa-check"></i><b>12.4.6</b> Pooling </a></li>
<li class="chapter" data-level="12.4.7" data-path="deeplearning1.html"><a href="deeplearning1.html#cnn-architectures"><i class="fa fa-check"></i><b>12.4.7</b> CNN Architectures</a></li>
<li class="chapter" data-level="12.4.8" data-path="deeplearning1.html"><a href="deeplearning1.html#forward-feed-1"><i class="fa fa-check"></i><b>12.4.8</b> Forward Feed </a></li>
<li class="chapter" data-level="12.4.9" data-path="deeplearning1.html"><a href="deeplearning1.html#backpropagation-1"><i class="fa fa-check"></i><b>12.4.9</b> BackPropagation </a></li>
<li class="chapter" data-level="12.4.10" data-path="deeplearning1.html"><a href="deeplearning1.html#optimization-1"><i class="fa fa-check"></i><b>12.4.10</b> Optimization</a></li>
<li class="chapter" data-level="12.4.11" data-path="deeplearning1.html"><a href="deeplearning1.html#normalization"><i class="fa fa-check"></i><b>12.4.11</b> Normalization</a></li>
<li class="chapter" data-level="12.4.12" data-path="deeplearning1.html"><a href="deeplearning1.html#step-decay"><i class="fa fa-check"></i><b>12.4.12</b> Step Decay</a></li>
<li class="chapter" data-level="12.4.13" data-path="deeplearning1.html"><a href="deeplearning1.html#gemm-matrix-multiplication"><i class="fa fa-check"></i><b>12.4.13</b> GEMM (Matrix Multiplication) </a></li>
<li class="chapter" data-level="12.4.14" data-path="deeplearning1.html"><a href="deeplearning1.html#depthwise-separable-convolution-dsc"><i class="fa fa-check"></i><b>12.4.14</b> Depthwise Separable Convolution (DSC)  </a></li>
<li class="chapter" data-level="12.4.15" data-path="deeplearning1.html"><a href="deeplearning1.html#cnn-implementation"><i class="fa fa-check"></i><b>12.4.15</b> CNN Implementation</a></li>
<li class="chapter" data-level="12.4.16" data-path="deeplearning1.html"><a href="deeplearning1.html#cnn-application"><i class="fa fa-check"></i><b>12.4.16</b> CNN Application</a></li>
<li class="chapter" data-level="12.4.17" data-path="deeplearning1.html"><a href="deeplearning1.html#summary-7"><i class="fa fa-check"></i><b>12.4.17</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="deeplearning2.html"><a href="deeplearning2.html"><i class="fa fa-check"></i><b>13</b> Computational Deep Learning II</a><ul>
<li class="chapter" data-level="13.1" data-path="deeplearning2.html"><a href="deeplearning2.html#residual-network-resnet"><i class="fa fa-check"></i><b>13.1</b> Residual Network (ResNet)  </a></li>
<li class="chapter" data-level="13.2" data-path="deeplearning2.html"><a href="deeplearning2.html#recurrent-neural-network-rnn"><i class="fa fa-check"></i><b>13.2</b> Recurrent Neural Network (RNN)  </a><ul>
<li class="chapter" data-level="13.2.1" data-path="deeplearning2.html"><a href="deeplearning2.html#vanilla-rnn"><i class="fa fa-check"></i><b>13.2.1</b> Vanilla RNN</a></li>
<li class="chapter" data-level="13.2.2" data-path="deeplearning2.html"><a href="deeplearning2.html#long-short-term-memory-lstm"><i class="fa fa-check"></i><b>13.2.2</b> Long Short-Term Memory (LSTM)  </a></li>
<li class="chapter" data-level="13.2.3" data-path="deeplearning2.html"><a href="deeplearning2.html#gated-recurrent-units-gru"><i class="fa fa-check"></i><b>13.2.3</b> Gated Recurrent Units (GRU)  </a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="deeplearning2.html"><a href="deeplearning2.html#deep-stacked-rnn"><i class="fa fa-check"></i><b>13.3</b> Deep Stacked RNN </a></li>
<li class="chapter" data-level="13.4" data-path="deeplearning2.html"><a href="deeplearning2.html#deep-stacked-bidirectional-rnn"><i class="fa fa-check"></i><b>13.4</b> Deep Stacked Bidirectional RNN </a></li>
<li class="chapter" data-level="13.5" data-path="deeplearning2.html"><a href="deeplearning2.html#transformer-neural-network-tnn"><i class="fa fa-check"></i><b>13.5</b> Transformer Neural Network (TNN)  </a><ul>
<li class="chapter" data-level="13.5.1" data-path="deeplearning2.html"><a href="deeplearning2.html#attention"><i class="fa fa-check"></i><b>13.5.1</b> Attention </a></li>
<li class="chapter" data-level="13.5.2" data-path="deeplearning2.html"><a href="deeplearning2.html#self-attention-and-trainability"><i class="fa fa-check"></i><b>13.5.2</b> Self-Attention and Trainability </a></li>
<li class="chapter" data-level="13.5.3" data-path="deeplearning2.html"><a href="deeplearning2.html#multi-head-attention"><i class="fa fa-check"></i><b>13.5.3</b> Multi-Head Attention </a></li>
<li class="chapter" data-level="13.5.4" data-path="deeplearning2.html"><a href="deeplearning2.html#word-embedding"><i class="fa fa-check"></i><b>13.5.4</b> Word Embedding </a></li>
<li class="chapter" data-level="13.5.5" data-path="deeplearning2.html"><a href="deeplearning2.html#positional-embedding"><i class="fa fa-check"></i><b>13.5.5</b> Positional Embedding </a></li>
<li class="chapter" data-level="13.5.6" data-path="deeplearning2.html"><a href="deeplearning2.html#sequence-alignment"><i class="fa fa-check"></i><b>13.5.6</b> Sequence Alignment</a></li>
<li class="chapter" data-level="13.5.7" data-path="deeplearning2.html"><a href="deeplearning2.html#transformer-architectures"><i class="fa fa-check"></i><b>13.5.7</b> Transformer Architectures </a></li>
</ul></li>
<li class="chapter" data-level="13.6" data-path="deeplearning2.html"><a href="deeplearning2.html#applications-using-tnn-and-rnn"><i class="fa fa-check"></i><b>13.6</b> Applications using TNN (and RNN)</a><ul>
<li class="chapter" data-level="13.6.1" data-path="deeplearning2.html"><a href="deeplearning2.html#speech-recognition"><i class="fa fa-check"></i><b>13.6.1</b> Speech Recognition </a></li>
<li class="chapter" data-level="13.6.2" data-path="deeplearning2.html"><a href="deeplearning2.html#mel-coefficients-feature-extraction"><i class="fa fa-check"></i><b>13.6.2</b> Mel Coefficients (Feature Extraction) </a></li>
<li class="chapter" data-level="13.6.3" data-path="deeplearning2.html"><a href="deeplearning2.html#connectionist-temporal-classification-ctc"><i class="fa fa-check"></i><b>13.6.3</b> Connectionist Temporal Classification (CTC)  </a></li>
<li class="chapter" data-level="13.6.4" data-path="deeplearning2.html"><a href="deeplearning2.html#model-evaluation"><i class="fa fa-check"></i><b>13.6.4</b> Model Evaluation</a></li>
</ul></li>
<li class="chapter" data-level="13.7" data-path="deeplearning2.html"><a href="deeplearning2.html#generative-adversarial-network-gan"><i class="fa fa-check"></i><b>13.7</b> Generative Adversarial Network (GAN)  </a></li>
<li class="chapter" data-level="13.8" data-path="deeplearning2.html"><a href="deeplearning2.html#deep-reinforcement-network-dqn"><i class="fa fa-check"></i><b>13.8</b> Deep Reinforcement Network (DQN)  </a></li>
<li class="chapter" data-level="13.9" data-path="deeplearning2.html"><a href="deeplearning2.html#summary-8"><i class="fa fa-check"></i><b>13.9</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="distributedcomputation.html"><a href="distributedcomputation.html"><i class="fa fa-check"></i><b>14</b> Distributed Computation</a><ul>
<li class="chapter" data-level="14.1" data-path="distributedcomputation.html"><a href="distributedcomputation.html#integration-and-interoperability"><i class="fa fa-check"></i><b>14.1</b> Integration and Interoperability</a></li>
<li class="chapter" data-level="14.2" data-path="distributedcomputation.html"><a href="distributedcomputation.html#ml-pipelines"><i class="fa fa-check"></i><b>14.2</b> ML Pipelines</a></li>
<li class="chapter" data-level="14.3" data-path="distributedcomputation.html"><a href="distributedcomputation.html#open-standards"><i class="fa fa-check"></i><b>14.3</b> Open Standards</a><ul>
<li class="chapter" data-level="14.3.1" data-path="distributedcomputation.html"><a href="distributedcomputation.html#predictive-model-markup-language-pmml"><i class="fa fa-check"></i><b>14.3.1</b> Predictive Model Markup Language (PMML)</a></li>
<li class="chapter" data-level="14.3.2" data-path="distributedcomputation.html"><a href="distributedcomputation.html#portable-format-for-analytics-pfa"><i class="fa fa-check"></i><b>14.3.2</b> Portable Format for Analytics (PFA)</a></li>
<li class="chapter" data-level="14.3.3" data-path="distributedcomputation.html"><a href="distributedcomputation.html#open-neural-network-exchange-onnx"><i class="fa fa-check"></i><b>14.3.3</b> Open Neural Network Exchange (ONNX)</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="distributedcomputation.html"><a href="distributedcomputation.html#general-summary"><i class="fa fa-check"></i><b>14.4</b> General Summary</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i><b>15</b> Appendix</a><ul>
<li class="chapter" data-level="15.1" data-path="appendix.html"><a href="appendix.html#appendix-a"><i class="fa fa-check"></i><b>15.1</b> Appendix A</a><ul>
<li class="chapter" data-level="15.1.1" data-path="appendix.html"><a href="appendix.html#trigonometry"><i class="fa fa-check"></i><b>15.1.1</b> Trigonometry</a></li>
<li class="chapter" data-level="15.1.2" data-path="appendix.html"><a href="appendix.html#logarithms"><i class="fa fa-check"></i><b>15.1.2</b> Logarithms</a></li>
<li class="chapter" data-level="15.1.3" data-path="appendix.html"><a href="appendix.html#category-theory"><i class="fa fa-check"></i><b>15.1.3</b> Category Theory</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="appendix.html"><a href="appendix.html#appendix-b"><i class="fa fa-check"></i><b>15.2</b> Appendix B</a><ul>
<li class="chapter" data-level="15.2.1" data-path="appendix.html"><a href="appendix.html#on-random-chances"><i class="fa fa-check"></i><b>15.2.1</b> On Random chances</a></li>
<li class="chapter" data-level="15.2.2" data-path="appendix.html"><a href="appendix.html#on-replacements"><i class="fa fa-check"></i><b>15.2.2</b> On Replacements</a></li>
<li class="chapter" data-level="15.2.3" data-path="appendix.html"><a href="appendix.html#on-permutations-and-combinations"><i class="fa fa-check"></i><b>15.2.3</b> On Permutations and Combinations</a></li>
<li class="chapter" data-level="15.2.4" data-path="appendix.html"><a href="appendix.html#on-conditional-probabilities"><i class="fa fa-check"></i><b>15.2.4</b> On Conditional Probabilities</a></li>
<li class="chapter" data-level="15.2.5" data-path="appendix.html"><a href="appendix.html#the-arithmetic-of-probabilities"><i class="fa fa-check"></i><b>15.2.5</b> The Arithmetic of Probabilities</a></li>
<li class="chapter" data-level="15.2.6" data-path="appendix.html"><a href="appendix.html#on-dependent-and-independent-events"><i class="fa fa-check"></i><b>15.2.6</b> On Dependent and Independent Events</a></li>
<li class="chapter" data-level="15.2.7" data-path="appendix.html"><a href="appendix.html#on-mutual-exclusivity"><i class="fa fa-check"></i><b>15.2.7</b> On Mutual Exclusivity</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="appendix.html"><a href="appendix.html#appendix-c"><i class="fa fa-check"></i><b>15.3</b> Appendix C</a></li>
<li class="chapter" data-level="15.4" data-path="appendix.html"><a href="appendix.html#appendix-d"><i class="fa fa-check"></i><b>15.4</b> Appendix D</a><ul>
<li class="chapter" data-level="15.4.1" data-path="appendix.html"><a href="appendix.html#lubridate-library"><i class="fa fa-check"></i><b>15.4.1</b> Lubridate Library</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="bibliography.html"><a href="bibliography.html"><i class="fa fa-check"></i>Bibliography</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">The Power and Art of Approximation</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="bayesian2" class="section level1 hasAnchor">
<h1><span class="header-section-number">Chapter 8</span> Bayesian Computation II<a href="bayesian2.html#bayesian2" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { 
      equationNumbers: {
            autoNumber: "AMS",
            formatNumber: function (n) {return '8.'+n}
      } 
  }
});
</script>
<p>In this chapter, we not only try to approximate the function that can closely represent the actual distribution of data, but we also try to simulate the sampling of data that can represent the actual distribution. Thus, we narrow it down to a sampling that can ultimately yield an approximate function for the simulated distribution. That is where we emphasize <strong>Bayesian Modeling</strong>.</p>
<p>Some concepts in this chapter, for example, <strong>Factor Graphs</strong> and <strong>Kalman Filters</strong>, are helpful in Robotics and Signal Processing <span class="citation">(Dellaert F. and Kaess M. <a href="bibliography.html#ref-ref975f">2017</a>; Dellaert F. <a href="bibliography.html#ref-ref984f">2021</a>; Marco Cox M. <a href="bibliography.html#ref-ref966m">2018</a>)</span>. It is therefore essential to get some fundamental intuition around such concepts.</p>
<div id="bayesian-models" class="section level2 hasAnchor">
<h2><span class="header-section-number">8.1</span> Bayesian Models <a href="bayesian2.html#bayesian-models" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We begin this chapter by introducing <strong>Bayesian Models</strong> and some concepts around <strong>Dynamic Systems</strong>, knowing that such systems tend to hold properties of <strong>uncertainty</strong>. Here, we briefly introduce three models borrowed from <strong>Graph Theory</strong> that can represent Bayesian models in three ways: <strong>Factor Graph</strong>, <strong>Undirected Graph</strong>, and <strong>Directed Graph</strong> <span class="citation">(Pernkopf F. et al. <a href="bibliography.html#ref-ref957p">2014</a>)</span>.</p>
<p><strong>Factor Graph</strong> and <strong>Bipartite Graph</strong>:  </p>
<p>Figure <a href="bayesian2.html#fig:factorgraph">8.1</a> illustrates two <strong>Bipartite graphs</strong> (or a <strong>bigraph</strong>). The left-side graph has the more common form of a <strong>Factor graph</strong>. The right-side graph has the more common form of a <strong>Bipartite graph</strong>.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:factorgraph"></span>
<img src="factorgraph.png" alt="Factor Graph and Bipartite Graph" width="90%" />
<p class="caption">
Figure 8.1: Factor Graph and Bipartite Graph
</p>
</div>

<p>A <strong>Factor graph</strong> is a probabilistic graphical representation of a joint distribution involving random variables and non-negative functions called <strong>Factors</strong>. A <strong>Factor graph</strong> consists of nodes and edges. There are two types of nodes: a variable node and a factor node. In Figure <a href="bayesian2.html#fig:factorgraph">8.1</a>, we have fourteen nodes. There are seven variable nodes, namely {A,B,C,D,E,F,G,H}, and seven factor nodes, namely {<span class="math inline">\(f_a,f_b,f_c,f_d,f_e,f_f,f_g,f_h\)</span>}. The <strong>Factor graph</strong> in the figure is expressed as so:</p>
<p><span class="math display">\[
g(a,b,c,d,e,f,g,h) = f_a(a,e)f_b(b,e)f_c(c,f)f_d(d,f)f_e(e,f)f_f(e,g)f_g(f,g)f_h(g,h)
\]</span></p>
<p>A <strong>Bipartite graph</strong> is a graph whose vertices can be divided into two independent (disjoint) sets, U and V, such that each edge connects one U vertex and one V vertex <span class="citation">(Dey A., <a href="bibliography.html#ref-ref2350a">n.d.</a>)</span>.</p>
<p>The joint probability is factorized into a product of seven factors. In the <strong>Belief Propagation</strong> section, we discuss <strong>marginalization</strong> which uses <strong>Factor graph</strong> as a graphical model.</p>
<p><strong>Undirected Graph</strong>: </p>
<p>Figure <a href="bayesian2.html#fig:directedgraph">8.2</a> shows an undirected graph and directed graph.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:directedgraph"></span>
<img src="directedgraph.png" alt="Undirected and Directed Graph" width="90%" />
<p class="caption">
Figure 8.2: Undirected and Directed Graph
</p>
</div>

<p><strong>Markov Network</strong> depicts a structured <strong>Undirected Graph</strong> similar to <strong>Factor Graph</strong> in that it also describes <strong>joint distribution</strong> but focused more on <strong>cliques</strong> than on <strong>factors</strong>. A <strong>clique</strong> describes a fully connected sub-graph. <strong>Markov Random Field (MRF)</strong> is one type of a <strong>Markov Network</strong>.</p>
<p>Notice also in the figure that a so-called <strong>Markov Blanket </strong> covers colored nodes. Given a root - in our case, we use node <strong>E</strong> - the <strong>Markov Blanket</strong> of node <strong>E</strong> for <strong>Undirected Graph</strong> includes the neighboring nodes of the root. As for the <strong>Directed Graph</strong>, the <strong>Markov Blanket</strong> includes the direct parents, direct children, and direct childrenâs parents.</p>
<p><strong>Directed Graph</strong>: </p>
<p><strong>Bayesian Network</strong> depicts a structured <strong>Directed Acyclic Graph (DAG)</strong> similar to Figure <a href="bayesian.html#fig:bayesnetwork">7.18</a> that offers a <strong>Probabilistic Graphical modeling (PGM)</strong> to guide in forming dependencies, eliminating extraneous conditional probabilities.</p>
<p>On the other hand, <strong>Markov Chain</strong> depicts a structured <strong>Directed Graph</strong> used to visually represent more complex structural relationships amongst variables. We discuss <strong>Markov Chain</strong> in detail two subsections ahead.</p>
<p>One of the popular cross-platform packages to graphically render any graph is called <strong>TikZ</strong>, which interprets <strong>Tex</strong> language. Figure <a href="bayesian2.html#fig:mcnetwork">8.3</a> is an example of a <strong>Directed graph</strong> rendered using <strong>TikZ</strong>.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:mcnetwork"></span>
<img src="mcnetwork.png" alt="Directed Graph" width="60%" />
<p class="caption">
Figure 8.3: Directed Graph
</p>
</div>

<p>Here is an example of <strong>Tex</strong> commands used to generate the <strong>three-state graph</strong> as shown in Figure <a href="bayesian2.html#fig:mcnetwork">8.3</a>:</p>

<pre><code>  \begin{tikzpicture}
  \begin{scope}[every node/.style={circle,thick}] 
      \node[draw] (A) at (4,6) {A};
      \node[draw] (B) at (2,2) {B};
      \node[draw] (C) at (6,2) {C};
      \node[rectangle] (R) at (4,0) {Three-State Graph};
  \end{scope}
  \begin{scope}[every node/.style={fill=white,circle},
                every edge/.style={draw=red,very thick,bend right=20}]
      \path [-&gt;] (A) edge[very thick] node {0.10} (B); 
      \path [-&gt;] (A) edge[very thick] node {0.90} (C); 
      \path [-&gt;] (B) edge[very thick] node {0.60} (A); 
      \path [-&gt;] (B) edge[very thick] node {0.40} (C); 
      \path [-&gt;] (C) edge[very thick] node {0.23} (A); 
      \path [-&gt;] (C) edge node {0.77} (B); 
  \end{scope}
  ...</code></pre>

<p>And here is an example of <strong>Tex</strong> commands used to generate the <strong>3x3 matrix or table</strong>:</p>

<pre><code>  ...
  \begin{scope}[
     cell/.style={rectangle,draw=black},
     space/.style={
                  matrix of nodes, 
                  minimum height  = 1.5em,
                  minimum width   = 2em,
                  row sep         = -\pgflinewidth,
                  column sep      = -\pgflinewidth,
                  column/.style   = {font=\ttfamily}, 
                  text width      = 2em, align=left,
                  align=right
                },
          text depth      = 0.5ex,
          text height     = 2ex,
          nodes in empty cells]
  \node (B) [right=of R, text width=4cm] at (6.5,0) {Bayesian Matrix};
  \matrix (second) [above=1cm of B, space,
              row 1/.style={
                  nodes={draw=gray, fill=gray!50!white,text centered}},
              column 1/.style={
                  nodes={draw=gray, fill=gray!50!white,text centered}},
              column 2/.style={nodes={draw=black}},
              column 3/.style={nodes={draw=black}},
              column 4/.style={nodes={draw=black}},
              column 5/.style={nodes={align=right}}
              ]
  {
     &amp;    A &amp;    B &amp;    C &amp; $\sum$\\
  A  &amp;      &amp; 0.10 &amp; 0.90 &amp;      1\\
  B  &amp; 0.60 &amp;      &amp; 0.40 &amp;      1\\
  C  &amp; 0.23 &amp; 0.77 &amp;      &amp;      1\\
  };
  \end{scope}
  \end{tikzpicture}</code></pre>

<p>In a few sections ahead, we show a few examples of <strong>Directed Graphs</strong> generated by <strong>TikZ</strong> to demonstrate <strong>Markov Chain</strong> graphs. See Figure <a href="bayesian2.html#fig:markovchain">8.9</a>.</p>
<p>However, it pays to review a few preliminaries first while introducing <strong>Belief Propagation and Expectation Propagation</strong>.</p>
<div id="belief-propagation" class="section level3 hasAnchor">
<h3><span class="header-section-number">8.1.1</span> Belief Propagation <a href="bayesian2.html#belief-propagation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Belief Propagation</strong> is a <strong>message passing sum-product</strong> algorithm for <strong>marginalization</strong>, also called <strong>variable elimination</strong>. To illustrate <strong>Belief Propagation</strong>, let us review a few preliminaries, starting with <strong>Marginalization</strong>. This section and the next section reference the works of Thomas P. Minka <span class="citation">(<a href="bibliography.html#ref-ref473t">2001</a><a href="bibliography.html#ref-ref473t">b</a>, <a href="bibliography.html#ref-ref463t">2001</a><a href="bibliography.html#ref-ref463t">a</a>)</span>.</p>
<p><strong>Marginalization</strong></p>
<p>We begin the discussion of <strong>Belief Propagation</strong> with joint probability distribution like so:</p>
<p><span class="math display">\[
P(x_1, x_2, x_3,...,x_n)
\]</span></p>
<p>Marginalization sums all random variables in a joint probability distribution except the one to be marginalized, so that if we are to marginalize <span class="math inline">\(x_1\)</span>, given <strong>n</strong> variables, then we have the following:</p>
<p><span class="math display">\[\begin{align}
P(x_1) =  P(x_1)\left[ \sum_{x_2}\sum_{x_3} ... \sum_{x_n} P_{x_2,...,x_n}(x_2, x_3,...,x_n) \right]
\end{align}\]</span></p>
<p><span class="math display">\[
where\ \ \ \ \sum_{x_2}\sum_{x_3} ... \sum_{x_n} P_{x_2,...,x_n}(x_2, x_3,...,x_n)  = 1
\]</span></p>
<p>In general, we can write the equation like so:</p>
<p><span class="math display">\[\begin{align}
P(x_k) =   \sum_{-x_k}\mathcal{Q}_{-x_k}(x_1,...,x_n)
\end{align}\]</span></p>
<p>This naive way of marginalization can get computationally costly, especially with a larger set of variables. We discuss two algorithms to solve this in the sections ahead.</p>
<p><strong>Message Passing</strong> </p>
<p><strong>Message passing</strong> is an algorithm that allows messages to pass from one type of node to a different type of node, e.g., passing a message from a variable node to a factor node or passing a message from a factor node to a variable node. Let us use Figure <a href="bayesian2.html#fig:messagepassing">8.4</a> to discuss <strong>message passing</strong>.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:messagepassing"></span>
<img src="messagepassing.png" alt="Message Passing" width="70%" />
<p class="caption">
Figure 8.4: Message Passing
</p>
</div>

<p>The factor graph in Figure <a href="bayesian2.html#fig:messagepassing">8.4</a> represents a joint probability distribution with factors.</p>
<p><span class="math display">\[
P(A,B,C,D,E,F,G) = f_1(A,B,C) f_2(D,E,F) f_3(C,G) f_4(F,G) f_5(G)
\]</span></p>
<p>If we treat the <strong>edges</strong> as channels for which messages pass through, then for <strong>marginalization</strong>, one can arbitrarily choose a variable node as root to marginalize and let factor nodes allow the flow of messages toward the root. In our case, we choose <strong>G</strong> as our root; therefore, messages flow starting from the leaf nodes, namely variable leaf nodes {A, B, D, E} and factor leaf node {<span class="math inline">\(f_5\)</span>}. Notice the existence of factor <span class="math inline">\(f_a\)</span>, which we ignore for now (greyed out in the figure) as this creates a loop. That is also called <strong>loopy belief propagation</strong> which tends to prevent convergence. We introduce <strong>Junction tree</strong> afterward as a possible solution for loopy graphs.</p>
<p>In terms of <strong>message passing</strong>, let us use the following generic notation:</p>
<p><span class="math display">\[
m_i = \mu_{{&lt;source\ node&gt;}\rightarrow{&lt;dest\ node&gt;}}(&lt;referenced\ node&gt;) 
\]</span></p>
<p>Here are a few examples based on the figure:</p>
<p><span class="math display">\[\begin{align*}
m_1 {}&amp;= \mu_{A \rightarrow f_1}(A)\ \ \ \text{(message from variable node A to factor node }f_1 \text{)}\\
m_3 &amp;= \mu_{f_1 \rightarrow C}(C)\ \ \ \text{(message from factor node }f_1 \text{ to variable node }C \text{)}\\
\end{align*}\]</span></p>
<p>A message from a leaf node produces the following:</p>
<p><span class="math display">\[\begin{align*}
{}&amp;m_1   = \mu_{A \rightarrow f_1}(A) = 1 &amp; \text{(variable leaf node)}\\
&amp;m_2     = \mu_{B \rightarrow f_1}(B) = 1 &amp; \text{(variable leaf node)}\\
&amp;m_4     = \mu_{D \rightarrow f_2}(D) = 1 &amp; \text{(variable leaf node)}\\
&amp;m_5     = \mu_{E \rightarrow f_2}(E) = 1 &amp; \text{(variable leaf node)}\\
&amp;m_{11}  = \mu_{f_5 \rightarrow G}(G) = f_5(G) &amp; \text{(factor leaf node)}\\
\end{align*}\]</span></p>
<p>where we assume <strong>uniform priors</strong> that produce an initial value of 1 for the above variable leaf nodes.</p>
<p>Here, let us discuss two <strong>message passing</strong> algorithms:</p>
<p><strong>Sum-Product algorithm</strong> </p>
<p>An example of this algorithm is <strong>Belief Propagation</strong>. <strong>Viterbi</strong> in HMM section follows a similar algorithm. We calculate a random marginal probability, e.g., <span class="math inline">\(P(x_i)\)</span>, by message passing starting from the leaf nodes. In other words, we marginalize out other variables except for variable <span class="math inline">\(\mathbf{x_i}\)</span> - so-called <strong>variable elimination</strong>.</p>
<p>In general, a message from factor node to variable node is expressed as:</p>
<p><span class="math display">\[\begin{align}
\mu_{f_j \rightarrow x_i}(x_i) = \sum_{x_n \in Ne(f_j)\backslash x_i}^N  f_j(x_n) 
\prod_{x_m \in Ne(f_j)\backslash x_i}^N \mu_{x_m \rightarrow f_j}(X_m)
\end{align}\]</span></p>
<p>where (<span class="math inline">\(x_n \in Ne(f_j)\)</span>\ <span class="math inline">\(x_i\)</span>) denotes a set of neighboring (Ne) variable nodes connecting to factor nodes <span class="math inline">\(f_j\)</span> excluding <span class="math inline">\(x_i\)</span>.</p>
<p>And a message from variable node to factor node is expressed as:</p>
<p><span class="math display">\[\begin{align}
\mu_{x_i \rightarrow f_j}(x_i) =  \prod_{f_n \in Ne(x_i)\backslash f_j}^N \mu_{f_n \rightarrow x_i}(x_i)
\end{align}\]</span></p>
<p>where (<span class="math inline">\(f \in Ne(x_i)\)</span>\ <span class="math inline">\(f_j\)</span>) denotes a set of neighboring (Ne) factor nodes connecting to variable nodes <span class="math inline">\(x_i\)</span> excluding <span class="math inline">\(f_j\)</span>.</p>
<p>To illustrate, we can get the <strong>marginal</strong> <span class="math inline">\(P(G)\)</span> this way in <span class="math inline">\(\mathcal{O}(N^7)\)</span> complexity:</p>
<p><span class="math display">\[\begin{align}
P(G) =  \sum_{F}\sum_{C}\sum_{E}\sum_{D} \sum_{B} \sum_{A}  f_5(G) f_4(F,G)f_3(C,G) f_2(D,E,F)  f_1(A,B,C)  
\end{align}\]</span></p>
<p>But with <strong>message passing sum-product (belief propagation)</strong> algorithm, we can reduce the complexity even down to <span class="math inline">\(\mathcal{O}(N^2)\)</span> by <strong>pushing in</strong> the summations.</p>

<p><span class="math display">\[\begin{align}
m_1  &amp;= \mu_{A \rightarrow f_1}(A) = 1\\
m_2  &amp;= \mu_{B \rightarrow f_1}(B) = 1\\
m_4  &amp;= \mu_{D \rightarrow f_2}(D) = 1\\
m_5  &amp;= \mu_{E \rightarrow f_2}(E) = 1\\
m_3  &amp;= \mu_{f_1 \rightarrow C}(C) = \sum_A \sum_B f_1(A,B,C) \\
m_6  &amp;= \mu_{f_2 \rightarrow F}(F) = \sum_D \sum_E f_2(D,E,F) \\
m_7  &amp;= \mu_{C \rightarrow f_3}(C) =  \sum_C f_3(C,G)\\
m_8  &amp;= \mu_{F \rightarrow f_4}(F) = \sum_F f_4(F,G) \\
m_9  &amp;= \mu_{f_3 \rightarrow G}(G) = \sum_C f_3(C,G)  \sum_A \sum_B f_1(A,B,C)\\
m_{10} &amp;= \mu_{f_4 \rightarrow G}(G) = \sum_F f_4(F,G) \sum_D \sum_E f_2(D,E,F)\\
m_{11} &amp;= \mu_{f_5 \rightarrow G}(G) = f_5(G)\\
\nonumber \\
P(G) &amp;=  
    \underbrace{f_5(G)}_{\mu_{f_5 \rightarrow G}(G)} \cdot
    \underbrace{
    \underbrace{ \sum_F f_4(F,G) }_{m_8 = \mu_{F \rightarrow f_4}(F)}\cdot
    \underbrace{ \sum_D \sum_E f_2(D,E,F) }_{m_6 = \mu_{f_2 \rightarrow F}(F)}\cdot
    }_{m_{10} = \mu_{f_4 \rightarrow G}(G)}
    \underbrace{
    \underbrace{ \sum_C f_3(C,G) }_{m_7 = \mu_{C \rightarrow f_3}(C)}\cdot
    \underbrace{ \sum_A \sum_B f_1(A,B,C) }_{m_3 = \mu_{f_1 \rightarrow C}(C)}
    }_{m_9 = \mu_{f_3 \rightarrow G}(G)}
\end{align}\]</span>
</p>
<p><strong>Max-Product algorithm</strong> </p>
<p>An example of a <strong>Max-Product</strong> algorithm is the <strong>Baum-Welch</strong> algorithm in HMM section. Similarly, the summation is replaced with maximization.</p>

<p><span class="math display">\[\begin{align}
P(G&amp;) =  \nonumber\\
&amp;   \underbrace{f_5(G)}_{\mu_{f_5 \rightarrow G}(G)} \cdot
    \underbrace{
    \underbrace{ \max_F f_4(F,G) }_{m_8 = \mu_{F \rightarrow f_4}(F)}\cdot
    \underbrace{ \max_D \max_E f_2(D,E,F) }_{m_6 = \mu_{f_2 \rightarrow F}(F)}\cdot
    }_{m_{10} = \mu_{f_4 \rightarrow G}(G)}
    \underbrace{
    \underbrace{ \max_C f_3(C,G) }_{m_7 = \mu_{C \rightarrow f_3}(C)}\cdot
    \underbrace{ \max_A \max_B f_1(A,B,C) }_{m_3 = \mu_{f_1 \rightarrow C}(C)}
    }_{m_9 = \mu_{f_3 \rightarrow G}(G)}
\end{align}\]</span>
</p>
<p>In cases where we observe <strong>loops</strong> in our graph, we can still use the <strong>belief propagation</strong> algorithm; however, convergence is not guaranteed. Therefore, let us see how the <strong>Junction Tree</strong> algorithm may help in place of <strong>loopy belief propagation</strong>.</p>
<p><strong>Junction Tree Algorithm</strong> </p>
<p><strong>Junction Tree</strong>, also called <strong>Clique Tree</strong>, algorithm decomposes a <strong>directed graph</strong> into maximal subgraphs that are consequently referenced to form a tree of <strong>cliques</strong>, localizing computation within tree nodes. The algorithm composes of the following significant steps:  </p>
<ul>
<li><strong>Moralization</strong> adds extra edges that connect parents sharing a child node while at the same time transforming a directed graph into an undirected graph.</li>
<li><strong>Triangulation</strong> is the process of adding <strong>Chords</strong>, effectively forming subgraphs called <strong>cliques</strong>. <strong>Chords</strong> are edges that connect non-adjacent nodes. Here, it helps to be aware of the <strong>Tarjan elimination</strong> algorithm.<br />
</li>
<li><strong>Clique Factorization</strong> involves identifying <strong>Cliques</strong>. A <strong>Clique</strong> is a subgraph in which every two distinct nodes in the set are adjacent (or connected by a distinct edge). </li>
<li><strong>Tree Construction</strong> - here, we leave readers to investigate the <strong>Kruskal or Prims</strong> algorithm used to construct junction trees, taking into account <strong>junction tree properties</strong> such as <strong>running intersections</strong>, <strong>preservation of local and global consistency</strong> such that neighboring cliques share a common marginal when other variables are summed out, and so on.  </li>
</ul>
<p>See Figure <a href="bayesian2.html#fig:junctiontree">8.5</a> for the transformation of a directed graph into a <strong>clique tree</strong>. Node <strong>h</strong> has two parents, namely nodes <strong>g</strong> and <strong>e</strong>. So we connect the two parents by moralization. Afterwhich, we can triangulate the graph and arrive at six <strong>cliques</strong>, namely {ADB, CBE, DBE, EGD, FGD, EGH} with five separators {DB, BE, ED, GD, EG}.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:junctiontree"></span>
<img src="junctiontree.png" alt="Moralized and Triangulated Graph" width="70%" />
<p class="caption">
Figure 8.5: Moralized and Triangulated Graph
</p>
</div>

<p>Even with the triangulated graph, we can use, for example, subgraph &lt;b,d,e,g&gt; to formulate an equation for its joint probability, in which the intersection <span class="math inline">\(\omega(e,d)\)</span> is a normalizer so that:</p>
<p><span class="math display">\[\begin{align}
P(b,d,e,g) = \frac{\gamma(d,b,e)\gamma(e,g,d)}{Z} = \frac{\gamma(d,b,e)\gamma(e,g,d)}{\omega(e,d)}
\end{align}\]</span></p>
<p>But for all purposes, our goal is to marginalize by the <strong>sum-product</strong> algorithm using the constructed <strong>Junction Tree</strong>. We perform <strong>variable elimination</strong> by starting from the tree leaves and using message passing to arrive at the root.</p>
<p>For message passing in the <strong>Junction tree</strong> form, below is a marginal sub-computation for a particular <strong>clique</strong>, namely <span class="math inline">\(\gamma(e,g,h)\)</span>, granting messages pass through <span class="math inline">\(\omega(e,g)\)</span> towards the clique, assuming the following:</p>
<p><span class="math display">\[\begin{align}
c1 = \gamma(e,g,d)\ \ \ \ \ \ \ c2 = \gamma(e,g,h)\ \ \ \ \ \ \mu_{c_1 \rightarrow c_2}(e,g)
\end{align}\]</span></p>
<p>then we get:</p>
<p><span class="math display">\[\begin{align}
P(e,g,h) {}&amp;\propto \gamma(e,g,h)\times \mu_{c_1 \rightarrow c_2}(e,g)\\
&amp;\propto \gamma(e,g,h)\times \omega(e,g)
\end{align}\]</span></p>
<p>If messages flow to <span class="math inline">\(c1\)</span> from <span class="math inline">\(c2\)</span> and <span class="math inline">\(c3\)</span> and exit towards <span class="math inline">\(\gamma(d,b,e)\)</span>:</p>
<p><span class="math display">\[\begin{align}
c1 = \gamma(e,g,d)\ \ \ \ \ \ c2 = \gamma(e,g,h)\ \ \ \ \ c3 = \gamma(f,g,d)\ \ \ \ \  \mu_{c_2 \rightarrow c_1}(e,g)\ \ \ \ \ \mu_{c_3 \rightarrow c_1}(g,d)
\end{align}\]</span></p>
<p>then for clique <strong>c1</strong> (focusing exclusively on the listed sub-graphs for illustration), we get:</p>
<p><span class="math display">\[\begin{align}
P(e,g,h) {}&amp;\propto \gamma(e,g,h)\times\mu_{c_2 \rightarrow c1}(e,g)\times\mu_{c_3 \rightarrow c1}(g,d)\\
 &amp;\propto \gamma(e,g,h)\times\omega(e,g)\times\omega(g,d)
\end{align}\]</span></p>
<p>For other <strong>message-passing</strong> algorithms and approximations, we leave readers to investigate the following:</p>
<ul>
<li><strong>Shafer Shenoy</strong> algorithm</li>
<li><strong>Hugin</strong> algorithm</li>
<li><strong>Bethe</strong> approximation</li>
<li><strong>Kikuchi</strong> approximation.</li>
</ul>
</div>
<div id="expectation-propagation" class="section level3 hasAnchor">
<h3><span class="header-section-number">8.1.2</span> Expectation Propagation <a href="bayesian2.html#expectation-propagation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In this section, we start the discussion of <strong>Expectation Propagation (EP)</strong> to solve a <strong>clutter problem</strong> in which we deal with a p-dimensional Gaussian distribution with noise and unknown clutter.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:clutterproblem"></span>
<img src="clutterproblem.png" alt="Factor Graph For A Clutter Problem" width="70%" />
<p class="caption">
Figure 8.6: Factor Graph For A Clutter Problem
</p>
</div>

<p>The factor graph in Figure <a href="bayesian2.html#fig:clutterproblem">8.6</a> illustrates a joint distribution that translates into the following:</p>
<p><span class="math display">\[\begin{align}
\underbrace{P(\theta, x)}_\text{joint}\ \ \ \ \ \rightarrow\ \ \ \ \ \ \ 
\underbrace{P(\theta|x_1,...,x_n)}_\text{posterior} \propto 
\underbrace{P(\theta)}_\text{prior} \cdot
\underbrace{\prod_{i=1}^n P(x_i|\theta)}_\text{likelihood}
\end{align}\]</span></p>
<p>where gaussian expression for <strong>prior</strong> corresponds to:</p>
<p><span class="math display">\[\begin{align}
P(\theta) \rightarrow \ \ \ \theta \sim \mathcal{N}( 0, \nu_1\mathbf{I_p})
\end{align}\]</span></p>
<p>and gaussian expression for <strong>likelihood</strong> corresponding to:</p>
<p><span class="math display">\[\begin{align}
P(x|\theta)\ \rightarrow\ \ \ \ \  x_i|\theta \sim (1 - \omega_i)\mathcal{N}(\theta, \mathbf{I}) + (\omega_i)\mathcal{N}(0, \nu_2\mathbf{I})
\end{align}\]</span></p>
<p>The likelihood equation suggests a <strong>Gaussian</strong> distribution of two mixture components. The first being an observation following a normal distribution and the second component being the <strong>clutter</strong>. Here, <strong>theta</strong> <span class="math inline">\(\theta\)</span> acts as placeholder for latent variable with parameters (e.g.Â unkown mean and variance ) and <strong>X</strong> denotes observation. The notation <span class="math inline">\(\omega\)</span> represents proportionality of the clutter (a.l.a <strong>mixture coefficients</strong> in Gaussian mixture model) for which we can use <strong>Bernoulli distribution</strong>, e.g. <span class="math inline">\(\omega_i \sim \mathbf{B}ern(\pi)\)</span>. We initialize the following parameters, e.g. <span class="math inline">\(\nu_1 = 100\)</span>, <span class="math inline">\(\nu_2 = 10\)</span>.</p>
<p>For inference, the use of <strong>Belief Propagation</strong> is discouraged due to the number of Gaussians involved in the computation, namely <span class="math inline">\(2^n\)</span>; rather, we can use the <strong>EP</strong> algorithm <span class="citation">(Minka T. <a href="bibliography.html#ref-ref473t">2001</a><a href="bibliography.html#ref-ref473t">b</a>)</span>.</p>
<p>In general, with the <strong>Clutter problem</strong> in mind, <strong>Expectation Propagation</strong> has the following algorithm.</p>
<p><strong>First</strong>, as often our case, the parameters of interest is based on the <strong>posterior</strong> distribution, namely <span class="math inline">\(P(\theta|x)\)</span>. The <strong>posterior</strong> is in the form of a product of factors like so:</p>
<p><span class="math display">\[\begin{align}
P(x,\theta) \propto \prod_{i=0}^N f_i(\theta),\ \ \ \ \ where: 
f_0(\theta) = P(\theta), \ \ \ 
f_i(\theta) = P(x_i|\theta).
\end{align}\]</span></p>
<p><strong>Second</strong>, then similar to <strong>VI</strong>, we introduce a corresponding approximating distribution for the posterior that, in the case of <strong>ADF</strong>, is also decomposed into a product of factors, each factor corresponding to our choice of a <strong>Gaussian</strong> exponential family, e.g., <strong>Spherical Gaussian</strong> is a convenient choice:</p>
<p><span class="math display">\[\begin{align}
\mathcal{Q}(\theta) = \prod_{i=0}^N \hat{f}_i(\theta) =  \prod_{i=0}^N  \left[\mathcal{N}(x_i; m_i, v_i\mathbf{I_p}) \cdot s_i \right]
\end{align}\]</span></p>
<p>where each factor, namely <span class="math inline">\(\hat{f}_i\)</span>, is approximated using the following example implementation of the Gaussian function in R code:</p>

<div class="sourceCode" id="cb879"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb879-1" data-line-number="1">N.Gauss &lt;-<span class="st"> </span><span class="cf">function</span>(x, m, v) {</a>
<a class="sourceLine" id="cb879-2" data-line-number="2"> <span class="kw">exp</span>(<span class="op">-</span><span class="st"> </span><span class="dv">1</span><span class="op">/</span>(<span class="dv">2</span><span class="op">*</span>v) <span class="op">*</span><span class="st"> </span>( <span class="kw">t</span>(x <span class="op">-</span><span class="st"> </span>m) <span class="op">%*%</span><span class="st"> </span>v<span class="op">^</span>(<span class="op">-</span><span class="dv">1</span>) <span class="op">%*%</span><span class="st"> </span>(x <span class="op">-</span>m ) ) )</a>
<a class="sourceLine" id="cb879-3" data-line-number="3">}</a></code></pre></div>

<p>and where parameters for the <strong>prior</strong>, <span class="math inline">\(\hat{f}_0\)</span>, are initialized to the following:</p>
<p><span class="math display">\[
m_0 = 0\ \ \ \ \ \ \ \ \ \ \nu_0 = 100\ \ \ \ \ \ \ \ \ \ \ s_0 = (2\pi v_i)^{(-p/2)}
\]</span></p>
<p>and parameters for the rest of the factors correspond to the following initialization:</p>
<p><span class="math display">\[
m_i = 0\ \ \ \ \ \ \ \ \ \ 
v_i\ \rightarrow \infty\ \ \ \ \ \ \ \ \ \
s_i = 1\ \ \ \ \ \ \text{(initialized to unity)}
\]</span>
such that the approximation distribution, namely <span class="math inline">\(\mathcal{Q}(\theta)\)</span>, therefore corresponds to the initialized <strong>prior</strong>.</p>

<div class="sourceCode" id="cb880"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb880-1" data-line-number="1">initialize &lt;-<span class="st"> </span><span class="cf">function</span>(N, <span class="dt">P =</span> <span class="dv">1</span>) {</a>
<a class="sourceLine" id="cb880-2" data-line-number="2">  m =<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, N); v =<span class="st"> </span><span class="kw">rep</span>(<span class="ot">Inf</span>, N); s =<span class="st"> </span><span class="kw">rep</span>(<span class="dv">1</span>, N)</a>
<a class="sourceLine" id="cb880-3" data-line-number="3">  v[<span class="dv">1</span>] =<span class="st"> </span><span class="dv">100</span>; s[<span class="dv">1</span>] =<span class="st"> </span>(<span class="dv">2</span> <span class="op">*</span><span class="st"> </span>pi <span class="op">*</span><span class="st"> </span>v[<span class="dv">1</span>])<span class="op">^</span>(<span class="op">-</span>P<span class="op">/</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb880-4" data-line-number="4">  m<span class="fl">.0</span> =<span class="st"> </span>m[<span class="dv">1</span>]; v<span class="fl">.0</span> =<span class="st"> </span>s[<span class="dv">1</span>]</a>
<a class="sourceLine" id="cb880-5" data-line-number="5">  <span class="kw">list</span>(<span class="st">&quot;m&quot;</span> =<span class="st"> </span>m, <span class="st">&quot;v&quot;</span> =<span class="st"> </span>v, <span class="st">&quot;s&quot;</span> =<span class="st"> </span>s, <span class="st">&quot;m.0&quot;</span> =<span class="st"> </span>m<span class="fl">.0</span>, <span class="st">&quot;v.0&quot;</span> =<span class="st"> </span>v<span class="fl">.0</span>)  </a>
<a class="sourceLine" id="cb880-6" data-line-number="6">}</a></code></pre></div>

<p>where <span class="math inline">\(\theta = (m_\theta, v_\theta)\)</span> so that initially, we have <span class="math inline">\(m_\theta = m_0\)</span> and <span class="math inline">\(\nu_\theta = \nu_0.\)</span></p>
<p><strong>Third</strong>, we create a <strong>cavity distribution</strong> by arbitrarily excluding the <strong>kth</strong> likelihood approximation from <span class="math inline">\(\mathcal{Q}(\theta)\)</span>. We can show this using any of two variants:</p>
<p><span class="math display">\[\begin{align}
\mathcal{Q}^{\backslash k}(\theta) {}&amp;\propto \frac{\mathcal{Q}(\theta)}{\hat{f}_i(\theta)} 
= \frac{\mathcal{N}(\theta; m, \nu \mathbf{I})}{s_i\mathcal{N}(\theta; m_i, \nu_i\mathbf{I})} &amp; \text{(ref M. Korvas 2013)}\\
\mathcal{Q}^{\backslash k}(\theta) &amp;\propto \prod_{i\ne k}^N \hat{f}_i(\theta) = \prod_{i\ne k}^N \mathcal{N}(\theta; m_i, \nu_i) &amp; \text{(ref O. Du}\check{s}\text{ek 2013)}
\end{align}\]</span></p>
<p>The approach is to calculate the moments like so:</p>
<p><span class="math display">\[\begin{align}
\nu_{\theta}^{\backslash k} = (\nu_{\theta}^{\backslash k*})^{-1} - \nu_{i}^{-1})^{-1}
\ \ \ \ \ \ \ \ \
m_{\theta}^{\backslash k}  = m_{\theta}^{\backslash k*} + \nu_{\theta}^{\backslash k}\nu_i^{-1}( m_{\theta}^{\backslash k*}  - m_i )
\end{align}\]</span></p>
<p>where <span class="math inline">\(\hat{f}_i(\theta)\)</span> is represented by the following <strong>sufficient statistics</strong>, namely <span class="math inline">\(\{m_i, \nu_i, s_i\}\)</span>.</p>
<p><strong>Fourth</strong>, we derive a refined distribution called <strong>tilted distribution</strong>, also called <strong>hybrid distribution</strong>, by taking the product of the actual likelihood and the <strong>cavity distribution</strong> - in our case, this is the product of Gaussian distributions.</p>
<p><span class="math display">\[\begin{align}
\underbrace{ \mathcal{Q}^*(\theta) }_{ \begin{array}{c}tilted\\distribution \end{array} }
=  \underbrace{\mathcal{Q}^{\backslash k}(\theta) }_{ \begin{array}{c}cavity\\distribution \end{array} } \cdot
\underbrace{f_i(\theta)}_{ \begin{array}{c}true\\likelihood \end{array} }
\ \ \ \ \ \ \ where\ \ \ Z_i = \int_{i\ne k} \mathcal{Q}^*(\theta) d \theta \label{eqn:eqnnumber325}
\end{align}\]</span></p>
<p>Equivalently, we calculate the projection (a new approximated distribution) by minimizing the <strong>KL divergence</strong>.</p>
<p><span class="math display">\[\begin{align}
\mathcal{Q}^*(\theta) = \underset{q}{argmin}\ 
\mathcal{KL}( \mathcal{Q}^{\backslash k}(\theta)  \cdot f_k(\theta) ||\mathcal{Q}^{\backslash k}(\theta) \cdot \hat{f}_k(\theta) )
\end{align}\]</span></p>
<p>Here, the approach is to calculate the <strong>sufficient statistics</strong> of the resulting distributions instead so that if the <strong>moments</strong> between <span class="math inline">\(\mathcal{Q}^*(\theta)\)</span> and <span class="math inline">\(\mathcal{Q}(\theta)\)</span> are the same, then minimizing <strong>KL divergence</strong> is equivalently achieved. This is also called <strong>moment matching</strong>. We calculate parameters <span class="math inline">\((\nu_{\theta}^{\backslash k*}, m_{\theta}^{\backslash k*}, Z_i )\)</span> from <span class="math inline">\((m_{\theta}^{\backslash k}, \nu_{\theta}^{\backslash k} )\)</span> as in <strong>ADF</strong>:</p>
<p><span class="math display">\[\begin{align}
Z_i {}&amp;= (1 - \omega)\mathcal{N}(y_i; m_{\theta}^{\backslash k}, (v_{\theta}^{\backslash k} + 1)\mathbf{I}) +  \omega\mathcal{N}(y_i; 0, 10\mathbf{I})\\
\tau_i &amp;= \frac{1}{Z_i} (1 - \omega)\mathcal{N}(y_i; m_{\theta}^{\backslash k}, (v_{\theta}^{\backslash k} + 1)\mathbf{I})\\
m_{\theta}^{\backslash k*}  &amp;= m_{\theta}^{\backslash k}  + v_{\theta}^{\backslash k} \tau_i \left( \frac{ y_i - m_{\theta}^{\backslash k}}{v_{\theta}^{\backslash k} + 1} \right) \\
\nu_{\theta}^{\backslash k*} &amp;= \nu_{\theta}^{\backslash k} - \tau_i \left( \frac{(\nu_{\theta}^{\backslash k})^2}{v_{\theta}^{\backslash k} + 1} \right) + 
\tau_i ( 1 - \tau_i) \left( \frac{(v_{\theta}^{\backslash k})^2\|y_i - m_{\theta}^{\backslash k} \|^2}{p(v_{\theta}^{\backslash k}+ 1)^2} \right)
\end{align}\]</span></p>
<p><strong>Fifth</strong>, we update (refine) the chosen approximate factor, namely <span class="math inline">\(\hat{f}_i\)</span>.</p>
<p><span class="math display">\[\begin{align}
\hat{f}_{i}^*(\theta) \propto \frac{ \mathcal{Q}^*(\theta) }{ \mathcal{Q}^{\backslash k}(\theta)}
\end{align}\]</span></p>
<p>The approach is to update parameters of the chosen factor:</p>
<p><span class="math display">\[\begin{align}
v_i {}&amp;= \left((v_{\theta}^{\backslash k*})^{-1} - (v_{\theta}^{\backslash k})^{-1} \right)^{-1}\\
m_i &amp;= m_\theta^{\backslash k} + (v_i + v_{\theta}^{\backslash k})(v_{\theta}^{\backslash k})^{-1}(m_\theta^{\backslash k*} - m_\theta^{\backslash k})\\
s_i &amp;= \frac{Z_i}{(2\pi v_i)^{(p/2)} \mathcal{N}(m_i; m_\theta^{\backslash k}, (v_i + v_\theta^{\backslash k})I)}
\end{align}\]</span></p>
<p><strong>Sixth</strong>, we then move on and choose the next factor and repeat the steps. Note that if all factors, e.g., their corresponding moments {<span class="math inline">\(m_i, v_i, s_i\)</span>}, are processed with no convergence in sight, we iterate again, starting with the first chosen factor.</p>
<p><strong>Clutter Problem</strong> </p>
<p>In summary, the idea is to <strong>refine</strong> an approximating distribution, <span class="math inline">\(\mathcal{Q}(\theta)\)</span>, by arbitrarily choosing and replacing one of its factors, <span class="math inline">\(\hat{f}_i(\theta)\)</span>, with its corresponding true factor, <span class="math inline">\(f_i(\theta)\)</span>, from the true posterior. We then create (so-called projecting) a new <strong>tilted distribution</strong>, namely <span class="math inline">\(\mathcal{Q}^*(\theta)\)</span>. We compare the distribution with the original approximating distribution using <strong>KL divergence</strong>; however, we use <strong>moment matching</strong> to minimize <strong>KL divergence</strong>. Subsequentially, we continue to perform the replacement for all factors in the distribution. This one pass is reflected in the <strong>ADF</strong> algorithm and tends to fall short of accuracy. We solve this in <strong>EP</strong> by performing multiple passes until convergence.</p>
<p>Figure <a href="bayesian2.html#fig:bimodalmix">8.7</a> illustrates the difference between a partial <strong>Variational Inference</strong> result and a partial <strong>Expectation Propagation</strong> result in terms of coverage. For example, <strong>VI</strong> covers a specific modal (e.g., as shown in the figure, it matches the first mode), whereas <strong>EP</strong> tends to be global. Note that the second mode in the figure is clutter.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:bimodalmix"></span>
<img src="DS_files/figure-html/bimodalmix-1.png" alt="Bimodal Mixture model" width="70%" />
<p class="caption">
Figure 8.7: Bimodal Mixture model
</p>
</div>

<p>With the parameter calculations presented above, we reference the <strong>EP</strong> algorithm from T. Minkaâs thesis (p.Â 21, MIT 2001) for a direct (crude) naive implementation of the <strong>clutter problem</strong> in R below. Fundamentally, we show the <strong>EP</strong> as a multi-pass algorithm:</p>

<div class="sourceCode" id="cb881"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb881-1" data-line-number="1">y =<span class="st"> </span>pd<span class="op">$</span>y</a>
<a class="sourceLine" id="cb881-2" data-line-number="2">N =<span class="st"> </span><span class="kw">length</span>(y)</a>
<a class="sourceLine" id="cb881-3" data-line-number="3">Q =<span class="st"> </span><span class="kw">initialize</span>(N, <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb881-4" data-line-number="4">P =<span class="st"> </span><span class="dv">1</span></a>
<a class="sourceLine" id="cb881-5" data-line-number="5">w =<span class="st"> </span><span class="fl">0.5</span></a>
<a class="sourceLine" id="cb881-6" data-line-number="6">limit =<span class="st"> </span><span class="dv">100</span></a>
<a class="sourceLine" id="cb881-7" data-line-number="7"><span class="cf">for</span> (iter <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>limit) {  <span class="co"># limiting iteration for illustration</span></a>
<a class="sourceLine" id="cb881-8" data-line-number="8">   <span class="co"># the actual alternative is to compare moments for convergence </span></a>
<a class="sourceLine" id="cb881-9" data-line-number="9">   <span class="co"># (e.g Q$m[i] == Q.old$m[i], Q$v[i] == Q.old$v[i],... )</span></a>
<a class="sourceLine" id="cb881-10" data-line-number="10">  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">2</span><span class="op">:</span>N) {</a>
<a class="sourceLine" id="cb881-11" data-line-number="11">    <span class="co"># create cavity distribution (represented by moments)</span></a>
<a class="sourceLine" id="cb881-12" data-line-number="12">    v<span class="fl">.0</span> =<span class="st"> </span>( Q<span class="op">$</span>v<span class="fl">.0</span><span class="op">^</span>(<span class="op">-</span><span class="dv">1</span>) <span class="op">-</span><span class="st"> </span>Q<span class="op">$</span>v[i]<span class="op">^</span>(<span class="op">-</span><span class="dv">1</span>))<span class="op">^</span>(<span class="op">-</span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb881-13" data-line-number="13">    m<span class="fl">.0</span> =<span class="st"> </span>Q<span class="op">$</span>m<span class="fl">.0</span> <span class="op">+</span><span class="st"> </span>v<span class="fl">.0</span> <span class="op">*</span><span class="st"> </span>Q<span class="op">$</span>v[i]<span class="op">^</span>(<span class="op">-</span><span class="dv">1</span>)  <span class="op">*</span><span class="st"> </span>( Q<span class="op">$</span>m<span class="fl">.0</span> <span class="op">-</span><span class="st"> </span>Q<span class="op">$</span>m[i])</a>
<a class="sourceLine" id="cb881-14" data-line-number="14">    <span class="co"># create tilted distribution</span></a>
<a class="sourceLine" id="cb881-15" data-line-number="15">    <span class="co"># recompute (Q$m.0 , Q$v.0, Zi) from (m.0, v.0) - ADF</span></a>
<a class="sourceLine" id="cb881-16" data-line-number="16">    ri =<span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>w) <span class="op">*</span><span class="st"> </span><span class="kw">N.Gauss</span>(y[i], m<span class="fl">.0</span>, (v<span class="fl">.0</span> <span class="op">+</span><span class="st"> </span><span class="dv">1</span>)) <span class="op">/</span></a>
<a class="sourceLine" id="cb881-17" data-line-number="17"><span class="st">       </span>( (<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>w) <span class="op">*</span><span class="st"> </span><span class="kw">N.Gauss</span>(y[i], m<span class="fl">.0</span>, (v<span class="fl">.0</span> <span class="op">+</span><span class="st"> </span><span class="dv">1</span>)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb881-18" data-line-number="18"><span class="st">               </span>w <span class="op">*</span><span class="st"> </span><span class="kw">N.Gauss</span>(y[i], <span class="dv">0</span>, <span class="dv">10</span>) )</a>
<a class="sourceLine" id="cb881-19" data-line-number="19">    Q<span class="op">$</span>m<span class="fl">.0</span> =<span class="st"> </span>m<span class="fl">.0</span> <span class="op">+</span><span class="st"> </span>v<span class="fl">.0</span> <span class="op">*</span><span class="st"> </span>ri <span class="op">*</span><span class="st"> </span>(y[i] <span class="op">-</span><span class="st"> </span>m<span class="fl">.0</span>) <span class="op">/</span><span class="st"> </span>(v<span class="fl">.0</span> <span class="op">+</span><span class="st"> </span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb881-20" data-line-number="20">    Q<span class="op">$</span>v<span class="fl">.0</span> =<span class="st"> </span>v<span class="fl">.0</span> <span class="op">-</span><span class="st"> </span>ri <span class="op">*</span><span class="st"> </span>v<span class="fl">.0</span><span class="op">^</span><span class="dv">2</span> <span class="op">/</span><span class="st"> </span>(v<span class="fl">.0</span> <span class="op">+</span><span class="st"> </span><span class="dv">1</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb881-21" data-line-number="21"><span class="st">                </span>ri <span class="op">*</span><span class="st"> </span>( <span class="dv">1</span> <span class="op">-</span><span class="st"> </span>ri) <span class="op">*</span><span class="st"> </span>v<span class="fl">.0</span><span class="op">^</span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>(<span class="kw">t</span> (y[i] <span class="op">-</span><span class="st"> </span>m<span class="fl">.0</span>) <span class="op">%*%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb881-22" data-line-number="22"><span class="st">                                  </span>(y[i] <span class="op">-</span><span class="st"> </span>m<span class="fl">.0</span>) ) <span class="op">/</span><span class="st"> </span>P <span class="op">*</span><span class="st"> </span>(v<span class="fl">.0</span> <span class="op">+</span><span class="st"> </span><span class="dv">1</span>)<span class="op">^</span><span class="dv">2</span></a>
<a class="sourceLine" id="cb881-23" data-line-number="23">    Zi =<span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>w) <span class="op">*</span><span class="st"> </span><span class="kw">N.Gauss</span>(y[i], m<span class="fl">.0</span>, (v<span class="fl">.0</span> <span class="op">+</span><span class="st"> </span><span class="dv">1</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb881-24" data-line-number="24"><span class="st">               </span>w <span class="op">*</span><span class="st"> </span><span class="kw">N.Gauss</span>(y[i], <span class="dv">0</span>, <span class="dv">10</span>)</a>
<a class="sourceLine" id="cb881-25" data-line-number="25">    </a>
<a class="sourceLine" id="cb881-26" data-line-number="26">    <span class="co"># Update chosen factor</span></a>
<a class="sourceLine" id="cb881-27" data-line-number="27">    Q<span class="op">$</span>v[i] =<span class="st"> </span>( Q<span class="op">$</span>v<span class="fl">.0</span><span class="op">^</span>(<span class="op">-</span><span class="dv">1</span>) <span class="op">-</span><span class="st"> </span>v<span class="fl">.0</span><span class="op">^</span>(<span class="op">-</span><span class="dv">1</span>) )<span class="op">^</span>(<span class="op">-</span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb881-28" data-line-number="28">    Q<span class="op">$</span>m[i] =<span class="st"> </span>m<span class="fl">.0</span> <span class="op">+</span><span class="st"> </span>(Q<span class="op">$</span>v[i] <span class="op">+</span><span class="st"> </span>v<span class="fl">.0</span>) <span class="op">*</span><span class="st"> </span>v<span class="fl">.0</span><span class="op">^</span>(<span class="op">-</span><span class="dv">1</span>) <span class="op">*</span><span class="st"> </span>( Q<span class="op">$</span>m<span class="fl">.0</span> <span class="op">-</span><span class="st"> </span>m<span class="fl">.0</span>)</a>
<a class="sourceLine" id="cb881-29" data-line-number="29">    Q<span class="op">$</span>s[i] =<span class="st"> </span>Zi <span class="op">/</span><span class="st"> </span>( <span class="dv">2</span><span class="op">*</span><span class="st"> </span>pi <span class="op">*</span><span class="st"> </span>Q<span class="op">$</span>v[i]<span class="op">^</span>(P<span class="op">/</span><span class="dv">2</span>) <span class="op">*</span><span class="st"> </span><span class="kw">N.Gauss</span>(Q<span class="op">$</span>m[i], m<span class="fl">.0</span>, </a>
<a class="sourceLine" id="cb881-30" data-line-number="30">                                                   (Q<span class="op">$</span>v[i] <span class="op">+</span><span class="st"> </span>v<span class="fl">.0</span>)))</a>
<a class="sourceLine" id="cb881-31" data-line-number="31">  }</a>
<a class="sourceLine" id="cb881-32" data-line-number="32">  Q.old =<span class="st"> </span>Q</a>
<a class="sourceLine" id="cb881-33" data-line-number="33">}</a></code></pre></div>

<p>Now, as we can imagine, dealing with a more significant number of factors can invite scalability concerns. The goal is to factorize the approximating distribution so that each factor maps to a corresponding <strong>site</strong> for parallel computation. See Figure <a href="bayesian2.html#fig:parallelep">8.8</a> derived from the idea of using a <strong>posterior server</strong> with multiple <strong>site workers</strong> <span class="citation">(L. Hasenclever et al, <a href="bibliography.html#ref-ref577l">2017</a>)</span>.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:parallelep"></span>
<img src="parallelep.png" alt="Expectation Propagation" width="100%" />
<p class="caption">
Figure 8.8: Expectation Propagation
</p>
</div>

<p>In the paper by L. Hasenclever et al., a <strong>posterior server</strong> is utilized to aggregate individual <strong>tilted</strong> distributions into a global <strong>posterior</strong> approximation and, in turn, delivers back individual <strong>cavity</strong> moments to the corresponding sites for each iteration until convergence.</p>
<p>A few methods are suggested <span class="citation">(Gelman A. et al. <a href="bibliography.html#ref-ref620a">2017</a>)</span> to approximate the moments, such as <strong>Laplace Approximation</strong>, which we cover in a previous section, and <strong>Markov Chain Monte Carlo (MCMC)</strong>, which we discuss under <strong>Simulation and Sampling</strong> section.</p>
<p>In the next section, we discuss <strong>Markov Chain</strong>. Here, we reference an introductory material from Anders Tolver <span class="citation">(<a href="bibliography.html#ref-ref1075a">2016</a>)</span>.</p>
</div>
<div id="markov-chain" class="section level3 hasAnchor">
<h3><span class="header-section-number">8.1.3</span> Markov Chain <a href="bayesian2.html#markov-chain" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Markov Chain</strong>, named after <strong>Andrey Markov</strong> (a Russian Mathematician), models a state sequence of random events that happen over time. The sequence is modeled based on a <strong>structured graph</strong> of all <strong>distinct</strong> countable <strong>states</strong> of a random event and their corresponding <strong>transition probabilities</strong>. Figure <a href="bayesian2.html#fig:markovchain">8.9</a> shows six <strong>state diagrams</strong>, also called <strong>transition diagram</strong>, for a Markov Chain; the first model being the simplest. Each model is a system of <strong>nodes</strong> and <strong>edges</strong> in which a <strong>node</strong> represents a state and an <strong>edge</strong> represents a <strong>transition probability</strong>. For example, to interpret the fifth graph (six-state graph), the transition probability of jumping from state E to state C is 25%.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:markovchain"></span>
<img src="markovchain.png" alt="Markov Chain Models" width="80%" />
<p class="caption">
Figure 8.9: Markov Chain Models
</p>
</div>

<p>Equivalently, we can also illustrate the models through a <strong>transition matrix</strong>, also called <strong>Markov matrix</strong>. The columns describe the <strong>next</strong> <strong>transition states</strong>. The rows describe a list of all distinct states (each row computes a total probability of one). Here, the values of each cell are called the <strong>transition probabilities</strong>.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:markovmatrix"></span>
<img src="markovmatrix.png" alt="Markov Chain (Transition Matrix)" width="70%" />
<p class="caption">
Figure 8.10: Markov Chain (Transition Matrix)
</p>
</div>

<p>A transition probability in a transition matrix is denoted as:</p>
<p><span class="math display">\[\begin{align}
(P^n)_{i,j} \equiv P(X_{n} = S_j|X_{n-1} = S_i)
\end{align}\]</span></p>
<p>The notation reads as the probability of transitioning from <strong>i</strong> state to <strong>j</strong> state in the nth step.</p>
<p>A simple example of using the <strong>Markov Chain</strong> is the famous <strong>Random Walk</strong> problem. Let us use the fifth model above in which the <strong>state-space</strong> contains all <strong>distinct</strong> countable states that a random event <span class="math inline">\(X_t\)</span> can transition at any given time (t):</p>
<p><span class="math display">\[
S \in \{ A,B,C,D,E,F \}
\]</span></p>
<p>For a random walk (random event), <span class="math inline">\(X\)</span>, we start <strong>walking</strong> at time zero (t = 0). Such an event at time zero is denoted by <span class="math inline">\(X_t = X_0\)</span>. Suppose the initial state at time zero is <span class="math inline">\(X_0 = A\)</span>. Therefore, we can express the marginal probability of such a random event at time zero with an initial state of A like so:</p>
<p><span class="math display">\[
P(X_0 = A) = 1
\]</span>
Now, if we start from time zero in state A and decide to walk to state D for some random choice, we then have the following expression:</p>
<p><span class="math display">\[
P(X_1 = D | X_0 = A) = 0.85
\]</span>
That is because the probability of walking from state A to D is 85%.</p>
<p>From state D, if we further randomly walk to state B, we then end up with the following probability:</p>
<p><span class="math display">\[
P(X_2 = B |  X_1 = D, X_0 = A) = 0.72
\]</span>
And if we continue to walk further from states B to C to F and back to D, we then end up with the following probability:</p>
<p><span class="math display">\[
P(X_5 = D | X_4 = F, X_3 = C, X_2 = B, X_1 = D, X_0 = A)     = 0.52
\]</span>
Notice that no matter how random and how many times we walk, we end up inheriting the probability of walking to the final next state, given <strong>only the last</strong> previous state:</p>
<p><span class="math display">\[\begin{align}
P(X_{n} {}&amp;= S_{k_{n}}  | X_{n-1} = S_{j_{n-1}}\ ,...,\ X_0 = S_{i_0}) \\
&amp;= 
P(X_{n}|X_{n-1}) \times P(X_{n-1}|X_{n-2})\times ... \times P(X_1|X_0)\times P(X_0) \\
&amp;=P(X_{n} = S_{k_{n}}  |  X_{n-1} = S_{j_{n-1}})\\
&amp;=(P^{n})_{j_{n-1}, k_{n}}
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\((P^{n})\)</span> is the transition probability in nth (<strong>temporal</strong>) steps</li>
<li><span class="math inline">\(S_{j_{n-1}}\)</span> is the jth state in (n-1)th (<strong>temporal</strong>) steps</li>
<li><span class="math inline">\(S_{k_{n}}\)</span> is the kth state in nth (<strong>temporal</strong>) steps</li>
</ul>
<p>Historical events are ignored, and only the last previous state is relevant. We call this <strong>memoryless property</strong> the <strong>Markov property</strong>. This characteristic is also called <strong>state independence</strong>.</p>
<p>There are five other essential properties of the <strong>Markov chain</strong>.</p>
<p><strong>Irreducibility</strong> </p>
<p><strong>Irreducibility</strong> states that every <strong>state node</strong> in the system (in the chain) communicates with every other <strong>state node</strong>. Note that communication happens if one state node can access the other node and vice versa. For example, in the second graph above (two-state graph) of Figure <a href="bayesian2.html#fig:markovchain">8.9</a>, state nodes A and B can access each other and thus can communicate with each other. However, in the fourth graph (three-state graph), state node A can access state node B, but state node B cannot access state node A. Therefore, A and B cannot communicate with each other.</p>
<p>Every node in graphs 1, 2, and 3 can communicate with every other node. Therefore each chain is an <strong>Irreducible Markov Chain</strong>. On the other hand, each chain in graphs 4, 5, and 6 is a <strong>Reducible Markov Chain</strong> because no other state node can communicate back with state node A.</p>
<p><strong>Aperiodicity</strong> </p>
<p><strong>Aperiodicity</strong> states that a <strong>Markov Chain</strong> is <strong>aperiodic</strong> if <strong>all its state nodes</strong> are <strong>aperiodic</strong>. Here, <strong>periodicity</strong> generally refers to the repeating (regular) occurrence of an event (or a state) at fix interval. In Markov Chain, one full cycle happens if we start walking from the state node (<span class="math inline">\(S_i\)</span>) to at least another non-repeating state node and back to the starting state node. This full cycle is called a <strong>period (d)</strong> and is expressed as:</p>
<p><span class="math display">\[\begin{align}
d(S_i) = gcd\{\ n \ge 1: (P^{n})_{i,i} &gt; 0\ \} =
\begin{cases}
=1 &amp; \text{(aperiodic)}\\
&gt;1 &amp; \text{(periodic)}
\end{cases} \label{eqn:eqnnumber326}
\end{align}\]</span></p>
<p>such that:</p>
<p><span class="math display">\[\begin{align}
(P^{n})_{i,i} = P(X_n = S_i| X_0 = S_i)
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li><strong>n</strong> is the number of steps taken.</li>
<li><strong>d</strong> is the period function taking in the <strong>gcd (greatest common denominator)</strong> outcome.</li>
<li><strong>P</strong> is the transition probability in a transition matrix.</li>
</ul>
<p>The notation, <span class="math inline">\((P^{n})_{i,i}\)</span>, describes the transition probability from <span class="math inline">\(S_i\)</span> to <span class="math inline">\(S_i\)</span> in nth steps.</p>
<p>In Figure <a href="bayesian2.html#fig:markovchain">8.9</a>, graphs 1,2,3 are <strong>periodic</strong>. The first graph is a <strong>2-periodic</strong> Markov Chain because any node can cycle back to itself in 2 steps (d = 2). The second graph has nodes that can cycle back to themselves in 3 steps (d = 3). And the third graph has nodes that can cycle back to themselves in 4 steps ( d = 4).</p>
<p>Graphs 4,5,6 are not <strong>periodic</strong> because they are not <strong>irreducible</strong> in the first place. That is because other state nodes cannot communicate with state node A - there is no path to use to communicate back. But granting there is a path from state node C to state node A in graph 4 to make the chain <strong>reducible</strong> (see Figure <a href="bayesian2.html#fig:aperiodic">8.11</a>). That still makes graph 4 <strong>aperiodic</strong>.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:aperiodic"></span>
<img src="aperiodic.png" alt="Aperiodic Markov Chain" width="30%" />
<p class="caption">
Figure 8.11: Aperiodic Markov Chain
</p>
</div>

<p>If we are to capture all possible trajectories, we end up with the following:</p>
<p><span class="math display">\[\begin{align*}
A {}&amp;\rightarrow B \rightarrow C \rightarrow A \\
B &amp;\rightarrow C \rightarrow B\\
C &amp;\rightarrow B \rightarrow C\\
\end{align*}\]</span></p>
<p>We have two periods: a 3-step period for the first trajectory and a 2-step period for the second and third trajectories. So if we get the GCD, it ends up being 1.</p>
<p><span class="math display">\[
gcd\{2, 3\} = 1 \leftarrow \text{(aperiodic)}
\]</span></p>
<p><strong>Ergodicity</strong> </p>
<p>A Markov Chain that is both <strong>aperiodic</strong> and <strong>irreducible</strong> is called an <strong>Ergodic</strong> Markov Chain.</p>
<p><strong>Transcience</strong> </p>
<p><strong>Transcience</strong> cites that a state node is <strong>transient</strong> if there is no other path to cycle back to itself. For example, in Figure <a href="bayesian2.html#fig:markovchain">8.9</a>, graphs 4, 5, and 6 show that state node A is a <strong>transient</strong> node because as soon as we leave state node A, there is no probability or no path that we can use to travel back to itself.</p>
<p><strong>Recurrence</strong> </p>
<p><strong>Recurrence</strong> cites that a state node is <strong>recurrent</strong> if there is at least one path to cycle back to itself. For example, in Figure <a href="bayesian2.html#fig:markovchain">8.9</a>, graphs 1, 2, and 3 show that all state nodes are <strong>recurrent</strong> because we can leave any state node and have a probability that we can find ourselves back to the same state node in some future number of steps.</p>
</div>
<div id="hidden-markov-model" class="section level3 hasAnchor">
<h3><span class="header-section-number">8.1.4</span> Hidden Markov Model  <a href="bayesian2.html#hidden-markov-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Hidden Markov model</strong> deals with a pair of sequences: a hidden state sequence and an emitted observation sequence. Figure <a href="bayesian2.html#fig:hiddenmarkov">8.12</a> shows a diagram of an <strong>HMM</strong> along with its corresponding <strong>trellis diagram</strong>.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:hiddenmarkov"></span>
<img src="hiddenmarkov.png" alt="Hidden Markov Chain" width="90%" />
<p class="caption">
Figure 8.12: Hidden Markov Chain
</p>
</div>

<p>Note that the trellis diagram is based on the state diagram. The sequence of hidden states is as follows:</p>
<p><span class="math display">\[
\text{Hidden State Sequence } \mathbf{(X^{seq})} = ( X_1,\ X_2,\ X_3,\ X_4 ) = ( A,\ C,\ B,\ A )
\]</span></p>
<p>The sequence of emitted observations is as follows:</p>
<p><span class="math display">\[
\text{Emitted Observation Sequence} \mathbf{(Y^{seq})} = ( Y_1  ,\ Y_2  ,\ Y_3  ,\ Y_4 ) = (\ R,P,Q,P )
\]</span></p>
<p>Though we receive a sequence of observed data, e.g., { R, P, Q, P }, we do not know the sort of system dynamics or sequence of random events responsible for emitting the outcome. For all we know, the unknown sequence of states could be any of the following sequences:</p>
<p><span class="math display">\[
( A,\ C,\ B,\ B)\ \ \ \ \ \ \
( B,\ A,\ C,\ B)\ \ \ \ \ \ \
( C,\ B,\ A,\ C)\ \ \ \ \ \ \
( A,\ B,\ C,\ A)\ \ \ \ \ \ \
\]</span></p>
<p>There are many examples of systems or sequences of random events in which we obtain a sample of observations <span class="math inline">\(\mathbf{Y^{seq}}\)</span>, but the state or condition of <span class="math inline">\(\mathbf{X^{seq}}\)</span> under which each of these observations is exposed is unknown to us. A typical toy example of such a sequence of random events is around activity patterns depending on weather patterns. For example, we estimate the probability of bringing an umbrella to the park for a walk based on observed weather patterns. Another case is in studying the cause of death in multiple regions over time due to the spread of a particular pathogen (e.g., COVID-19) from region to region. Such a case does not necessarily demonstrate a one-to-one map between the hidden Markov Chain and the observable data; thus, we may call for the use of interpolation to fill the gap.</p>
<p>There are <strong>three common goals</strong> we need to accomplish when dealing with <strong>HMM</strong>. To help accomplish the goals, we have a few items (or <strong>guides</strong>) to be aware of:</p>
<p><strong>First</strong>, we require three matrix-based parameters to form our hidden markov model (HMM), namely <span class="math inline">\(\mathbb{M}\)</span>: the (<span class="math inline">\(\mathbb{T}\)</span>) transition probability matrix , the (<span class="math inline">\(\mathbb{E}\)</span>) emission probability matrix, and the (<span class="math inline">\(\mathbf{\pi}\)</span>) initial probability matrix. See Figure <a href="bayesian2.html#fig:hmmmatrix">8.13</a>.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:hmmmatrix"></span>
<img src="hmmmatrix.png" alt="Transition and Emission Matrix" width="90%" />
<p class="caption">
Figure 8.13: Transition and Emission Matrix
</p>
</div>

<p>where:</p>
<ul>
<li><strong>n</strong> is the number of all possible distinct countable states, namely <span class="math inline">\(S \in \{\ A,\ B,\ C\ \}\)</span>.</li>
<li><strong>m</strong> is the number of all possible distinct countable outcomes, namely <span class="math inline">\(O \in \{\ P,\ Q,\ R\ \}\)</span>.</li>
</ul>
<p>Note that both transition and emission probability matrices contain rows of stochastic probabilities summing to 1. The initial probability matrix also sums to 1.</p>
<p><strong>Second</strong>, we also require the use of the <strong>HMM diagram</strong> in Figure <a href="bayesian2.html#fig:blockedhmm">8.14</a>. Just for illustration, let us treat each state node - in particular <span class="math inline">\(X_t\)</span> - as a â<strong>blocking</strong>â state node that cuts off dependencies.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:blockedhmm"></span>
<img src="blockhmm.png" alt="Blocked State" width="90%" />
<p class="caption">
Figure 8.14: Blocked State
</p>
</div>

<p><strong>Third</strong>, to show what a <strong>blocking</strong> state node is all about, let us first simplify the joint probability equation below by using the <strong>Chain rule</strong> and <strong>memoryless property</strong> of the Markov Chain.</p>
<p>In Figure <a href="bayesian2.html#fig:blockedhmm">8.14</a>, the probability of <strong>HMM system</strong> in <span class="math inline">\(X_4\)</span> is expressed as such using the <strong>Chain rule</strong>:</p>
<p><span class="math display">\[\begin{align}
P(X_{1:4}) {}&amp;= P(X_1,...,X_4) \\
&amp;= P(X_4, X_3, X_2 , X_1)\\
&amp;= P(X_4| X_3, X_2 , X_1) P(X_3 , X_2, X_1) \\
&amp;= P(X_4| X_3, X_2 , X_1) P(X_3 | X_2, X_1) P(X_2,  X_1)\\
&amp;= P(X_4| X_4, X_2 , X_1) P(X_3 | X_2, X_1) P(X_2|X_1)  P(X_1)
\end{align}\]</span></p>
<p>However, with the <strong>memoryless property</strong>, the dependency of <span class="math inline">\(X_4\)</span> to other previous states is â<strong>blocked</strong>â by <span class="math inline">\(X_3\)</span>; the states <span class="math inline">\(X_{1:2}\)</span>, therefore, become irrelevant and can be dropped. <span class="math inline">\(X_4\)</span> depends on <span class="math inline">\(X_3\)</span> and so <span class="math inline">\(X_3\)</span> stays. Here is what we have:</p>
<p><span class="math display">\[\begin{align}
\begin{array}{lll}
P(X_1,...,X_4) &amp;= P(X_4 , X_3 , X_2, X_1) &amp; = P(X_4 , X_3)\\
&amp;= P(X_4|X_3 , X_2 , X_1) P(X_3,  X_1 , X_1) &amp; = P(X_4|X_3 ) P(X_3 )\\
\end{array} \label{eqn:eqnnumber327}
\end{align}\]</span></p>
<p>In general:</p>
<p><span class="math display">\[\begin{align}
P(X_{1:t}) = P(X_t| X_{t-1})P(X_{t-1}).
\end{align}\]</span></p>
<p><strong>Fourth</strong>, the same manner applies for the below equation in which the next state, <span class="math inline">\(X_t\)</span>, depends on the previous state, <span class="math inline">\(X_{t-1}\)</span>. The <span class="math inline">\(X_4\)</span> state blocks <span class="math inline">\(X_5\)</span> from <span class="math inline">\(Y_{1:4}\)</span> and <span class="math inline">\(X_{1:3}\)</span>. Therefore, we have:</p>
<p><span class="math display">\[\begin{align}
\begin{array}{lll}
P(X_4| Y_1,...,Y_3, X_1,...,X_3) &amp;= P(X_4 | Y_3, Y_2 , Y_1,  X_3, X_2 , X_1) &amp; = P(X_4| X_3 )\\
\end{array} \label{eqn:eqnnumber328}
\end{align}\]</span></p>
<p>In general:</p>
<p><span class="math display">\[\begin{align}
P(X_t | Y_{1:{t-1}}, X_{1:{t-1}}) = P(X_t|X_{t-1})\ \ \ \ \leftarrow \mathbf{\text{(state transition probability)}}.
\end{align}\]</span></p>
<p><strong>Fifth</strong>, the same manner applies with the below equation in which the observed data, <span class="math inline">\(Y_3\)</span>, depends on the sequence of states. We drop <span class="math inline">\(X_{1:2}\)</span> and <span class="math inline">\(Y_{1:2}\)</span> as they are blocked by state <span class="math inline">\(X_3\)</span> from <span class="math inline">\(Y_3\)</span>. Here is what we have:</p>
<p><span class="math display">\[\begin{align}
\begin{array}{lll}
P(Y_3| Y_1,...,Y_2, X_1,...,X_3) &amp;= P(Y_3 | Y_2 , Y_1,  X_3, X_2 , X_1) &amp; = P(Y_3| X_3 ).
\end{array} \label{eqn:eqnnumber329}
\end{align}\]</span></p>
<p>In general:</p>
<p><span class="math display">\[\begin{align}
P(Y_t | Y_{1:{t-1}}, X_{1:t}) = P(Y_t|X_t)\ \ \ \ \leftarrow \mathbf{\text{(emission probability)}}.
\end{align}\]</span></p>
<p><strong>Lastly</strong>, we, therefore, have five <strong>HMM</strong> items to use in accomplishing our three goals, broken down into a model (<span class="math inline">\(\mathbb{M}\)</span>) and a pair of sequences (<span class="math inline">\(\mathbb{S}\)</span>)</p>
<p><span class="math display">\[\begin{align}
\mathbb{M} = ( \mathbb{T}^{\ transition}, \mathbb{E}^{\ emission},\pi^{\ initial} ) = \{ \mathbb{T}, \mathbb{E}, \pi \},\ \ \ \ \ \ \ \ \ \ \ \mathbb{Seq} = \{\ X^{seq}, Y^{seq}\ \}
\end{align}\]</span></p>
<p>Here, we use the following notations for convenience:</p>
<p><span class="math display">\[\begin{align*}
\mathbb{T}_{X_1}(X_2) &amp;\leftarrow \text{ the transition probability from current hidden state } X_1\  \text{to state }X_2\\
\mathbb{E}_{X_1}(Y_1) &amp;\leftarrow \text{ the emission probability of observing $Y_1$  given current hidden state $X_1$}.
\end{align*}\]</span></p>
<p>With all that, we now discuss the three goals (Rabiner and Juang 1986). Other literature may refer to these three goals in terms of <strong>Evaluation, Decoding, and Learning</strong> tasks in solving HMM problems.</p>
<p><strong>First Goal (Evaluation)</strong></p>
<p>In an <strong>HMM</strong> system, determine the probability of observing <span class="math inline">\(Y^{seq}\)</span>, given that the temporal series of states, namely <span class="math inline">\(X^{seq}\)</span>, is unknown. Here, the model <span class="math inline">\(\mathbb{M}\)</span> is known.</p>
<p>This is expressed as:</p>
<p><span class="math display">\[\begin{align}
P_{\mathbb{M}}(Y^{seq}) {}&amp;= \sum P_{\mathbb{M}}(Y^{seq}, X^{seq}) &amp; \text{(sum rule)}\\
&amp;= \sum P_{\mathbb{M}}(Y^{seq}| X^{seq})P_{\mathbb{M}}(X^{seq}) &amp; \text{(chain rule)} \label{eqn:eqnnumber35}
\end{align}\]</span></p>
<p>Note that we are using the notation <span class="math inline">\(P_{\mathbb{M}}(Y^{seq})\)</span> instead of <span class="math inline">\(P(Y^{seq}|\mathbb{M})\)</span> to show that <span class="math inline">\(\mathbb{M}\)</span> is used as a known and already given (model) parameter. Also, it may be a bit cleaner that way.</p>
<p>We break down the problem by computing the probability of seeing <span class="math inline">\(Y^{seq}\)</span> and the probability of having <span class="math inline">\(X^{seq}\)</span>.</p>
<p><span class="math display">\[\begin{align}
P_{\mathbb{M}}( X^{seq}) {}&amp;= \sum \pi (X_1) P_{\mathbb{M}}(X_2| X_1)
P_{\mathbb{M}}(X_3| X_2) ... P_{\mathbb{M}}(X_T| X_{T-1})\\
&amp;= \sum \pi(X_1)\mathbb{T}_{X_1}(X_2)\mathbb{T}_{X_2}(X_3) ... \mathbb{T}_{X_{T-1}}(X_T) \\
&amp;= \sum \pi(X_1)\prod_{i=1}^{T-1} \mathbb{T}_{X_i}(X_{i+1})\ \ \ \ \text{(all possible X sequences)}
\end{align}\]</span></p>
<p><span class="math display">\[\begin{align}
P_{\mathbb{M}}( Y^{seq}| X^{seq}) &amp;= \sum P_{\mathbb{M}}(Y_1| X_1) P_{\mathbb{M}}(Y_2| X_2) P_{\mathbb{M}}(Y_3 | X_3 ... P_{\mathbb{M}}(Y_T| X_T)
\\
&amp;= \sum \mathbb{E}_{X_1}(Y_1)\mathbb{E}_{X_2}(Y_2)\mathbb{E}_{X_3}(Y_3) ... \mathbb{E}_{X_T}(Y_T) \\
&amp;= \sum \prod_{j=1}^{T} \mathbb{E}_{X_j}(Y_j)\ \ \ \ \text{(all possible Y sequences)}
\end{align}\]</span></p>
<p><span class="math display">\[\begin{align}
\therefore P_{\mathbb{M}}(Y^{seq}) 
&amp;= \sum P_{\mathbb{M}}(Y^{seq}| X^{seq})P_{\mathbb{M}}(X^{seq}) \\
&amp;=\sum \pi(X_1)\prod_{i=1}^{T-1} P_{\mathbb{M}}(X_{i+1}| X_{i})\prod_{i=1}^{T} P_{\mathbb{M}}(Y_{i}| X_{i})\\
&amp;= \sum \pi(X_1)\prod_{i=1}^{T-1} \mathbb{T}_{X_i}(X_{i+1})\prod_{j=1}^{T} \mathbb{E}_{X_j}(Y_j)\ \ \ \ \text{(all possible XY sequences)}  
\end{align}\]</span></p>
<p>where <span class="math inline">\(\pi(X_1)\)</span> is the probability of starting in state <span class="math inline">\(X_1 \in \{A,B,C\}\)</span> at step 1.</p>
<p>The computational requirement for the equation is <span class="math inline">\(O(T\cdot N^T)\)</span>, which is expensive, and it can get impractical to use if our model deals with larger countable states and longer series. An alternative solution is to optimize the computation and bring it to <span class="math inline">\(O(T\cdot N^2)\)</span>. We call this <strong>Forward Algorithm</strong>.</p>
<p>The alternative solution determines the <strong>most probable chance</strong> of being in a hidden state <span class="math inline">\(X_t\)</span> at step t for a partial series of observations up to step t, namely <span class="math inline">\(Y_{1:t}\)</span>.
Mathematically, we can derive an equation for the <strong>Forward algorithm</strong> and write the problem statement as a recursive function:</p>
<p><span class="math display">\[\begin{align}
\alpha_{S_j}(t) {}&amp;=  \sum P_\mathbb{M}(X_t,Y_{1:t})\\
&amp;= \sum P_\mathbb{M}(X_t, X_{t-1}, Y_t, Y_{1:t-1})  \ \text{(expand)}   \\
&amp;= \sum P_\mathbb{M}(Y_t| X_t, X_{t-1}, Y_{1:t-1}) P_\mathbb{M}( X_t, X_{t-1},Y_{1:t-1})  \ \text{(chain rule)}\\ 
&amp;= \sum P_\mathbb{M}(Y_t| X_t) P_\mathbb{M}( X_t, X_{t-1}, Y_{1:t-1})  \  \text{( markov property)}\\ 
&amp;= \sum P_\mathbb{M}(Y_t| X_t) P_\mathbb{M}( X_t | X_{t-1}, Y_{1:t-1}) P_\mathbb{M}( X_{t-1}, Y_{1:t-1})  \  \text{(chain rule)}\\ 
&amp;= \sum P_\mathbb{M}(Y_t| X_t) P_\mathbb{M}( X_t | X_{t-1}) P_\mathbb{M}( X_{t-1},Y_{1:t-1})  \ \text{(markov property)}\\ 
&amp;= \sum_{i=1:n} \mathbb{E}_{S_j}(Y_t)\mathbb{T}_{S_i}(S_j)\alpha_{S_i}(t-1) \ \text{(matrix lookup)}
\end{align}\]</span></p>
<p>where:</p>
<p><span class="math display">\[
\alpha_{S_i}(t-1) =  P_\mathbb{M}( X_{t-1},Y_{1:t-1})\ \ \ \ \ \ \text{(probability of all previous observations, given state }S_i )
\]</span></p>
<p>The algorithm has three steps:</p>
<ol style="list-style-type: decimal">
<li>Initialize <span class="math inline">\(\alpha_{S_i}(1)\)</span>, where <span class="math inline">\(1 \le i \le n\)</span> and <span class="math inline">\(S \in \{\ A,B,C\ \}\)</span>. For <span class="math inline">\(\mathbf{i \leftarrow i+1}\)</span> until <span class="math inline">\(\mathbf{i=n}\)</span>:</li>
</ol>
<p><span class="math display">\[\begin{align}
\alpha_{S_i}(1) = \pi(S_i) \cdot \mathbb{E}_{S_i}(Y_1)
\end{align}\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li>Perform recursive computation using the below equation. For step <span class="math inline">\(\mathbf{t} \leftarrow \mathbf{2}\)</span> until <span class="math inline">\(\mathbf{T}\)</span>:</li>
</ol>
<p><span class="math display">\[\begin{align}
\alpha_{S_j}(t) =  \left[\sum_{i=1}^n \alpha_{S_i}(t-1) \mathbb{T}_{S_i}(S_j)\right]  \mathbb{E}_{S_j}(Y_t)
\end{align}\]</span></p>
<ol start="3" style="list-style-type: decimal">
<li>Finally, at the end of the recursion, we perform the following computation for <span class="math inline">\(P_{\mathbb{M}}(Y^{seq})\)</span>.</li>
</ol>
<p><span class="math display">\[\begin{align}
P_{\mathbb{M}}(Y^{seq}) \leftarrow P(Y^{T}|\mathbb{M}) = \sum_{i=1}^{n=3} \alpha_{S_i}(T)
\end{align}\]</span></p>
<p>Let us review Figure <a href="bayesian2.html#fig:hmmforward">8.15</a>. The model <span class="math inline">\(\mathbb{M}\)</span> is based on Figure <a href="bayesian2.html#fig:hmmmatrix">8.13</a>.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:hmmforward"></span>
<img src="hmmforward.png" alt="Forward Algorithm Diagram" width="100%" />
<p class="caption">
Figure 8.15: Forward Algorithm Diagram
</p>
</div>

<p>To illustrate, let us build the model <span class="math inline">\(\mathbb{M}\)</span> and the pair of sequences <span class="math inline">\(\mathbb{S}\)</span> in R code:</p>

<div class="sourceCode" id="cb882"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb882-1" data-line-number="1">S =<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;A&quot;</span>, <span class="st">&quot;B&quot;</span>, <span class="st">&quot;C&quot;</span>)          <span class="co"># list of states</span></a>
<a class="sourceLine" id="cb882-2" data-line-number="2">O =<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;P&quot;</span>, <span class="st">&quot;Q&quot;</span>, <span class="st">&quot;R&quot;</span>)          <span class="co"># list of observation symbols</span></a>
<a class="sourceLine" id="cb882-3" data-line-number="3">X.seq =<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;A&quot;</span>, <span class="st">&quot;C&quot;</span>, <span class="st">&quot;B&quot;</span>, <span class="st">&quot;A&quot;</span>) <span class="co"># hidden states</span></a>
<a class="sourceLine" id="cb882-4" data-line-number="4">Y.seq =<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;R&quot;</span>, <span class="st">&quot;P&quot;</span>, <span class="st">&quot;Q&quot;</span>, <span class="st">&quot;P&quot;</span>) <span class="co"># observations</span></a>
<a class="sourceLine" id="cb882-5" data-line-number="5">T =<span class="st"> </span><span class="kw">matrix</span>( <span class="co"># transition probabilities matrix</span></a>
<a class="sourceLine" id="cb882-6" data-line-number="6">      <span class="kw">c</span>(<span class="fl">0.00</span>, <span class="fl">0.10</span>, <span class="fl">0.90</span>, </a>
<a class="sourceLine" id="cb882-7" data-line-number="7">        <span class="fl">0.60</span>, <span class="fl">0.00</span>, <span class="fl">0.40</span>, </a>
<a class="sourceLine" id="cb882-8" data-line-number="8">        <span class="fl">0.23</span>, <span class="fl">0.77</span>, <span class="fl">0.00</span>), <span class="dt">nrow=</span><span class="dv">3</span>, <span class="dt">ncol=</span><span class="dv">3</span>, <span class="dt">byrow=</span><span class="ot">TRUE</span></a>
<a class="sourceLine" id="cb882-9" data-line-number="9">)</a>
<a class="sourceLine" id="cb882-10" data-line-number="10"><span class="kw">colnames</span>(T) =<span class="st"> </span>S</a>
<a class="sourceLine" id="cb882-11" data-line-number="11"><span class="kw">rownames</span>(T) =<span class="st"> </span>S</a>
<a class="sourceLine" id="cb882-12" data-line-number="12">E =<span class="st"> </span><span class="kw">matrix</span>( <span class="co"># emission probabilities matrix</span></a>
<a class="sourceLine" id="cb882-13" data-line-number="13">      <span class="kw">c</span>(<span class="fl">0.43</span>, <span class="fl">0.37</span>, <span class="fl">0.20</span>, </a>
<a class="sourceLine" id="cb882-14" data-line-number="14">        <span class="fl">0.24</span>, <span class="fl">0.76</span>, <span class="fl">0.00</span>, </a>
<a class="sourceLine" id="cb882-15" data-line-number="15">        <span class="fl">0.52</span>, <span class="fl">0.48</span>, <span class="fl">0.00</span>), <span class="dt">nrow=</span><span class="dv">3</span>, <span class="dt">ncol=</span><span class="dv">3</span>, <span class="dt">byrow=</span><span class="ot">TRUE</span></a>
<a class="sourceLine" id="cb882-16" data-line-number="16">)</a>
<a class="sourceLine" id="cb882-17" data-line-number="17"><span class="kw">colnames</span>(E) =<span class="st"> </span>O</a>
<a class="sourceLine" id="cb882-18" data-line-number="18"><span class="kw">rownames</span>(E) =<span class="st"> </span>S</a>
<a class="sourceLine" id="cb882-19" data-line-number="19"><span class="co"># Initial probabilities matrix</span></a>
<a class="sourceLine" id="cb882-20" data-line-number="20">I =<span class="st"> </span><span class="kw">c</span>(<span class="fl">0.28</span>, <span class="fl">0.12</span>, <span class="fl">0.60</span>); <span class="kw">names</span>(I) =<span class="st"> </span>S</a>
<a class="sourceLine" id="cb882-21" data-line-number="21"><span class="co"># the hidden markov model</span></a>
<a class="sourceLine" id="cb882-22" data-line-number="22">(<span class="dt">M =</span> <span class="kw">list</span>(<span class="st">&quot;T&quot;</span> =<span class="st"> </span>T, <span class="st">&quot;E&quot;</span> =<span class="st"> </span>E, <span class="st">&quot;I&quot;</span> =<span class="st"> </span>I, <span class="st">&quot;S&quot;</span>=S, <span class="st">&quot;O&quot;</span>=O))  </a></code></pre></div>
<pre><code>## $T
##      A    B   C
## A 0.00 0.10 0.9
## B 0.60 0.00 0.4
## C 0.23 0.77 0.0
## 
## $E
##      P    Q   R
## A 0.43 0.37 0.2
## B 0.24 0.76 0.0
## C 0.52 0.48 0.0
## 
## $I
##    A    B    C 
## 0.28 0.12 0.60 
## 
## $S
## [1] &quot;A&quot; &quot;B&quot; &quot;C&quot;
## 
## $O
## [1] &quot;P&quot; &quot;Q&quot; &quot;R&quot;</code></pre>

<p>Below is an example implementation of the <strong>Forward algorithm</strong> in R code:</p>

<div class="sourceCode" id="cb884"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb884-1" data-line-number="1">hmm.forward &lt;-<span class="st"> </span><span class="cf">function</span>(Y, M) {</a>
<a class="sourceLine" id="cb884-2" data-line-number="2">  T =<span class="st"> </span><span class="kw">length</span>(Y)</a>
<a class="sourceLine" id="cb884-3" data-line-number="3">  a =<span class="st"> </span>M<span class="op">$</span>T;  b =<span class="st"> </span>M<span class="op">$</span>E; r =<span class="st"> </span>M<span class="op">$</span>I; n =<span class="st"> </span><span class="kw">nrow</span>(a)</a>
<a class="sourceLine" id="cb884-4" data-line-number="4">  alpha =<span class="st">  </span><span class="kw">matrix</span>(<span class="dv">0</span>, <span class="dt">nrow =</span> n, <span class="dt">ncol =</span> T)</a>
<a class="sourceLine" id="cb884-5" data-line-number="5">  alpha[,<span class="dv">1</span>] =<span class="st"> </span>r <span class="op">*</span><span class="st"> </span>b[, Y[<span class="dv">1</span>]]</a>
<a class="sourceLine" id="cb884-6" data-line-number="6">  <span class="cf">for</span> (t <span class="cf">in</span> <span class="dv">2</span><span class="op">:</span>T) {</a>
<a class="sourceLine" id="cb884-7" data-line-number="7">    <span class="co"># use log-sum-exp to avoid underflow for large multiplications</span></a>
<a class="sourceLine" id="cb884-8" data-line-number="8">    <span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n) { </a>
<a class="sourceLine" id="cb884-9" data-line-number="9">         alpha[j,t]  =<span class="st"> </span><span class="kw">sum</span>( alpha[,t<span class="dv">-1</span>] <span class="op">*</span><span class="st"> </span>a[,j] ) <span class="op">*</span><span class="st"> </span>b[j,Y[t]] </a>
<a class="sourceLine" id="cb884-10" data-line-number="10">    } </a>
<a class="sourceLine" id="cb884-11" data-line-number="11">  } </a>
<a class="sourceLine" id="cb884-12" data-line-number="12">  <span class="kw">list</span>(<span class="st">&quot;alpha.matrix&quot;</span>=alpha, <span class="st">&quot;Probability&quot;</span>=<span class="kw">sum</span>(alpha[,T]))</a>
<a class="sourceLine" id="cb884-13" data-line-number="13">}</a>
<a class="sourceLine" id="cb884-14" data-line-number="14"><span class="kw">hmm.forward</span>(Y.seq, M)</a></code></pre></div>
<pre><code>## $alpha.matrix
##       [,1]     [,2]     [,3]      [,4]
## [1,] 0.056 0.000000 0.002529 0.0039824
## [2,] 0.000 0.001344 0.015337 0.0001084
## [3,] 0.000 0.026208 0.000258 0.0043735
## 
## $Probability
## [1] 0.008464</code></pre>

<p>Let us validate by using <strong>backward()</strong> function from a 3rd-party library called <strong>HMM</strong>:</p>

<div class="sourceCode" id="cb886"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb886-1" data-line-number="1"><span class="kw">library</span>(HMM)</a>
<a class="sourceLine" id="cb886-2" data-line-number="2">hmm =<span class="st"> </span><span class="kw">initHMM</span>(S, O, <span class="dt">startProbs =</span> M<span class="op">$</span>I, </a>
<a class="sourceLine" id="cb886-3" data-line-number="3">          <span class="dt">transProbs =</span> M<span class="op">$</span>T, <span class="dt">emissionProbs =</span> M<span class="op">$</span>E)</a>
<a class="sourceLine" id="cb886-4" data-line-number="4"><span class="kw">exp</span>(<span class="kw">forward</span>(hmm, Y.seq)) <span class="co"># library uses log</span></a></code></pre></div>
<pre><code>##       index
## states     1        2        3         4
##      A 0.056 0.000000 0.002529 0.0039824
##      B 0.000 0.001344 0.015337 0.0001084
##      C 0.000 0.026208 0.000258 0.0043735</code></pre>

<p>We can also validate the result by using <strong>Backward algorithm</strong>, which is the reverse of <strong>Forward algorithm</strong>. The derivation of the <strong>Backward equation</strong> is as such:</p>
<p><span class="math display">\[\begin{align}
\beta_{Si}(t) {}&amp;= \sum P_\mathbb{M}(Y_{t+1:T}|X_t)\\
&amp;= \sum P_\mathbb{M}(Y_{t+1},Y_{t+2:Y_T},X_{t+1}|X_t)  \ \text{(expand)}\\
&amp;= \sum P_\mathbb{M}(Y_{t+2:Y_T}|Y_{t+1},X_{t+1},X_t) P_\mathbb{M}(Y_{t+1},X_{t+1},X_t)  \ \text{(chain rule)}\\
&amp;= \sum P_\mathbb{M}(Y_{t+2:Y_T}|Y_{t+1},X_{t+1},X_t) P_\mathbb{M}(Y_{t+1}|X_{t+1},X_t)P_\mathbb{M}(X_{t+1},X_t)   \ \text{(chain rule)}\\
&amp;= \sum P_\mathbb{M}(Y_{t+2:Y_T}|X_{t+1}) P_\mathbb{M}(Y_{t+1}|X_{t+1})P_\mathbb{M}(X_{t+1}|X_t)   \ \text{(markov property)}\\
&amp;= \sum_{j=1:n} \beta_{Sj}(t+1) \mathbb{E}_{S_j}(Y_{t+1})\mathbb{T}_{S_i}(X_{S_j})
\end{align}\]</span></p>
<p>where:</p>
<p><span class="math display">\[
\beta_{S_j}(t+1) = P_\mathbb{M}(Y_{t+2:Y_T}|X_{t+1})\ \ \ \ \ \ \text{(probability of all future observations, given state }S_j )
\]</span></p>
<p>The algorithm has three steps:</p>
<ol style="list-style-type: decimal">
<li>Initialize <span class="math inline">\(\beta_{Si}(T)\)</span>. For <span class="math inline">\(\mathbf{i \leftarrow i+1}\)</span> until <span class="math inline">\(\mathbf{i=n}\)</span>:</li>
</ol>
<p><span class="math display">\[\begin{align}
\beta_{Si}(T) = 1
\end{align}\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li>Perform recursive computation using the below equation. For step <span class="math inline">\(\mathbf{t} \leftarrow \mathbf{2}\)</span> until <span class="math inline">\(\mathbf{T}\)</span>:</li>
</ol>
<p><span class="math display">\[\begin{align}
\beta_{S_i}(t) =  \sum_{j=1}^n \mathbb{T}_{S_i}(S_j)  \mathbb{E}_{S_j}(Y_{t+1}) \beta_{S_j}(t+1) 
\end{align}\]</span></p>
<ol start="3" style="list-style-type: decimal">
<li>Finally, at the end of the recursion, we perform the following computation for <span class="math inline">\(P_{\mathbb{M}}(Y^{seq})\)</span>.</li>
</ol>
<p><span class="math display">\[\begin{align}
P_{\mathbb{M}}(Y^{seq}) \leftarrow P(Y^{T}|\mathbb{M}) = \sum_{i=1}^{n=3} \pi(S_i) \mathbb{E}_{S_i}(Y_1)\beta_{S_i}(1)
\end{align}\]</span></p>
<p>Let us review Figure <a href="bayesian2.html#fig:hmmbackward">8.16</a>. The model <span class="math inline">\(\mathbb{M}\)</span> is based on Figure <a href="bayesian2.html#fig:hmmmatrix">8.13</a>.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:hmmbackward"></span>
<img src="hmmbackward.png" alt="Backward Algorithm Diagram" width="100%" />
<p class="caption">
Figure 8.16: Backward Algorithm Diagram
</p>
</div>

<p>Below is an example implementation of the <strong>Backward algorithm</strong> in R code:</p>

<div class="sourceCode" id="cb888"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb888-1" data-line-number="1">hmm.backward &lt;-<span class="st"> </span><span class="cf">function</span>(Y, M) {</a>
<a class="sourceLine" id="cb888-2" data-line-number="2">  T =<span class="st"> </span><span class="kw">length</span>(Y)</a>
<a class="sourceLine" id="cb888-3" data-line-number="3">  a =<span class="st"> </span>M<span class="op">$</span>T;  b =<span class="st"> </span>M<span class="op">$</span>E; r =<span class="st"> </span>M<span class="op">$</span>I; n =<span class="st"> </span><span class="kw">nrow</span>(a)</a>
<a class="sourceLine" id="cb888-4" data-line-number="4">  beta =<span class="st">  </span><span class="kw">matrix</span>(<span class="dv">1</span>, <span class="dt">nrow =</span> n, <span class="dt">ncol =</span> T)</a>
<a class="sourceLine" id="cb888-5" data-line-number="5">  beta[,T] =<span class="st"> </span><span class="dv">1</span></a>
<a class="sourceLine" id="cb888-6" data-line-number="6">  <span class="cf">for</span> (t <span class="cf">in</span> (T<span class="dv">-1</span>)<span class="op">:</span><span class="dv">1</span>) {</a>
<a class="sourceLine" id="cb888-7" data-line-number="7">    <span class="co"># use log-sum-exp to avoid underflow for large multiplications</span></a>
<a class="sourceLine" id="cb888-8" data-line-number="8">    <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n) {</a>
<a class="sourceLine" id="cb888-9" data-line-number="9">       beta[i,t] =<span class="st"> </span><span class="kw">sum</span>( a[i,] <span class="op">*</span><span class="st"> </span>b[, Y[t<span class="op">+</span><span class="dv">1</span>]] <span class="op">*</span><span class="st">  </span>beta[,t<span class="op">+</span><span class="dv">1</span>])</a>
<a class="sourceLine" id="cb888-10" data-line-number="10">    }</a>
<a class="sourceLine" id="cb888-11" data-line-number="11">  }</a>
<a class="sourceLine" id="cb888-12" data-line-number="12">  <span class="kw">list</span>( <span class="st">&quot;beta.matrix&quot;</span>=beta, </a>
<a class="sourceLine" id="cb888-13" data-line-number="13">        <span class="st">&quot;Probability&quot;</span>=<span class="kw">sum</span>(r <span class="op">*</span><span class="st"> </span>b[, Y[<span class="dv">1</span>]] <span class="op">*</span><span class="st">  </span>beta[,<span class="dv">1</span>] ))</a>
<a class="sourceLine" id="cb888-14" data-line-number="14">}</a>
<a class="sourceLine" id="cb888-15" data-line-number="15"><span class="kw">hmm.backward</span>(Y.seq, M)</a></code></pre></div>
<pre><code>## $beta.matrix
##         [,1]   [,2]   [,3] [,4]
## [1,] 0.15115 0.1580 0.4920    1
## [2,] 0.10619 0.1637 0.4660    1
## [3,] 0.04587 0.3146 0.2837    1
## 
## $Probability
## [1] 0.008464</code></pre>

<p>Let us validate by using <strong>backward()</strong> function from a 3rd-party library called <strong>HMM</strong>:</p>

<div class="sourceCode" id="cb890"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb890-1" data-line-number="1"><span class="kw">library</span>(HMM)</a>
<a class="sourceLine" id="cb890-2" data-line-number="2">hmm =<span class="st"> </span><span class="kw">initHMM</span>(S, O, <span class="dt">startProbs =</span> M<span class="op">$</span>I, </a>
<a class="sourceLine" id="cb890-3" data-line-number="3">          <span class="dt">transProbs =</span> M<span class="op">$</span>T, <span class="dt">emissionProbs =</span> M<span class="op">$</span>E)</a>
<a class="sourceLine" id="cb890-4" data-line-number="4"><span class="kw">exp</span>(<span class="kw">backward</span>(hmm, Y.seq)) <span class="co"># library uses log</span></a></code></pre></div>
<pre><code>##       index
## states       1      2      3 4
##      A 0.15115 0.1580 0.4920 1
##      B 0.10619 0.1637 0.4660 1
##      C 0.04587 0.3146 0.2837 1</code></pre>

<p><strong>Second Goal (Decoding)</strong></p>
<p>A second goal when dealing with <strong>HMM</strong> is to estimate the most probable (or likely) <strong>trajectory (or path)</strong> of the state sequence (<span class="math inline">\(\mathbf{X^{seq}}\)</span>) after seeing the observation sequence, namely (<span class="math inline">\(\mathbf{Y^{seq}}\)</span>).</p>
<p>We use the famous <strong>Viterbi (Decoding) Algorithm</strong> to do that. </p>
<p>Recall the following equation from the first goal (See Equation <span class="math inline">\(\ref{eqn:eqnnumber35}\)</span>):</p>
<p><span class="math display">\[\begin{align}
P_{\mathbb{M}}(Y^{seq}, X^{seq}) {}&amp;= \sum P_{\mathbb{M}}(Y^{seq}| X^{seq})P_{\mathbb{M}}(X^{seq}) &amp; \text{(likelihood)}
\end{align}\]</span></p>
<p>Here, instead of using the summation notation, we use the maximization notation:</p>
<p><span class="math display">\[\begin{align}
P_{\mathbb{M}}(Y^{seq}, X^{seq})  {}&amp;=  max\  P_{\mathbb{M}}(Y^{seq}| X^{seq})P_{\mathbb{M}}(X^{seq}) &amp; \text{(decode)}
\end{align}\]</span></p>
<p>For the trajectory of probable state sequence, we have the following:</p>
<p><span class="math display">\[\begin{align}
X^* =  \underset{1 \le i \le n}{argmax}\  P_{\mathbb{M}}(Y^{seq}| X^{seq})P_{\mathbb{M}}(X^{seq}) 
\end{align}\]</span></p>
<p>We can break down the problem by computing the probability of seeing <span class="math inline">\(Y^{seq}\)</span> and the probability of having <span class="math inline">\(X^{seq}\)</span>.</p>

<p><span class="math display">\[\begin{align}
P_{\mathbb{M}}( X^{seq}) {}&amp;
= max\ \pi(X_1)\prod_{i=1}^{T-1} \mathbb{T}_{X_i}(X_{i+1})\ \ \ \ \text{(all possible X sequences)}  \\
\nonumber \\
P_{\mathbb{M}}( Y^{seq}| X^{seq}) 
&amp;= max\ \prod_{j=1}^{T} \mathbb{E}_{X_j}(Y_j)\ \ \ \ \text{(all possible Y sequences)}  \\
\nonumber \\
\therefore P_{\mathbb{M}}(Y^{seq}) 
&amp;= max\ \pi(X_1)\prod_{i=1}^{T-1} \mathbb{T}_{X_i}(X_{i+1})\prod_{j=1}^{T} \mathbb{E}_{X_j}(Y_j)\ \ \ \ \text{(all possible XY sequences)}  
\end{align}\]</span>
</p>
<p>Similarly, to optimize computation, we use the following alternative equation:</p>
<p><span class="math display">\[\begin{align}
\alpha_{S_j}(t) {}&amp;= max\  P_\mathbb{M}(X_t,Y_{1:t})\\
&amp;= \underset{i=1:n}{max}\  \mathbb{T}_{S_i}(S_j)\mathbb{E}_{S_j}(Y_t)\alpha_{S_i}(t-1) &amp; \text{(decode)}
\end{align}\]</span></p>
<p>Therefore, the <strong>Viterbi algorithm</strong> follows the <strong>Forward algorithm</strong>, except it does not sum probabilities; instead, it finds the maximum probabilities.</p>
<p>Below is an example implementation of the <strong>Viterbi algorithm</strong> in R code:</p>

<div class="sourceCode" id="cb892"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb892-1" data-line-number="1">hmm.viterbi &lt;-<span class="st"> </span><span class="cf">function</span>(Y, M) {</a>
<a class="sourceLine" id="cb892-2" data-line-number="2">  T =<span class="st"> </span><span class="kw">length</span>(Y)</a>
<a class="sourceLine" id="cb892-3" data-line-number="3">  a =<span class="st"> </span>M<span class="op">$</span>T;  b =<span class="st"> </span>M<span class="op">$</span>E; S =<span class="st"> </span>M<span class="op">$</span>S; r =<span class="st"> </span>M<span class="op">$</span>I; n =<span class="st"> </span><span class="kw">nrow</span>(a)</a>
<a class="sourceLine" id="cb892-4" data-line-number="4">  alpha =<span class="st">  </span><span class="kw">matrix</span>(<span class="dv">0</span>, <span class="dt">nrow =</span> n, <span class="dt">ncol =</span> T)</a>
<a class="sourceLine" id="cb892-5" data-line-number="5">  alpha[,<span class="dv">1</span>] =<span class="st"> </span>r <span class="op">*</span><span class="st"> </span>b[, Y[<span class="dv">1</span>]]</a>
<a class="sourceLine" id="cb892-6" data-line-number="6">  <span class="cf">for</span> (t <span class="cf">in</span> <span class="dv">2</span><span class="op">:</span>T) {</a>
<a class="sourceLine" id="cb892-7" data-line-number="7">    <span class="co"># use log-sum-exp to avoid underflow for large multiplications</span></a>
<a class="sourceLine" id="cb892-8" data-line-number="8">    <span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n) { </a>
<a class="sourceLine" id="cb892-9" data-line-number="9">         alpha[j,t]  =<span class="st"> </span><span class="kw">max</span>( alpha[,t<span class="dv">-1</span>] <span class="op">*</span><span class="st"> </span>a[,j]  <span class="op">*</span><span class="st"> </span>b[j,Y[t]] )</a>
<a class="sourceLine" id="cb892-10" data-line-number="10">    } </a>
<a class="sourceLine" id="cb892-11" data-line-number="11">  } </a>
<a class="sourceLine" id="cb892-12" data-line-number="12">  <span class="co"># Let&#39;s do the decoding </span></a>
<a class="sourceLine" id="cb892-13" data-line-number="13">  m =<span class="st"> </span><span class="kw">apply</span>(alpha, <span class="dv">2</span>, which.max) <span class="co"># argmax</span></a>
<a class="sourceLine" id="cb892-14" data-line-number="14">  code =<span class="st"> </span>S[m]</a>
<a class="sourceLine" id="cb892-15" data-line-number="15">  <span class="kw">rownames</span>(alpha) =<span class="st"> </span>S</a>
<a class="sourceLine" id="cb892-16" data-line-number="16">  <span class="kw">list</span>(<span class="st">&quot;alpha.matrix&quot;</span>=alpha, <span class="st">&quot;Probability&quot;</span>=<span class="kw">max</span>(alpha[,T]), </a>
<a class="sourceLine" id="cb892-17" data-line-number="17">       <span class="st">&quot;Decoded State Sequence&quot;</span>=code)</a>
<a class="sourceLine" id="cb892-18" data-line-number="18">}</a>
<a class="sourceLine" id="cb892-19" data-line-number="19"><span class="kw">hmm.viterbi</span>(Y.seq, M)</a></code></pre></div>
<pre><code>## $alpha.matrix
##    [,1]     [,2]     [,3]       [,4]
## A 0.056 0.000000 0.002230 0.00395693
## B 0.000 0.001344 0.015337 0.00005353
## C 0.000 0.026208 0.000258 0.00319008
## 
## $Probability
## [1] 0.003957
## 
## $`Decoded State Sequence`
## [1] &quot;A&quot; &quot;C&quot; &quot;B&quot; &quot;A&quot;</code></pre>

<p>Let us validate by using <strong>viterbi(.)</strong> function from a 3rd-party library called <strong>HMM</strong>:</p>

<div class="sourceCode" id="cb894"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb894-1" data-line-number="1"><span class="kw">library</span>(HMM)</a>
<a class="sourceLine" id="cb894-2" data-line-number="2">hmm =<span class="st"> </span><span class="kw">initHMM</span>(S, O, <span class="dt">startProbs =</span> M<span class="op">$</span>I, </a>
<a class="sourceLine" id="cb894-3" data-line-number="3">          <span class="dt">transProbs =</span> M<span class="op">$</span>T, <span class="dt">emissionProbs =</span> M<span class="op">$</span>E)</a>
<a class="sourceLine" id="cb894-4" data-line-number="4"><span class="kw">viterbi</span>(hmm, Y.seq) </a></code></pre></div>
<pre><code>## [1] &quot;A&quot; &quot;C&quot; &quot;B&quot; &quot;A&quot;</code></pre>

<p>Note that other efforts are taken to improve the <strong>Viterbi</strong> algorithm. For that, we leave readers to investigate other variations.</p>
<p><strong>Third Goal (Learning)</strong></p>
<p>A third goal when dealing with <strong>HMM</strong> is to estimate the probability of (or âtrainâ) a <strong>new model</strong> <span class="math inline">\(\mathbb{M}^* = \{ \mathbb{T}^*, \mathbb{E}^*, \pi^*\}\)</span> after seeing the observation sequence, namely <span class="math inline">\(Y^{seq}\)</span>. Here, an initial model, namely <span class="math inline">\(\mathbb{M}^0\)</span>, is randomly provided.</p>
<p>To do that, we use the <strong>Baum-Welch Algorithm</strong>, also called <strong>Forward-Backward Algorithm</strong>. </p>
<p>The <strong>Baum-Welch Algorithm</strong> is an <strong>Expectation-Maximization (EM)</strong> algorithm.</p>
<p>For the <strong>Estimation (E) Step</strong>, we follow the following steps:</p>
<p><strong>First</strong>, we randomly initialize the elements of each parameter in the model <span class="math inline">\(\mathbb{M}^0\)</span>. Here, the size of each of the parameters is fixed.</p>
<p><span class="math display">\[\begin{align}
\mathbb{M}^0 = \{ \mathbb{T}^0, \mathbb{E}^0, \pi^0\}
\end{align}\]</span></p>
<p><strong>Second</strong>, we compute the probability of all observations. That is the start of the iteration.</p>
<p>Recall the <strong>Forward</strong> algorithm. We compute for <span class="math inline">\(\alpha_{S_j}(t)\)</span>:</p>
<p><span class="math display">\[\begin{align}
\alpha_{S_i}(1) {}&amp;= \pi(S_i)^0 \cdot \mathbb{E}_{S_i}^0(Y_1),\ \ \ \ \ \ \ i = 1\ ...\ n \\
\alpha_{S_j}(t) {}&amp;=  \left[\sum_{i=1}^n \alpha_{S_i}(t-1) \mathbb{T}_{S_i}^0(S_j)\right]  \mathbb{E}_{S_j}^0(Y_t)
\end{align}\]</span></p>
<p>Recall the <strong>Backward</strong> algorithm. We compute for <span class="math inline">\(\beta_{S_i}(t)\)</span>:</p>
<p><span class="math display">\[\begin{align}
\beta_{Si}(T) {}&amp;= 1,\ \ \ \ \ \ \ i = 1\ ...\ n \\
\beta_{S_i}(t) &amp;=  \sum_{j=1}^n \mathbb{T}_{S_i}^0(S_j)  \mathbb{E}_{S_j}^0(Y_{t+1}) \beta_{S_j}(t+1)
\end{align}\]</span></p>
<p><strong>Third</strong>, using <strong>Bayes Theorem</strong>, we combine both <strong>Forward</strong> and <strong>Backward</strong> equations to generate the two-state probabilities below:</p>
<p><span class="math display">\[\begin{align}
\gamma_{S_i}(t)  {}&amp;= P_\mathbb{M^0}(X_t = S_i | Y^{seq}) =
\frac{P_\mathbb{M^0}(X_t = S_i , Y^{seq})}{P_\mathbb{M^0}(Y^{seq})}\ \ \ \ \ \ 
\leftarrow\ \text{posterior} = \frac{\text{belief}}{\text{marginal}}\\
&amp;= \frac{ \alpha_{S_i}(t)\beta_{S_i}(t) } {\sum_{j=1}^n \alpha_{S_j}(t)\beta_{S_j}(t)}\ \ \ \ \text{(normalized)}\\
\nonumber \\
\xi_{S_i,S_j}(t) &amp;= 
P_\mathbb{M^0}(X_t = S_i, X_{t+1} = S_j | Y^{seq})  = \frac{P_\mathbb{M^0}(X_t = S_i , X_{t+1} = S_j,  Y^{seq})}{P_\mathbb{M^0}(Y^{seq})}\\
&amp;= \frac{ 
\alpha_{S_i}(t)\mathbb{T}_{S_i}^0(S_j)\beta_{S_j}(t+1) \mathbb{E}_{S_j}^0(Y_{t+1})
} 
{\sum_{k=1}^n \sum_{l=1}^n
\alpha_{S_k}(t)\mathbb{T}_{S_k}^0(S_l)\beta_{S_l}(t+1) \mathbb{E}_{S_l}^0(Y_{t+1})
}\ \ \ \ \text{(normalized)}
\end{align}\]</span></p>
<p>where, given <span class="math inline">\(Y^{seq}\)</span>:</p>
<ul>
<li><span class="math inline">\(\gamma_{Si}(t)\)</span> is the probability of being in state <span class="math inline">\(S_i\)</span> at time t.</li>
<li><span class="math inline">\(\xi_{S_i,S_j}(t)\)</span> is the expected transition from state <span class="math inline">\(S_i\)</span> to state <span class="math inline">\(S_j\)</span> at time t+1.</li>
</ul>
<p><strong>Fourth</strong>, for the <strong>Maximization (M) step</strong>, we then train the model <span class="math inline">\(\mathbb{M^1}\)</span>.</p>
<p>We compute for the expected number of transitions from <span class="math inline">\(S_i\)</span> and from <span class="math inline">\(S_i\)</span> to <span class="math inline">\(S_j\)</span>:</p>
<p><span class="math display">\[\begin{align}
\sum_{t=1}^{T} \gamma_{Si}(t)\ \ \ \ \ \ \ \ \ \ \
\sum_{t=1}^{T} \xi_{S_i,S_j}(t)
\end{align}\]</span></p>
<p>With that, we use the following model parameters:</p>
<p><span class="math display">\[\begin{align}
\mathbb{T}^1_{S_i}(S_j) = \frac{\sum_{t=1}^{T-1} \xi_{S_i,S_j}(t) }{\sum_{t=1}^{T-1} \gamma_{Si}(t)}\ \ \ \ \ \ \ \ \ \ \ 
\mathbb{E}^1_{S_i}(O_k) = \frac{\sum_{t=1}^{T} \left[I(Y_t = O_k) \times \gamma_{S_i}(t) \right]}{\sum_{t=1}^{T} \gamma_{S_i}(t)}
\end{align}\]</span></p>
<p><span class="math display">\[\begin{align}
\pi^1(S_i) = \gamma_{S_i}(1)
\end{align}\]</span></p>
<p>where:</p>
<p><span class="math display">\[\begin{align}
I(Y_t = O_k) = 1_{Y_t = O_k} = \begin{cases}
1 &amp; Y_t = O_k\\
0 &amp; otherwise
\end{cases}\ \ \ \ \leftarrow\ \ \ \text{(indicator function)} \label{eqn:eqnnumber330}
\end{align}\]</span></p>
<p><strong>Finally</strong>, from there, we iterate the <strong>EM steps</strong> until we get a final model (by convergence):</p>
<p><span class="math display">\[\begin{align}
\mathbb{M^0}\ \ \rightarrow\ \ \mathbb{M^1}\ \ \rightarrow\ \ \mathbb{M^2}\ \ \rightarrow \ \ ...\ \ \rightarrow\ \ \mathbb{M^*}
\end{align}\]</span></p>
<p>To illustrate, let us first randomly initialize a hidden markov model, namely <span class="math inline">\(\mathbb{M}^0\)</span>:</p>

<div class="sourceCode" id="cb896"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb896-1" data-line-number="1">S =<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;A&quot;</span>, <span class="st">&quot;B&quot;</span>, <span class="st">&quot;C&quot;</span>)          <span class="co"># list of states</span></a>
<a class="sourceLine" id="cb896-2" data-line-number="2">O =<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;P&quot;</span>, <span class="st">&quot;Q&quot;</span>, <span class="st">&quot;R&quot;</span>)          <span class="co"># list of observation symbols</span></a>
<a class="sourceLine" id="cb896-3" data-line-number="3">X.seq =<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;A&quot;</span>, <span class="st">&quot;C&quot;</span>, <span class="st">&quot;B&quot;</span>, <span class="st">&quot;A&quot;</span>) <span class="co"># hidden states</span></a>
<a class="sourceLine" id="cb896-4" data-line-number="4">Y.seq =<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;R&quot;</span>, <span class="st">&quot;P&quot;</span>, <span class="st">&quot;Q&quot;</span>, <span class="st">&quot;P&quot;</span>) <span class="co"># observations</span></a>
<a class="sourceLine" id="cb896-5" data-line-number="5">random.range &lt;-<span class="st"> </span><span class="cf">function</span>(ncols, seed, <span class="dt">skip=</span><span class="dv">0</span>) {</a>
<a class="sourceLine" id="cb896-6" data-line-number="6">  <span class="kw">set.seed</span>(seed)</a>
<a class="sourceLine" id="cb896-7" data-line-number="7">  x =<span class="st"> </span><span class="kw">runif</span>(ncols, <span class="dt">min=</span><span class="dv">0</span>, <span class="dt">max=</span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb896-8" data-line-number="8">  x =<span class="st"> </span><span class="kw">round</span>( x <span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(x), <span class="dv">2</span>)</a>
<a class="sourceLine" id="cb896-9" data-line-number="9">  x[ncols] =<span class="st"> </span><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">sum</span>(x[<span class="dv">1</span><span class="op">:</span>(ncols<span class="dv">-1</span>)])</a>
<a class="sourceLine" id="cb896-10" data-line-number="10">  <span class="cf">if</span> (skip <span class="op">!=</span><span class="st"> </span><span class="dv">0</span>) {  <span class="co"># mimic our HMM structure</span></a>
<a class="sourceLine" id="cb896-11" data-line-number="11">    <span class="cf">if</span> (skip <span class="op">==</span><span class="st"> </span><span class="dv">1</span>) {  x[ncols] =<span class="st"> </span>x[ncols] <span class="op">+</span><span class="st"> </span>x[skip] </a>
<a class="sourceLine" id="cb896-12" data-line-number="12">    } <span class="cf">else</span> {  x[skip<span class="dv">-1</span>] =<span class="st"> </span>x[skip<span class="dv">-1</span>] <span class="op">+</span><span class="st"> </span>x[skip] </a>
<a class="sourceLine" id="cb896-13" data-line-number="13">    }</a>
<a class="sourceLine" id="cb896-14" data-line-number="14">    x[skip] =<span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb896-15" data-line-number="15">  }</a>
<a class="sourceLine" id="cb896-16" data-line-number="16">  x</a>
<a class="sourceLine" id="cb896-17" data-line-number="17">}</a>
<a class="sourceLine" id="cb896-18" data-line-number="18">T0 =<span class="st"> </span><span class="kw">matrix</span>( <span class="co"># transition probabilities matrix</span></a>
<a class="sourceLine" id="cb896-19" data-line-number="19">      <span class="kw">c</span>(<span class="kw">random.range</span>(<span class="dv">3</span>, <span class="dt">seed=</span><span class="dv">12</span>, <span class="dt">skip=</span><span class="dv">1</span>), </a>
<a class="sourceLine" id="cb896-20" data-line-number="20">        <span class="kw">random.range</span>(<span class="dv">3</span>, <span class="dt">seed=</span><span class="dv">85</span>, <span class="dt">skip=</span><span class="dv">2</span>), </a>
<a class="sourceLine" id="cb896-21" data-line-number="21">        <span class="kw">random.range</span>(<span class="dv">3</span>, <span class="dt">seed=</span><span class="dv">75</span>, <span class="dt">skip=</span><span class="dv">3</span>)), <span class="dt">nrow=</span><span class="dv">3</span>, <span class="dt">ncol=</span><span class="dv">3</span>, <span class="dt">byrow=</span><span class="ot">TRUE</span></a>
<a class="sourceLine" id="cb896-22" data-line-number="22">)</a>
<a class="sourceLine" id="cb896-23" data-line-number="23"><span class="kw">colnames</span>(T0) =<span class="st"> </span>S</a>
<a class="sourceLine" id="cb896-24" data-line-number="24"><span class="kw">rownames</span>(T0) =<span class="st"> </span>S</a>
<a class="sourceLine" id="cb896-25" data-line-number="25">E0 =<span class="st"> </span><span class="kw">matrix</span>( <span class="co"># emission probabilities matrix</span></a>
<a class="sourceLine" id="cb896-26" data-line-number="26">      <span class="kw">c</span>(<span class="kw">random.range</span>(<span class="dv">3</span>, <span class="dt">seed=</span><span class="dv">45</span>,<span class="dt">skip=</span><span class="dv">0</span>), </a>
<a class="sourceLine" id="cb896-27" data-line-number="27">        <span class="kw">random.range</span>(<span class="dv">3</span>, <span class="dt">seed=</span><span class="dv">67</span>,<span class="dt">skip=</span><span class="dv">3</span>), </a>
<a class="sourceLine" id="cb896-28" data-line-number="28">        <span class="kw">random.range</span>(<span class="dv">3</span>, <span class="dt">seed=</span><span class="dv">41</span>,<span class="dt">skip=</span><span class="dv">3</span>)), <span class="dt">nrow=</span><span class="dv">3</span>, <span class="dt">ncol=</span><span class="dv">3</span>, <span class="dt">byrow=</span><span class="ot">TRUE</span></a>
<a class="sourceLine" id="cb896-29" data-line-number="29">)</a>
<a class="sourceLine" id="cb896-30" data-line-number="30"><span class="kw">colnames</span>(E0) =<span class="st"> </span>O</a>
<a class="sourceLine" id="cb896-31" data-line-number="31"><span class="kw">rownames</span>(E0) =<span class="st"> </span>S</a>
<a class="sourceLine" id="cb896-32" data-line-number="32"><span class="co"># Initial probabilities matrix</span></a>
<a class="sourceLine" id="cb896-33" data-line-number="33">I0 =<span class="st"> </span><span class="kw">random.range</span>(<span class="dv">3</span>, <span class="dt">seed=</span><span class="dv">382</span>); <span class="kw">names</span>(I0) =<span class="st"> </span>S</a>
<a class="sourceLine" id="cb896-34" data-line-number="34"><span class="co"># the hidden markov model</span></a>
<a class="sourceLine" id="cb896-35" data-line-number="35">(<span class="dt">M0 =</span> <span class="kw">list</span>(<span class="st">&quot;T&quot;</span> =<span class="st"> </span>T0, <span class="st">&quot;E&quot;</span> =<span class="st"> </span>E0, <span class="st">&quot;I&quot;</span> =<span class="st"> </span>I0, <span class="st">&quot;S&quot;</span> =<span class="st"> </span>S, <span class="st">&quot;O&quot;</span> =<span class="st"> </span>O))  </a></code></pre></div>
<pre><code>## $T
##      A    B    C
## A 0.00 0.45 0.55
## B 0.68 0.00 0.32
## C 0.23 0.77 0.00
## 
## $E
##      P    Q   R
## A 0.53 0.27 0.2
## B 0.59 0.41 0.0
## C 0.12 0.88 0.0
## 
## $I
##    A    B    C 
## 0.08 0.54 0.38 
## 
## $S
## [1] &quot;A&quot; &quot;B&quot; &quot;C&quot;
## 
## $O
## [1] &quot;P&quot; &quot;Q&quot; &quot;R&quot;</code></pre>

<p>Below is an example implementation of the <strong>Baum-Welch algorithm</strong> in R code:</p>

<div class="sourceCode" id="cb898"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb898-1" data-line-number="1">hmm.estimate_gamma &lt;-<span class="st"> </span><span class="cf">function</span>(alpha, beta) {</a>
<a class="sourceLine" id="cb898-2" data-line-number="2">  ( alpha <span class="op">*</span><span class="st"> </span>beta ) <span class="op">/</span><span class="st"> </span><span class="kw">colSums</span>(alpha <span class="op">*</span><span class="st"> </span>beta )</a>
<a class="sourceLine" id="cb898-3" data-line-number="3">}</a>
<a class="sourceLine" id="cb898-4" data-line-number="4">hmm.estimate_xi &lt;-<span class="st"> </span><span class="cf">function</span>(Y, alpha, beta, a, b) {</a>
<a class="sourceLine" id="cb898-5" data-line-number="5">  T =<span class="st"> </span><span class="kw">length</span>(Y); n =<span class="st"> </span><span class="kw">nrow</span>(a)</a>
<a class="sourceLine" id="cb898-6" data-line-number="6">  xi =<span class="st">  </span><span class="kw">array</span>(<span class="dv">0</span>, <span class="dt">dim =</span> <span class="kw">c</span>(n, n, T)) <span class="co"># 3-dimensional</span></a>
<a class="sourceLine" id="cb898-7" data-line-number="7">  <span class="cf">for</span> (t <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>(T<span class="dv">-1</span>)) {</a>
<a class="sourceLine" id="cb898-8" data-line-number="8">    sum.xi =<span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb898-9" data-line-number="9">    <span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n) {</a>
<a class="sourceLine" id="cb898-10" data-line-number="10">      <span class="cf">for</span> (l <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n) {</a>
<a class="sourceLine" id="cb898-11" data-line-number="11">        sum.xi  =<span class="st"> </span>sum.xi <span class="op">+</span><span class="st"> </span>alpha[k,t] <span class="op">*</span><span class="st"> </span>a[k,l] <span class="op">*</span><span class="st"> </span>beta[l,t<span class="op">+</span><span class="dv">1</span>] <span class="op">*</span></a>
<a class="sourceLine" id="cb898-12" data-line-number="12"><span class="st">          </span>b[l, Y[t<span class="op">+</span><span class="dv">1</span>]]</a>
<a class="sourceLine" id="cb898-13" data-line-number="13">      }</a>
<a class="sourceLine" id="cb898-14" data-line-number="14">    }</a>
<a class="sourceLine" id="cb898-15" data-line-number="15">    <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n) {</a>
<a class="sourceLine" id="cb898-16" data-line-number="16">      <span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n) {</a>
<a class="sourceLine" id="cb898-17" data-line-number="17">        xi [i, j, t]  =<span class="st"> </span>alpha[i,t] <span class="op">*</span><span class="st"> </span>a[i,j] <span class="op">*</span><span class="st"> </span>beta[j,t<span class="op">+</span><span class="dv">1</span>] <span class="op">*</span><span class="st"> </span></a>
<a class="sourceLine" id="cb898-18" data-line-number="18"><span class="st">          </span>b[j, Y[t<span class="op">+</span><span class="dv">1</span>]]</a>
<a class="sourceLine" id="cb898-19" data-line-number="19">        xi [i, j, t] =<span class="st"> </span>xi [i, j, t] <span class="op">/</span><span class="st"> </span>sum.xi</a>
<a class="sourceLine" id="cb898-20" data-line-number="20">      }</a>
<a class="sourceLine" id="cb898-21" data-line-number="21">    }</a>
<a class="sourceLine" id="cb898-22" data-line-number="22">  }</a>
<a class="sourceLine" id="cb898-23" data-line-number="23">  xi</a>
<a class="sourceLine" id="cb898-24" data-line-number="24">}</a>
<a class="sourceLine" id="cb898-25" data-line-number="25">hmm.estimate_T &lt;-<span class="st"> </span><span class="cf">function</span>(Y, S, gamma, xi) {</a>
<a class="sourceLine" id="cb898-26" data-line-number="26">  T =<span class="st"> </span><span class="kw">length</span>(Y); n =<span class="st"> </span><span class="kw">nrow</span>(gamma)</a>
<a class="sourceLine" id="cb898-27" data-line-number="27">  T1 =<span class="st"> </span><span class="kw">matrix</span>(<span class="dv">0</span>, <span class="dt">nrow=</span>n, <span class="dt">ncol=</span>n)</a>
<a class="sourceLine" id="cb898-28" data-line-number="28">  <span class="kw">colnames</span>(T1) =<span class="st"> </span>S;  <span class="kw">rownames</span>(T1) =<span class="st"> </span>S</a>
<a class="sourceLine" id="cb898-29" data-line-number="29">  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n) {</a>
<a class="sourceLine" id="cb898-30" data-line-number="30">    sum.gamma =<span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb898-31" data-line-number="31">    <span class="cf">for</span> (t <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>(T<span class="dv">-1</span>)) {</a>
<a class="sourceLine" id="cb898-32" data-line-number="32">        sum.gamma =<span class="st"> </span>sum.gamma <span class="op">+</span><span class="st"> </span>gamma[i,t]</a>
<a class="sourceLine" id="cb898-33" data-line-number="33">    }</a>
<a class="sourceLine" id="cb898-34" data-line-number="34">    <span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n) {</a>
<a class="sourceLine" id="cb898-35" data-line-number="35">      sum.xi =<span class="st"> </span><span class="dv">0</span>; </a>
<a class="sourceLine" id="cb898-36" data-line-number="36">      <span class="cf">for</span> (t <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>(T<span class="dv">-1</span>)) {</a>
<a class="sourceLine" id="cb898-37" data-line-number="37">        sum.xi =<span class="st"> </span>sum.xi <span class="op">+</span><span class="st"> </span>xi[i,j,t]</a>
<a class="sourceLine" id="cb898-38" data-line-number="38">      }</a>
<a class="sourceLine" id="cb898-39" data-line-number="39">      T1[i,j] =<span class="st"> </span>sum.xi <span class="op">/</span><span class="st"> </span>sum.gamma     </a>
<a class="sourceLine" id="cb898-40" data-line-number="40">    }</a>
<a class="sourceLine" id="cb898-41" data-line-number="41">  }</a>
<a class="sourceLine" id="cb898-42" data-line-number="42">  T1</a>
<a class="sourceLine" id="cb898-43" data-line-number="43">}</a>
<a class="sourceLine" id="cb898-44" data-line-number="44">hmm.estimate_E &lt;-<span class="st"> </span><span class="cf">function</span>(Y, S, O, gamma) {</a>
<a class="sourceLine" id="cb898-45" data-line-number="45">  T =<span class="st"> </span><span class="kw">length</span>(Y); n =<span class="st"> </span><span class="kw">nrow</span>(gamma); m =<span class="st"> </span><span class="kw">length</span>(O)</a>
<a class="sourceLine" id="cb898-46" data-line-number="46">  E1 =<span class="st"> </span><span class="kw">matrix</span>(<span class="dv">0</span>, <span class="dt">nrow=</span>n, <span class="dt">ncol=</span>m) </a>
<a class="sourceLine" id="cb898-47" data-line-number="47">  <span class="kw">colnames</span>(E1) =<span class="st"> </span>O;  <span class="kw">rownames</span>(E1) =<span class="st"> </span>S; </a>
<a class="sourceLine" id="cb898-48" data-line-number="48">  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n) {</a>
<a class="sourceLine" id="cb898-49" data-line-number="49">    sum.gamma.denom =<span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb898-50" data-line-number="50">    <span class="cf">for</span> (t <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>T) {</a>
<a class="sourceLine" id="cb898-51" data-line-number="51">      sum.gamma.denom =<span class="st"> </span>sum.gamma.denom <span class="op">+</span><span class="st"> </span>gamma[i,t]</a>
<a class="sourceLine" id="cb898-52" data-line-number="52">    }</a>
<a class="sourceLine" id="cb898-53" data-line-number="53">    <span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>m) {</a>
<a class="sourceLine" id="cb898-54" data-line-number="54">      sum.gamma.num =<span class="st"> </span><span class="dv">0</span>; </a>
<a class="sourceLine" id="cb898-55" data-line-number="55">      <span class="cf">for</span> (t <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>T) {</a>
<a class="sourceLine" id="cb898-56" data-line-number="56">        I =<span class="st"> </span>(Y[t] <span class="op">==</span><span class="st"> </span>O[k]) <span class="op">+</span><span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb898-57" data-line-number="57">        sum.gamma.num =<span class="st"> </span>sum.gamma.num <span class="op">+</span><span class="st"> </span>I <span class="op">*</span><span class="st"> </span>gamma[i,t]</a>
<a class="sourceLine" id="cb898-58" data-line-number="58">      }</a>
<a class="sourceLine" id="cb898-59" data-line-number="59">      E1[i,k] =<span class="st"> </span>sum.gamma.num <span class="op">/</span><span class="st"> </span>sum.gamma.denom     </a>
<a class="sourceLine" id="cb898-60" data-line-number="60">    }</a>
<a class="sourceLine" id="cb898-61" data-line-number="61">  }</a>
<a class="sourceLine" id="cb898-62" data-line-number="62">  E1</a>
<a class="sourceLine" id="cb898-63" data-line-number="63">}</a>
<a class="sourceLine" id="cb898-64" data-line-number="64">hmm.baum_welch &lt;-<span class="st"> </span><span class="cf">function</span>(Y, M, <span class="dt">n.iter =</span> <span class="dv">2</span>, <span class="dt">tol =</span> <span class="fl">1e-5</span>) {</a>
<a class="sourceLine" id="cb898-65" data-line-number="65">  <span class="co"># set variables</span></a>
<a class="sourceLine" id="cb898-66" data-line-number="66">  T =<span class="st"> </span><span class="kw">length</span>(Y); n =<span class="st"> </span><span class="kw">nrow</span>(M<span class="op">$</span>T)</a>
<a class="sourceLine" id="cb898-67" data-line-number="67">  S =<span class="st"> </span>M<span class="op">$</span>S; O =<span class="st"> </span>M<span class="op">$</span>O; </a>
<a class="sourceLine" id="cb898-68" data-line-number="68">  limit =<span class="st"> </span>n.iter; T.norm =<span class="st"> </span>E.norm =<span class="st"> </span>err =<span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb898-69" data-line-number="69">  sequence =<span class="st"> </span><span class="kw">matrix</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">4</span>)</a>
<a class="sourceLine" id="cb898-70" data-line-number="70">  <span class="cf">for</span> (h <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>limit) {</a>
<a class="sourceLine" id="cb898-71" data-line-number="71">    a =<span class="st"> </span>M<span class="op">$</span>T;  b =<span class="st"> </span>M<span class="op">$</span>E</a>
<a class="sourceLine" id="cb898-72" data-line-number="72">    <span class="co"># Elimination Step: generate transition probabilities</span></a>
<a class="sourceLine" id="cb898-73" data-line-number="73">    alpha =<span class="st"> </span><span class="kw">hmm.forward</span>(Y,M)<span class="op">$</span>alpha.matrix</a>
<a class="sourceLine" id="cb898-74" data-line-number="74">    beta  =<span class="st"> </span><span class="kw">hmm.backward</span>(Y,M)<span class="op">$</span>beta.matrix</a>
<a class="sourceLine" id="cb898-75" data-line-number="75">    gamma =<span class="st"> </span><span class="kw">hmm.estimate_gamma</span>(alpha, beta)</a>
<a class="sourceLine" id="cb898-76" data-line-number="76">    xi    =<span class="st"> </span><span class="kw">hmm.estimate_xi</span>(Y, alpha, beta, a, b)</a>
<a class="sourceLine" id="cb898-77" data-line-number="77">    <span class="co"># Maximization Step: estimate model</span></a>
<a class="sourceLine" id="cb898-78" data-line-number="78">    T1 =<span class="st"> </span><span class="kw">hmm.estimate_T</span>(Y, S, gamma, xi)</a>
<a class="sourceLine" id="cb898-79" data-line-number="79">    E1 =<span class="st"> </span><span class="kw">hmm.estimate_E</span>(Y, S, O, gamma)</a>
<a class="sourceLine" id="cb898-80" data-line-number="80">    I1 =<span class="st"> </span>gamma[,<span class="dv">1</span>]  <span class="co"># this seems fix for baumWelch() </span></a>
<a class="sourceLine" id="cb898-81" data-line-number="81">    <span class="co"># Update Model</span></a>
<a class="sourceLine" id="cb898-82" data-line-number="82">    M<span class="op">$</span>T =<span class="st"> </span>T1;  M<span class="op">$</span>E =<span class="st"> </span>E1; M<span class="op">$</span>I =<span class="st"> </span>I1</a>
<a class="sourceLine" id="cb898-83" data-line-number="83">    <span class="co"># Evaluate convergence </span></a>
<a class="sourceLine" id="cb898-84" data-line-number="84">    T.norm =<span class="st"> </span><span class="kw">norm</span>(T1); E.norm =<span class="st"> </span><span class="kw">norm</span>(E1)</a>
<a class="sourceLine" id="cb898-85" data-line-number="85">    err =<span class="st"> </span><span class="kw">abs</span>( <span class="kw">norm</span>(T1) <span class="op">-</span><span class="st"> </span><span class="kw">norm</span>(a))</a>
<a class="sourceLine" id="cb898-86" data-line-number="86">    sequence =<span class="st"> </span><span class="kw">rbind</span>(sequence, <span class="kw">c</span>(h, T.norm, E.norm,  err))</a>
<a class="sourceLine" id="cb898-87" data-line-number="87">    <span class="cf">if</span> ( err <span class="op">&lt;</span><span class="st"> </span>tol ) <span class="cf">break</span></a>
<a class="sourceLine" id="cb898-88" data-line-number="88">  }</a>
<a class="sourceLine" id="cb898-89" data-line-number="89">  <span class="kw">colnames</span>(sequence) =<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Iteration&quot;</span>, <span class="st">&quot;T.norm&quot;</span>, <span class="st">&quot;E.norm&quot;</span>, <span class="st">&quot;error&quot;</span>)</a>
<a class="sourceLine" id="cb898-90" data-line-number="90">  <span class="kw">list</span>(<span class="st">&quot;Iteration&quot;</span>=<span class="st"> </span>sequence, M)</a>
<a class="sourceLine" id="cb898-91" data-line-number="91">}</a>
<a class="sourceLine" id="cb898-92" data-line-number="92"><span class="kw">hmm.baum_welch</span>(Y.seq, M0, <span class="dt">n.iter=</span><span class="dv">5</span>, <span class="dt">tol=</span><span class="fl">1e-5</span>)</a></code></pre></div>
<pre><code>## $Iteration
##      Iteration T.norm E.norm     error
## [1,]         1  1.649  1.334 4.292e-01
## [2,]         2  1.947  1.090 2.976e-01
## [3,]         3  1.999  1.013 5.171e-02
## [4,]         4  2.000  1.000 1.484e-03
## [5,]         5  2.000  1.000 2.143e-06
## 
## [[2]]
## [[2]]$T
##           A B         C
## A 0.000e+00 1 2.124e-38
## B 3.351e-08 0 1.000e+00
## C 4.592e-12 1 0.000e+00
## 
## [[2]]$E
##           P         Q R
## A 4.592e-12 3.351e-08 1
## B 1.000e+00 3.065e-66 0
## C 2.124e-38 1.000e+00 0
## 
## [[2]]$I
## [1] 1 0 0
## 
## [[2]]$S
## [1] &quot;A&quot; &quot;B&quot; &quot;C&quot;
## 
## [[2]]$O
## [1] &quot;P&quot; &quot;Q&quot; &quot;R&quot;</code></pre>

<p>Let us validate by using <strong>baumWelch(.)</strong> function from a 3rd-party library called <strong>HMM</strong>:</p>

<div class="sourceCode" id="cb900"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb900-1" data-line-number="1"><span class="kw">library</span>(HMM)</a>
<a class="sourceLine" id="cb900-2" data-line-number="2">hmm =<span class="st"> </span><span class="kw">initHMM</span>(S, O, <span class="dt">startProbs =</span> M0<span class="op">$</span>I, </a>
<a class="sourceLine" id="cb900-3" data-line-number="3">          <span class="dt">transProbs =</span> M0<span class="op">$</span>T, <span class="dt">emissionProbs =</span> M0<span class="op">$</span>E)</a>
<a class="sourceLine" id="cb900-4" data-line-number="4"><span class="kw">baumWelch</span>(hmm, Y.seq, <span class="dt">maxIterations=</span><span class="dv">5</span>, <span class="dt">delta=</span><span class="fl">1e-5</span>) </a></code></pre></div>
<pre><code>## $hmm
## $hmm$States
## [1] &quot;A&quot; &quot;B&quot; &quot;C&quot;
## 
## $hmm$Symbols
## [1] &quot;P&quot; &quot;Q&quot; &quot;R&quot;
## 
## $hmm$startProbs
##    A    B    C 
## 0.08 0.54 0.38 
## 
## $hmm$transProbs
##     to
## from         A B         C
##    A 0.000e+00 1 2.124e-38
##    B 3.351e-08 0 1.000e+00
##    C 4.592e-12 1 0.000e+00
## 
## $hmm$emissionProbs
##       symbols
## states         P         Q R
##      A 4.592e-12 3.351e-08 1
##      B 1.000e+00 3.065e-66 0
##      C 2.124e-38 1.000e+00 0
## 
## 
## $difference
## [1] 1.5226767 0.8705965 0.3070583 0.0386797 0.0005191</code></pre>

<p>To be more effective, <strong>Baum-Welch</strong> requires more observed data (<span class="math inline">\(Y^{seq}\)</span>) to be able to learn and train a better model. Also, the algorithm is not necessarily aware of the structure of the hidden Markov model (let alone the graphical representation); nonetheless, it uses <strong>MLE</strong> for estimation. That said, it helps to estimate closer to the actual model for an expected convergence.</p>
<p>There are other efforts made to improve upon the <strong>Baum-Welch</strong> algorithm. We leave readers to investigate other variations, including the application of <strong>HMM</strong> in speech recognition, gesture recognition, natural language processing (e.g., pos-tagging), genome/DNA sequencing, time-series forecasting, etc.</p>
<p>For further reading, we encourage readers to investigate the application of HMM in Speech Recognition <span class="citation">(Rabiner L. R. <a href="bibliography.html#ref-ref1558l">1988</a>)</span>.</p>
</div>
<div id="dynamic-system-model" class="section level3 hasAnchor">
<h3><span class="header-section-number">8.1.5</span> Dynamic System Model<a href="bayesian2.html#dynamic-system-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In <strong>HMM</strong> section, recall how we use a model <span class="math inline">\(\mathbb{M}\)</span> consisting of a set of matrix-based parameters, namely <span class="math inline">\(\{\mathbb{T}, \mathbb{E}, \pi\}\)</span>. The transition probability matrix, namely <span class="math inline">\(\mathbb{T}\)</span>, contains an arbitrary <strong>fix (constant) probability</strong> of transitioning from one <strong>discrete state</strong> to another. The emission probability matrix, namely <span class="math inline">\(\mathbb{E}\)</span>, contains an arbitrary <strong>fix (constant) probability</strong> of emitting an observation (or measurement) state. Here, we have the following list of <strong>discrete states</strong> and <strong>discrete observation symbols</strong>.</p>
<p><span class="math display">\[
S \in \{\ A,\ B,\ C\ \}\ \ \ \ \ \ \ \ \ O \in \{\ P,\ Q,\ R\ \}
\]</span></p>
<p>In this section, we extend the concept of <strong>HMM</strong> by introducing <strong>Dynamic Systems</strong>, which may deal with moving targets, and therefore the states and measurements (or observations) are not arbitrary (not fixed) and are thus <strong>continuous</strong>. And so, being <strong>continuous</strong>, we deal with distributions - particularly <strong>Gaussian</strong> distributions. Here, we have the following <strong>continuous</strong> states.</p>
<p><span class="math display">\[
S\ \in\ \mathbb{R}\ \ \ \ \ \ \ \ \ \ O\ \in\ \mathbb{R}
\]</span></p>
<p>It is essential to switch context from a set of constant categorical states to a set of dynamic continuous states that follow <strong>Gaussian</strong> distribution. Also, observed data is not only constrained within a set of discrete categorical states but also within possibly continuous (moving) linear states.</p>
<p>we use two models:</p>
<ul>
<li><strong>process model</strong> is also called the action model or motion model.</li>
<li><strong>measurement model</strong> is also called the sensor model.</li>
</ul>
<p>In the context of <strong>Dynamic Systems</strong>, let us use a simple <strong>Feedback loop</strong> diagram (see Figure <a href="bayesian2.html#fig:dynamicsystem">8.17</a>).</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:dynamicsystem"></span>
<img src="feedbackloop.png" alt="Recursive Dynamic System Diagram" width="70%" />
<p class="caption">
Figure 8.17: Recursive Dynamic System Diagram
</p>
</div>

<p>In the diagram, we have a dynamic system that accepts an input and produces an output; but also, based on certain conditions, it can recursively loop back to update the system for better output.</p>
<p>Our focus on dynamic systems includes three tasks: <strong>Filtering, Smoothing, and Prediction</strong>. Especially for <strong>Filtering</strong>, we cover four techniques:</p>
<ul>
<li>Bayes Filter (Stochastic Filter)</li>
<li>Kalman Filter (Linear Filter)</li>
<li>Extended Kalman Filter (Non-Linear Filter by Local Linearization)</li>
<li>Unscented Kalman Filter (Non-Linear, non-Jacobian Filter)</li>
<li>Particle Filter (Non-parametric Filter, sampling required)</li>
</ul>
</div>
<div id="bayes-filter" class="section level3 hasAnchor">
<h3><span class="header-section-number">8.1.6</span> Bayes Filter <a href="bayesian2.html#bayes-filter" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We start the discussion of <strong>Bayes Filtering</strong> (Ho and Lee), also called <strong>Recursive Bayesian Estimation</strong> and <strong>Bayesian Learning</strong> (Lin and Yau), using <strong>Bayesian Network</strong> with the addition of a <strong>control</strong>. In this section and the following sections, we reference Wan E.A. et al. <span class="citation">(<a href="bibliography.html#ref-ref1093e">2000</a>)</span>, Fox D. et al. <span class="citation">(<a href="bibliography.html#ref-ref1084d">2003</a>)</span>, Urrea C. and Agramonte R. <span class="citation">(<a href="bibliography.html#ref-ref1102c">2021</a>)</span>,</p>
<p>Let us use Figure <a href="bayesian2.html#fig:bayesfilter">8.18</a> to explain <strong>Bayes Filter</strong> (borrowed from sample HMM graph and extended).</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:bayesfilter"></span>
<img src="bayesfilter.png" alt="Dynamic System Diagram" width="70%" />
<p class="caption">
Figure 8.18: Dynamic System Diagram
</p>
</div>

<p>The figure shows a simple general model which depicts a single state, namely <strong>X</strong>, of an object transitioning from time <strong>t-1</strong> to <strong>t</strong> and from time <strong>t</strong> to time <strong>t+1</strong>. It explains a rather fundamental part of a dynamic system. A good example is an <strong>autonomous robot</strong> that navigates a landscape guided by some control in the form of action inputs (Thrun, Burgard, Fox, Abbeel). In the figure, notice the introduction of <span class="math inline">\(\mathbf{U}\)</span> variable, which represents an input. Localization (mapping) and navigation are common problems that require location estimation, presented by <strong>X</strong> - the state - guided by some input <strong>U</strong>. In other words, we use the general notation below to approximate the probability of the state of a system denoted by <strong>X</strong>, conditioned on both an observation, namely <strong>Y</strong>, and possibly control, namely <strong>U</strong>:</p>
<p><span class="math display">\[
P(X_{0:T},M| Z_{1:T}, U_{1:T})
\]</span>
where:</p>
<ul>
<li><strong>Y</strong> is sensor measurement (the observation)</li>
<li><strong>U</strong> is action (the control - user input to control robot)</li>
<li><strong>X</strong> is state (the state of object)</li>
<li><strong>M</strong> is map (or landmarks or environment constraints)</li>
<li><strong>T</strong> is time</li>
</ul>
<p>In other complex cases, we may require to form a joint posterior estimate with <strong>M</strong>, which represents landmarks surrounding an object depending on the problem statement.</p>
<p><span class="math display">\[\begin{align}
P(X_t,M| Z_{1:t}, U_{1:t}) = \int_{x_0} ... \int_{x_{t-1}} p(x_{0:t},m| z_{1:t}, u_{1,t}) dx_{t-1} ... d_{x_0}
\end{align}\]</span></p>
<p>Observations, namely <strong>Y</strong>, are generated by sensors in the form of measurements. We use such measurements to estimate the posterior density of the state of the object. Our goal is to estimate whether an object is locally positioned at an exact place. Otherwise, we estimate if the object is positioned somewhere in (or around) the place (which calls for uncertainty - probabilistic) by estimating measurements (and, in addition, by predicting the next state). If uncertainty is extremely large (e.g., over 99.99999%), then we can ignore uncertainty.</p>
<p>In our simple <strong>toy robot example</strong>, however, the world or environment around a robot is dynamic and is therefore full of uncertainty. With no assumptions about the surrounding environment, or object itself, we can start with a uniform distribution (e.g., we do not know <strong>X</strong> - the state is hidden). Let us exclude the map of the environment for a moment:</p>
<p><span class="math display">\[
P(X_{0:T}| Z_{1:T}, U_{1:T})
\]</span></p>
<p>Here, we explore the idea that the location of an object is conditioned on a single sensor. In reality, a self-driving car requires multiple sensors to feed the dynamic system to generate a better state of the car from time <strong>t</strong> to time <strong>t+1</strong>.</p>
<p>Our goal is to predict a posterior distribution, which we term as <strong>Belief</strong>, denoted by <strong>Bel(.)</strong>. The following general equation drives our Belief for <strong>X</strong> at time <strong>t</strong>:</p>
<p><span class="math display">\[\begin{align}
{}&amp;\underbrace{Bel(X_t)}_\text{belief} = \underbrace{P(X_t|Y_{1:t}, U_{1:t})}_\text{posterior} \nonumber \\
&amp;= \eta P(y_t|x_t, y_{1:t-1}, u_{1:t})P(x_t|y_{1:t-1}, u_{1:t-1}, u_t)\\
&amp;= \eta P(y_t|x_t)P(x_t|y_{1:t-1},u_{1:t-1}, u_t) \ \text{(markov property)}\\
&amp;= \eta P(y_t|x_t) \int_{x_{t-1}} P(x_t|x_{t-1}, y_{1:t-1}, u_{1:t}) P(x_{t-1}|y_{1:t-1}, u_{1:t-1}, u_t) dx_{t-1} \ \text{(sum rule)}\\
&amp;= \eta P(y_t|x_t) \int_{x_{t-1}} P(x_t|x_{t-1}, u_{1:t}) P(x_{t-1}|y_{1:t-1},u_{1:t-1}) dx_{t-1} \  \text{(markov property}\\
&amp;= \eta P(y_t|x_t) \int_{x_{t-1}} P(x_t|x_{t-1}, u_{1:t}) Bel(X_{t-1}) dx_{t-1} \ \text{(recursive belief)}
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(\eta\)</span> is a normalizing state. Note that all possible probabilities of state <strong>X</strong> sum up to 1.</li>
</ul>
<p>We use the <strong>recursive bayesian</strong> equation above to illustrate the algorithm.</p>
<p><strong>First</strong>, we start the algorithm by constructing two models - recall <strong>transition probabilities</strong> model and <strong>emission probabilities</strong> model in <strong>HMM</strong>). Here, we use <strong>process</strong> model and <strong>measurement</strong> model. See Figure <a href="bayesian2.html#fig:bayesstates">8.19</a>.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:bayesstates"></span>
<img src="bayesstates.png" alt="Bayes Filter Model" width="100%" />
<p class="caption">
Figure 8.19: Bayes Filter Model
</p>
</div>

<ul>
<li><p><strong>Process (Transition) model</strong> - this model deals with state changes. For example, Figure <a href="bayesian2.html#fig:bayesstates">8.19</a> shows a three-state process matrix that defines the transition probability of one state to another state.</p></li>
<li><p><strong>Measurement (Emission) model</strong> - this model, also called <strong>Sensor model</strong>, deals with measurements (observed data).</p></li>
</ul>
<p><strong>Second</strong>, assume our problem statement includes the following sequence of binary inputs and observed measurements - the sequence of states is hidden:</p>
<p><span class="math display">\[
U = \{0_{t=1}, 1_{t=2},1_{t=3}... \}\ \ \ \ \ \ 
Y = \{Q_{t=1},Q_{t=2},R_{t=3},...\}
\]</span></p>
<p>Assume that the probabilities in the process and measurement models correspond to uncertain results (with noise already inclusive).</p>
<p><strong>Third</strong>, we perform a recursive iteration by alternately executing a <strong>prediction step</strong>, which calculates a <strong>prior</strong> and a <strong>correction step</strong>, which calculates a <strong>posterior</strong> in turn. The iteration becomes recursive from <strong>t</strong> to <strong>t+1</strong>. Here, the prior in the <strong>prediction step</strong> is needed to calculate the posterior in the <strong>correction step</strong>. Likewise, the posterior in the <strong>correction step</strong> is needed to calculate the prior in the <strong>prediction step</strong>.</p>
<p>The <strong>general algorithm</strong> for <strong>Discrete Bayes Filter</strong> is as follows:</p>
<p><strong>For all possible states</strong>, namely <span class="math inline">\(\mathbf{X_t}\)</span>, then do the following:</p>
<p>Â Â Â Â Â Â Â Â  <strong>Prediction Step</strong> (e.g.Â Action/Movement):</p>
<p><span class="math display">\[\begin{align}
\underbrace{\overline{Bel}(X_t)}_{\begin{array}{c}new\\prior\end{array}} 
=  \sum_{x_{t-1}} 
  \underbrace{ P (X_t|X_{t-1}, U_{t})}_{\begin{array}{c}motion\\model\end{array}} 
  \underbrace{ Bel(X_{t-1})}_{\begin{array}{c}previous\\posterior\end{array}} \label{eqn:eqnnumber331}
\end{align}\]</span></p>
<p>Â Â Â Â Â Â Â Â  where:</p>
<p><span class="math display">\[\begin{align}
Bel(X_{t-1}) = P(X_{t-1}|Y_{1:t-1})
\end{align}\]</span></p>
<p>Â Â Â Â Â Â Â Â  <strong>Correction (Update) Step</strong> (e.g.Â Sensor):</p>
<p><span class="math display">\[\begin{align}
\underbrace{Bel(X_t)}_{\begin{array}{c}new\\posterior\end{array}}  = \eta 
\underbrace{\overbrace{ P(y_t|x_t)}^{\begin{array}{c}measurement\\model \end{array}}}_{likelihood} \underbrace{\overline{Bel}(X_{t})}_{\begin{array}{c}current\\prior\end{array}} \label{eqn:eqnnumber332}
\end{align}\]</span></p>
<p>Â Â Â Â Â Â Â Â  where:</p>
<p><span class="math display">\[\begin{align}
\frac{1}{\eta} = P(Y_t|Y_{1:t-1}) = \int P(Y_t|X_t)\mathcal(X_t|Y_{1:t-1}) dx_t
\end{align}\]</span></p>
<p>We then obtain the final <span class="math inline">\(Bel(X_t)\)</span> upon reaching the tolerance level, ending the recursive iteration.</p>
<p>To illustrate, given the matrices in Figure <a href="bayesian2.html#fig:bayesstates">8.19</a>, let us perform some recursive iteration:</p>
<p>Starting at <strong>t=1</strong>, let us solve for a new prior in the <strong>prediction step</strong>. Then, using the new prior as the current prior, we solve for the posterior in the <strong>correction step</strong>:</p>
<p><strong>Prediction step</strong>:</p>
<p><span class="math display">\[\begin{align}
\overline{Bel}(x_1) = \sum P(x_1|x_0, u_1) Bel(x_0)
\end{align}\]</span></p>
<p>Based on the process model, <span class="math inline">\(P(x_1|x_0, u_1 = 0)\)</span> is read as the transition probability from <span class="math inline">\(x_0\)</span> to <span class="math inline">\(x_1\)</span>, given an input <span class="math inline">\(u_1 = 0\)</span>. For example:</p>
<p><span class="math display">\[\begin{align*}
P(x_1 = A|x_0 = A, u_1 = 0) = 1.00\\
P(x_1 = B|x_0 = A, u_1 = 0) = 0.00\\
P(x_1 = C|x_0 = A, u_1 = 0) = 0.00
\end{align*}\]</span></p>
<p>We derive the same for the other initial transitions.</p>
<p>The initial priors are:</p>
<p><span class="math display">\[
Bel(x_0 = A) = 0.28\ \ \ \ \ \ \ \ \ \ \ \
Bel(x_0 = B) = 0.12\ \ \ \ \ \ \ \ \ \ \ \
Bel(x_0 = C) = 0.60
\]</span></p>
<p>Therefore:</p>
<p><span class="math display">\[\begin{align}
\overline{Bel}(x_1 = A) {}&amp;= P(x_1 = A|x_0 = A, u_1 = 0) Bel(x_0 = A) \nonumber \\ 
&amp;+  P(x_1 = A|x_0 = B, u_1 = 0) Bel(x_0 = B) \nonumber \\
&amp;+  P(x_1 = A|x_0 = C, u_1 = 0) Bel(x_0 = C)  \\
&amp;= (1.00)(0.28) + (0.00)(0.12) + (0.00)(0.60) = 0.28 \nonumber \\
\overline{Bel}(x_1 = B) &amp;= (0.00)(0.28) + (1.00)(0.12) + (0.00)(0.60) =  0.12 \nonumber \\
\overline{Bel}(x_1 = C) &amp;= (0.00)(0.28) + (0.00)(0.12) + (1.00)(0.60) =  0.60 \nonumber 
\end{align}\]</span></p>
<p><strong>Correction (Update) step</strong>:</p>
<p><span class="math display">\[\begin{align}
Bel(x_1 ) = \eta P(y_1|x_1) \overline{Bel}(x_1 )
\end{align}\]</span></p>
<p>Based on the <strong>measurement model</strong>, <span class="math inline">\(P(y_1|x_1)\)</span> is read as likelihood of <span class="math inline">\(y_1\)</span> given <span class="math inline">\(x_1\)</span>.</p>

<p><span class="math display">\[\begin{align*}
P(y_1 = P|x_1 = A) {}&amp;= 0.90\ \ \ \ \ \ 
P(y_1 = Q|x_1 = A) = 0.07\ \ \ \ \ \ 
P(y_1 = R|x_1 = A) = 0.03\\
P(y_1 = P|x_1 = B) &amp;= 0.09\ \ \ \ \ \ 
P(y_1 = Q|x_1 = B) = 0.80\ \ \ \ \ \ 
P(y_1 = R|x_1 = B) = 0.11\\
P(y_1 = P|x_1 = C) &amp;= 0.07\ \ \ \ \ \ 
P(y_1 = Q|x_1 = C) = 0.08\ \ \ \ \ \ 
P(y_1 = R|x_1 = C) = 0.85\\
\end{align*}\]</span>
</p>
<p>Here, we solve for <span class="math inline">\(\eta\)</span> first (using observation at t=1, e.g. <span class="math inline">\(y_1\)</span> = Q).</p>
<p><span class="math display">\[\begin{align}
Bel(x_1 = A) {}&amp;= \eta P(y_1 = Q|x_1 = A) \overline{Bel}(x_1 = A) \\
&amp;=  \eta (0.07)(0.28) = \eta (0.0196) \nonumber \\
Bel(x_1 = B) &amp;= \eta P(y_1 = Q|x_1 = B) \overline{Bel}(x_1 = B) \\
&amp;=  \eta (0.80)(0.12) = \eta (0.096) \nonumber \\
Bel(x_1 = C) &amp;= \eta P(y_1 = Q|x_1 = C) \overline{Bel}(x_1 = C) \\
&amp;=  \eta (0.08)(0.60) = \eta (0.048) \nonumber 
\end{align}\]</span></p>
<p><span class="math display">\[\begin{align}
Bel(x_1 = A) + Bel(x_1 = B) + Bel(x_1 = C) {}&amp;= 1 \\
\eta (0.0196)  + \eta  (0.096) + \eta (0.048)  &amp;= 1 \nonumber  \\
\eta &amp;= 6.112469 \nonumber
\end{align}\]</span></p>
<p>Therefore, our new set of posteriors at <strong>t=1</strong> is:</p>
<p><span class="math display">\[
Bel(x_1 = A) =  0.1198044
\ \ \ \ \ \ \ \ \ 
Bel(x_1 = B) =  0.586797
\ \ \ \ \ \ \ \ \ 
Bel(x_1 = C) = 0.2933985
\]</span>
Here, it suggests that our hidden state is closer to <strong>B</strong>.</p>
<p>At <strong>t=2</strong>, we use the above <strong>beliefs</strong> as the posterior for the next iteration. This time, our input is <span class="math inline">\(\omega_2\)</span>; meaning, we are now going to use process model 2 so that we have the following:</p>
<p><strong>Prediction step</strong></p>
<p>Using process model 2, we have the following examples for <span class="math inline">\(P(x2|x_1 = A, u_2 = 1)\)</span>:</p>
<p><span class="math display">\[\begin{align*}
P(x_2 = A|x_1 = A, u_2 = 1) = 0.20\\
P(x_2 = B|x_1 = A, u_2 = 1) = 0.10\\
P(x_2 = C|x_1 = A, u_2 = 1) = 0.70
\end{align*}\]</span></p>
<p>We derive the same for the other initial transitions.</p>
<p>Our new prior becomes then:</p>

<p><span class="math display">\[\begin{align*}
\overline{Bel}(x_2 = A) {}&amp;= (0.20)(0.1198044) + (0.50)(0.586797) + (0.25)(0.2933985) = 0.390709\\
\overline{Bel}(x_2 = B) &amp;= (0.10)(0.1198044) + (0.10)(0.586797) + (0.65)(0.2933985) = 0.2613692\\
\overline{Bel}(x_2 = C) &amp;= (0.70)(0.1198044) + (0.40)(0.586797) + (0.10)(0.2933985) = 0.3479217\\
\end{align*}\]</span>
</p>
<p><strong>Correction (Update) step</strong>:</p>
<p>Here, we solve for <span class="math inline">\(\eta\)</span> using observations at t=2, e.g. <span class="math inline">\(y_2 = Q\)</span>.</p>
<p><span class="math display">\[\begin{align*}
Bel(x_2 = A) {}&amp;= \eta(0.07)(0.390709) = \eta (0.02734963)\\
Bel(x_2 = B) &amp;= \eta(0.80)(0.2613692) = \eta (0.2090954)\\
Bel(x_2 = C) &amp;= \eta(0.08)(0.3479217) = \eta (0.02783374)
\end{align*}\]</span></p>
<p>Our new <span class="math inline">\(\eta\)</span> is then:</p>
<p><span class="math display">\[
\eta = 3.783883
\]</span></p>
<p>Therefore, our new set of posteriors is now:</p>

<p><span class="math display">\[
Bel(x_2 = A) =  0.1034878
\ \ \ \ \ \ \ \ \ \ 
Bel(x_2 = B) =  0.7911925
\ \ \ \ \ \ \ \ \ \ 
Bel(x_2 = C) = 0.1053196
\]</span>
</p>
<p>Here, our hidden state <strong>X</strong> looks more like <strong>B</strong>.</p>
<p>We can continue to iterate further to see if X gets 100% closer to being <strong>B</strong>.</p>
<p>We leave readers to review some applications of <strong>Bayes Filter</strong> in surveillance, mine exploration, terrain mapping, and reef monitoring. A similar concept of localization applies to consumer wares such as vacuum cleaners, drones, and self-driving cars.</p>
<p>Additionally, we leave readers to investigate <strong>sensor fusion</strong>, <strong>sensor aliasing</strong>, <strong>SLAM (simultaneous localization and mapping)</strong>, and <strong>DATMO (detection and tracking of moving objects)</strong>.</p>
</div>
<div id="kalman-filter" class="section level3 hasAnchor">
<h3><span class="header-section-number">8.1.7</span> Kalman Filter <a href="bayesian2.html#kalman-filter" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Kalman Filter</strong>, also called <strong>Linear Quadratic Estimator (LQE)</strong>, extends upon <strong>HMM</strong> by dealing with <strong>continuous states</strong>. It complements the concept of <strong>Bayes Filter</strong>.</p>
<p>The basic idea of <strong>Kalman Filter</strong> is to estimate a true measurement. Here, we deal with an <strong>Estimated measurement</strong> denoted as <strong>X</strong> and a <strong>True measurement</strong> denoted as <strong>Y</strong>. It may help to assume that estimated measurements come with errors and thus may best be denoted as <span class="math inline">\(\mathbf{X^e}\)</span> for emphasis. Similarly, we often deal with <strong>observed measurements</strong> which also come with errors instead of the <strong>true measurements</strong> and thus it may also help to denote that as <span class="math inline">\(\mathbf{Y^e}\)</span>.</p>
<p><span class="math display">\[
\begin{array}{llllll}
X&amp;\leftarrow&amp;\text{Estimation} &amp;
Y&amp;\leftarrow&amp;\text{True Measurement}\\
X^e&amp;\leftarrow&amp;\text{Estimation with Error} &amp;
Y^e&amp;\leftarrow&amp;\text{(Observed) Measurement with Error}\\
E^x&amp;\leftarrow&amp;\text{Error in Estimation} &amp;
E^y&amp;\leftarrow&amp;\text{Error in Observed Measurement} 
\end{array}
\]</span></p>
<p>The <strong>Kalman Filter</strong> algorithm starts with an initial estimate of the true measurement. Then, we perform iteration such that the estimate gets closer to the true measurement. Because we may not necessarily know the true measurement, we rely on the available observed measurement. The iteration goes through three calculations.</p>
<p><span class="math display">\[\begin{align}
K  = \frac{E^x}{E^x + E^y}
\ \ \ \ &amp;\rightarrow \ \ \ \ \
X^e_t = X^e_{t-1} + K(Y^e_t + X^e_{t-1}) \\
\ \ \ \ &amp;\rightarrow \ \ \ \ \
E^x_t = \frac{(E^y)(E^x_{t-1})}{(E^y)(E^x_{t-1})} = (1 - K)(E^x_{t-1})
\end{align}\]</span></p>
<p>where <strong>K</strong> is the <strong>Kalman Gain</strong>.</p>
<p>To illustrate a simple example, suppose we are estimating the weight of an object using a weighing scale. The true weight is 21.40 kilograms (assume this is not known - but we use it as our mean and add error/noise, e.g., 0.5 variance, to simulate an observed measurement ). What is known to us, however, are the following (in kilograms):</p>
<p><span class="math display">\[
\begin{array}{ll}
X^e = 22.5  &amp; Y^e \sim N(21.40, 0.5) \\
E^x = 2 &amp; E^y = 2.5
\end{array}
\]</span></p>
<p>Let us implement the equations into R code:</p>

<div class="sourceCode" id="cb902"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb902-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">2000</span>)</a>
<a class="sourceLine" id="cb902-2" data-line-number="2">kalman_gain &lt;-<span class="st"> </span><span class="cf">function</span>(E.x, E.y) { E.x <span class="op">/</span><span class="st"> </span>( E.x <span class="op">+</span><span class="st"> </span>E.y) }</a>
<a class="sourceLine" id="cb902-3" data-line-number="3">estimate    &lt;-<span class="st"> </span><span class="cf">function</span>(X.e, Y.e, K) { X.e <span class="op">+</span><span class="st"> </span>K <span class="op">*</span><span class="st"> </span>(Y.e <span class="op">-</span><span class="st"> </span>X.e) }</a>
<a class="sourceLine" id="cb902-4" data-line-number="4">error       &lt;-<span class="st"> </span><span class="cf">function</span>(E.x, K) { (<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>K ) <span class="op">*</span><span class="st"> </span>E.x }</a>
<a class="sourceLine" id="cb902-5" data-line-number="5">n =<span class="st"> </span><span class="dv">50</span></a>
<a class="sourceLine" id="cb902-6" data-line-number="6">x =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">1</span>, <span class="dv">10</span>, <span class="dt">length.out=</span>n)</a>
<a class="sourceLine" id="cb902-7" data-line-number="7">y =<span class="st"> </span><span class="fl">21.40</span></a>
<a class="sourceLine" id="cb902-8" data-line-number="8">X.e =<span class="st"> </span><span class="fl">100.5</span>;    E.x =<span class="st"> </span><span class="dv">90</span>;  E.y =<span class="st"> </span><span class="fl">2.5</span></a>
<a class="sourceLine" id="cb902-9" data-line-number="9">Y.e =<span class="st"> </span><span class="kw">rnorm</span>(n, y, <span class="fl">0.5</span>)  </a>
<a class="sourceLine" id="cb902-10" data-line-number="10">outcome =<span class="st"> </span><span class="kw">matrix</span>(<span class="dv">0</span>, n, <span class="dv">4</span>)</a>
<a class="sourceLine" id="cb902-11" data-line-number="11"><span class="cf">for</span> (t <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n) {</a>
<a class="sourceLine" id="cb902-12" data-line-number="12">   K =<span class="st"> </span><span class="kw">kalman_gain</span>(E.x, E.y)</a>
<a class="sourceLine" id="cb902-13" data-line-number="13">   X.e =<span class="st"> </span><span class="kw">estimate</span>(X.e, Y.e[t], K)</a>
<a class="sourceLine" id="cb902-14" data-line-number="14">   E.x =<span class="st"> </span><span class="kw">error</span>(E.x, K)</a>
<a class="sourceLine" id="cb902-15" data-line-number="15">   outcome[t,] =<span class="st"> </span><span class="kw">round</span>(<span class="kw">c</span>(Y.e[t], X.e, E.x, K ),<span class="dv">2</span>)</a>
<a class="sourceLine" id="cb902-16" data-line-number="16">}</a>
<a class="sourceLine" id="cb902-17" data-line-number="17"><span class="kw">colnames</span>(outcome) =<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Measurement&quot;</span>, <span class="st">&quot;Estimate&quot;</span>, </a>
<a class="sourceLine" id="cb902-18" data-line-number="18">                      <span class="st">&quot;Error&quot;</span>, <span class="st">&quot;Kalman Gain&quot;</span>)</a>
<a class="sourceLine" id="cb902-19" data-line-number="19"><span class="kw">tail</span>(outcome)</a></code></pre></div>
<pre><code>##       Measurement Estimate Error Kalman Gain
## [45,]       22.17    21.46  0.06        0.02
## [46,]       21.83    21.46  0.05        0.02
## [47,]       21.88    21.47  0.05        0.02
## [48,]       21.14    21.47  0.05        0.02
## [49,]       21.71    21.47  0.05        0.02
## [50,]       21.68    21.48  0.05        0.02</code></pre>

<p>Our final estimate is at 21.48 kilograms at 10 iterations. See Figure <a href="bayesian2.html#fig:kalmanfilter1">8.20</a>.</p>

<div class="sourceCode" id="cb904"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb904-1" data-line-number="1"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">ylim=</span><span class="kw">range</span>(<span class="dv">20</span>, <span class="dv">23</span>), <span class="dt">xlim=</span><span class="kw">range</span>(<span class="dv">1</span>,<span class="dv">10</span>), </a>
<a class="sourceLine" id="cb904-2" data-line-number="2">     <span class="dt">xlab=</span><span class="st">&quot;T&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;Weight (Lbs)&quot;</span>,</a>
<a class="sourceLine" id="cb904-3" data-line-number="3">     <span class="dt">main=</span><span class="st">&quot;Kalman Filter model&quot;</span>,  <span class="dt">frame=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb904-4" data-line-number="4"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb904-5" data-line-number="5"><span class="kw">points</span>(x, Y.e, <span class="dt">col=</span><span class="kw">c</span>(<span class="st">&quot;black&quot;</span>), <span class="dt">pch=</span><span class="dv">16</span>, <span class="dt">cex=</span><span class="fl">0.80</span>)</a>
<a class="sourceLine" id="cb904-6" data-line-number="6"><span class="kw">abline</span>(<span class="dt">h=</span>y, <span class="dt">col=</span><span class="kw">c</span>(<span class="st">&quot;darksalmon&quot;</span>), <span class="dt">lwd=</span><span class="dv">3</span>)</a>
<a class="sourceLine" id="cb904-7" data-line-number="7"><span class="kw">lines</span>(x, outcome[,<span class="dv">2</span>], <span class="dt">col=</span><span class="kw">c</span>(<span class="st">&quot;navyblue&quot;</span>), <span class="dt">lwd=</span><span class="dv">3</span>)</a>
<a class="sourceLine" id="cb904-8" data-line-number="8"><span class="kw">legend</span>(<span class="st">&quot;bottomright&quot;</span>, <span class="dt">inset=</span>.<span class="dv">02</span>, </a>
<a class="sourceLine" id="cb904-9" data-line-number="9">   <span class="kw">c</span>(<span class="st">&quot;True Measurement&quot;</span>,<span class="st">&quot;Estimate (KF)&quot;</span>, <span class="st">&quot;Observation&quot;</span>), </a>
<a class="sourceLine" id="cb904-10" data-line-number="10">   <span class="dt">col=</span><span class="kw">c</span>(<span class="st">&quot;darksalmon&quot;</span>, <span class="st">&quot;navyblue&quot;</span>, <span class="st">&quot;black&quot;</span>), </a>
<a class="sourceLine" id="cb904-11" data-line-number="11">   <span class="dt">horiz=</span><span class="ot">FALSE</span>, <span class="dt">cex=</span><span class="fl">0.8</span>, <span class="dt">lty=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>, <span class="dv">0</span>), <span class="dt">lwd=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>), <span class="dt">pch=</span><span class="kw">c</span>(<span class="op">-</span><span class="dv">1</span>,<span class="op">-</span><span class="dv">1</span>, <span class="dv">16</span>))</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:kalmanfilter1"></span>
<img src="DS_files/figure-html/kalmanfilter1-1.png" alt="Kalman Filter" width="70%" />
<p class="caption">
Figure 8.20: Kalman Filter
</p>
</div>

<p>For a multi-dimensional case, let us reference Figure <a href="bayesian2.html#fig:kalmanfilter">8.21</a> (a modified version of the diagram from Farhad Merchant et al. <span class="citation">(<a href="bibliography.html#ref-ref298f">2018</a>)</span>, Ghosh A <span class="citation">(<a href="bibliography.html#ref-ref291a">2019</a>)</span>, and shown in Michel van Biezen <span class="citation">(<a href="bibliography.html#ref-ref308m">2015</a>)</span>. The notation used in the discussion references M. van Biezen <span class="citation">(<a href="bibliography.html#ref-ref308m">2015</a>)</span>.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:kalmanfilter"></span>
<img src="kalmanfilter.png" alt="Kalman Filter" width="100%" />
<p class="caption">
Figure 8.21: Kalman Filter
</p>
</div>

<p>Similar to <strong>Bayesian Filter</strong>, the <strong>KF</strong> algorithm uses a <strong>prediction step</strong> and an <strong>update step</strong> with the corresponding equations as shown in Figure <a href="bayesian2.html#fig:kalmanfilter">8.21</a>.</p>
<p>For a <strong>dynamic system</strong>, we can relate the calculation of <strong>estimated prediction of measurement</strong>, namely <span class="math inline">\(X_t\)</span>, with the popular kinematics equation, e.g., newtonâs law of motion, as demonstrated by M. van Biezen <span class="citation">(<a href="bibliography.html#ref-ref308m">2015</a>)</span> for a falling and moving object as an example. The newton equation is as follows:</p>
<p><span class="math display">\[\begin{align}
d =  vt + a\frac{1}{2}t^2
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li>v = velocity of the moving object</li>
<li>a = accelaration of the moving object</li>
<li>d = displacement (new location)</li>
<li>t = time</li>
</ul>
<p>In general, <strong>Kalman filter</strong> uses the following <strong>dynamic system</strong> of equations.</p>
<p>For <strong>State Prediction</strong>, we have the following general linear system of equations (each term maps to the corresponding term in the kinematics equation):</p>
<p><span class="math display">\[\begin{align}
\underbrace{X_t}_\text{d} = 
\underbrace{AX_{t-1}}_\text{vt} + 
\underbrace{B_t U_t}_{a\frac{1}{2}t^2} + w_{t},\ \ \ \ \ \ \ w_{t} \sim \mathcal{N}(0, W_{t})
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(\mathbf{X_t}\)</span> is <strong>prediction state</strong>,</li>
<li><span class="math inline">\(\mathbf{X_{t-1}}\)</span> is <strong>prior state</strong>,</li>
<li><span class="math inline">\(\mathbf{U_{t}}\)</span> is <strong>control state</strong>,</li>
<li><span class="math inline">\(\mathbf{w_{t}}\)</span> is <strong>system perturbation</strong> (gaussian noise),</li>
<li><span class="math inline">\(\mathbf{W_{t}}\)</span> is <strong>stochastic diffusion</strong> (covariance),</li>
<li><span class="math inline">\(\mathbf{A}\)</span> and <span class="math inline">\(\mathbf{B_t}\)</span> depend upon the application or system used (e.g., gravity for falling object and acceleration for moving object). <strong>A</strong> is a state-transition matrix and <strong>B</strong> is a control-transition matrix similar to the <strong>Bayes Filter</strong> process models previously discussed.</li>
</ul>
<p>The state <strong>X</strong> can represent a vector that includes position (p), velocity (v), acceleration (a):</p>
<p><span class="math display">\[
X_t = \left[ \begin{array}{c} x_1^{(p)} \\ x_1^{(v)}  \\ x_1^{(a)}  \end{array} \right]
\]</span></p>
<p>For cases in which <span class="math inline">\(\mathbf{x_1}\)</span> and <span class="math inline">\(\mathbf{x_2}\)</span> are vectors that include only position (p) and velocity (v), we show the following:</p>
<p><span class="math display">\[
X_t = \left[ \begin{array}{c} x_1^{(p)} \\ x_1^{(v)}\end{array} \right]
\ \ \ \ \ 
A_{2x2} =  \left[ \begin{array}{cc} 1 &amp; \Delta t\\ 0 &amp; 1 \end{array} \right]_{2x2}
\ \ \ \ \ \ \ \ or \ \ \ \ \  
X_t = \left[ \begin{array}{c} x_1^{(p)} \\ x_2^{(p)} \\ x_1^{(v)} \\ x_2^{(v)} \end{array} \right]
\]</span></p>
<p><span class="math display">\[
A_{4x4} =  \left[ \begin{array}{cccc} 
    1 &amp; 0 &amp; \Delta t &amp; 0 \\ 
    0 &amp; 1 &amp; 0 &amp; \Delta t \\
    0 &amp; 0 &amp; 1 &amp; 0\\
    0 &amp; 0 &amp; 0 &amp; 1
    \end{array} \right]_{4x4}
\]</span></p>
<p>Let us consider the 1D case like so:</p>
<p><span class="math display">\[
X_t = 
\underbrace{\left[\begin{array}{cc}1 &amp; \Delta t\\ 0 &amp; 1 \end{array}\right]}_\text{A}
X_{t-1} + 
\underbrace{\left[\begin{array}{c } \frac{1}{2}\Delta t^2\\ \Delta t \end{array}\right]}_\text{B}
U_{t} + w_t
\ \ \ \ \ where:\ U_t = \begin{cases}g = 9.8 \frac{m}{s^2} \\ a = accel.\end{cases}
\]</span></p>
<p>For <strong>Measurement (Sensor) Observation</strong>, we have the following general linear system of equations:</p>
<p><span class="math display">\[\begin{align}
Y_t = CX_t + v_t,\ \ \ \ \ \ \ v_t \sim \mathcal{N}(0, V_t) 
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(\mathbf{Y_t}\)</span> is <strong>sensor (measurement) state</strong>,</li>
<li><span class="math inline">\(\mathbf{X_t}\)</span> is <strong>prediction state</strong>,</li>
<li><span class="math inline">\(\mathbf{v_t}\)</span> is <strong>measurement perturbation</strong> (gaussian noise),</li>
<li><span class="math inline">\(\mathbf{V_t}\)</span> is <strong>stochastic diffusion</strong> (covariance),</li>
<li><span class="math inline">\(\mathbf{C}\)</span> is a measurement transformation matrix that maps the state <span class="math inline">\(X_t\)</span> to a corresponding observed measurement <span class="math inline">\(Y_t\)</span>.</li>
</ul>
<p>So then, we have the following:</p>
<p><span class="math display">\[
Y_t = 
\underbrace{\left[\begin{array}{cc}1 &amp; 0 \end{array}\right]}_\text{C}
X_{t} + v_t
\]</span></p>
<p>For <strong>Error in Estimate</strong>, we have:</p>
<p><span class="math display">\[\begin{align}
P_t = AP_{t-1}A^T + Q_t
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li>A = Predicted State Transformation Matrix</li>
<li><span class="math inline">\(P_t\)</span> = Process Covariance Matrix (Error in Predicted State Estimate)</li>
<li>Q = Process Noise Covariance Matrix</li>
</ul>
<p>Assume we have obtained the following initial errors:</p>
<p><span class="math display">\[
\underbrace{E^{P} = 16\ m\ \ \ \ \ \ \ E^{U} = 2.5\ m/s}_\text{Error in Estimate} 
\]</span></p>
<p><span class="math display">\[where: \ 16 \times 16 = 256,\ \ \ \ 16 \times 2.5 = 40,\ \ \ \ 2.5 \times 2.5 = 6.25\]</span></p>
<p><span class="math display">\[
\underbrace{E^{X} = 15\ m\ \ \ \ \ \ \ E^{V}= 3.0\ m/s}_\text{Error in Measurement}
\]</span></p>
<p><span class="math display">\[where: \ 15 \times 15 = 225,\ \ \ \ 15 \times 3.0 = 45,\ \ \ \ 3.0 \times 3.0 = 9.00\]</span></p>
<p>So then, we have the following:</p>
<p><span class="math display">\[
P_t = \left[\begin{array}{rr}1 &amp; \Delta t\\ 0 &amp; 1 \end{array}\right]
\left[\begin{array}{rr}256 &amp; 0\\ 0 &amp; 6.25 \end{array}\right]
\left[\begin{array}{rr}1 &amp; 0 \\ \Delta t &amp; 1 \end{array}\right] + 0
= 
\left[\begin{array}{rr}262.25 &amp; 0\\ 0 &amp; 6.25 \end{array}\right]
\]</span></p>
<p><span class="math display">\[
where: \Delta t = 1\ and\ Q_t = 0
\]</span></p>
<p>For <strong>Kalman Gain</strong>, we have:</p>
<p><span class="math display">\[\begin{align}
K = \frac{P_t H}{HP_t H^T + R}
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li>H = Identity matrix</li>
<li>P = Process Covariance Matrix</li>
<li>R = Sensor Noise Covariance Matrix</li>
</ul>
<p>So then, we have the following:</p>
<p><span class="math display">\[
K = 
\frac{
\left[\begin{array}{rr}262.25 &amp; 0\\ 0 &amp; 6.25 \end{array}\right]
\left[\begin{array}{rr} 1 &amp; 0 \\ 0 &amp; 1 \end{array} \right]
}{
\left[\begin{array}{rr} 1 &amp; 0 \\ 0 &amp; 1 \end{array} \right]
\left[\begin{array}{rr}262.25 &amp; 0\\ 0 &amp; 6.25 \end{array}\right]
\left[\begin{array}{rr} 1 &amp; 0 \\ 0 &amp; 1 \end{array} \right] +
\left[\begin{array}{rr} 225 &amp; 0 \\ 0 &amp; 9 \end{array} \right]
} =
\left[\begin{array}{rr} 487.25 &amp; 0 \\ 0 &amp; 15.25 \end{array} \right]
\]</span></p>
<p>For <strong>State Error Update</strong>, we have:</p>
<p><span class="math display">\[\begin{align}
P_t^* = (I - KH)P_t
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(P^*_t\)</span> = Process Covariance Matrix (Update in Error in Estimate)</li>
<li>I = Identity matrix</li>
<li>K = Kalman Gain</li>
<li>H = Identity matrix</li>
</ul>
<p>So then, we have the following:</p>
<p><span class="math display">\[
P_t^* = \left(
\left[\begin{array}{cc} 1 &amp; 0 \\ 0 &amp; 1 \end{array} \right]
- 
\left[\begin{array}{rr} 487.25 &amp; 0 \\ 0 &amp; 15.25 \end{array} \right]
\left[\begin{array}{cc} 1 &amp; 0 \\ 0 &amp; 1 \end{array} \right]
\right)
\left[\begin{array}{rr}262.25 &amp; 0\\ 0 &amp; 6.25 \end{array}\right]
\]</span></p>
<p>For <strong>State Estimate Update</strong>, we have:</p>
<p><span class="math display">\[\begin{align}
X_t^* = X_t + K(Y_t - HX_t)
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(\mathbf{X_t^*}\)</span> is <strong>Update in State estimate</strong>,</li>
<li><span class="math inline">\(\mathbf{Y_t}\)</span> is <strong>observed measurement</strong>,</li>
<li><span class="math inline">\(\mathbf{K}\)</span> is <strong>Kalman Gain</strong>,</li>
<li><span class="math inline">\(\mathbf{H}\)</span> is <strong>Identity Matrix (transformation)</strong>.</li>
</ul>
<p>The <strong>Kalman Gain</strong> is a <strong>weight</strong> parameter to adjust the <strong>measurement error</strong>, namely <span class="math inline">\((Y_t - HX_t)\)</span>, thereby getting a state estimate closer to the actual state. The equation in <strong>Kalman Gain</strong> uses an <strong>H</strong> matrix which can be treated as an <strong>identity matrix</strong>.</p>
<p>We preserve the updates for the estimate, including error measurements, for each iteration until all observations are processed.</p>
<p>To illustrate, let us generate our models (movement and measurement models) using <strong>random walk</strong>. Here, we do not assume any control input; thus, the use of the <strong>B</strong> and <strong>U</strong> variables are ignored.</p>

<div class="sourceCode" id="cb905"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb905-1" data-line-number="1">n =<span class="st"> </span><span class="dv">200</span></a>
<a class="sourceLine" id="cb905-2" data-line-number="2">seed =<span class="st"> </span><span class="dv">2020</span>; <span class="kw">set.seed</span>(seed)</a>
<a class="sourceLine" id="cb905-3" data-line-number="3">x &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, n, <span class="dt">length.out =</span> n) </a>
<a class="sourceLine" id="cb905-4" data-line-number="4">y &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">2</span>, <span class="dv">6</span>, <span class="dt">length.out =</span> n)</a>
<a class="sourceLine" id="cb905-5" data-line-number="5">Y.e &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, n, <span class="dt">length.out =</span> n)</a>
<a class="sourceLine" id="cb905-6" data-line-number="6">V =<span class="st"> </span><span class="kw">rnorm</span>(n, <span class="dv">0</span>, <span class="fl">0.50</span>)  </a>
<a class="sourceLine" id="cb905-7" data-line-number="7"><span class="co"># Simple 2 direction Random Walk</span></a>
<a class="sourceLine" id="cb905-8" data-line-number="8"><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">2</span><span class="op">:</span>n) {</a>
<a class="sourceLine" id="cb905-9" data-line-number="9">    <span class="kw">set.seed</span>(seed <span class="op">+</span><span class="st"> </span>i)</a>
<a class="sourceLine" id="cb905-10" data-line-number="10">    y[i] =<span class="st"> </span>y[i<span class="dv">-1</span>] <span class="op">+</span><span class="st"> </span><span class="kw">runif</span>(<span class="dv">1</span>, <span class="fl">-0.5</span>, <span class="fl">0.5</span>)   <span class="co"># true measurement  </span></a>
<a class="sourceLine" id="cb905-11" data-line-number="11">    Y.e[i] =<span class="st"> </span>y[i] <span class="op">+</span><span class="st"> </span>V[i]  <span class="co"># observed measurement with noise</span></a>
<a class="sourceLine" id="cb905-12" data-line-number="12">}</a></code></pre></div>

<p>Below is the implementation of the functions in R code corresponding to the steps in Figure <a href="bayesian2.html#fig:kalmanfilter">8.21</a> above:</p>

<div class="sourceCode" id="cb906"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb906-1" data-line-number="1">predict.kalman &lt;-<span class="st"> </span><span class="cf">function</span>(A,X,P,Q) {</a>
<a class="sourceLine" id="cb906-2" data-line-number="2">   X =<span class="st"> </span>A <span class="op">*</span><span class="st"> </span>X</a>
<a class="sourceLine" id="cb906-3" data-line-number="3">   P =<span class="st"> </span>A <span class="op">*</span><span class="st"> </span>P <span class="op">*</span><span class="st"> </span><span class="kw">t</span>(A) <span class="op">+</span><span class="st"> </span>Q</a>
<a class="sourceLine" id="cb906-4" data-line-number="4">   <span class="kw">list</span>(<span class="st">&quot;X&quot;</span> =<span class="st"> </span>X, <span class="st">&quot;P&quot;</span> =<span class="st"> </span>P)</a>
<a class="sourceLine" id="cb906-5" data-line-number="5">}</a>
<a class="sourceLine" id="cb906-6" data-line-number="6">update.kalman &lt;-<span class="st"> </span><span class="cf">function</span>(Y, X, P, H, R) {</a>
<a class="sourceLine" id="cb906-7" data-line-number="7">  I =<span class="st"> </span><span class="dv">1</span></a>
<a class="sourceLine" id="cb906-8" data-line-number="8">  K =<span class="st"> </span>P <span class="op">*</span><span class="st"> </span>H <span class="op">/</span><span class="st"> </span>( H <span class="op">*</span><span class="st"> </span>P <span class="op">*</span><span class="st"> </span><span class="kw">t</span>(H) <span class="op">+</span><span class="st"> </span>R)</a>
<a class="sourceLine" id="cb906-9" data-line-number="9">  X =<span class="st"> </span>X <span class="op">+</span><span class="st"> </span>K<span class="op">*</span>(Y <span class="op">-</span><span class="st"> </span>H <span class="op">*</span><span class="st"> </span>X)</a>
<a class="sourceLine" id="cb906-10" data-line-number="10">  P =<span class="st"> </span>(I <span class="op">-</span><span class="st"> </span>K<span class="op">*</span>H) <span class="op">*</span><span class="st"> </span>P</a>
<a class="sourceLine" id="cb906-11" data-line-number="11">  <span class="kw">list</span>(<span class="st">&quot;K&quot;</span> =<span class="st"> </span>K, <span class="st">&quot;X&quot;</span> =<span class="st"> </span>X, <span class="st">&quot;P&quot;</span> =<span class="st"> </span>P)</a>
<a class="sourceLine" id="cb906-12" data-line-number="12">}</a></code></pre></div>

<p>Here is an example implementation of <strong>Kalman Filter</strong> in R code. Note that we reduce the variables to <strong>scalar</strong> instead of the <strong>matrices</strong> discussed above for the sake of intuition. Therefore, the identity and transformation matrices, namely <strong>H</strong>, <strong>R</strong>, <strong>Q</strong>, and <strong>A</strong>, are set to 1, including <strong>P</strong> (assuming constant control with stationary covariances):</p>

<div class="sourceCode" id="cb907"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb907-1" data-line-number="1">X.e =<span class="st"> </span><span class="kw">c</span>()</a>
<a class="sourceLine" id="cb907-2" data-line-number="2">Q =<span class="st"> </span><span class="dv">1</span>; R =<span class="st"> </span><span class="dv">1</span>; A =<span class="st"> </span><span class="dv">1</span>; H =<span class="st"> </span><span class="dv">1</span>; P =<span class="st"> </span><span class="dv">1</span></a>
<a class="sourceLine" id="cb907-3" data-line-number="3">X =<span class="st"> </span>Y.e[<span class="dv">1</span>]; X.e =<span class="st"> </span><span class="kw">c</span>(X)</a>
<a class="sourceLine" id="cb907-4" data-line-number="4"><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">2</span><span class="op">:</span>n) {</a>
<a class="sourceLine" id="cb907-5" data-line-number="5">  new.state =<span class="st"> </span><span class="kw">predict.kalman</span>(A,X,P,Q)</a>
<a class="sourceLine" id="cb907-6" data-line-number="6">  X =<span class="st"> </span>new.state<span class="op">$</span>X; P =<span class="st"> </span>new.state<span class="op">$</span>P</a>
<a class="sourceLine" id="cb907-7" data-line-number="7">  current.state =<span class="st"> </span><span class="kw">update.kalman</span>(Y.e[i], X, P, H, R)</a>
<a class="sourceLine" id="cb907-8" data-line-number="8">  X =<span class="st"> </span>current.state<span class="op">$</span>X</a>
<a class="sourceLine" id="cb907-9" data-line-number="9">  P =<span class="st"> </span>current.state<span class="op">$</span>P</a>
<a class="sourceLine" id="cb907-10" data-line-number="10">  K =<span class="st"> </span>current.state<span class="op">$</span>K</a>
<a class="sourceLine" id="cb907-11" data-line-number="11">  X.e =<span class="st"> </span><span class="kw">cbind</span>(X.e, X)</a>
<a class="sourceLine" id="cb907-12" data-line-number="12">}</a></code></pre></div>

<p>Try to play around with the <strong>R</strong> scalar value and observe the effect of the <strong>Kalman Gain</strong>.</p>
<p>See Figure <a href="bayesian2.html#fig:kalmanfilter3">8.22</a> for a plot of the <strong>random walk</strong> and the estimate.</p>

<div class="sourceCode" id="cb908"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb908-1" data-line-number="1"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="dv">0</span>, n), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="dv">10</span>), </a>
<a class="sourceLine" id="cb908-2" data-line-number="2">     <span class="dt">xlab=</span><span class="st">&quot;T&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;Location&quot;</span>,</a>
<a class="sourceLine" id="cb908-3" data-line-number="3">     <span class="dt">main=</span><span class="st">&quot;Kalman Filter&quot;</span>,  <span class="dt">frame=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb908-4" data-line-number="4"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb908-5" data-line-number="5"><span class="kw">points</span>(x, Y.e, <span class="dt">col=</span><span class="kw">c</span>(<span class="st">&quot;grey&quot;</span>), <span class="dt">pch=</span><span class="dv">16</span>, <span class="dt">cex=</span><span class="fl">0.80</span>)</a>
<a class="sourceLine" id="cb908-6" data-line-number="6"><span class="kw">lines</span>(x, y, <span class="dt">col=</span><span class="kw">c</span>(<span class="st">&quot;darksalmon&quot;</span>), <span class="dt">lwd=</span><span class="dv">3</span>)</a>
<a class="sourceLine" id="cb908-7" data-line-number="7"><span class="kw">lines</span>(x, X.e, <span class="dt">col=</span><span class="kw">c</span>(<span class="st">&quot;navyblue&quot;</span>), <span class="dt">lwd=</span><span class="dv">3</span>)</a>
<a class="sourceLine" id="cb908-8" data-line-number="8"><span class="kw">legend</span>(<span class="st">&quot;topleft&quot;</span>, <span class="dt">inset=</span>.<span class="dv">02</span>, </a>
<a class="sourceLine" id="cb908-9" data-line-number="9">   <span class="kw">c</span>(<span class="st">&quot;True Measurement&quot;</span>,<span class="st">&quot;Estimate (KF)&quot;</span>, <span class="st">&quot;Observation&quot;</span>), </a>
<a class="sourceLine" id="cb908-10" data-line-number="10">   <span class="dt">col=</span><span class="kw">c</span>(<span class="st">&quot;darksalmon&quot;</span>, <span class="st">&quot;navyblue&quot;</span>, <span class="st">&quot;grey&quot;</span>), </a>
<a class="sourceLine" id="cb908-11" data-line-number="11">   <span class="dt">horiz=</span><span class="ot">FALSE</span>, <span class="dt">cex=</span><span class="fl">0.8</span>, <span class="dt">lty=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>, <span class="dv">0</span>), <span class="dt">lwd=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>), <span class="dt">pch=</span><span class="kw">c</span>(<span class="op">-</span><span class="dv">1</span>,<span class="op">-</span><span class="dv">1</span>, <span class="dv">16</span>))</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:kalmanfilter3"></span>
<img src="DS_files/figure-html/kalmanfilter3-1.png" alt="Kalman Filter" width="70%" />
<p class="caption">
Figure 8.22: Kalman Filter
</p>
</div>

<p>We leave readers to investigate other variations or improvements of <strong>Kalman filter</strong> equations and algorithms.</p>
<p>Apart from the same range of applications of <strong>Bayes Filter</strong>, other applications of <strong>Kalman filter</strong> are found in navigation tracking (e.g., GPS - global positioning system, IMU - inertial measurement unit). That includes object tracking (e.g., using radar to track moving targets), pod/drone landing, robotics, and econometrics with time-series and forecasting requirements.</p>
</div>
<div id="extended-kalman-filter" class="section level3 hasAnchor">
<h3><span class="header-section-number">8.1.8</span> Extended Kalman Filter <a href="bayesian2.html#extended-kalman-filter" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Extended Kalman Filter (EKF)</strong> extends the concept of <strong>Kalman Filter</strong> by dealing with non-linear cases (e.g., non-gaussian distributions). In such cases, <strong>EFK</strong> transforms non-linearity into a locally linear model using <strong>Taylor series expansion</strong> around the mean up to a given order, e.g., first-order Taylor series. Let us use Figure <a href="bayesian2.html#fig:extendedkalman">8.23</a>.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:extendedkalman"></span>
<img src="extendedkalman.png" alt="Extended Kalman Filter" width="60%" />
<p class="caption">
Figure 8.23: Extended Kalman Filter
</p>
</div>

<p>Our case starts with the assumption that the state <strong>X</strong> and measurement <strong>Y</strong> are non-linear; thus, we deal with non-linear functions.</p>
<p><span class="math display">\[\begin{align}
X_t = \overbrace{A X_{t-1} + B U_t + W_t}^\text{linear model}\ \ \ 
{}&amp;\rightarrow X_t = \overbrace{f(X_{t-1}, U_t, W_t)}^\text{non-linear model}  \\
Y_t = C X_t + V_t \ \ \ \ &amp;\rightarrow Y_t = g(X_t, V_t) 
\end{align}\]</span></p>
<p>Both functions represent a first-order Taylor series expansion split into vectored functions of length m.</p>
<p>To optimize the function, we perform partial derivatives and derive a jacobian matrix, effectively linearizing <span class="math inline">\(X_t\)</span> and <span class="math inline">\(Y_t\)</span> like so:</p>
<p><span class="math display">\[
F = \left.\frac{\partial f}{\partial x}\right|_{X_{t-1}, U_t} = 
\left[
\begin{array}{cccc}
\frac{\partial f_1}{\partial x_1} &amp; \frac{\partial f_1}{\partial x_2} &amp; \cdots &amp; \frac{\partial f_1}{\partial x_n} \\
\frac{\partial f_2}{\partial x_1} &amp; \frac{\partial f_2}{\partial x_2} &amp; \cdots &amp;\frac{\partial f_2}{\partial x_n} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
\frac{\partial f_m}{\partial x_1} &amp; \frac{\partial f_m}{\partial x_2} &amp; \cdots &amp; \frac{\partial f_m}{\partial x_n} \\
\end{array}
\right]_{mxn}
\]</span></p>
<p><span class="math display">\[
G = \left.\frac{\partial g}{\partial x}\right|_{X_t} = 
\left[
\begin{array}{cccc}
\frac{\partial g_1}{\partial x_1} &amp; \frac{\partial g_1}{\partial x_2} &amp; \cdots &amp; \frac{\partial g_1}{\partial x_n} \\
\frac{\partial g_2}{\partial x_1} &amp; \frac{\partial g_2}{\partial x_2} &amp; \cdots &amp;\frac{\partial g_2}{\partial x_n} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
\frac{\partial g_m}{\partial x_1} &amp; \frac{\partial g_m}{\partial x_2} &amp; \cdots &amp; \frac{\partial g_m}{\partial x_n} \\
\end{array}
\right]_{mxn}
\]</span>
After computing for the <strong>F</strong> and <strong>G</strong> jacobian matrices, we can now extend <strong>Kalman Filter</strong> by reformulating the steps:</p>
<p><span class="math display">\[
\begin{array}{ll}
\mathbf{\text{Kalman Filter}} &amp;\ \ \ \ \ \ \ \ \ \ \ \mathbf{\text{Extended Kalman Filter}}\\
\text{==============} &amp;\ \ \ \ \ \ \ \ \ \ \ \text{=================}\\
\begin{array}{ll}
X_t &amp;= A X_{t-1} + B U_t + W_t \\
P_t &amp;= AP_{t-1}A^T + Q_t \\
K &amp;= \frac{P_t H}{HP_t H^T + R} \\
P_t^* &amp;= (I - KH)P_t \\
X_t^* &amp;= X_t + K(Y_t - HX_t) \\
\end{array} &amp;\ \ \ \ \ \ \ \ \ \ \
\begin{array}{ll}
X_t &amp;=  f(X_{t-1},  U_t, W_t)   \\
P_t &amp;= FP_{t-1}F^T + Q_t \\
K &amp;= \frac{P_t G}{GP_t G^T + R} \\
P_t^* &amp;= (I - KG)P_t \\
X_t^* &amp;= X_t + K(Y_t - g(X_t, V_t)) \\
\end{array}
\end{array}
\]</span>
The algorithm is the same as the original <strong>Kalman Filter</strong>, following the same <strong>prediction step</strong> and <strong>correction step</strong> as before.</p>
</div>
<div id="unscented-kalman-filter" class="section level3 hasAnchor">
<h3><span class="header-section-number">8.1.9</span> Unscented Kalman Filter <a href="bayesian2.html#unscented-kalman-filter" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Unscented Kalman Filter (UKF)</strong> avoids <strong>linearization</strong> in the non-linear transformation; instead, it transforms a distribution into an approximate distribution by transforming a select set of data points into a set of transformed and weighted <strong>sigma points</strong>. For discussion, we follow van der Merwe R. et al <span class="citation">(<a href="bibliography.html#ref-ref619r">2013</a>)</span> and Stachniss C. <span class="citation">(<a href="bibliography.html#ref-ref623c">2013</a>)</span>]. See Figure <a href="bayesian2.html#fig:unscentedkalman">8.24</a>.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unscentedkalman"></span>
<img src="unscentedkalman.png" alt="Unscented Kalman Filter" width="80%" />
<p class="caption">
Figure 8.24: Unscented Kalman Filter
</p>
</div>

<p>Sigma Points Properties</p>
<p><span class="math display">\[\begin{align}
\sum_i^n w_i = 1\ \ \ \ \ \ \ \ \ \ \ \ \mu = \sum_i^n  w_i x_i\ \ \ \ \ \ \ \ \ \ \ \ \Sigma = \sum_i^n  w_i (x_i - \mu)(x_i - \mu)^T
\end{align}\]</span></p>
<p>With the corresponding mean <span class="math inline">\(\mu\)</span> and covariance <span class="math inline">\(\Sigma\)</span>, we should be able to recover the original <strong>gaussian distribution</strong> using the following formula:</p>
<p><span class="math display">\[\begin{align}
\mu_0 = \sum_{i=0}^{2p} w_i f(x_i)\ \ \ \ \ \Sigma_0 = \sum_{i=0}^{2p} w_i ( f(x_i) - \mu)( f(x_i) - \mu)^T
\end{align}\]</span></p>
<p>Note that the function <span class="math inline">\(f(x)\)</span> is an arbitrary non-linear function depending on the case; thus omits the required <strong>Taylor series expansion</strong> for <strong>EKF</strong>.</p>
<p>In terms of selecting the candidate sigma points, we use the following <strong>Sigma points</strong> and <strong>Sigma weights</strong>:</p>
<p><span class="math display">\[\begin{align}
\begin{array}{llllc}
x_0 = \mu &amp; &amp;\ \ \ \ &amp;\omega_0^{(m)} = \frac{\lambda}{p + \lambda} &amp; \\
x_i = \mu + \sqrt{(p + \lambda)\Sigma_x}_i &amp;  i = 1,...,p 
&amp;\ \ \ \ &amp;\omega_0^{(c)} = \omega_0^{(m)}  + (1 - \alpha^2 + \beta) &amp; \\
x_i = \mu - \sqrt{(p + \lambda)\Sigma_x}_{i-p} &amp;  i = p+1,...,2p
&amp;\ \ \ \ &amp;\omega_i^{m} = \omega_i^{(c)} =  \frac{1}{2(p + \lambda)},\ i = 1,...,2p
\end{array} \label{eqn:eqnnumber333}
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(\Sigma_x\)</span> is the process-covariance matrix (see <strong>Cholesky Factorization</strong> for numerical computation),</li>
<li><strong>p</strong> is the p-dimensions,</li>
<li><span class="math inline">\(\alpha \in (0,1)\)</span> (denoting spread of sigma points around the mean),</li>
<li><span class="math inline">\(\lambda = \alpha^2(p + \lambda) - p\)</span> (denoting degrees of freedom),</li>
<li><span class="math inline">\(\beta = 2\)</span> (2 being optimal).</li>
</ul>
<p>The <strong>UKF</strong> follows the same steps as <strong>KF</strong> and <strong>EKF</strong> like so:</p>
<p><strong>Prediction Step</strong>:</p>
<p><span class="math display">\[\begin{align}
X_{t-1} {}&amp;= (\mu_{t-1}\ \ \ \ \mu_{t-1} + \lambda\sqrt{\Sigma_{t-1}}\ \ \ \ \ \mu_{t-1} - \lambda\sqrt{\Sigma_{t-1}})\\
\hat{X}_t &amp;= f(X_t, U_t, W_t)\\
\bar{\mu}_t &amp;= \sum_{i=0}^{2p} w_i^{(m)} \hat{X}_{t_i} \\
\bar{\Sigma}_t &amp;= \sum_{i=1}^{2p} w_i^{(c)} ( \hat{X}_{t_i} - \bar{\mu}_t) ( \hat{X}_{t_i} - \bar{\mu}_t)^T + Q_t
\end{align}\]</span></p>
<p><strong>Correction (Update) Step</strong>:</p>
<p><span class="math display">\[\begin{align}
\bar{X}_t {}&amp;= (\bar{\mu}_t\ \ \ \ \bar{\mu}_t + \lambda\sqrt{\bar{\Sigma}_t}\ \ \ \ \ \bar{\mu}_t - \lambda\sqrt{\bar{\Sigma}_t})\\ 
Y_t &amp;= g(\bar{X}_t, V_t)\\
\bar{y}_t &amp;= \sum_{i=0}^{2p} w_i^{(m)}  Y_{t_{i}}\\
S_t^{y,y} &amp;= \sum_{i=0}^{2p} w_i^{(c)} ( Y_{t_{i}} - \bar{y}_t) ( Y_{t_{i}} - \bar{y}_t)^T + R_t\\
S_t^{x,y} &amp;= \sum_{i=0}^{2p} w_i^{(c)} ( \bar{X}_{t_{i}} - \bar{\mu}_t ) ( Y_{t_{i}} - \bar{y}_t)^T \\
K_t &amp;= S_t^{x,y}  (S_t^{y,y})^{-1}\\
\mu_t &amp;=  \bar{\mu}_t  + K_t(y_t - \bar{y}_t)\\
\Sigma_t &amp;= \bar{\Sigma}_t  - K_tS_t^{y,y} K_t^T
\end{align}\]</span></p>
<p>Similarly, we iterate over the two steps until all observations are accounted for. We then obtain the final result, namely <span class="math inline">\(\mu_t\)</span> and <span class="math inline">\(\Sigma_t\)</span>, which we can use to generate the <strong>Gaussian distribution</strong>; in this case, it is an approximate distribution.</p>
</div>
<div id="particle-filter" class="section level3 hasAnchor">
<h3><span class="header-section-number">8.1.10</span> Particle Filter <a href="bayesian2.html#particle-filter" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Particle Filter (PF)</strong> follows the same concept as <strong>UKF</strong> in that <strong>Sigma points</strong> are derived. However, the <strong>Sigma points</strong> are derived from an arbitrary sample in <strong>PF</strong>; rather than following the equations presented in the previous <strong>UKF</strong> discussion to select a candidate set of data points. Note that <strong>PF</strong> becomes more computationally expensive with larger samples though more flexible than the three Kalman filters discussed previously.</p>
<p>In later sections, we discuss <strong>simulation and sampling</strong> techniques such as <strong>Markov Chain Monte Carlo (MCMC)</strong> and <strong>Metropolis-Hastings MC</strong> algorithms that can be used to support the random draws of the <strong>Sigma points</strong>.</p>
<p>We leave readers to investigate <strong>Particle Filters</strong>further.</p>
</div>
<div id="ensemble-kalman-filter" class="section level3 hasAnchor">
<h3><span class="header-section-number">8.1.11</span> Ensemble Kalman Filter <a href="bayesian2.html#ensemble-kalman-filter" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Ensemble Kalman Filter (EnKF)</strong>uses <strong>Monte Carlo</strong> sampling to filter an <strong>ensemble</strong> of samples from a distribution. It is suitable for datasets with high dimensionality (high features). Similar to <strong>Particle Filter</strong>, <strong>EnKF</strong> uses multiple samples generated using <strong>Monte Carlo</strong>. However, the same steps apply as before with modifications in the equations to accommodate the datasets.</p>
<p>We leave readers to investigate <strong>Ensemble Kalman Filter</strong>further. In addition, it helps to be aware of topics around <strong>Data Assimilation</strong> and <strong>Sensor Fusion</strong> and the use of multiple sensors such as <strong>Lidar</strong>, <strong>Infrared</strong>, and <strong>Radar</strong> for autonomous objects.</p>
</div>
</div>
<div id="simulation-and-sampling" class="section level2 hasAnchor">
<h2><span class="header-section-number">8.2</span> Simulation and Sampling<a href="bayesian2.html#simulation-and-sampling" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>This section discusses a few <strong>simulation</strong> and <strong>sampling</strong> techniques. Such need for simulation and sampling becomes apparent in situations where there are no practical means to obtain samples of an observation. Especially in models with very high dimensionality, such as <strong>lattice models</strong> in which we deal with thousands or even millions of variables (or features in machine learning), numerical computation may not be possible. Sampling data points from large datasets are ideal in this case.</p>
<div id="monte-carlo-estimation" class="section level3 hasAnchor">
<h3><span class="header-section-number">8.2.1</span> Monte Carlo Estimation <a href="bayesian2.html#monte-carlo-estimation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A concept behind <strong>Monte Carlo estimation</strong> is the <strong>Law of the Unconscious Statistician (LOTUS)</strong>, which states that the expected value of a function can be calculated without depending on its distribution. That can be written as such:</p>
<p><span class="math display">\[\begin{align}
\mathbb{E}\left[f(X)\right] = \underbrace{\int f(X) P_{(pdf)}(X) dX}_\text{continuous} \approx \underbrace{\sum_{i=1}^N f(X_i)  P_{(pmf)}(X)}_\text{discrete}
\end{align}\]</span></p>
<p>Here, we define the expected value as the sum of the product of the function (the transformed value) and the probability distribution (of the original value). The idea is to use this calculation to estimate the complex integration of a function; thus, this is also called <strong>Monte Carlo integration</strong>.</p>
<p><span class="math display">\[\begin{align}
\mathcal{I}(f(x)) = \mathbb{E}\left[f(X)\right] \approx \frac{1}{N} \sum^N_{i=1} f(x_i)
\end{align}\]</span></p>
<p>To illustrate, suppose we have the following simple function: <span class="math inline">\(f(X) = 3X\)</span>. We then generate ten random outcomes between 1 and 5 for X that give us the calculated (transformed) values using <span class="math inline">\(f(X)\)</span>:</p>

<div class="sourceCode" id="cb909"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb909-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">2020</span>)</a>
<a class="sourceLine" id="cb909-2" data-line-number="2">f &lt;-<span class="st"> </span><span class="cf">function</span>(X) { <span class="dv">3</span><span class="op">*</span>X }</a>
<a class="sourceLine" id="cb909-3" data-line-number="3">N =<span class="st"> </span><span class="dv">1000</span></a>
<a class="sourceLine" id="cb909-4" data-line-number="4">possible.outcome =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">1</span>, <span class="dv">5</span>)</a>
<a class="sourceLine" id="cb909-5" data-line-number="5">prob =<span class="st"> </span><span class="kw">c</span>(<span class="fl">0.10</span>, <span class="fl">0.20</span>, <span class="fl">0.30</span>, <span class="fl">0.05</span>, <span class="fl">0.35</span>)</a>
<a class="sourceLine" id="cb909-6" data-line-number="6">X =<span class="st"> </span><span class="kw">sample</span>(<span class="dt">x =</span> possible.outcome, <span class="dt">size =</span> N, <span class="dt">replace=</span><span class="ot">TRUE</span>, <span class="dt">prob=</span>prob)</a>
<a class="sourceLine" id="cb909-7" data-line-number="7">Y =<span class="st"> </span><span class="kw">f</span>(X)</a>
<a class="sourceLine" id="cb909-8" data-line-number="8">D =<span class="st"> </span><span class="kw">rbind</span>(X[<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>], Y[<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>]) <span class="co"># show only the 10 values</span></a>
<a class="sourceLine" id="cb909-9" data-line-number="9">Df =<span class="st"> </span><span class="kw">data.frame</span>(D)</a>
<a class="sourceLine" id="cb909-10" data-line-number="10"><span class="kw">rownames</span>(Df) =<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;original (x)&quot;</span>, <span class="st">&quot;transformed f(x)&quot;</span>)</a>
<a class="sourceLine" id="cb909-11" data-line-number="11">Df</a></code></pre></div>
<pre><code>##                  X1 X2 X3 X4 X5 X6 X7 X8 X9 X10
## original (x)      3  3  3  3  5  5  5  3  5   3
## transformed f(x)  9  9  9  9 15 15 15  9 15   9</code></pre>
<div class="sourceCode" id="cb911"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb911-1" data-line-number="1"><span class="kw">hist</span>(Y,   <span class="dt">breaks =</span> <span class="dv">5</span>, <span class="dt">las=</span><span class="dv">1</span>, <span class="dt">xlab=</span><span class="st">&quot;f(X)&quot;</span>,</a>
<a class="sourceLine" id="cb911-2" data-line-number="2">      <span class="dt">cex.main =</span> <span class="fl">1.55</span>, <span class="dt">cex.lab =</span> <span class="dv">1</span>, <span class="dt">freq =</span> <span class="ot">TRUE</span>,</a>
<a class="sourceLine" id="cb911-3" data-line-number="3">     <span class="dt">main=</span><span class="st">&quot;Monte Carlo Estimation&quot;</span>,</a>
<a class="sourceLine" id="cb911-4" data-line-number="4">           <span class="dt">border=</span><span class="st">&quot;black&quot;</span>,  <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>)</a>
<a class="sourceLine" id="cb911-5" data-line-number="5"><span class="kw">axis</span>(<span class="dv">1</span>, <span class="kw">seq</span>(<span class="dv">1</span>,<span class="dv">15</span>,<span class="dv">1</span>) )</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:mcestimation"></span>
<img src="DS_files/figure-html/mcestimation-1.png" alt="Monte Carlo Estimation" width="70%" />
<p class="caption">
Figure 8.25: Monte Carlo Estimation
</p>
</div>

<p>Note that <span class="math inline">\(f(X)\)</span> generates a new distribution different from the distribution of <strong>X</strong>.</p>
<p>Now, suppose we know the probability distribution of our function:</p>
<p><span class="math display">\[
f(x) = (3,6,9,12,15)\ \ maps\ to\ \ \ \ P\left[f(x)\right] = \left( 0.10, 0.20, 0.30, 0.05, 0.35\right).
\]</span></p>
<p>In that case, we can calculate the expected value based on the known probabilities of all possible outcomes (of the function):</p>
<p><span class="math display">\[\begin{align}
I_q {}&amp;= f(x = 1)P\left[f(x=1)\right] + 
f(x = 2)P\left[f(x=2)\right] +
f(x = 3)P\left[f(x=3)\right] + \nonumber \\
&amp;f(x = 4)P\left[f(x=4)\right] + 
f(x = 5)P\left[f(x=5)\right]\\
&amp;= 3 \times 0.10 + 6 \times 0.20 + 9 \times 0.30 + 12 \times 0.05 + 15 \times 0.35 \nonumber \\
&amp;= 10.05 \nonumber
\end{align}\]</span></p>
<p>Otherwise, if the probability distribution of the function is not known, then we use the probability distribution of the original values like so (here, we use uniform probabilities):</p>
<p><span class="math display">\[
X = (1,2,3,4,5)\ \ maps\ to\ \ \ \ P\left(X\right) = \left( 
\frac{1}{5}, \frac{1}{5}, \frac{1}{5}, \frac{1}{5}, \frac{1}{5}
\right).
\]</span></p>
<p>so that, we then get the following expected value:</p>
<p><span class="math display">\[\begin{align}
I_q {}&amp;= f(x = 1)P\left(x = 1\right) + 
f(x = 2)P\left(x = 2\right) +
f(x = 3)P\left(x = 3\right) + \nonumber \\
&amp;f(x = 4)P\left(x = 4\right) + 
f(x = 5)P\left(x = 5\right)\\
&amp;= 3 \times 0.20 + 6 \times 0.20 + 9 \times 0.20  + 12 \times 0.20  + 15 \times 0.20 \nonumber \\
&amp;= 9.0 \nonumber
\end{align}\]</span></p>
<p>Below is a simple implementation of <strong>Monte Carlo estimation</strong> in R code:</p>

<div class="sourceCode" id="cb912"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb912-1" data-line-number="1">Pf =<span class="st"> </span>prob <span class="co"># known probabilities of function</span></a>
<a class="sourceLine" id="cb912-2" data-line-number="2">E =<span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb912-3" data-line-number="3">n =<span class="st"> </span><span class="kw">length</span>(possible.outcome)</a>
<a class="sourceLine" id="cb912-4" data-line-number="4"><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n) {</a>
<a class="sourceLine" id="cb912-5" data-line-number="5">  E =<span class="st"> </span>E <span class="op">+</span><span class="st">  </span><span class="kw">f</span>(possible.outcome[i]) <span class="op">*</span><span class="st"> </span>Pf[possible.outcome[i]]</a>
<a class="sourceLine" id="cb912-6" data-line-number="6">}</a>
<a class="sourceLine" id="cb912-7" data-line-number="7"><span class="kw">print</span>(<span class="kw">paste0</span>(<span class="st">&quot;Expected Value = &quot;</span>, <span class="kw">round</span>(E,<span class="dv">5</span>)))</a></code></pre></div>
<pre><code>## [1] &quot;Expected Value = 10.05&quot;</code></pre>

<p>We further discuss using <strong>Monte Carlo estimation</strong> in the <strong>Importance sampling</strong> section.</p>
</div>
<div id="monte-carlo-simulation" class="section level3 hasAnchor">
<h3><span class="header-section-number">8.2.2</span> Monte Carlo Simulation <a href="bayesian2.html#monte-carlo-simulation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Monte Carlo simulation</strong>, also called <strong>Monte Carlo method</strong> and <strong>Monte Carlo sampling</strong>, offers the ability to draw random samples from a posterior distribution by simulating probabilities. The objective is to measure risk and uncertainty.</p>
<p>To demonstrate <strong>Monte Carlo</strong>, we can use an R function called <strong>sample(.)</strong> to simulate multiple random tosses of a coin:</p>

<div class="sourceCode" id="cb914"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb914-1" data-line-number="1">data =<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;H&quot;</span>, <span class="st">&quot;T&quot;</span>)</a>
<a class="sourceLine" id="cb914-2" data-line-number="2"><span class="kw">sample</span>(data, <span class="dt">size=</span><span class="dv">10</span>, <span class="dt">replace=</span><span class="ot">TRUE</span>)</a></code></pre></div>
<pre><code>##  [1] &quot;T&quot; &quot;H&quot; &quot;H&quot; &quot;H&quot; &quot;T&quot; &quot;H&quot; &quot;T&quot; &quot;H&quot; &quot;T&quot; &quot;H&quot;</code></pre>

<p>Another popular function used in R to implement <strong>MC</strong> is the <strong>rnorm(.)</strong> which simulates generating random numbers, given a mean <span class="math inline">\(\mu = 0\)</span> and variance <span class="math inline">\(\sigma^2=1\)</span>, like so:</p>

<div class="sourceCode" id="cb916"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb916-1" data-line-number="1">mu =<span class="st"> </span><span class="dv">0</span>;  sigma =<span class="st"> </span><span class="kw">sqrt</span>(<span class="dv">1</span>)</a>
<a class="sourceLine" id="cb916-2" data-line-number="2"><span class="kw">rnorm</span>(<span class="dt">n=</span><span class="dv">5</span>, <span class="dt">mean=</span>mu, <span class="dt">sd=</span>sigma)</a></code></pre></div>
<pre><code>## [1] -0.8781 -0.4207 -2.6625 -1.6323  1.0070</code></pre>

<p>A simple example of <strong>MC</strong> is a simulated random walk using the function <strong>rbinom(.)</strong>. See Figure <a href="bayesian2.html#fig:randomwalk">8.26</a>):</p>

<div class="sourceCode" id="cb918"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb918-1" data-line-number="1">random.walk &lt;-<span class="st"> </span><span class="cf">function</span>(<span class="dt">no_of_walks =</span> <span class="dv">5</span>) {</a>
<a class="sourceLine" id="cb918-2" data-line-number="2">  <span class="kw">set.seed</span>(<span class="dv">2020</span> )</a>
<a class="sourceLine" id="cb918-3" data-line-number="3">  direction =<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;north&quot;</span>, <span class="st">&quot;south&quot;</span>, <span class="st">&quot;east&quot;</span>, <span class="st">&quot;west&quot;</span>)</a>
<a class="sourceLine" id="cb918-4" data-line-number="4">  walk =<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, no_of_walks)</a>
<a class="sourceLine" id="cb918-5" data-line-number="5">  rnd =<span class="st"> </span><span class="kw">rbinom</span>(<span class="dt">n =</span> no_of_walks, <span class="dt">size =</span> <span class="dv">3</span>, <span class="dt">prob=</span><span class="fl">0.50</span>) <span class="op">+</span><span class="st"> </span><span class="dv">1</span></a>
<a class="sourceLine" id="cb918-6" data-line-number="6">  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>no_of_walks) {</a>
<a class="sourceLine" id="cb918-7" data-line-number="7">    walk[i] =<span class="st"> </span>direction[rnd[i]]</a>
<a class="sourceLine" id="cb918-8" data-line-number="8">  }</a>
<a class="sourceLine" id="cb918-9" data-line-number="9">  walk</a>
<a class="sourceLine" id="cb918-10" data-line-number="10">}</a>
<a class="sourceLine" id="cb918-11" data-line-number="11">walk =<span class="st"> </span><span class="kw">random.walk</span>(<span class="dv">100</span>)</a></code></pre></div>


<div class="figure" style="text-align: center"><span style="display:block;" id="fig:randomwalk"></span>
<img src="DS_files/figure-html/randomwalk-1.png" alt="Random Walk (Monte Carlo)" width="70%" />
<p class="caption">
Figure 8.26: Random Walk (Monte Carlo)
</p>
</div>

<p>A more complex example of using <strong>Monte Carlo</strong> is studying autonomous vehicles, e.g., self-driving cars, especially around tracking multiple targets (Kim, D., Hong, S. 2013). One property of an autonomous moving vehicle is to detect surrounding objects and thus be able to avoid a collision ultimately. Therefore, the vehicle needs to monitor and measure the distance and velocity between the moving vehicle and multiple targets. The problem statement is to distinguish and map detected measurements with corresponding targets.</p>
<p>There are six independent measurements generated from six sensors attached to an autonomous vehicle, namely Infrared Sensor, Ultrasonic Sensor, VideoCam, GPS, Lidar Sensor using light waves, and Radar Sensor using radio waves. Such sensor measurements are fed into the central computer for analysis.</p>
<p>In particular, let us focus on linear Doppler shifts of light waves detected from an FMCW Lidar sensor. See Figure <a href="bayesian2.html#fig:fmcw">8.27</a> showing two frequencies, namely a transmitted frequency from a moving vehicle and a reflected frequency from a stationary object straight up ahead.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:fmcw"></span>
<img src="fmcw.png" alt="Triangular Chirp Modulation for an FMCW system" width="70%" />
<p class="caption">
Figure 8.27: Triangular Chirp Modulation for an FMCW system
</p>
</div>

<p>The diagram demonstrates a triangular chirp (or beat) modulation for the two frequencies allowing a calculation of the distance and velocity of a moving source to a stationary target. To a moving object (being the source) and a stationary observer (being the target), classic radar sensors detect changes in wave frequency called Doppler shifts (denoted <span class="math inline">\(\mathbf{f_D}\)</span>). As for light-based sensors, Doppler frequency has the following equation:</p>
<p><span class="math display">\[\begin{align}
f_D = \frac{2V_r f_o}{C} 
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(\mathbf{V_r}\)</span> is relative Velocity,</li>
<li><span class="math inline">\(\mathbf{f_o}\)</span> is operating frequency of transmitted signal,</li>
<li><strong>C</strong> is a constant for speed of light, e.g. <span class="math inline">\(3\times 10^8\)</span> m/s.</li>
</ul>
<p>For example, suppose a moving vehicle has a speed of 30 m/s with a lidar signal transmitted at a frequency of 77 GHz. Therefore, the Doppler frequency is calculated to be:</p>
<p><span class="math display">\[
f_D = \frac{2 (30) (77\times 10^9)} {(3\times 10^8)} = 15.4\ \text{kHz}
\]</span></p>
<p>Now, suppose our goal is to prevent a collision by allowing a moving vehicle to autonomously slow down to a stop at a safe stopping distance from multiple stationary targets detected straight ahead. For that, we need to measure the distance and velocity of the moving object using the following series of equations and their derivations based on Figure <a href="bayesian2.html#fig:fmcw">8.27</a>:</p>
<p><span class="math display">\[\begin{align}
\begin{array}{lllll}
\tau &amp;= \frac{2R}{C}&amp;\ \ \ \ &amp;f_b &amp;= (\tau)\frac{B}{T_s} (slope = \frac{rise}{run})\\
f_{bu} &amp;= f_b - f_D&amp;\ \ \ \ &amp;f_{bd} &amp;= f_b + f_D\\
R &amp;= \frac{CT_s}{2B} \times\frac{(f_{bd} + f_{bu})}{2}&amp;\ \ \ \ 
&amp;V_r &amp;= \frac{C}{2 f_o}\times\frac{(f_{bd} - f_{bu})}{2}
\end{array} \label{eqn:eqnnumber334}
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li><strong>C</strong> is a constant for speed of light, e.g. <span class="math inline">\(3\times 10^8\)</span> m/s,</li>
<li><strong>B</strong> is chirp (triangular modulation) bandwidth,</li>
<li><span class="math inline">\(\mathbf{T_s}\)</span> is one chirp sweep period (wave period),</li>
<li><span class="math inline">\(\tau\)</span> is time delay,</li>
<li><span class="math inline">\(\mathbf{f_o}\)</span> is operating frequency of transmitted signal,</li>
<li><span class="math inline">\(\mathbf{f_b}\)</span> is frequency of beat (chirp rate),</li>
<li><span class="math inline">\(\mathbf{f_{bu}}\)</span> is frequency of beat (up=ramp rate of chirp),</li>
<li><span class="math inline">\(\mathbf{f_{bd}}\)</span> is frequency of beat (down-ramp rate of chirp),</li>
<li><span class="math inline">\(\mathbf{f_D}\)</span> is Doppler frequency shift,</li>
<li><strong>R</strong> is range (distance) from source to target,</li>
<li><span class="math inline">\(\mathbf{V_r}\)</span> is velocity of moving source.</li>
</ul>
<p>Note that measurements of Doppler shifts may come with distortion, leakage, biases, and ambiguity. Thus, with such uncertainty, our goal is to improve the accuracy of the sensors by calibration. One approach is to simulate sampling of multiple measurements across a wide range of targets positioned in different locations and distances and possibly inducing a wide range of distortions, leakage, biases, and ambiguity. That is where <strong>Monte Carlo</strong> comes into play.</p>
<p>While we may not illustrate the case in this book, we leave readers to investigate this simulation.</p>
<p>Notice that our discussion of <strong>Monte Carlo</strong> illustrates <strong>random sampling</strong>; however, in <strong>bayesian sense</strong>, we draw random samples from a posterior distribution. In the case of a <strong>Normal distribution</strong>, we use its <strong>sufficient statistics</strong>, namely <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^2\)</span>, to help generate the random sample.</p>
</div>
<div id="markov-chain-monte-carlo" class="section level3 hasAnchor">
<h3><span class="header-section-number">8.2.3</span> Markov Chain Monte Carlo  <a href="bayesian2.html#markov-chain-monte-carlo" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Markov Chain Monte Carlo (MCMC)</strong> is a <strong>Monte Carlo</strong> technique that draws random sampling in which each drawn sample is conditionally dependent upon the recent previous drawn sample. This dependency property is one of <strong>Markov Chain</strong> properties <span class="citation">(suppl refs: Robert C., George Casella G. <a href="bibliography.html#ref-ref1002c">2008</a>; Speagle J. S. <a href="bibliography.html#ref-ref993j">2020</a>)</span>.</p>
<p>Unlike the previous random walk example, let us modify our random walk to illustrate <strong>MCMC</strong>. Here, let us introduce a table of transition probabilities so that if our next random step makes a transition to a greater probability than that of our recent previous step, then we take that step; otherwise, we use the direction of the previous step for our next step. Here, we only use three movements (F = walk forward, L = walk left, R = walk right). See Figure <a href="bayesian2.html#fig:mcmc">8.28</a>.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:mcmc"></span>
<img src="mcmc.png" alt="MCMC Model" width="70%" />
<p class="caption">
Figure 8.28: MCMC Model
</p>
</div>

<p>Here is a sample R code for the <strong>MCMC</strong> random walk:</p>

<div class="sourceCode" id="cb919"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb919-1" data-line-number="1">random.walk &lt;-<span class="st"> </span><span class="cf">function</span>(<span class="dt">no_of_walks =</span> <span class="dv">5</span>) {</a>
<a class="sourceLine" id="cb919-2" data-line-number="2">  <span class="kw">set.seed</span>(<span class="dv">123</span>)</a>
<a class="sourceLine" id="cb919-3" data-line-number="3">  transition =<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="fl">0.10</span>, <span class="fl">0.45</span>, <span class="fl">0.45</span>,</a>
<a class="sourceLine" id="cb919-4" data-line-number="4">                        <span class="fl">0.45</span>, <span class="fl">0.10</span>, <span class="fl">0.45</span>, </a>
<a class="sourceLine" id="cb919-5" data-line-number="5">                        <span class="fl">0.45</span>, <span class="fl">0.45</span>, <span class="fl">0.10</span>), <span class="dt">nrow=</span><span class="dv">3</span>, <span class="dt">byrow=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb919-6" data-line-number="6">  direction =<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;F&quot;</span>, <span class="st">&quot;L&quot;</span>, <span class="st">&quot;R&quot;</span>)</a>
<a class="sourceLine" id="cb919-7" data-line-number="7">  walk =<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, no_of_walks)</a>
<a class="sourceLine" id="cb919-8" data-line-number="8">  seq.of.steps  =<span class="st"> </span><span class="kw">rbinom</span>(<span class="dt">n =</span> no_of_walks, <span class="dt">size =</span> <span class="dv">2</span>, <span class="dt">prob=</span><span class="fl">0.50</span>) <span class="op">+</span><span class="st"> </span><span class="dv">1</span></a>
<a class="sourceLine" id="cb919-9" data-line-number="9">  prev.prob =<span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb919-10" data-line-number="10">  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>no_of_walks) {</a>
<a class="sourceLine" id="cb919-11" data-line-number="11">    step =<span class="st"> </span>direction[seq.of.steps [i]]</a>
<a class="sourceLine" id="cb919-12" data-line-number="12">    <span class="cf">if</span> (i <span class="op">&gt;</span><span class="st"> </span><span class="dv">1</span>) {</a>
<a class="sourceLine" id="cb919-13" data-line-number="13">      previous.step =<span class="st"> </span>walk[i<span class="dv">-1</span>]</a>
<a class="sourceLine" id="cb919-14" data-line-number="14">      previous.idx =<span class="st"> </span><span class="kw">which</span>(direction<span class="op">==</span>previous.step)</a>
<a class="sourceLine" id="cb919-15" data-line-number="15">      probability =<span class="st"> </span>transition[previous.idx, seq.of.steps[i]]</a>
<a class="sourceLine" id="cb919-16" data-line-number="16">      <span class="cf">if</span> (previous.step <span class="op">!=</span><span class="st"> </span>step) {</a>
<a class="sourceLine" id="cb919-17" data-line-number="17">        <span class="cf">if</span> (prev.prob <span class="op">&lt;=</span><span class="st"> </span>probability) {</a>
<a class="sourceLine" id="cb919-18" data-line-number="18">          prev.prob =<span class="st"> </span>probability</a>
<a class="sourceLine" id="cb919-19" data-line-number="19">        } <span class="cf">else</span> {</a>
<a class="sourceLine" id="cb919-20" data-line-number="20">          step =<span class="st"> </span>previous.step</a>
<a class="sourceLine" id="cb919-21" data-line-number="21">        }</a>
<a class="sourceLine" id="cb919-22" data-line-number="22">      }</a>
<a class="sourceLine" id="cb919-23" data-line-number="23">    } </a>
<a class="sourceLine" id="cb919-24" data-line-number="24">    walk[i] =<span class="st"> </span>step</a>
<a class="sourceLine" id="cb919-25" data-line-number="25">  }</a>
<a class="sourceLine" id="cb919-26" data-line-number="26">  walk</a>
<a class="sourceLine" id="cb919-27" data-line-number="27">}</a>
<a class="sourceLine" id="cb919-28" data-line-number="28">walk =<span class="st"> </span><span class="kw">random.walk</span>(<span class="dv">100</span>)</a>
<a class="sourceLine" id="cb919-29" data-line-number="29"><span class="kw">head</span>(walk)</a></code></pre></div>
<pre><code>## [1] &quot;L&quot; &quot;R&quot; &quot;L&quot; &quot;R&quot; &quot;R&quot; &quot;F&quot;</code></pre>

<p>Figure <a href="bayesian2.html#fig:randomwalk1">8.29</a> shows the revised random walk.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:randomwalk1"></span>
<img src="DS_files/figure-html/randomwalk1-1.png" alt="Random Walk (MCMC)" width="70%" />
<p class="caption">
Figure 8.29: Random Walk (MCMC)
</p>
</div>

</div>
<div id="metropolis-hastings-monte-carlo" class="section level3 hasAnchor">
<h3><span class="header-section-number">8.2.4</span> Metropolis-Hastings Monte Carlo  <a href="bayesian2.html#metropolis-hastings-monte-carlo" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Metropolis-Hastings Monte Carlo (MHMC)</strong> is an <strong>MCMC</strong> technique so that given an approximation (proposal) distribution, namely <span class="math inline">\(\mathcal{Q}(x^*|x)\)</span>, the goal is to refine the distribution until such that it settles into a target (equilibrium) distribution, namely <span class="math inline">\(\pi(x)\)</span>. While <strong>MHMC</strong> may best suit distributions that do not rather fall under the common list of distributions, let us use <strong>Gaussian</strong> distribution as a case in our discussion for simplicity and illustration, but only up to the constant (meaning, we ignore the normalizer). This section includes supplemental references: <span class="citation">(C.P. Robert <a href="bibliography.html#ref-ref523c">2016</a>; Burke N. <a href="bibliography.html#ref-ref1011n">2018</a>)</span>.</p>
<p><span class="math display">\[\begin{align}
\mathcal{Q}(x^*|x)  
 \propto \left\{ \pi(x; \mu, \sigma^2)= exp \left(-\frac{(x - \mu)^2}{2 \sigma^2}\right) \right\}
\end{align}\]</span></p>
<p>where <span class="math inline">\(x^*\)</span> is a proposed candidate data point.</p>
<p><strong>MHMC</strong> has the following algorithm:</p>
<p><span class="math display">\[
\begin{array}{l}
\text{Initialize the first data point, e.g. }x_0 = \text{&lt;an arbitrary value&gt;}\\
\text{For i in 1,...,n,    repeat the following:}\\
\ \ \ \ \ \ \ \text{Propose a candidate by drawing a sample from }\mathcal{Q}(x^*|x)\\
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 
x^* \sim \mathcal{Q}(x^*|x_{i-1})\\
\ \ \ \ \ \ \ \text{Calculate the Acceptance Probability (A)}:\\
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 
\underbrace{\text{A = min}\left(\frac{\mathcal{Q}(x_{i-1}|x^*)\pi(x^*)}{\mathcal{Q}(x^*|x_{i-1})\pi(x_{i-1})}, 1\right)}_\text{asymmetric}
\ \ \ \ \ \ or \\
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 
\underbrace{\text{A = min}\left(\frac{\pi(x^*)}{\pi(x_{i-1})}, 1\right)}_\text{symmetric}\\
\ \ \ \ \ \ \ \text{Draw a random number u and campare with A}\\
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 
\ \ \ \ \ \ \ u \sim \text{Uniform}(0,1)\\
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 
\ \ \ \ \ \ \ \text{If u &lt; A, we accept the proposal}\\
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 
x_i = x^*\\
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 
\text{Otherwise, we reject:}\\
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 
x_i = x_{i-1}\\
\text{return x  where  x = }(x_1, x_2,...)
\end{array}
\]</span></p>
<p>Note that <span class="math inline">\(\frac{\mathcal{Q}(x_{i-1}|x^*)}{\mathcal{Q}(x^*|x_{i-1})}\)</span> is called the <strong>Hasting ratio</strong>. If the <strong>ratio</strong> is 1, it means that the distribution is symmetric; thus, we can use the <strong>symmetric</strong> version of the <strong>acceptance probability</strong> equation.</p>
<p>The <strong>proposed candidate</strong> uses the previous sample value with added noise (perturbation) so that, in our case, we have the following:</p>
<p><span class="math display">\[\begin{align}
x^* = x_{i-1} + \mathcal{N}(0, 1)
\end{align}\]</span></p>
<p>Or in the case of simulating a random walk for <strong>MHMC</strong>, we also can use:</p>
<p><span class="math display">\[\begin{align}
x^* = x_{i-1} + \mathcal{U}(x_{i-1} - 1, x_{i-1} + 1)
\end{align}\]</span></p>
<p>Below is a simple example of <strong>MHMC</strong> implementation in R code (see Figure <a href="bayesian2.html#fig:mhmc">8.30</a>).</p>

<div class="sourceCode" id="cb921"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb921-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">2020</span>)</a>
<a class="sourceLine" id="cb921-2" data-line-number="2">kernel &lt;-<span class="st"> </span><span class="cf">function</span>(x) { <span class="co"># Gaussian Kernel</span></a>
<a class="sourceLine" id="cb921-3" data-line-number="3">  mu =<span class="st"> </span><span class="dv">0</span>; sd =<span class="st"> </span><span class="dv">1</span></a>
<a class="sourceLine" id="cb921-4" data-line-number="4">  <span class="kw">exp</span>(<span class="op">-</span>(x <span class="op">-</span><span class="st"> </span>mu)<span class="op">^</span><span class="dv">2</span><span class="op">/</span><span class="st"> </span>(<span class="dv">2</span> <span class="op">*</span><span class="st"> </span>sd))</a>
<a class="sourceLine" id="cb921-5" data-line-number="5">}</a>
<a class="sourceLine" id="cb921-6" data-line-number="6">pi.func &lt;-<span class="st"> </span><span class="cf">function</span>(x) { <span class="kw">kernel</span>(x) }</a>
<a class="sourceLine" id="cb921-7" data-line-number="7">metropolis.hasting &lt;-<span class="st"> </span><span class="cf">function</span>(n) { <span class="co"># symmetric</span></a>
<a class="sourceLine" id="cb921-8" data-line-number="8">  x =<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>,n)</a>
<a class="sourceLine" id="cb921-9" data-line-number="9">  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">2</span><span class="op">:</span>n) {</a>
<a class="sourceLine" id="cb921-10" data-line-number="10">      previous.x =<span class="st"> </span>x[i<span class="dv">-1</span>]</a>
<a class="sourceLine" id="cb921-11" data-line-number="11">      proposed.x =<span class="st">  </span>previous.x <span class="op">+</span><span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n=</span><span class="dv">1</span>, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span><span class="dv">1</span>) </a>
<a class="sourceLine" id="cb921-12" data-line-number="12">      A =<span class="st"> </span><span class="kw">min</span>( <span class="kw">pi.func</span>(proposed.x)<span class="op">/</span><span class="kw">pi.func</span>(previous.x), <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb921-13" data-line-number="13">      u =<span class="st"> </span><span class="kw">runif</span>(<span class="dt">n =</span> <span class="dv">1</span>, <span class="dt">min=</span><span class="dv">0</span>, <span class="dt">max=</span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb921-14" data-line-number="14">      <span class="cf">if</span> ( u <span class="op">&gt;</span><span class="st"> </span>A) {</a>
<a class="sourceLine" id="cb921-15" data-line-number="15">        proposed.x =<span class="st"> </span>previous.x</a>
<a class="sourceLine" id="cb921-16" data-line-number="16">      }</a>
<a class="sourceLine" id="cb921-17" data-line-number="17">      x[i] =<span class="st"> </span>proposed.x</a>
<a class="sourceLine" id="cb921-18" data-line-number="18">  }</a>
<a class="sourceLine" id="cb921-19" data-line-number="19">  x</a>
<a class="sourceLine" id="cb921-20" data-line-number="20">}</a>
<a class="sourceLine" id="cb921-21" data-line-number="21">plot.metropolis &lt;-<span class="st"> </span><span class="cf">function</span>(n) {</a>
<a class="sourceLine" id="cb921-22" data-line-number="22">  <span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="op">-</span><span class="dv">4</span>,<span class="dv">4</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="fl">0.8</span>), </a>
<a class="sourceLine" id="cb921-23" data-line-number="23">     <span class="dt">xlab=</span><span class="st">&quot;x&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;density&quot;</span>,</a>
<a class="sourceLine" id="cb921-24" data-line-number="24">     <span class="dt">main=</span><span class="kw">paste0</span>(<span class="st">&quot;MHCM (n=&quot;</span>, n, <span class="st">&quot;)&quot;</span>),  <span class="dt">frame=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb921-25" data-line-number="25">  <span class="kw">grid</span>()</a>
<a class="sourceLine" id="cb921-26" data-line-number="26">  x =<span class="st"> </span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">5</span>, <span class="dv">5</span>, <span class="dt">length.out=</span><span class="dv">100</span>)</a>
<a class="sourceLine" id="cb921-27" data-line-number="27">  <span class="kw">curve</span>(<span class="kw">dnorm</span>(x, <span class="dv">0</span>, <span class="dv">1</span>), <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">lwd=</span><span class="dv">1</span>, <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb921-28" data-line-number="28">  pt =<span class="st"> </span><span class="kw">density</span>(<span class="kw">metropolis.hasting</span>(n))</a>
<a class="sourceLine" id="cb921-29" data-line-number="29">  <span class="kw">lines</span>(pt<span class="op">$</span>x, pt<span class="op">$</span>y, <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>, <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">lty=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb921-30" data-line-number="30">}</a>
<a class="sourceLine" id="cb921-31" data-line-number="31"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))</a>
<a class="sourceLine" id="cb921-32" data-line-number="32"><span class="kw">plot.metropolis</span>(<span class="dt">n=</span><span class="dv">10</span>)</a>
<a class="sourceLine" id="cb921-33" data-line-number="33"><span class="kw">plot.metropolis</span>(<span class="dt">n=</span><span class="dv">50</span>)</a>
<a class="sourceLine" id="cb921-34" data-line-number="34"><span class="kw">plot.metropolis</span>(<span class="dt">n=</span><span class="dv">500</span>)</a>
<a class="sourceLine" id="cb921-35" data-line-number="35"><span class="kw">plot.metropolis</span>(<span class="dt">n=</span><span class="dv">10000</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:mhmc"></span>
<img src="DS_files/figure-html/mhmc-1.png" alt="Metropolis-Hastings MC (MHMC)" width="100%" />
<p class="caption">
Figure 8.30: Metropolis-Hastings MC (MHMC)
</p>
</div>

</div>
<div id="hamiltonian-monte-carlo" class="section level3 hasAnchor">
<h3><span class="header-section-number">8.2.5</span> Hamiltonian Monte Carlo  <a href="bayesian2.html#hamiltonian-monte-carlo" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Hamiltonian Monte Carlo (HMC)</strong> algorithm, also called <strong>Hybrid Monte Carlo</strong>, extends the concept of the <strong>Metropolis-Hastings</strong> algorithm <span class="citation">(Tianqi Chen et al. <a href="bibliography.html#ref-ref542t">2014</a>)</span>.</p>
<p>We start with the simple <strong>Monte Carlo</strong> concept of operating on a posterior distribution, given by the notation <span class="math inline">\(\mathcal{Q}(q) \propto P(q|D)\)</span> where <strong>q</strong> is a <strong>latent variable</strong> for which we simulate drawing samples from <strong>D</strong> observations. We then introduce an <strong>auxiliary variable</strong>, namely <strong>p</strong>, so that we form a joint distribution like so:</p>
<p><span class="math display">\[\begin{align}
\mathcal{Q}(q, p) = \mathcal{Q}(q|p)\mathcal{Q}(p)\ \ \ \ \ \leftarrow \text{(chain rule)}
\end{align}\]</span></p>
<p>Here, <strong>HMC</strong> uses the Hamiltonian dynamics in physics to describe the conservation of energy so that our joint distribution adapts to the <strong>Hamiltonian</strong> equation below:</p>
<p><span class="math display">\[\begin{align}
\mathcal{Q}(q, p) \propto exp^{-H(q,p)} 
\end{align}\]</span></p>
<p>The idea is to decompose the equation above into <strong>kinetic (kinematic) energy</strong> and <strong>potential energy</strong> functions so that we then have the following:</p>
<p><span class="math display">\[\begin{align}
\mathcal{H}(q, p) {}&amp;= - \log_e \mathcal{Q}(q,p) \\
&amp;= \underbrace{ \underbrace{-\log_e \mathcal{Q}(p|q)}_\text{Kinetic Energy}}_\text{K(p)} - 
   \underbrace{ \underbrace{\log_e \mathcal{Q}(q)}_\text{Potential Energy}}_\text{U(q)}
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(\mathbf{H(q,p)}\)</span> is the total energy of the system,</li>
<li><span class="math inline">\(\mathbf{U(q)}\)</span> is the potential energy (PE) function,</li>
<li><span class="math inline">\(\mathbf{K(p)}\)</span> is the kinetic energy (KE) function,</li>
<li><strong>q</strong> is the position state, described in terms of d-dimensional vector,</li>
<li><strong>p</strong> is the momentum state, described in terms of d-dimensional vector.</li>
</ul>
<p>The dynamics of particles in motion are described by a <strong>Hamiltonian system</strong> in which particles flow through a landscape of high-dimensionality, governed by forces of kinetic and potential energies. Such particles are sampled and approximated in terms of their position and momentum, for which the potential energy depends only on position (<strong>q</strong>) and the kinetic energy depends only on the momentum (<strong>p</strong>), expressed mathematically as so:</p>
<p><span class="math display">\[\begin{align}
\underbrace{ U(q) = \frac{q^2}{2} \ \ \ \ \ \ \ \ \ \  K(p) = \frac{p^2}{2}}_\text{univariate}
\ \ \ or \ \ \ \ \
\underbrace{ U(q) = \frac{q\Sigma^{-1}q}{2} \ \ \ \ \ \ \ \ \ \  K(p) = \frac{p \cdot p}{2}}_\text{multivariate}
\end{align}\]</span></p>
<p>where <span class="math inline">\(\Sigma^{-1}\)</span> is a covariance matrix for a gaussian distribution - assuming some rough perturbation.</p>
<p>The Hamiltonian functions are implemented as such:</p>

<div class="sourceCode" id="cb922"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb922-1" data-line-number="1">U &lt;-<span class="st"> </span><span class="cf">function</span>(q) {</a>
<a class="sourceLine" id="cb922-2" data-line-number="2">  d =<span class="st"> </span><span class="dv">2</span> <span class="co"># d-dimension</span></a>
<a class="sourceLine" id="cb922-3" data-line-number="3">  Sigma =<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">1</span>, <span class="fl">0.8</span>, <span class="fl">0.8</span>, <span class="dv">1</span>), <span class="dt">nrow=</span>d, <span class="dt">byrow=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb922-4" data-line-number="4">  <span class="kw">sum</span>( (q <span class="op">%*%</span><span class="st"> </span>Sigma<span class="op">^-</span><span class="dv">1</span>) <span class="op">*</span><span class="st"> </span>q ) <span class="op">/</span><span class="st"> </span><span class="dv">2</span></a>
<a class="sourceLine" id="cb922-5" data-line-number="5">}</a>
<a class="sourceLine" id="cb922-6" data-line-number="6">K &lt;-<span class="st"> </span><span class="cf">function</span>(p) {</a>
<a class="sourceLine" id="cb922-7" data-line-number="7">  <span class="kw">sum</span>( p <span class="op">*</span><span class="st"> </span>p) <span class="op">/</span><span class="st"> </span><span class="dv">2</span></a>
<a class="sourceLine" id="cb922-8" data-line-number="8">}</a>
<a class="sourceLine" id="cb922-9" data-line-number="9">H &lt;-<span class="st"> </span><span class="cf">function</span>(q,p) {  <span class="kw">U</span>(q) <span class="op">+</span><span class="st"> </span><span class="kw">K</span>(p) }</a>
<a class="sourceLine" id="cb922-10" data-line-number="10">MH.correction &lt;-<span class="st"> </span><span class="cf">function</span>(q, p, q.new, p.new) {</a>
<a class="sourceLine" id="cb922-11" data-line-number="11">  <span class="kw">exp</span>(<span class="kw">H</span>(q, p) <span class="op">-</span><span class="st"> </span><span class="kw">H</span>(q.new, p.new))</a>
<a class="sourceLine" id="cb922-12" data-line-number="12">}</a></code></pre></div>

<p>Changes in position and momentum that occur over time are described in terms of the following <strong>Hamiltonian equations</strong>:</p>
<p><span class="math display">\[\begin{align}
\frac{dq}{dt} = +\frac{\partial H}{\partial p} = +\frac{\partial K}{\partial p}
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 
\frac{dp}{dt} = - \frac{\partial H}{\partial q} = -\frac{\partial K}{\partial q} - \frac{\partial U}{\partial q} 
\end{align}\]</span></p>
<p>The idea is to calculate the gradient of the Hamiltonian function - the direction towards the next state (next position and momentum):</p>
<p><span class="math display">\[\begin{align}
(q_{t+1}, p_{t+1}) = (q_t, p_t) + \epsilon \times \nabla \mathcal{H}(q_t, p_t)
\end{align}\]</span></p>
<p>Alternatively in <strong>HMC</strong>, we use the <strong>LeapFrog algorithm</strong> as outlined below <span class="citation">(Wei-Lun Chao <a href="bibliography.html#ref-ref657w">2015</a>; Mohammed Alfaki M. <a href="bibliography.html#ref-ref1020m">2008</a>)</span>:</p>
<p><span class="math display">\[
\begin{array}{l}
p = p - \frac{\epsilon}{2}\frac{\partial U}{\partial q}(q)\\
\text{for i in 1,...,L},\ \ \ \text{repeat the following}:\\
\ \ \ \ \ \ \ \ \ \  \begin{array}{l}
q = q + \epsilon M^{-1}  p\\
if\ (i\ne L)\ p = p- \frac{\epsilon}{2}\frac{\partial U}{\partial q}(q)\\
\end{array}\\
p = p - \frac{\epsilon}{2}\frac{\partial U}{\partial q}(q)\\
(q^*, p^*) = (q^{(L)}, p^{(L)})
\end{array}
\]</span></p>
<p>where <span class="math inline">\(M^{-1}\)</span> serves as a mass matrix (usually a covariance/identity matrix) and epsilon <span class="math inline">\(\epsilon\)</span> is a time interval (stepsize).</p>
<p>Because time is continuous, we have to discretize time to simulate <strong>Hamiltonian dynamics</strong> using a time interval value as stepsize denoted by <span class="math inline">\(\epsilon\)</span>.</p>
<p>The <strong>LeapFrog</strong> algorithm is implemented in R code like so: </p>

<div class="sourceCode" id="cb923"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb923-1" data-line-number="1"><span class="kw">library</span>(pracma)</a>
<a class="sourceLine" id="cb923-2" data-line-number="2">U.gradient &lt;-<span class="st">  </span>jacobian</a>
<a class="sourceLine" id="cb923-3" data-line-number="3">leap.frog &lt;-<span class="st"> </span><span class="cf">function</span>(q, p, <span class="dt">e =</span> <span class="fl">0.10</span>, <span class="dt">L=</span><span class="dv">10</span>) {</a>
<a class="sourceLine" id="cb923-4" data-line-number="4">  p =<span class="st"> </span>p <span class="op">-</span><span class="st"> </span>e<span class="op">/</span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="kw">U.gradient</span>(U,q)</a>
<a class="sourceLine" id="cb923-5" data-line-number="5">  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>L) {</a>
<a class="sourceLine" id="cb923-6" data-line-number="6">    q =<span class="st"> </span>q <span class="op">+</span><span class="st"> </span>e <span class="op">*</span><span class="st"> </span>p</a>
<a class="sourceLine" id="cb923-7" data-line-number="7">    <span class="cf">if</span> (i <span class="op">!=</span><span class="st"> </span>L) { p =<span class="st"> </span>p <span class="op">-</span><span class="st"> </span>e<span class="op">/</span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="kw">U.gradient</span>(U,q) }</a>
<a class="sourceLine" id="cb923-8" data-line-number="8">  }</a>
<a class="sourceLine" id="cb923-9" data-line-number="9">  p =<span class="st"> </span>p <span class="op">-</span><span class="st"> </span>e<span class="op">/</span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="kw">U.gradient</span>(U,q)</a>
<a class="sourceLine" id="cb923-10" data-line-number="10">  <span class="kw">list</span>(<span class="st">&quot;q&quot;</span> =<span class="st"> </span>q, <span class="st">&quot;p&quot;</span> =<span class="st"> </span>p)</a>
<a class="sourceLine" id="cb923-11" data-line-number="11">}</a></code></pre></div>

<p>With all that, <strong>HMC</strong> has the following algorithm:</p>
<p><span class="math display">\[
\begin{array}{l}
\text{Initialize the position state } q_0 \text{ drawn from } q \sim \mathcal{N}(0, \Sigma^{-1})\\
\text{For t in 1,2,...  repeat the following:}\\
\ \ \ \ \ \ \ \text{Propose a candidate momentum by drawing a sample from }\\
\ \ \ \ \ \ \ \ \ \ \ \ \mathcal{Q}(p_{t-1}) \text{ - the canonical distribution}\\
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 
p^* \sim \mathcal{N}(0, M) \leftarrow \mathcal{Q}(p_{t-1}) \\
\ \ \ \ \ \ \ \text{Perform LeapFrog Algorithm}\\
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (q^*, p^*) = LeapFrog(q_{t-1}, p_{t-1}, \epsilon, L=5)\\
\ \ \ \ \ \ \ \text{Calculate the Acceptance Probability (A) - (}\mathbf{\text{MH}} \text{ correction):}\\
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 
\text{A = min}\left(exp\left[H(q_{t-1},p_{t-1}) - H(q^*, p^*)\right], 1\right)
\\
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 
\ \ \ \ \ \ \ u \sim \text{Uniform}(0,1)\\
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 
\ \ \ \ \ \ \ \text{If u &lt; A, we accept the proposal}\\
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 
q_t = q^*\\
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 
\text{Otherwise, we reject:}\\
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 
q_t = q_{t-1}\\
\text{return q  where  q = }(q_1, q_2,...)
\end{array}
\]</span></p>
<p>Here is an example implementation of <strong>HMC</strong> in R code for a bivariate normal case (motivated by a python implementation by Gergely-Flamich):</p>



<div class="sourceCode" id="cb924"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb924-1" data-line-number="1"><span class="kw">library</span>(MASS)</a>
<a class="sourceLine" id="cb924-2" data-line-number="2"><span class="kw">set.seed</span>(<span class="dv">10</span>)</a>
<a class="sourceLine" id="cb924-3" data-line-number="3">HMC &lt;-<span class="st"> </span><span class="cf">function</span>(<span class="dt">N =</span> <span class="dv">300</span>, <span class="dt">L =</span> <span class="dv">10</span>, <span class="dt">epsilon =</span> <span class="fl">0.10</span>) {</a>
<a class="sourceLine" id="cb924-4" data-line-number="4">  d =<span class="st"> </span><span class="dv">2</span> <span class="co"># Dimension</span></a>
<a class="sourceLine" id="cb924-5" data-line-number="5">  current.q =<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, d) </a>
<a class="sourceLine" id="cb924-6" data-line-number="6">  q =<span class="st"> </span><span class="kw">matrix</span>(<span class="dv">0</span>, <span class="dt">nrow =</span> N, <span class="dt">ncol=</span>d, <span class="dt">byrow=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb924-7" data-line-number="7">  <span class="cf">for</span> (t <span class="cf">in</span> <span class="dv">2</span><span class="op">:</span>N) {</a>
<a class="sourceLine" id="cb924-8" data-line-number="8">    current.p =<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n =</span> d, <span class="dt">mean =</span> <span class="dv">0</span>, <span class="dt">sd =</span> <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb924-9" data-line-number="9">    state =<span class="st"> </span><span class="kw">leap.frog</span>(current.q, current.p , <span class="dt">e =</span> epsilon, <span class="dt">L =</span> L)</a>
<a class="sourceLine" id="cb924-10" data-line-number="10">    proposed.q =<span class="st"> </span>state<span class="op">$</span>q</a>
<a class="sourceLine" id="cb924-11" data-line-number="11">    proposed.p =<span class="st"> </span>state<span class="op">$</span>p</a>
<a class="sourceLine" id="cb924-12" data-line-number="12">    A =<span class="st"> </span><span class="kw">min</span>( <span class="kw">MH.correction</span>(current.q, current.p, </a>
<a class="sourceLine" id="cb924-13" data-line-number="13">                           proposed.q, proposed.p), <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb924-14" data-line-number="14">    u =<span class="st"> </span><span class="kw">runif</span>(<span class="dt">n =</span> <span class="dv">1</span>, <span class="dt">min=</span><span class="dv">0</span>, <span class="dt">max=</span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb924-15" data-line-number="15">    <span class="cf">if</span> ( u <span class="op">&gt;</span><span class="st"> </span>A) {</a>
<a class="sourceLine" id="cb924-16" data-line-number="16">      proposed.q =<span class="st"> </span>current.q</a>
<a class="sourceLine" id="cb924-17" data-line-number="17">    }</a>
<a class="sourceLine" id="cb924-18" data-line-number="18">    q[t,] =<span class="st"> </span>proposed.q</a>
<a class="sourceLine" id="cb924-19" data-line-number="19">  }</a>
<a class="sourceLine" id="cb924-20" data-line-number="20">  q</a>
<a class="sourceLine" id="cb924-21" data-line-number="21">}</a>
<a class="sourceLine" id="cb924-22" data-line-number="22">N =<span class="st"> </span><span class="dv">300</span>; L =<span class="st"> </span><span class="dv">10</span>; epsilon =<span class="st"> </span><span class="fl">0.10</span> </a>
<a class="sourceLine" id="cb924-23" data-line-number="23">q =<span class="st"> </span><span class="kw">HMC</span>(N, L, epsilon)</a></code></pre></div>

<p>Figure <a href="bayesian2.html#fig:hmc">8.31</a> shows the left-side plot of only 20 data points using HMM random walk. The right-side plot shows the complete sampling from the HMM random walk.</p>

<div class="sourceCode" id="cb925"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb925-1" data-line-number="1"><span class="kw">library</span>(KernSmooth)</a>
<a class="sourceLine" id="cb925-2" data-line-number="2">data =<span class="st"> </span><span class="kw">cbind</span>(q[,<span class="dv">1</span>], q[,<span class="dv">2</span>])</a>
<a class="sourceLine" id="cb925-3" data-line-number="3">kde.grid =<span class="st"> </span><span class="kw">bkde2D</span>(<span class="dt">x =</span> data, <span class="dt">bandwidth=</span><span class="dv">3</span>)</a>
<a class="sourceLine" id="cb925-4" data-line-number="4"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</a>
<a class="sourceLine" id="cb925-5" data-line-number="5"><span class="kw">contour</span>(kde.grid<span class="op">$</span>x1, kde.grid<span class="op">$</span>x2, kde.grid<span class="op">$</span>fhat,</a>
<a class="sourceLine" id="cb925-6" data-line-number="6">        <span class="dt">xlim=</span><span class="kw">range</span>(<span class="op">-</span><span class="fl">2.5</span>, <span class="fl">2.5</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="op">-</span><span class="fl">3.5</span>, <span class="fl">3.5</span>), </a>
<a class="sourceLine" id="cb925-7" data-line-number="7">        <span class="dt">xlab=</span><span class="st">&quot;q&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;p&quot;</span>, <span class="dt">col =</span> <span class="st">&quot;darksalmon&quot;</span>,</a>
<a class="sourceLine" id="cb925-8" data-line-number="8">         <span class="dt">main=</span><span class="kw">paste0</span>(<span class="st">&quot;HMM (Random Walk)&quot;</span>)</a>
<a class="sourceLine" id="cb925-9" data-line-number="9">        )</a>
<a class="sourceLine" id="cb925-10" data-line-number="10">x1 =<span class="st"> </span><span class="dv">0</span>; x2 =<span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb925-11" data-line-number="11"><span class="kw">points</span>(x1, x2, <span class="dt">pch=</span><span class="dv">20</span>, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>)</a>
<a class="sourceLine" id="cb925-12" data-line-number="12"><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">20</span>) {</a>
<a class="sourceLine" id="cb925-13" data-line-number="13">  x =<span class="st">  </span>q[i,<span class="dv">1</span>] <span class="op">-</span><span class="st"> </span>x1; y =<span class="st">  </span>q[i,<span class="dv">2</span>] <span class="op">-</span><span class="st"> </span>x2</a>
<a class="sourceLine" id="cb925-14" data-line-number="14">  <span class="kw">segments</span>(x1, x2, x1 <span class="op">+</span><span class="st"> </span>x, x2, <span class="dt">col=</span><span class="st">&quot;deepskyblue&quot;</span>)</a>
<a class="sourceLine" id="cb925-15" data-line-number="15">  <span class="kw">segments</span>(x1 <span class="op">+</span><span class="st"> </span>x, x2, x1 <span class="op">+</span><span class="st"> </span>x, x2 <span class="op">+</span><span class="st"> </span>y, <span class="dt">col=</span><span class="st">&quot;deepskyblue&quot;</span>)</a>
<a class="sourceLine" id="cb925-16" data-line-number="16">  x1 =<span class="st"> </span>q[i,<span class="dv">1</span>]; x2 =<span class="st"> </span>q[i,<span class="dv">2</span>]</a>
<a class="sourceLine" id="cb925-17" data-line-number="17">  <span class="kw">points</span>(x1, x2, <span class="dt">pch=</span><span class="dv">20</span>)</a>
<a class="sourceLine" id="cb925-18" data-line-number="18">}</a>
<a class="sourceLine" id="cb925-19" data-line-number="19"><span class="kw">contour</span>(kde.grid<span class="op">$</span>x1, kde.grid<span class="op">$</span>x2, kde.grid<span class="op">$</span>fhat,</a>
<a class="sourceLine" id="cb925-20" data-line-number="20">        <span class="dt">xlim=</span><span class="kw">range</span>(<span class="op">-</span><span class="fl">2.5</span>, <span class="fl">2.5</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="op">-</span><span class="fl">3.5</span>, <span class="fl">3.5</span>), </a>
<a class="sourceLine" id="cb925-21" data-line-number="21">        <span class="dt">xlab=</span><span class="st">&quot;q&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;p&quot;</span>, <span class="dt">col =</span> <span class="st">&quot;darksalmon&quot;</span>,</a>
<a class="sourceLine" id="cb925-22" data-line-number="22">         <span class="dt">main=</span><span class="kw">paste0</span>(<span class="st">&quot;HMM Sampling (Bivariate)&quot;</span>)</a>
<a class="sourceLine" id="cb925-23" data-line-number="23">        )</a>
<a class="sourceLine" id="cb925-24" data-line-number="24"><span class="kw">points</span>(q[,<span class="dv">1</span>], q[,<span class="dv">2</span>], <span class="dt">pch=</span><span class="dv">4</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:hmc"></span>
<img src="DS_files/figure-html/hmc-1.png" alt="Hamiltonian Monte Carlo (HMC)" width="70%" />
<p class="caption">
Figure 8.31: Hamiltonian Monte Carlo (HMC)
</p>
</div>

<p>We leave readers to investigate other enhancements to the <strong>HMC</strong> algorithm, for example, tuning the stepsize <span class="math inline">\(\epsilon\)</span>. Also, investigate <strong>MCMC</strong> for <strong>Lagrangian Dynamics</strong>.</p>
</div>
<div id="gibbs-sampling" class="section level3 hasAnchor">
<h3><span class="header-section-number">8.2.6</span> Gibbs Sampling <a href="bayesian2.html#gibbs-sampling" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Gibbs Sampler</strong> algorithm is a variant of the <strong>Metropolis-Hastings MCMC</strong> algorithm in that instead of performing an acceptance-rejection evaluation, proposed probabilities are always accepted <span class="citation">(Burke N. <a href="bibliography.html#ref-ref1011n">2018</a>)</span>. The algorithm operates on conditional probabilities such that we estimate the distribution of one random variable conditioned on all other random variables so that given the following (for a case with <strong>p</strong> dimensions),</p>
<p><span class="math display">\[\begin{align}
X = (X_1, X_2,...,X_p)
\end{align}\]</span></p>
<p>the goal is to generate a random sample from the following joint distribution:</p>
<p><span class="math display">\[\begin{align}
P(X_i|X_1,X_2,...,X_p) =
\frac{P(X_1,X_2,...,X_p)}{\int P(X_1,X_2,...,X_p) d_{X_i}}
\end{align}\]</span></p>
<p>Here, <strong>Gibbs sampler</strong> simplifies the calculation by handling individual random variables like so:</p>
<p><span class="math display">\[\begin{align}
\begin{array}{lll}
X_1^{(k+1)} &amp;\sim P(X_1| X_{\backslash 1 }^{(k)} ) &amp;\equiv P(X_1|X_2^{(k)}, X_3^{(k)},...,X_p^{(k)})\\
X_2^{(k+1)} &amp;\sim P(X_2| X_1^{(k+1)} , X_{\backslash 2 }^{(k)} ) &amp;\equiv  P(X_2|X_1^{(k+1)}, X_3^{(k)},...,X_p^{(k)})\\
X_3^{(k+1)} &amp;\sim P(X_3| X_1^{(k+1)}, X_2^{(k+1)}, X_{\backslash 3 }^{(k)} ) &amp;\equiv P(X_3|X_1^{(k+1)}, X_2^{(k+1)},X_4,...,X_p^{(k)})\\
\vdots&amp;\vdots&amp;\vdots \nonumber \\
X_p^{(k+1)} &amp;\sim P(X_p| X_{\backslash p }^{(k+1)} ) &amp;\equiv P(X_p|X_1^{(k+1)}, X_2^{(k+1)},...,X_{p-1}^{(k+1)})\\
\end{array}
\end{align}\]</span></p>
<p>In general, <strong>Gibbs Sampling</strong> has the following algorithm:</p>
<p><span class="math display">\[
\begin{array}{l}
\text{Initialize the variables } X\ where\ X = (X_1, X_2, ..., X_p)\\
\text{For k in 1,2,...  repeat the following:}\\
\ \ \ \ \ \ \ \text{For i in 1,...,p  repeat the following:}\\
\ \ \ \ \ \ \ \ \ \ \ \ \text{Sample }\ X_i\text{, given all variables except the ith X variable}\\
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ X_i^{k+1} = P\left(X_i|X_{\backslash i}^{(k) },X_{\backslash i}^{(k+1)}\right)\\
\text{return X  where  X = }(X_1, X_2,..., X_p)
\end{array}
\]</span></p>
<p>Below is a naive implementation of <strong>Gibbs Sampler</strong> in R code using only two random variables. Note that <strong>Gibbs</strong> sampling for posterior distribution is discussed in <strong>JAGS modeling</strong> in a section ahead:</p>

<div class="sourceCode" id="cb926"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb926-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">2020</span>)</a>
<a class="sourceLine" id="cb926-2" data-line-number="2">gibbs.sampler &lt;-<span class="st"> </span><span class="cf">function</span>(N, <span class="dt">mu0 =</span> <span class="dv">1</span>, <span class="dt">mu1 =</span> <span class="dv">1</span>, <span class="dt">scale =</span> <span class="fl">0.8</span>) {</a>
<a class="sourceLine" id="cb926-3" data-line-number="3">  x1 =<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, N); x2 =<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, N)</a>
<a class="sourceLine" id="cb926-4" data-line-number="4">  x1[<span class="dv">1</span>] =<span class="st"> </span>mu0; x2[<span class="dv">1</span>] =<span class="st"> </span>mu1</a>
<a class="sourceLine" id="cb926-5" data-line-number="5">  <span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>N) {</a>
<a class="sourceLine" id="cb926-6" data-line-number="6">    x1[k] =<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n=</span><span class="dv">1</span>, <span class="dt">mean =</span> x2[k], <span class="dt">sd =</span> <span class="kw">sqrt</span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>scale<span class="op">^</span><span class="dv">2</span>))</a>
<a class="sourceLine" id="cb926-7" data-line-number="7">    x2[k] =<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n=</span><span class="dv">1</span>, <span class="dt">mean =</span> x1[k], <span class="dt">sd =</span> <span class="kw">sqrt</span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>scale<span class="op">^</span><span class="dv">2</span>))</a>
<a class="sourceLine" id="cb926-8" data-line-number="8">  }</a>
<a class="sourceLine" id="cb926-9" data-line-number="9">  <span class="kw">list</span>(<span class="st">&quot;x1&quot;</span> =<span class="st"> </span>x1, <span class="st">&quot;x2&quot;</span> =<span class="st"> </span>x2)</a>
<a class="sourceLine" id="cb926-10" data-line-number="10">}</a>
<a class="sourceLine" id="cb926-11" data-line-number="11">N =<span class="st"> </span><span class="dv">200</span></a>
<a class="sourceLine" id="cb926-12" data-line-number="12">X =<span class="st"> </span><span class="kw">gibbs.sampler</span>(N)</a>
<a class="sourceLine" id="cb926-13" data-line-number="13"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</a>
<a class="sourceLine" id="cb926-14" data-line-number="14"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="op">-</span><span class="dv">2</span>,<span class="dv">2</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="op">-</span><span class="dv">2</span>,<span class="dv">2</span>), </a>
<a class="sourceLine" id="cb926-15" data-line-number="15">     <span class="dt">xlab=</span><span class="st">&quot;x1&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;x2&quot;</span>,</a>
<a class="sourceLine" id="cb926-16" data-line-number="16">     <span class="dt">main=</span><span class="kw">paste0</span>(<span class="st">&quot;Gibbs Sampler (Random Walk)&quot;</span>),  <span class="dt">frame=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb926-17" data-line-number="17"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>)</a>
<a class="sourceLine" id="cb926-18" data-line-number="18">x1 =<span class="st"> </span><span class="dv">0</span>; x2 =<span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb926-19" data-line-number="19"><span class="kw">points</span>(x1, x2, <span class="dt">pch=</span><span class="dv">20</span>, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>)</a>
<a class="sourceLine" id="cb926-20" data-line-number="20"><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">20</span>) {</a>
<a class="sourceLine" id="cb926-21" data-line-number="21">  x =<span class="st">  </span>X<span class="op">$</span>x1[i] <span class="op">-</span><span class="st"> </span>x1; y =<span class="st">  </span>X<span class="op">$</span>x2[i] <span class="op">-</span><span class="st"> </span>x2</a>
<a class="sourceLine" id="cb926-22" data-line-number="22">  <span class="kw">segments</span>(x1, x2, x1 <span class="op">+</span><span class="st"> </span>x, x2, <span class="dt">col=</span><span class="st">&quot;deepskyblue&quot;</span>)</a>
<a class="sourceLine" id="cb926-23" data-line-number="23">  <span class="kw">segments</span>(x1 <span class="op">+</span><span class="st"> </span>x, x2, x1 <span class="op">+</span><span class="st"> </span>x, x2 <span class="op">+</span><span class="st"> </span>y, <span class="dt">col=</span><span class="st">&quot;deepskyblue&quot;</span>)</a>
<a class="sourceLine" id="cb926-24" data-line-number="24">  x1 =<span class="st"> </span>X<span class="op">$</span>x1[i]; x2 =<span class="st"> </span>X<span class="op">$</span>x2[i]</a>
<a class="sourceLine" id="cb926-25" data-line-number="25">  <span class="kw">points</span>(x1, x2, <span class="dt">pch=</span><span class="dv">20</span>)</a>
<a class="sourceLine" id="cb926-26" data-line-number="26">}</a>
<a class="sourceLine" id="cb926-27" data-line-number="27"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="op">-</span><span class="dv">2</span>,<span class="dv">2</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="op">-</span><span class="dv">2</span>,<span class="dv">2</span>), </a>
<a class="sourceLine" id="cb926-28" data-line-number="28">     <span class="dt">xlab=</span><span class="st">&quot;x1&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;x2&quot;</span>,</a>
<a class="sourceLine" id="cb926-29" data-line-number="29">     <span class="dt">main=</span><span class="kw">paste0</span>(<span class="st">&quot;Gibbs Sampler (Bivariate)&quot;</span>),  <span class="dt">frame=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb926-30" data-line-number="30"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>)</a>
<a class="sourceLine" id="cb926-31" data-line-number="31"><span class="kw">points</span>(X<span class="op">$</span>x1, X<span class="op">$</span>x2, <span class="dt">pch=</span><span class="dv">20</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:gibbs"></span>
<img src="DS_files/figure-html/gibbs-1.png" alt="Gibbs Sampler" width="70%" />
<p class="caption">
Figure 8.32: Gibbs Sampler
</p>
</div>

<p>We leave readers to investigate <strong>blocked Gibbs sampling</strong>. The idea is to operate on groups (called blocks) of random variables instead of individual variables.</p>
<p>Also, other important control properties for <strong>Gibbs Sampling</strong> are <strong>Burn-in</strong> and <strong>Thinning</strong>. The <strong>Burn-in</strong> or <strong>Warm-up</strong>* is discussed under <strong>JAGS modeling</strong> section further ahead. <strong>Thinning</strong> - which skips samples - is discussed under <strong>Autocorrelation</strong> section.</p>
</div>
<div id="importance-sampling" class="section level3 hasAnchor">
<h3><span class="header-section-number">8.2.7</span> Importance Sampling <a href="bayesian2.html#importance-sampling" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Our discussion on <strong>Importance sampling</strong> focuses on the expectation of an arbitrary function, namely <span class="math inline">\(f(x)\)</span>, as a point of comparison between calculating the simple average of its outcome with respect to a given target density, namely <span class="math inline">\(P(x)\)</span>, and the weighted average of its outcome with respect to a chosen approximating density, namely <span class="math inline">\(\mathcal{Q}(x)\)</span>.</p>
<p>Here, the premise is to find an approximating distribution that we can use to sample when the target distribution is difficult to sample easily. For example, sometimes, the tail of a Normal distribution matters. There is a possibility that that important region may not have enough data points to sample; thus, it may be necessary to propose a distribution representing that critical region of the distribution. From there, we simulate sampling from the newly proposed distribution - this is called <strong>importance sampling</strong> <span class="citation">(Bugallo M.F. et al. <a href="bibliography.html#ref-ref1138m">2017</a>; Elvira V. and Martino L. <a href="bibliography.html#ref-ref1129v">2021</a>)</span>.</p>
<p>To illustrate <strong>Importance sampling</strong>, recall the <strong>Law of Unconscious Statistician</strong> in the <strong>Monte Carlo estimation</strong> section. We start by using the following integral of the distribution in question:</p>
<p><span class="math display">\[\begin{align}
\begin{array}{ll}
\mathcal{I}_p = \int f(x) P(x) dx &amp;\ \ \ \ \ \ \ \ where\ \mathcal{I}_p = \mathbb{E}_p\left[f(x)\right]\\
\end{array} \label{eqn:eqnnumber335}
\end{align}\]</span></p>
<p>Here, we prescribe what we call an <strong>importance weight</strong> or a <strong>likelihood ratio</strong> by introducing an approximating distribution like so:  </p>
<p><span class="math display">\[\begin{align}
\begin{array}{ll}
\mathcal{I}_q = \int f(x) P(x) \frac{\mathbf{Q}(x)}{\mathbf{Q}(x)} dx 
&amp;\ \ \ \ \ \ \ \ where\ \mathcal{I}_q = \mathbb{E}_q\left[\frac{f(x)P(x)}{\mathcal{Q}(x)}\right]
\end{array} \label{eqn:eqnnumber336}
\end{align}\]</span></p>
<p>The prescribed <strong>importance weight</strong> or <strong>likelihood ratio</strong> is written as:</p>
<p><span class="math display">\[\begin{align}
\mathcal{I}_q  = \int f(x)\mathcal{Q}(x) \omega(x) dx\ \ \ \leftarrow\ \ \ \ \ \omega(x) = \frac{P(x)}{\mathcal{Q}(x)}\ \ \text{(importance weight)}
\end{align}\]</span></p>
<p>This ratio bears weight to the region of interest.</p>
<p>Note that choosing a distribution for <span class="math inline">\(\mathcal{Q}(x)\)</span> is arbitrary with no hard rules. However, ideally, it may be best to choose one that closely matches <span class="math inline">\(P(x)\)</span> or <span class="math inline">\(| f(x) | \mathcal{\omega}(x)\)</span>.</p>
<p>To illustrate, let us define and implement the three functions, namely <strong>f(x)</strong>, <span class="math inline">\(\mathbf{P}(x)\)</span>, and <span class="math inline">\(\mathbf{\mathcal{Q}}(x)\)</span>:</p>

<div class="sourceCode" id="cb927"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb927-1" data-line-number="1">mu1 =<span class="st"> </span><span class="dv">4</span>; mu2 =<span class="dv">6</span></a>
<a class="sourceLine" id="cb927-2" data-line-number="2">f &lt;-<span class="st"> </span><span class="cf">function</span>(X, <span class="dt">rate =</span> <span class="fl">0.4</span>) {  <span class="co"># f(x)</span></a>
<a class="sourceLine" id="cb927-3" data-line-number="3">  <span class="kw">dexp</span>(X, <span class="dt">rate =</span> rate)  <span class="co"># arbitrary function</span></a>
<a class="sourceLine" id="cb927-4" data-line-number="4">}</a>
<a class="sourceLine" id="cb927-5" data-line-number="5">P.normal.pdf &lt;-<span class="st"> </span><span class="cf">function</span>(X, <span class="dt">mu =</span> mu1, <span class="dt">sd =</span> <span class="dv">1</span>, <span class="dt">log=</span><span class="ot">FALSE</span>) { <span class="co"># P(x)</span></a>
<a class="sourceLine" id="cb927-6" data-line-number="6">  <span class="kw">dnorm</span>(X, <span class="dt">mean =</span> mu, <span class="dt">sd=</span>sd, <span class="dt">log =</span> log) </a>
<a class="sourceLine" id="cb927-7" data-line-number="7">}</a>
<a class="sourceLine" id="cb927-8" data-line-number="8">Q.normal.pdf &lt;-<span class="st"> </span><span class="cf">function</span>(X, <span class="dt">mu =</span> mu2, <span class="dt">sd =</span> <span class="dv">1</span>, <span class="dt">log=</span><span class="ot">FALSE</span>) { <span class="co"># Q(x)</span></a>
<a class="sourceLine" id="cb927-9" data-line-number="9">  <span class="kw">dnorm</span>(X, <span class="dt">mean =</span> mu, <span class="dt">sd=</span>sd, <span class="dt">log =</span> log)</a>
<a class="sourceLine" id="cb927-10" data-line-number="10">}</a>
<a class="sourceLine" id="cb927-11" data-line-number="11">N =<span class="st"> </span><span class="dv">1000</span></a>
<a class="sourceLine" id="cb927-12" data-line-number="12">X =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">10</span>, <span class="dt">length.out =</span> N)</a>
<a class="sourceLine" id="cb927-13" data-line-number="13">P =<span class="st"> </span><span class="kw">P.normal.pdf</span>(X, <span class="dt">mu =</span> mu1, <span class="dt">sd =</span> <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb927-14" data-line-number="14">Q =<span class="st"> </span><span class="kw">Q.normal.pdf</span>(X, <span class="dt">mu =</span> mu2, <span class="dt">sd =</span> <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb927-15" data-line-number="15">G =<span class="st"> </span><span class="kw">f</span>(X, <span class="dt">rate =</span> <span class="fl">0.4</span>)</a></code></pre></div>

<p>See Figure <a href="bayesian2.html#fig:importance">8.33</a> for the plot of <span class="math inline">\(f(x) \sim Expo(x)\)</span>, <span class="math inline">\(\mathbf{P}(x) \sim \mathcal{N}(4, 1)\)</span>, and <span class="math inline">\(\mathbf{\mathcal{Q}}(x) \sim \mathcal{N}(6, 1)\)</span>.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:importance"></span>
<img src="DS_files/figure-html/importance-1.png" alt="Importance Sampling" width="70%" />
<p class="caption">
Figure 8.33: Importance Sampling
</p>
</div>

<p>Now, let us evaluate two calculations (the simple average and weighted average):</p>

<div class="sourceCode" id="cb928"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb928-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">2020</span>)</a>
<a class="sourceLine" id="cb928-2" data-line-number="2">simple.avarage &lt;-<span class="st"> </span><span class="cf">function</span>(N) {</a>
<a class="sourceLine" id="cb928-3" data-line-number="3">  E =<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, N)</a>
<a class="sourceLine" id="cb928-4" data-line-number="4">  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>N) {</a>
<a class="sourceLine" id="cb928-5" data-line-number="5">    X =<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n =</span> <span class="dv">1</span>, <span class="dt">mean =</span> mu1, <span class="dt">sd =</span> <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb928-6" data-line-number="6">    E[i] =<span class="st"> </span><span class="kw">f</span>(X, <span class="dt">rate=</span><span class="fl">0.4</span>)  </a>
<a class="sourceLine" id="cb928-7" data-line-number="7">  }</a>
<a class="sourceLine" id="cb928-8" data-line-number="8">  <span class="kw">sum</span>(E) <span class="op">/</span><span class="st"> </span>N</a>
<a class="sourceLine" id="cb928-9" data-line-number="9">}</a>
<a class="sourceLine" id="cb928-10" data-line-number="10">importance.sampling &lt;-<span class="st"> </span><span class="cf">function</span>(N) {</a>
<a class="sourceLine" id="cb928-11" data-line-number="11">  E =<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, N)</a>
<a class="sourceLine" id="cb928-12" data-line-number="12">  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>N) {</a>
<a class="sourceLine" id="cb928-13" data-line-number="13">    X =<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n =</span> <span class="dv">1</span>, <span class="dt">mean =</span> mu2, <span class="dt">sd =</span> <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb928-14" data-line-number="14">    W =<span class="st"> </span><span class="kw">exp</span>(<span class="kw">P.normal.pdf</span>(X, <span class="dt">mu=</span>mu1, <span class="dt">log=</span><span class="ot">TRUE</span>) <span class="op">-</span><span class="st"> </span></a>
<a class="sourceLine" id="cb928-15" data-line-number="15"><span class="st">            </span><span class="kw">Q.normal.pdf</span>(X, <span class="dt">mu=</span>mu2, <span class="dt">log=</span><span class="ot">TRUE</span>))</a>
<a class="sourceLine" id="cb928-16" data-line-number="16">    E[i] =<span class="st"> </span><span class="kw">f</span>(X, <span class="dt">rate=</span><span class="fl">0.4</span>) <span class="op">*</span><span class="st"> </span>W</a>
<a class="sourceLine" id="cb928-17" data-line-number="17">  }</a>
<a class="sourceLine" id="cb928-18" data-line-number="18">  <span class="kw">sum</span>(E) <span class="op">/</span><span class="st"> </span>N</a>
<a class="sourceLine" id="cb928-19" data-line-number="19">}</a>
<a class="sourceLine" id="cb928-20" data-line-number="20"><span class="kw">c</span>(<span class="st">&quot;Simple Average&quot;</span> =<span class="st"> </span><span class="kw">simple.avarage</span>(N), </a>
<a class="sourceLine" id="cb928-21" data-line-number="21">  <span class="st">&quot;Weighted Average&quot;</span> =<span class="st"> </span><span class="kw">importance.sampling</span> (N) )</a></code></pre></div>
<pre><code>##   Simple Average Weighted Average 
##          0.08889          0.09341</code></pre>

<p>We leave readers to investigate <strong>Simulated Annealing</strong> and <strong>Annealed Importance Sampling (AIS)</strong>.</p>
</div>
<div id="rejection-sampling" class="section level3 hasAnchor">
<h3><span class="header-section-number">8.2.8</span> Rejection Sampling <a href="bayesian2.html#rejection-sampling" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Rejection Sampling</strong>, also called <strong>Acceptance-Rejection Sampling</strong>, introduces the concept of an <strong>envelope distribution</strong> (our proposal distribution) <span class="citation">(Erraqabi A. et al. <a href="bibliography.html#ref-ref1111a">2016</a>; Gilks, W. R., &amp; Wild, P. <a href="bibliography.html#ref-ref1120g">1992</a>)</span>. The idea is to scale (or stretch) an approximating distribution, namely <span class="math inline">\(\mathcal{Q}(x)\)</span>, such that it is tall and wide enough to <strong>envelope</strong> or <strong>cover</strong> the entire target distribution, <span class="math inline">\(P(x)\)</span>. It is natural and perhaps intuitive to use <strong>uniform distribution</strong> for our <strong>envelope distribution</strong> that is scaled to cover the target distribution; however, we use a <strong>normal distribution</strong>in our example. See Figure <a href="bayesian2.html#fig:rejection">8.34</a> for the plot of the <strong>Rejection Sampling</strong>.  </p>
<p>To illustrate, let us implement a <strong>univariate bimodal mixture distribution</strong> for our target distribution using a function called <strong>dnorml.mixt(.)</strong> from a third-party library called <strong>ks</strong>. Our bimodal mixture has an equal proportion.</p>
<p><span class="math display">\[\begin{align}
P(x) \sim \mathcal{N}(\mu=25, \sigma = 2 ) + \mathcal{N}(\mu=35, \sigma = 4 )
\end{align}\]</span></p>
<p>We then can choose any <strong>approximating distribution</strong> that closely match our target distribution. Here, we choose <strong>Gaussian distribution</strong>:</p>
<p><span class="math display">\[\begin{align}
\mathcal{Q}(x) \sim \mathcal{N}(\mu = 30, \sigma = 6)
\end{align}\]</span></p>
<p>Next, we compute for the scale factor denoted as <strong>k</strong>:</p>
<p><span class="math display">\[\begin{align}
k = max\left(\frac{P(x)}{\mathcal{Q}(x)}\right)
\end{align}\]</span></p>
<p>Therefore, our <strong>envelope distribution</strong> is generated using the following equation - represented by an <strong>envelope function</strong>, <span class="math inline">\(Q^*(x)\)</span>:</p>
<p><span class="math display">\[\begin{align}
Q^*(x) = k \times \mathcal{Q}(x)
\end{align}\]</span></p>
<p>We then generate sufficient samples from a uniform distribution with a height equal to our <strong>envelope distribution</strong>.</p>
<p><span class="math display">\[\begin{align}
U \sim \mathcal{U}(N=1000, 0, max(Q^*{(x)}))
\end{align}\]</span></p>
<p>We then use the uniformly generated sample to accept data points as our primary sample with a height below our <strong>target distribution</strong>.</p>
<p><span class="math display">\[
if\ U \le P(x)\ \ \ \text{accept region below or along target density}
\]</span></p>
<p>Additionally, we also can sample the region below the envelope density and above the target density for our plotting purpose:</p>
<p><span class="math display">\[
if\ U &lt; \mathcal{Q}^*(x)\ and\ U &gt; P(x)\ \ \ 
\begin{cases}
\begin{array}{l}\text{accept region below envelope density}\\
\text{and above the target density}
\end{array}
\end{cases}
\]</span></p>
<p>Below is a simple implementation of <strong>Rejection sampling</strong>.</p>

<div class="sourceCode" id="cb930"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb930-1" data-line-number="1"><span class="kw">library</span>(ks)</a></code></pre></div>
<pre><code>## 
## Attaching package: &#39;ks&#39;</code></pre>
<pre><code>## The following object is masked _by_ &#39;.GlobalEnv&#39;:
## 
##     kde</code></pre>
<div class="sourceCode" id="cb933"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb933-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">2020</span>)</a>
<a class="sourceLine" id="cb933-2" data-line-number="2">P.normal.pdf &lt;-<span class="st"> </span><span class="cf">function</span>(x) { <span class="co"># P(x)</span></a>
<a class="sourceLine" id="cb933-3" data-line-number="3">  y =<span class="st"> </span><span class="kw">dnorm.mixt</span>(x, <span class="dt">mus=</span><span class="kw">c</span>(<span class="dv">25</span>,<span class="dv">35</span>), <span class="dt">sigmas=</span><span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">4</span>), <span class="dt">props=</span><span class="kw">c</span>(<span class="fl">0.5</span>, <span class="fl">0.5</span>))</a>
<a class="sourceLine" id="cb933-4" data-line-number="4">  <span class="kw">list</span>(<span class="st">&quot;y&quot;</span> =<span class="st"> </span>y)</a>
<a class="sourceLine" id="cb933-5" data-line-number="5">}</a>
<a class="sourceLine" id="cb933-6" data-line-number="6">Q.normal.pdf &lt;-<span class="st"> </span><span class="cf">function</span>(x) { <span class="co"># Q(x)</span></a>
<a class="sourceLine" id="cb933-7" data-line-number="7">  y =<span class="st"> </span><span class="kw">dnorm.mixt</span>(x, <span class="dt">mus=</span><span class="kw">c</span>(<span class="dv">30</span>), <span class="dt">sigmas=</span><span class="kw">c</span>(<span class="dv">6</span>), <span class="dt">props=</span><span class="kw">c</span>(<span class="dv">1</span>))</a>
<a class="sourceLine" id="cb933-8" data-line-number="8">  <span class="kw">list</span>(<span class="st">&quot;y&quot;</span> =<span class="st"> </span>y)</a>
<a class="sourceLine" id="cb933-9" data-line-number="9">}</a>
<a class="sourceLine" id="cb933-10" data-line-number="10">rejection.sampling &lt;-<span class="st"> </span><span class="cf">function</span>(X, <span class="dt">N =</span> <span class="dv">500</span>) {</a>
<a class="sourceLine" id="cb933-11" data-line-number="11">  target =<span class="st"> </span><span class="kw">P.normal.pdf</span>(X)</a>
<a class="sourceLine" id="cb933-12" data-line-number="12">  approximate =<span class="st"> </span><span class="kw">Q.normal.pdf</span>(X)</a>
<a class="sourceLine" id="cb933-13" data-line-number="13">  <span class="co"># compute for the scale factor</span></a>
<a class="sourceLine" id="cb933-14" data-line-number="14">  k =<span class="st">  </span><span class="kw">max</span> ( <span class="kw">exp</span>( <span class="kw">log</span>( target<span class="op">$</span>y, <span class="dv">2</span>) <span class="op">-</span><span class="st"> </span><span class="kw">log</span>( approximate<span class="op">$</span>y, <span class="dv">2</span>)) )</a>
<a class="sourceLine" id="cb933-15" data-line-number="15">  envelop =<span class="st"> </span>approximate<span class="op">$</span>y <span class="op">*</span><span class="st"> </span>k</a>
<a class="sourceLine" id="cb933-16" data-line-number="16">  <span class="co"># generate sufficient samples</span></a>
<a class="sourceLine" id="cb933-17" data-line-number="17">  xu1 =<span class="st"> </span><span class="kw">runif</span>(N, <span class="dt">min=</span><span class="dv">15</span>, <span class="dt">max=</span><span class="dv">45</span>)</a>
<a class="sourceLine" id="cb933-18" data-line-number="18">  yu1 =<span class="st"> </span><span class="kw">runif</span>(N, <span class="dt">min=</span><span class="dv">0</span>, <span class="dt">max=</span> <span class="kw">max</span> (envelop))</a>
<a class="sourceLine" id="cb933-19" data-line-number="19">  <span class="co"># density from target distribution</span></a>
<a class="sourceLine" id="cb933-20" data-line-number="20">  p.density =<span class="st"> </span><span class="kw">P.normal.pdf</span>(xu1)<span class="op">$</span>y</a>
<a class="sourceLine" id="cb933-21" data-line-number="21">  <span class="co"># density from envelope distribution</span></a>
<a class="sourceLine" id="cb933-22" data-line-number="22">  q.density =<span class="st"> </span><span class="kw">Q.normal.pdf</span>(xu1)<span class="op">$</span>y <span class="op">*</span><span class="st"> </span>k</a>
<a class="sourceLine" id="cb933-23" data-line-number="23">  <span class="co"># accept region below  target density</span></a>
<a class="sourceLine" id="cb933-24" data-line-number="24">  accept1 =<span class="st"> </span><span class="kw">which</span>(yu1 <span class="op">&lt;=</span><span class="st"> </span>p.density)</a>
<a class="sourceLine" id="cb933-25" data-line-number="25">  <span class="co"># accept region using envelope density</span></a>
<a class="sourceLine" id="cb933-26" data-line-number="26">  accept2 =<span class="st"> </span><span class="kw">which</span>(yu1 <span class="op">&lt;</span><span class="st"> </span>q.density <span class="op">&amp;</span><span class="st"> </span>yu1 <span class="op">&gt;</span><span class="st"> </span>p.density)</a>
<a class="sourceLine" id="cb933-27" data-line-number="27">  <span class="kw">list</span>(<span class="st">&quot;P.x&quot;</span> =<span class="st"> </span>xu1[accept1], <span class="st">&quot;P.y&quot;</span> =<span class="st"> </span>yu1[accept1],</a>
<a class="sourceLine" id="cb933-28" data-line-number="28">       <span class="st">&quot;Q.x&quot;</span> =<span class="st"> </span>xu1[accept2], <span class="st">&quot;Q.y&quot;</span> =<span class="st"> </span>yu1[accept2],</a>
<a class="sourceLine" id="cb933-29" data-line-number="29">       <span class="st">&quot;envelop&quot;</span> =<span class="st"> </span>envelop, </a>
<a class="sourceLine" id="cb933-30" data-line-number="30">       <span class="st">&quot;approximate&quot;</span> =<span class="st"> </span>approximate<span class="op">$</span>y, <span class="st">&quot;k&quot;</span> =<span class="st"> </span>k,</a>
<a class="sourceLine" id="cb933-31" data-line-number="31">       <span class="st">&quot;target&quot;</span> =<span class="st"> </span>target<span class="op">$</span>y)</a>
<a class="sourceLine" id="cb933-32" data-line-number="32">}</a>
<a class="sourceLine" id="cb933-33" data-line-number="33">N =<span class="st"> </span><span class="dv">500</span></a>
<a class="sourceLine" id="cb933-34" data-line-number="34">X =<span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">45</span>, <span class="dt">length.out =</span> N)</a>
<a class="sourceLine" id="cb933-35" data-line-number="35">RS =<span class="st"> </span><span class="kw">rejection.sampling</span> (X, N )</a></code></pre></div>

<p>Below is the plot of our final sampling (data points denoted by <strong>P.x</strong> and <strong>P.y</strong>):</p>

<div class="sourceCode" id="cb934"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb934-1" data-line-number="1"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="dv">15</span>, <span class="dv">45</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="op">-</span><span class="fl">0.01</span>, <span class="fl">0.25</span>), </a>
<a class="sourceLine" id="cb934-2" data-line-number="2">     <span class="dt">xlab=</span><span class="st">&quot;X&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;Y&quot;</span>, <span class="dt">lwd=</span><span class="dv">2</span>,  <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>,</a>
<a class="sourceLine" id="cb934-3" data-line-number="3">     <span class="dt">main=</span><span class="kw">paste0</span>(<span class="st">&quot;Rejection Sampling&quot;</span>),  <span class="dt">frame=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb934-4" data-line-number="4"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>)</a>
<a class="sourceLine" id="cb934-5" data-line-number="5"><span class="kw">points</span>(RS<span class="op">$</span>Q.x, RS<span class="op">$</span>Q.y, <span class="dt">pch=</span><span class="dv">4</span>, <span class="dt">col=</span><span class="st">&quot;grey&quot;</span>)</a>
<a class="sourceLine" id="cb934-6" data-line-number="6"><span class="kw">points</span>(RS<span class="op">$</span>P.x, RS<span class="op">$</span>P.y, <span class="dt">pch=</span><span class="dv">20</span>, <span class="dt">col=</span><span class="st">&quot;seagreen&quot;</span>)</a>
<a class="sourceLine" id="cb934-7" data-line-number="7"><span class="kw">lines</span>(X, RS<span class="op">$</span>target, <span class="dt">col=</span><span class="st">&quot;seagreen&quot;</span>,  <span class="dt">lwd=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb934-8" data-line-number="8"><span class="kw">lines</span>(X, RS<span class="op">$</span>approximate, <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">lty=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb934-9" data-line-number="9"><span class="kw">lines</span>(X, RS<span class="op">$</span>envelop, <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>, <span class="dt">lwd=</span><span class="dv">2</span> )</a>
<a class="sourceLine" id="cb934-10" data-line-number="10">max.y1 =<span class="st"> </span><span class="kw">max</span>(RS<span class="op">$</span>approximate)</a>
<a class="sourceLine" id="cb934-11" data-line-number="11">max.y2 =<span class="st"> </span><span class="kw">max</span>(RS<span class="op">$</span>envelop)</a>
<a class="sourceLine" id="cb934-12" data-line-number="12"><span class="kw">arrows</span>(<span class="dv">30</span>, max.y1, <span class="dv">30</span>, max.y2, <span class="dt">col=</span><span class="st">&quot;blue&quot;</span>)</a>
<a class="sourceLine" id="cb934-13" data-line-number="13"><span class="kw">text</span>(<span class="fl">31.2</span>, <span class="fl">0.15</span>, <span class="dt">label=</span><span class="st">&quot;scale&quot;</span>)</a>
<a class="sourceLine" id="cb934-14" data-line-number="14"><span class="kw">text</span>(<span class="fl">31.4</span>, <span class="fl">0.13</span>, <span class="dt">label=</span><span class="kw">paste0</span>(<span class="st">&quot;by &quot;</span>, <span class="kw">round</span>(RS<span class="op">$</span>k,<span class="dv">1</span>)))</a>
<a class="sourceLine" id="cb934-15" data-line-number="15"><span class="kw">text</span>(<span class="dv">30</span>, <span class="fl">-0.01</span>, <span class="dt">label=</span><span class="st">&quot;accept region&quot;</span>, <span class="dt">col=</span><span class="st">&quot;seagreen&quot;</span>)</a>
<a class="sourceLine" id="cb934-16" data-line-number="16"><span class="kw">text</span>(<span class="dv">30</span>, <span class="fl">0.10</span>, <span class="dt">label=</span><span class="st">&quot;reject region&quot;</span>, <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>)</a>
<a class="sourceLine" id="cb934-17" data-line-number="17"><span class="kw">legend</span>(<span class="dv">34</span>, <span class="fl">0.25</span>, </a>
<a class="sourceLine" id="cb934-18" data-line-number="18">    <span class="dt">legend=</span><span class="kw">c</span>( <span class="st">&quot;P(x) - Target Dist&quot;</span>, </a>
<a class="sourceLine" id="cb934-19" data-line-number="19">              <span class="st">&quot;Q(x) - Approx Dist&quot;</span>, </a>
<a class="sourceLine" id="cb934-20" data-line-number="20">              <span class="st">&quot;Envelope Dist&quot;</span>),</a>
<a class="sourceLine" id="cb934-21" data-line-number="21">    <span class="dt">col=</span><span class="kw">c</span>(<span class="st">&quot;seagreen&quot;</span>, <span class="st">&quot;darksalmon&quot;</span>, <span class="st">&quot;navyblue&quot;</span>),  </a>
<a class="sourceLine" id="cb934-22" data-line-number="22">    <span class="dt">lty=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">3</span>,<span class="dv">1</span>), <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">cex=</span><span class="fl">0.8</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:rejection"></span>
<img src="DS_files/figure-html/rejection-1.png" alt="Rejection Sampling" width="70%" />
<p class="caption">
Figure 8.34: Rejection Sampling
</p>
</div>

<p>Below are other methods of sampling that are worth investigating:</p>
<ul>
<li>Grid Sampling</li>
<li>Bridge Sampling</li>
<li>Nested Sampling</li>
<li>Stepping Stone Sampling</li>
<li>Path Sampling</li>
<li>Dependent Sampling</li>
<li>Independent Sampling</li>
<li>Slice Sampling</li>
</ul>
<p>We leave readers to investigate the <strong>Adaptive Rejection Sampling (ARS)</strong>, which uses both <strong>envelope function</strong> and <strong>squeezing function</strong> to constraint the <strong>approximating function</strong> to upper and lower bounds <span class="citation">(Gilks, W. R., &amp; Wild, P. <a href="bibliography.html#ref-ref1120g">1992</a>)</span>.</p>
</div>
<div id="jags-modeling" class="section level3 hasAnchor">
<h3><span class="header-section-number">8.2.9</span> JAGS Modeling <a href="bayesian2.html#jags-modeling" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We extend the discussion around <strong>flat</strong> prior and <strong>hyperparameter</strong> by introducing a <strong>modeling</strong> technique called <strong>JAGS modeling</strong> relevant to our choice of prior and hyperparameters <span class="citation">(Plummer M. <a href="bibliography.html#ref-ref1252m">2003</a>; Kruschke J.K. <a href="bibliography.html#ref-ref241j">2015</a>)</span>.</p>
<p>We introduce an R package called <strong>rjags</strong> in this section. <strong>JAGS</strong> stands for <strong>Just Another GIBBS Sampler</strong>. There are three overlapping concepts when dealing with JAGS: <strong>GIBBS sampling</strong>, <strong>Markov Chain Monte Carlo (MCMC) simulation</strong>, and <strong>JAGS modeling</strong>. This section focuses on <strong>JAGS modeling</strong> using <strong>JAGS</strong> using the other two concepts to demonstrate a case in modeling and simulating sampling.</p>
<p>To illustrate, let us discuss how to model a few <strong>bayesian</strong> cases relevant to a family of conjugacy which is discussed in previous sections.</p>
<p><strong>Normal-Normal Model</strong></p>
<p>Let us recall <strong>normal-normal conjugacy</strong> with unknown mean, <span class="math inline">\(\mu\)</span>, and known variance, <span class="math inline">\(\sigma^2\)</span>. For this family of <strong>conjugacy</strong>, we have the following description of <strong>prior distribution</strong> and <strong>sampling density (likelihood)</strong>:</p>
<p><span class="math display">\[\begin{align}
P(\mu) {}&amp;\rightarrow\ \ \ \ \ \mu \sim \mathcal{N}(\mu_0, \sigma^2_0)\\
\nonumber \\
Lik(x_1,...,x_n|\mu) &amp;\rightarrow\ \ \ \ \ x_1,...,x_n|\mu, \sigma^2 \sim \mathcal{N}(\mu, \sigma^2)\ \ \ \text{(sampling density)}
\end{align}\]</span></p>
<p>We use BUGS language to model in Jags. Below is an example of implementing Jags model for the prior and sampling density in R based on the two distributions above (note in JAGS that we use precision which is the inverse of the variance):</p>
<pre><code>model {
  for (i in 1:N) {                 # N = sampling size
   x[i] ~ dnorm(mu[i], 1/sigma[i]) # sampling density (likelihood)
   mu[i] ~ dnorm(mu0, 1/sigma0)        # prior (mean)
  }
  mu0 ~ dunif(-1000, 1000) # hyperparameter (mean)
  sigma0 ~ dunif(0, 1000)  # hyperparameter (sd for variance)
}</code></pre>
<p>In the model, we use the following hyperparameters for a flat hyperprior:</p>
<p><span class="math display">\[\begin{align*}
\mu_0 {}&amp;\sim U(-1000,1000) &amp; -\infty &lt; \mu_0 &lt; \infty\\
\sigma^2_0 &amp;\sim  U(0,1000) &amp; \sigma^2_0 &lt; \infty
\end{align*}\]</span></p>
<p>For <strong>normal-normal conjugacy</strong> with known mean <span class="math inline">\(\mu\)</span> and unknown variance <span class="math inline">\(\sigma^2\)</span>, we have the following description of <strong>prior distribution</strong> and <strong>sampling density (likelihood)</strong>:</p>
<p><span class="math display">\[\begin{align*}
P(\sigma^2) {}&amp;\rightarrow\ \ \ \ \ \sigma^2 \sim Inv.\ Gamma(\alpha_0,\beta_0)\\
\\
Lik(x_1,...,x_n|\sigma^2) &amp;\rightarrow\ \ \ \ \ x|\sigma \sim \mathcal{N}(\mu, \sigma^2)\ \ \ \text{(sampling density)}
\end{align*}\]</span></p>
<p>We use BUGS language to model in Jags. Below is an example of implementing the Jags model for the prior and sampling density in R code based on the two distributions above (note in JAGS that we use precision which is the inverse of the variance):</p>
<pre><code>model {
  for (i in 1:N) {                   # N = sampling size
   x[i] ~ dnorm(mu[i], 1/sigma[i])   # sampling density (likelihood)  
   sigma[i] ~ dgamma(alpha0, beta0)  # prior (sd)
  }
  alpha0 ~ dunif(0, 1000)       # hyperparameter (alpha)
  beta0 ~ dunif(0, 1000)        # hyperparameter (beta)
}</code></pre>
<p>In the model, we use the following hyperparameters for a flat hyperprior:</p>
<p><span class="math display">\[\begin{align*}
\alpha_0 {}&amp;\sim U(0,1000) &amp; \alpha_0 &lt; \infty\\
\beta_0 &amp;\sim  U(0,1000) &amp; \beta_0 &lt; \infty
\end{align*}\]</span></p>
<p><strong>Binomial-Beta Model</strong></p>
<p>For <strong>Binomial-Beta conjugacy</strong>, we have the following description of <strong>prior distribution</strong> and <strong>sampling density (likelihood)</strong>:</p>
<p><span class="math display">\[\begin{align}
P(\rho) {}&amp;\rightarrow\ \ \ \ \ \rho \sim Beta(\alpha_0, \beta_0)\\
\nonumber \\
Lik(x_1,...,x_n|\rho) &amp;\rightarrow\ \ \ \ \ x_1,...,x_n|\rho \sim Bin(n, \rho)\ \ \ \text{(sampling density)}
\end{align}\]</span></p>
<p>Below is an example of implementing the Jags model for the prior and sampling density in R code based on the two distributions above:</p>
<pre><code>model {
  for (i in 1:M) {                # M = sampling size
    x[i] ~ dbin(n, rho[i])        # sampling density (likelihood)
    rho[i] ~ dbeta(alpha0, beta0) # prior
  }
  alpha0 ~ dunif(0, 1)       # hyperparameter (alpha)
  beta0 ~ dunif(0, 1)        # hyperparameter (beta)
}</code></pre>
<p>In the model, we use the following hyperparameters for a flat hyperprior:</p>
<p><span class="math display">\[\begin{align*}
\alpha_0 {}&amp;\sim U(0,1) &amp; \alpha_0 &lt; \infty\\
\beta_0 &amp;\sim  U(0,1) &amp; \beta_0 &lt; \infty\\
\end{align*}\]</span></p>
<p>Figure <a href="bayesian2.html#fig:rjagmodel">8.35</a> shows a visual representation of the <strong>JAGS model</strong>. In the figure, the circle nodes represent random variables. There are five variables in each model. The shaded circle node labeled as <span class="math inline">\(\mathbf{x}\)</span> represents the <strong>observed data</strong>. The circles inside the rectangular plate are vector variables with a sampling size of <span class="math inline">\(N\ or\ M\)</span>. The model forms a <strong>hierarchical</strong> child-parent relationship and, in our case, follows a DAG model (directed acyclic graph).</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:rjagmodel"></span>
<img src="rjagmodel.png" alt="JAGS Model" width="100%" />
<p class="caption">
Figure 8.35: JAGS Model
</p>
</div>

<p>To illustrate, let us implement the first model using R code. Here, we only focus on the <strong>likelihood</strong> and <strong>prior</strong> for the <strong>normal-normal</strong> model with unknown <span class="math inline">\(\mu\)</span> and known <span class="math inline">\(\sigma^2\)</span>. We simulate by sampling ten separate groups, each sample with about fifty observations. We then calculate the variance within each sample. For demonstration, we leave the mean unknown for each sample. Our goal is to parameterize the unknown <span class="math inline">\(\mu\)</span>.</p>



<div class="sourceCode" id="cb938"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb938-1" data-line-number="1"><span class="co"># load coda and rjags library first</span></a>
<a class="sourceLine" id="cb938-2" data-line-number="2"><span class="kw">library</span>(coda);</a>
<a class="sourceLine" id="cb938-3" data-line-number="3"><span class="kw">library</span>(rjags)</a>
<a class="sourceLine" id="cb938-4" data-line-number="4"><span class="kw">set.seed</span>(<span class="dv">2020</span>)</a>
<a class="sourceLine" id="cb938-5" data-line-number="5">sample_size =<span class="st"> </span><span class="dv">50</span>   <span class="co"># observations</span></a>
<a class="sourceLine" id="cb938-6" data-line-number="6">sampling_size =<span class="st"> </span><span class="dv">4</span> <span class="co"># group size</span></a>
<a class="sourceLine" id="cb938-7" data-line-number="7">range =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">11</span>, <span class="dv">20</span>, <span class="dt">length.out=</span><span class="dv">10</span>)</a>
<a class="sourceLine" id="cb938-8" data-line-number="8">sampling =<span class="st"> </span><span class="kw">replicate</span>(<span class="dt">n=</span>sampling_size, <span class="kw">sample</span>(range, <span class="dt">size=</span>sample_size, </a>
<a class="sourceLine" id="cb938-9" data-line-number="9">                                             <span class="dt">replace=</span><span class="ot">TRUE</span>))</a>
<a class="sourceLine" id="cb938-10" data-line-number="10">mean.with.noise &lt;-<span class="st"> </span><span class="cf">function</span>(x) {  </a>
<a class="sourceLine" id="cb938-11" data-line-number="11">      noise =<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n =</span> <span class="dv">1</span>, <span class="dt">mean =</span> <span class="dv">0</span>, <span class="dt">sd =</span> <span class="fl">1.2</span>) <span class="co"># introduce error/noise</span></a>
<a class="sourceLine" id="cb938-12" data-line-number="12">      <span class="kw">mean</span>(x)  <span class="op">+</span><span class="st"> </span>noise</a>
<a class="sourceLine" id="cb938-13" data-line-number="13">  }</a>
<a class="sourceLine" id="cb938-14" data-line-number="14">data =<span class="st"> </span><span class="kw">as.data.frame</span>( </a>
<a class="sourceLine" id="cb938-15" data-line-number="15">  <span class="kw">matrix</span>( <span class="kw">c</span>( <span class="kw">seq</span>(<span class="dv">1</span>, sampling_size), </a>
<a class="sourceLine" id="cb938-16" data-line-number="16">          <span class="kw">sqrt</span>(<span class="kw">apply</span>(sampling, <span class="dv">2</span>, var)), <span class="kw">apply</span>(sampling, <span class="dv">2</span>, </a>
<a class="sourceLine" id="cb938-17" data-line-number="17">                                               mean.with.noise )),  </a>
<a class="sourceLine" id="cb938-18" data-line-number="18">     <span class="dt">nrow=</span>sampling_size, <span class="dt">ncol=</span><span class="dv">3</span>, <span class="dt">byrow=</span><span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb938-19" data-line-number="19">  )</a>
<a class="sourceLine" id="cb938-20" data-line-number="20"><span class="kw">colnames</span>(data) =<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;index&quot;</span>, <span class="st">&quot;sd&quot;</span>, <span class="st">&quot;mean&quot;</span>)</a>
<a class="sourceLine" id="cb938-21" data-line-number="21">data</a></code></pre></div>
<pre><code>##   index    sd  mean
## 1     1 3.051 13.65
## 2     2 2.507 13.95
## 3     3 2.862 15.12
## 4     4 3.044 15.86</code></pre>

<p><strong>First</strong>, we construct a list of parameters to pass to the model:</p>

<div class="sourceCode" id="cb940"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb940-1" data-line-number="1">model.data &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="st">&quot;N&quot;</span> =<span class="st"> </span><span class="kw">nrow</span>(data), <span class="st">&quot;X&quot;</span> =<span class="st"> </span>data<span class="op">$</span>mean,  </a>
<a class="sourceLine" id="cb940-2" data-line-number="2">                   <span class="st">&quot;sigma&quot;</span> =<span class="st"> </span>data<span class="op">$</span>sd) </a></code></pre></div>

<p><strong>Second</strong>, we then generate and initialize the model:</p>

<div class="sourceCode" id="cb941"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb941-1" data-line-number="1">modelstring =<span class="st"> &quot;</span></a>
<a class="sourceLine" id="cb941-2" data-line-number="2"><span class="st">  model {</span></a>
<a class="sourceLine" id="cb941-3" data-line-number="3"><span class="st">    for (i in 1:N) {                 # N = sampling size</span></a>
<a class="sourceLine" id="cb941-4" data-line-number="4"><span class="st">     X[i] ~ dnorm(mu[i], 1/sigma[i]) # sampling density (likelihood)</span></a>
<a class="sourceLine" id="cb941-5" data-line-number="5"><span class="st">     mu[i] ~ dnorm(mu0, 1/sigma0)    # prior (mean)</span></a>
<a class="sourceLine" id="cb941-6" data-line-number="6"><span class="st">    }</span></a>
<a class="sourceLine" id="cb941-7" data-line-number="7"><span class="st">    mu0 ~ dunif(-1000, 1000)         # hyperparameter (mean)</span></a>
<a class="sourceLine" id="cb941-8" data-line-number="8"><span class="st">    sigma0 ~ dunif(0, 1000)          # hyperparameter (sd for variance)</span></a>
<a class="sourceLine" id="cb941-9" data-line-number="9"><span class="st">  }</span></a>
<a class="sourceLine" id="cb941-10" data-line-number="10"><span class="st">&quot;</span>  </a>
<a class="sourceLine" id="cb941-11" data-line-number="11">model =<span class="st"> </span><span class="kw">jags.model</span>(<span class="kw">textConnection</span>(modelstring), </a>
<a class="sourceLine" id="cb941-12" data-line-number="12">                   <span class="dt">data=</span>model.data, <span class="dt">n.chains=</span><span class="dv">2</span>)</a></code></pre></div>
<pre><code>## Compiling model graph
##    Resolving undeclared variables
##    Allocating nodes
## Graph information:
##    Observed stochastic nodes: 4
##    Unobserved stochastic nodes: 6
##    Total graph size: 24
## 
## Initializing model</code></pre>

<p><strong>Third</strong>, with the generated model, let us go through a <strong>burn-in</strong> stage. This stage is a preliminary <strong>warm-up</strong> stage, only hoping that our Markov Chain gets closer to a higher probability.</p>

<div class="sourceCode" id="cb943"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb943-1" data-line-number="1"><span class="co"># Burn-In</span></a>
<a class="sourceLine" id="cb943-2" data-line-number="2"><span class="kw">update</span>(model, <span class="dv">2000</span>)  </a></code></pre></div>

<p><strong>Fourth</strong>, start the <strong>sampling</strong> process and monitor the <strong>prior</strong> hyperparameters: <span class="math inline">\(\mu_0\)</span> and <span class="math inline">\(\frac{1}{\sigma^2_0}\)</span>.</p>

<div class="sourceCode" id="cb944"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb944-1" data-line-number="1"><span class="co"># Iteration 5000 times for the mu, mu0 and sigma0 samples.</span></a>
<a class="sourceLine" id="cb944-2" data-line-number="2">cs &lt;-<span class="st"> </span><span class="kw">coda.samples</span>(model, <span class="kw">c</span>(  <span class="st">&quot;mu&quot;</span>, <span class="st">&quot;mu0&quot;</span>, <span class="st">&quot;sigma0&quot;</span> ), <span class="dt">n.iter=</span><span class="dv">5000</span>)</a></code></pre></div>

<p><strong>Fifth</strong>, let us review a summary of the parameters. Here, we obtain statistics of the parameter estimates. It allows us to review the mean, standard deviation, standard error of (<span class="math inline">\(\mu_0\)</span> and <span class="math inline">\(\sigma^2_0\)</span>) hyperparameters and (<span class="math inline">\(\mu\)</span>) parameter for our prior. Notice that the unknown mean across the four samplings has values between 13 and 15 with a standard error of 0.019.</p>

<div class="sourceCode" id="cb945"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb945-1" data-line-number="1"><span class="co"># Summary for the mu, mu0, sigma0 samples</span></a>
<a class="sourceLine" id="cb945-2" data-line-number="2"><span class="kw">summary</span>(cs)</a></code></pre></div>
<pre><code>## 
## Iterations = 3001:8000
## Thinning interval = 1 
## Number of chains = 2 
## Sample size per chain = 5000 
## 
## 1. Empirical mean and standard deviation for each variable,
##    plus standard error of the mean:
## 
##        Mean    SD Naive SE Time-series SE
## mu[1]  14.0  1.55   0.0155         0.0227
## mu[2]  14.2  1.40   0.0140         0.0191
## mu[3]  14.9  1.50   0.0150         0.0206
## mu[4]  15.4  1.55   0.0155         0.0250
## mu0    14.6  3.31   0.0331         0.1268
## sigma0 40.5 86.11   0.8611         9.3145
## 
## 2. Quantiles for each variable:
## 
##          2.5%   25%   50%  75% 97.5%
## mu[1]  10.846 12.95 14.00 15.0  16.9
## mu[2]  11.317 13.26 14.20 15.1  16.8
## mu[3]  12.051 13.96 14.89 15.9  18.0
## mu[4]  12.456 14.36 15.35 16.4  18.5
## mu0     7.633 13.42 14.65 15.8  21.2
## sigma0  0.146  2.52  9.06 35.0 310.9</code></pre>

<p><strong>Sixth</strong>, we use <strong>Gelman-Rubin</strong> diagnostic tool to analyze convergence. The first diagram plots the iterations taken by JAGS for each of the sampled <span class="math inline">\(\mu\)</span>. Notice that each posterior sampling of <span class="math inline">\(\mu\)</span> consistently stays somewhere around 15 through the iterations from 2000 to 5000, accompanied by the corresponding density. </p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:gelmanrubin1-1"></span>
<img src="DS_files/figure-html/gelmanrubin1-1.png" alt="Gelman-Rubin (Trace and Density)" width="100%" />
<p class="caption">
Figure 8.36: Gelman-Rubin (Trace and Density)
</p>
</div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:gelmanrubin1-2"></span>
<img src="DS_files/figure-html/gelmanrubin1-2.png" alt="Gelman-Rubin (Trace and Density)" width="100%" />
<p class="caption">
Figure 8.37: Gelman-Rubin (Trace and Density)
</p>
</div>

<p>Reviewing the <strong>Potential scare reduction factors</strong>, the parameters <span class="math inline">\(\mu\)</span>s have a point estimate equal to or close to 1 and a confidence interval equal to or close to 1, indicating that convergence is sufficiently met.</p>

<div class="sourceCode" id="cb947"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb947-1" data-line-number="1"><span class="kw">gelman.diag</span>(cs, <span class="dt">autoburnin=</span><span class="ot">FALSE</span>)</a></code></pre></div>
<pre><code>## Potential scale reduction factors:
## 
##        Point est. Upper C.I.
## mu[1]        1.00       1.00
## mu[2]        1.00       1.00
## mu[3]        1.00       1.00
## mu[4]        1.00       1.00
## mu0          1.03       1.03
## sigma0       1.12       1.21
## 
## Multivariate psrf
## 
## 1.01</code></pre>

<p>To complement that, Figure <a href="bayesian2.html#fig:gelmanrubin2">8.38</a> illustrates convergence to 1 of two chains for each of the parameters <span class="math inline">\(\mu\)</span>s.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:gelmanrubin2"></span>
<img src="DS_files/figure-html/gelmanrubin2-1.png" alt="Gelman-Rubin (Convergence)" width="100%" />
<p class="caption">
Figure 8.38: Gelman-Rubin (Convergence)
</p>
</div>

<p><strong>Alternatively</strong>, we can manually plot the <strong>parameter</strong> estimates and the <strong>hyperparameter</strong> estimates for the prior:</p>

<div class="sourceCode" id="cb949"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb949-1" data-line-number="1"><span class="co"># Showing Densities</span></a>
<a class="sourceLine" id="cb949-2" data-line-number="2">result =<span class="st"> </span><span class="kw">as.matrix</span>(cs)</a>
<a class="sourceLine" id="cb949-3" data-line-number="3"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))</a>
<a class="sourceLine" id="cb949-4" data-line-number="4"><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>sampling_size) {</a>
<a class="sourceLine" id="cb949-5" data-line-number="5">  <span class="kw">plot</span>(<span class="kw">density</span>(result[, <span class="kw">c</span>(<span class="kw">paste0</span>(<span class="st">&quot;mu[&quot;</span>,i,<span class="st">&quot;]&quot;</span>))]),  </a>
<a class="sourceLine" id="cb949-6" data-line-number="6">       <span class="dt">main=</span><span class="kw">paste0</span>(<span class="st">&quot;Density of mu[&quot;</span>,i,<span class="st">&quot;]&quot;</span>))</a>
<a class="sourceLine" id="cb949-7" data-line-number="7">}</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:jagsmodel-1"></span>
<img src="DS_files/figure-html/jagsmodel-1.png" alt="Jags Result" width="80%" />
<p class="caption">
Figure 8.39: Jags Result
</p>
</div>
<div class="sourceCode" id="cb950"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb950-1" data-line-number="1"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</a>
<a class="sourceLine" id="cb950-2" data-line-number="2"><span class="kw">plot</span>(<span class="kw">density</span>(result[, <span class="kw">c</span>(<span class="st">&quot;mu0&quot;</span>)]), <span class="dt">main=</span><span class="st">&quot;Density of mu0&quot;</span>)</a>
<a class="sourceLine" id="cb950-3" data-line-number="3"><span class="kw">plot</span>(<span class="kw">density</span>(result[, <span class="kw">c</span>(<span class="st">&quot;sigma0&quot;</span>)]), <span class="dt">main=</span><span class="st">&quot;Density of sigma0&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:jagsmodel-2"></span>
<img src="DS_files/figure-html/jagsmodel-2.png" alt="Jags Result" width="80%" />
<p class="caption">
Figure 8.40: Jags Result
</p>
</div>

<p>We can now reparameterize our prior mean and generate our posterior by obtaining the ten means for the corresponding ten samples. If we are to monitor <span class="math inline">\(X\)</span>, we also should be able to capture the sampling densities:</p>

<div class="sourceCode" id="cb951"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb951-1" data-line-number="1"><span class="co"># Iteration 5000 times for the X samples.</span></a>
<a class="sourceLine" id="cb951-2" data-line-number="2">cs &lt;-<span class="st"> </span><span class="kw">coda.samples</span>(model, <span class="kw">c</span>(  <span class="st">&quot;X&quot;</span> ), <span class="dt">n.iter=</span><span class="dv">5000</span>)</a>
<a class="sourceLine" id="cb951-3" data-line-number="3">result =<span class="st"> </span><span class="kw">as.matrix</span>(cs)</a>
<a class="sourceLine" id="cb951-4" data-line-number="4">samplings =<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;X1&quot;</span> =<span class="st"> </span><span class="kw">mean</span>( result[, <span class="kw">c</span>(<span class="st">&quot;X[1]&quot;</span>)]), </a>
<a class="sourceLine" id="cb951-5" data-line-number="5">              <span class="st">&quot;X2&quot;</span> =<span class="st"> </span><span class="kw">mean</span>( result[, <span class="kw">c</span>(<span class="st">&quot;X[2]&quot;</span>)]),</a>
<a class="sourceLine" id="cb951-6" data-line-number="6">  <span class="st">&quot;X3&quot;</span> =<span class="st"> </span><span class="kw">mean</span>( result[, <span class="kw">c</span>(<span class="st">&quot;X[3]&quot;</span>)]), <span class="st">&quot;X4&quot;</span> =<span class="st"> </span><span class="kw">mean</span>(result[, <span class="kw">c</span>(<span class="st">&quot;X[4]&quot;</span>)]))</a></code></pre></div>

<p>Therefore, our estimated likelihood for the first sampling is:</p>

<div class="sourceCode" id="cb952"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb952-1" data-line-number="1">samplings</a></code></pre></div>
<pre><code>##    X1    X2    X3    X4 
## 13.65 13.95 15.12 15.86</code></pre>

</div>
</div>
<div id="bayesian-analysis" class="section level2 hasAnchor">
<h2><span class="header-section-number">8.3</span> Bayesian Analysis<a href="bayesian2.html#bayesian-analysis" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In a <strong>Bayesian</strong> context, we use <strong>prior</strong> to represent our belief which comes with uncertainty. In a <strong>Non-Bayesian</strong> context, uncertainty happens due to residuals. <strong>Residual</strong> may be interpreted differently: perturbation, distortion, bias, and error. As such, we perform <strong>Residual Analysis</strong>.</p>
<p>We start with some observation (or evidence) - backed by some initial prior belief - and perform the estimation. Estimation in most - if not all - cases has the property of being inaccurate (whether this affects our notion of uncertainty or not). Our goal is to reduce the inaccuracy which is analyzing such residuals. There are many approaches to doing that - in general, our <strong>Bayesian</strong> approach is to collect more evidence to update our prior beliefs. After all, in Chapter <strong>9</strong> (<strong>Computational Learning I</strong>), we follow the same strategy: we train and keep learning. Also, to complement <strong>Bayesian Analysis</strong> in line with quantifying <strong>uncertainty</strong>, let us recall in the previous Chapter that we encourage readers to investigate the topic around <strong>Uncertainty Quantification</strong>.</p>
<p>Let us end this Chapter by enumerating a few other topics around <strong>Bayesian analysis</strong> starting with <strong>autocorrelation</strong>.</p>
<div id="autocorrelation" class="section level3 hasAnchor">
<h3><span class="header-section-number">8.3.1</span> Autocorrelation <a href="bayesian2.html#autocorrelation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>When operating <strong>MCMC</strong> to generate multiple samples during sampling simulation, there are situations when the proposed samples begin to form a strong correlation. However, such <strong>autocorrelation</strong> of samples may not provide further improvements (in terms of convergence) even with a large number of iterations. Thus, we apply <strong>thinning</strong> to <strong>thin</strong> the sample by reducing the number of iterations. Here, for example, we can skip every <strong>kth</strong> iteration.</p>
<p>As for <strong>mixing</strong>, a multimodal distribution is a good use case in which if our simulation is more biased on a particular peak, then we consider this as <strong>poor mixing</strong>; otherwise, our samples are <strong>well-mixed</strong>.</p>
<p>Note that high correlation or poor mixing may slow down or even prevent convergence. Thus, one possible solution is to choose initialization values that are more closely <strong>centered</strong> on the target distribution when modeling the proposal distribution.</p>
</div>
<div id="predictive-probability" class="section level3 hasAnchor">
<h3><span class="header-section-number">8.3.2</span> Predictive Probability <a href="bayesian2.html#predictive-probability" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Predictive distribution</strong> is a distribution formed by future observations. For example, if our observation is associated with posterior parameters, we expect a <strong>posterior predictive distribution</strong>; if our observation is associated with prior parameters, we expect a <strong>prior predictive distribution</strong>.</p>
<p>The <strong>posterior predictive distribution</strong> of future observations, namely <span class="math inline">\(y&#39;\)</span>, can be expressed as so:</p>
<p><span class="math display">\[\begin{align}
P(y&#39;|y) = \int P(y&#39;|\theta)P(\theta|y) d\theta
\end{align}\]</span></p>
<p>For example, suppose we have a set of observations that follow a normal distribution characterized by posterior parameter <span class="math inline">\(\theta\)</span> such that <span class="math inline">\(\theta \sim \mathcal{N}(\mu = 10, \sigma = 1)\)</span>; then we can draw our future observation <span class="math inline">\(y&#39;\)</span>. Here, we assume a posterior distribution with <span class="math inline">\(\mu = 10\)</span> and <span class="math inline">\(\sigma = 1\)</span>.</p>

<div class="sourceCode" id="cb954"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb954-1" data-line-number="1">sample_size =<span class="st"> </span><span class="dv">200</span></a>
<a class="sourceLine" id="cb954-2" data-line-number="2">future_sample_size =<span class="st"> </span><span class="dv">50</span></a>
<a class="sourceLine" id="cb954-3" data-line-number="3">theta =<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n =</span> sample_size, <span class="dt">mean =</span> <span class="dv">10</span>, <span class="dt">sd =</span> <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb954-4" data-line-number="4">y.pred =<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n =</span> future_sample_size, <span class="dt">mean =</span> theta, <span class="dt">sd =</span> <span class="dv">1</span>)</a></code></pre></div>

<p>Our <strong>posterior predictive distribution</strong> has the following mean:</p>

<div class="sourceCode" id="cb955"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb955-1" data-line-number="1"><span class="kw">mean</span>(y.pred)</a></code></pre></div>
<pre><code>## [1] 9.868</code></pre>

<p>with the following quantile:</p>

<div class="sourceCode" id="cb957"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb957-1" data-line-number="1"><span class="kw">quantile</span>(y.pred, <span class="kw">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>) )</a></code></pre></div>
<pre><code>##   2.5%  97.5% 
##  7.027 12.407</code></pre>

</div>
<div id="posterior-interval" class="section level3 hasAnchor">
<h3><span class="header-section-number">8.3.3</span> Posterior Interval <a href="bayesian2.html#posterior-interval" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Posterior Interval</strong>, also called <strong>Credible Interval</strong>, is similar in concept as <strong>Prediction Interval</strong>. <strong>Credible Interval</strong> is enforced based on a given <span class="math inline">\(\alpha\)</span>, e.g. <span class="math inline">\(\alpha = 0.05\)</span>, and is denoted as:</p>
<p><span class="math display">\[
\mathcal{C}(X) = 1 - \alpha, 
\ \ \ \ \ \ \ \ \ \ \ \ e.g., \mathcal{C}(X) = 0.95\ \ \ where: \alpha = 0.05
\]</span>
If there is such a boundary, namely <strong>a</strong> and <strong>b</strong>, to limit our parameter space (<strong>X</strong> being our random variable parameter), then a <strong>credible interval</strong> of 95% limits <strong>X</strong> such that:</p>
<p><span class="math display">\[
P(a \le X \le b |\theta) = 1 - \alpha\ \ \ \ where\ \alpha = 0.05
\]</span>
<strong>Interval Censorship</strong> is the term used to limit our parameter space. However, there are other ways to express a limit to our parameter space:</p>
<p><span class="math display">\[
P(X &lt; a) = \alpha \ \ \ \ \ \ \ \ \ P(X &gt; b) = \alpha
\]</span></p>
</div>
<div id="bayes-factor" class="section level3 hasAnchor">
<h3><span class="header-section-number">8.3.4</span> Bayes Factor <a href="bayesian2.html#bayes-factor" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Recall <strong>Significance of Difference and Regression</strong> in Chapter <strong>6</strong> (<strong>Statistical Computation</strong>), which discusses <strong>Statistical Significance</strong>tests. Similarly, in <strong>Bayesian Statistics</strong>, we perform <strong>hypothesis test</strong> using <strong>Bayes Factor</strong> which evaluates two competing <strong>hypotheses</strong>, namely <strong>H1</strong> and <strong>H0</strong>.</p>
<p><strong>Bayes Factor</strong> is expressed as a ratio of two posterior probabilities:</p>
<p><span class="math display">\[\begin{align}
K = \frac{P(\theta_1|X_1)}{P(\theta_2|X_2)}
\end{align}\]</span></p>
<p>It follows guidelines measured in terms of <strong>evidence</strong> levels based on the below <strong>Jeffreyâs scale</strong> table:</p>

<table>
<caption><span id="tab:bayesfactor">Table 8.1: </span>Bayes Factor</caption>
<colgroup>
<col width="11%" />
<col width="35%" />
<col width="16%" />
<col width="35%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">K</th>
<th align="left">Intepretation for H1</th>
<th align="left">K</th>
<th align="left">Interpretation for H0</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">&gt;100</td>
<td align="left">Extreme evidence for H1</td>
<td align="left">&lt; 1/100</td>
<td align="left">Extreme evidence for H0</td>
</tr>
<tr class="even">
<td align="left">30 - 100</td>
<td align="left">Very Strong evidence for H1</td>
<td align="left">1/100 - 1/30</td>
<td align="left">Very Strong evidence for H0</td>
</tr>
<tr class="odd">
<td align="left">10 - 30</td>
<td align="left">Strong evidence for H1</td>
<td align="left">1/30 - 1/10</td>
<td align="left">Strong evidence for H0</td>
</tr>
<tr class="even">
<td align="left">3 - 10</td>
<td align="left">Substantial evidence for H1</td>
<td align="left">1/10 - 1/3</td>
<td align="left">Substantial evidence for H0</td>
</tr>
<tr class="odd">
<td align="left">1 - 3</td>
<td align="left">Anecdotal evidence for H1</td>
<td align="left">1/3 - 1</td>
<td align="left">Anecdotal evidence for H0</td>
</tr>
<tr class="even">
<td align="left">1</td>
<td align="left">No evidence for H1</td>
<td align="left"></td>
<td align="left"></td>
</tr>
</tbody>
</table>

<p>For example, if our <strong>Bayes Factor</strong> happens to be <strong>K=0.20</strong>, then there is a piece of very strong evidence that our <strong>Null Hypothesis (H0)</strong> holds.</p>
</div>
</div>
<div id="summary-5" class="section level2 hasAnchor">
<h2><span class="header-section-number">8.4</span> Summary<a href="bayesian2.html#summary-5" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In Bayesian statistics, events are treated with uncertainty in that observations are random and thus follow a particular type of distribution. We introduce <strong>Bayes Theorem</strong> which is central to the Bayesian computation of uncertainty. Bayesian analysis sits on the premise of prior knowledge and likelihood, which are used to estimate a parameter model in the form of a posterior distribution. However, posterior distribution may not always be tractable (not closed-form). For this reason, we introduce the concept of <strong>Conjugacy</strong> by injecting <strong>conjugate priors</strong> into the equation. For intractable posterior distribution with no <strong>conjugate prior</strong>, we resort to the <strong>Variational Bayes</strong> method, simulation, and sampling techniques such as <strong>Markov Chain Monte Carlo</strong>.</p>
<p>In dealing with point estimates, we introduce maximum likelihood (<strong>MLE</strong>) and maximum posterior (<strong>MAP</strong>) estimates to seek an optimal parameter model.</p>
<p>Also, we introduce the <strong>expectation-maximization (EM)</strong> technique used in cases where we have missing data, and our model has not fully regressed.</p>
<p>We leave readers to investigate <strong>Stochastic Tunneling</strong> and <strong>Local Relaxation</strong> around optimization ideas for further reading.</p>
<p>In volume III of this book, we begin to discuss <strong>approximations</strong> in the context of <strong>Computational Learning</strong> and <strong>Computational Deep Learning</strong>, covering major topics around <strong>supervised</strong> and <strong>non-supervised</strong> learning. We cover <strong>Regressions</strong>, <strong>Classifications</strong> such as <strong>SVM</strong>, and <strong>Neural Networks</strong> such as <strong>Perceptrons</strong>, <strong>CNN</strong>, <strong>RNN</strong>, and <strong>Transformers</strong>. We end the book with <strong>Model Management</strong> discussions.</p>


</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="bayesian.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="machinelearning1.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "sepia",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["DS.pdf", "DS.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
