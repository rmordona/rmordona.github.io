<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>5.9 Types of Distribution | The Power and Art of Approximation</title>
  <meta name="description" content="Enthused by the promising future of self-learning machines and the continuous advancement of technology, we write this book to cover a compendium of analytical and numerical techniques conflated into a common idea that highlights the fundamental requirements of Data Science and Machine Learning (ML) Engineering. In this book, we review and give brief insights into numerous fundamental ideas around methods of approximation conceived by great experts. We aim to share them with those new to Data Science who are just beginning to develop an inclination toward this field but may not know where to begin. In addition, we hope to introduce some essential aspects of Data Science in a more progressive and possibly structured manner. This book avoids being specific to a target audience depending on interest. The premise is that Data Science can be for everybody, whether one is an engineer, a researcher within a particular domain, or, for that matter, an undergraduate student just trying to get into this field. While we note that our common theme across the book is intuition, contemplating more on basic operations than mathematical rigor, it is essential to revive our understanding of mathematical concepts first. That is founded upon the idea that we express most of what we do in Data Science in the language of mathematics, more numerically inclined in fact than analytical - meaning, we live to decide based on close approximation in many situations. Therefore, it is essential to have some introductory perspective of the mathematical foundations in which Machine Learning algorithms may have come about - if not at least what they depend upon fundamentally. For that reason, we cover a list of mathematical concepts that are no doubt valuable to eventually get us to Machine Learning concepts. However, only a particular elementary and introductory portion of each field of mathematics is covered as we emphasize only relevant and essential areas. That said, this book comes in three volumes. Volumes I and II of this book briefly cover common topics in Linear Algebra, Numerical Analysis, Statistical Analysis, and Bayesian Analysis. The third part (or volume III) of this book covers Machine Learning and Deep Learning in detail." />
  <meta name="generator" content="bookdown 0.32 and GitBook 2.6.7" />

  <meta property="og:title" content="5.9 Types of Distribution | The Power and Art of Approximation" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Enthused by the promising future of self-learning machines and the continuous advancement of technology, we write this book to cover a compendium of analytical and numerical techniques conflated into a common idea that highlights the fundamental requirements of Data Science and Machine Learning (ML) Engineering. In this book, we review and give brief insights into numerous fundamental ideas around methods of approximation conceived by great experts. We aim to share them with those new to Data Science who are just beginning to develop an inclination toward this field but may not know where to begin. In addition, we hope to introduce some essential aspects of Data Science in a more progressive and possibly structured manner. This book avoids being specific to a target audience depending on interest. The premise is that Data Science can be for everybody, whether one is an engineer, a researcher within a particular domain, or, for that matter, an undergraduate student just trying to get into this field. While we note that our common theme across the book is intuition, contemplating more on basic operations than mathematical rigor, it is essential to revive our understanding of mathematical concepts first. That is founded upon the idea that we express most of what we do in Data Science in the language of mathematics, more numerically inclined in fact than analytical - meaning, we live to decide based on close approximation in many situations. Therefore, it is essential to have some introductory perspective of the mathematical foundations in which Machine Learning algorithms may have come about - if not at least what they depend upon fundamentally. For that reason, we cover a list of mathematical concepts that are no doubt valuable to eventually get us to Machine Learning concepts. However, only a particular elementary and introductory portion of each field of mathematics is covered as we emphasize only relevant and essential areas. That said, this book comes in three volumes. Volumes I and II of this book briefly cover common topics in Linear Algebra, Numerical Analysis, Statistical Analysis, and Bayesian Analysis. The third part (or volume III) of this book covers Machine Learning and Deep Learning in detail." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="5.9 Types of Distribution | The Power and Art of Approximation" />
  
  <meta name="twitter:description" content="Enthused by the promising future of self-learning machines and the continuous advancement of technology, we write this book to cover a compendium of analytical and numerical techniques conflated into a common idea that highlights the fundamental requirements of Data Science and Machine Learning (ML) Engineering. In this book, we review and give brief insights into numerous fundamental ideas around methods of approximation conceived by great experts. We aim to share them with those new to Data Science who are just beginning to develop an inclination toward this field but may not know where to begin. In addition, we hope to introduce some essential aspects of Data Science in a more progressive and possibly structured manner. This book avoids being specific to a target audience depending on interest. The premise is that Data Science can be for everybody, whether one is an engineer, a researcher within a particular domain, or, for that matter, an undergraduate student just trying to get into this field. While we note that our common theme across the book is intuition, contemplating more on basic operations than mathematical rigor, it is essential to revive our understanding of mathematical concepts first. That is founded upon the idea that we express most of what we do in Data Science in the language of mathematics, more numerically inclined in fact than analytical - meaning, we live to decide based on close approximation in many situations. Therefore, it is essential to have some introductory perspective of the mathematical foundations in which Machine Learning algorithms may have come about - if not at least what they depend upon fundamentally. For that reason, we cover a list of mathematical concepts that are no doubt valuable to eventually get us to Machine Learning concepts. However, only a particular elementary and introductory portion of each field of mathematics is covered as we emphasize only relevant and essential areas. That said, this book comes in three volumes. Volumes I and II of this book briefly cover common topics in Linear Algebra, Numerical Analysis, Statistical Analysis, and Bayesian Analysis. The third part (or volume III) of this book covers Machine Learning and Deep Learning in detail." />
  

<meta name="author" content="Raymond Michael Ofiaza Ordoña" />


<meta name="date" content="2023-03-12" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="5.8-special-functions.html"/>
<link rel="next" href="5.10-summary-3.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">The Power and Art of Approximation</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="" data-path="acknowledgment-and-motivations.html"><a href="acknowledgment-and-motivations.html"><i class="fa fa-check"></i>Acknowledgment and Motivations</a></li>
<li class="chapter" data-level="" data-path="caveat-and-disclaimer.html"><a href="caveat-and-disclaimer.html"><i class="fa fa-check"></i>Caveat and Disclaimer</a></li>
<li class="chapter" data-level="" data-path="about-the-author.html"><a href="about-the-author.html"><i class="fa fa-check"></i>About the Author</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="" data-path="mathematical-notation.html"><a href="mathematical-notation.html"><i class="fa fa-check"></i>Mathematical Notation</a><ul>
<li class="chapter" data-level="0.1" data-path="0.1-notation.html"><a href="0.1-notation.html"><i class="fa fa-check"></i><b>0.1</b> Notation</a></li>
<li class="chapter" data-level="0.2" data-path="0.2-number-system.html"><a href="0.2-number-system.html"><i class="fa fa-check"></i><b>0.2</b> Number System</a></li>
<li class="chapter" data-level="0.3" data-path="0.3-implementation.html"><a href="0.3-implementation.html"><i class="fa fa-check"></i><b>0.3</b> Implementation</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="1-numericalmethods.html"><a href="1-numericalmethods.html"><i class="fa fa-check"></i><b>1</b> Direct and Indirect Methods</a><ul>
<li class="chapter" data-level="1.1" data-path="1.1-closed-form-equation.html"><a href="1.1-closed-form-equation.html"><i class="fa fa-check"></i><b>1.1</b> Closed-form equation</a></li>
<li class="chapter" data-level="1.2" data-path="1.2-analytical-and-numerical-solutions.html"><a href="1.2-analytical-and-numerical-solutions.html"><i class="fa fa-check"></i><b>1.2</b> Analytical and Numerical solutions  </a></li>
<li class="chapter" data-level="1.3" data-path="1.3-significant-figures.html"><a href="1.3-significant-figures.html"><i class="fa fa-check"></i><b>1.3</b> Significant figures</a></li>
<li class="chapter" data-level="1.4" data-path="1.4-accuracy.html"><a href="1.4-accuracy.html"><i class="fa fa-check"></i><b>1.4</b> Accuracy</a></li>
<li class="chapter" data-level="1.5" data-path="1.5-precision.html"><a href="1.5-precision.html"><i class="fa fa-check"></i><b>1.5</b> Precision </a></li>
<li class="chapter" data-level="1.6" data-path="1.6-stability-and-sensitivity.html"><a href="1.6-stability-and-sensitivity.html"><i class="fa fa-check"></i><b>1.6</b> Stability and Sensitivity  </a></li>
<li class="chapter" data-level="1.7" data-path="1.7-stiffness-and-implicitness.html"><a href="1.7-stiffness-and-implicitness.html"><i class="fa fa-check"></i><b>1.7</b> Stiffness and Implicitness  </a></li>
<li class="chapter" data-level="1.8" data-path="1.8-conditioning-and-posedness.html"><a href="1.8-conditioning-and-posedness.html"><i class="fa fa-check"></i><b>1.8</b> Conditioning and Posedness  </a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="2-linearalgebra.html"><a href="2-linearalgebra.html"><i class="fa fa-check"></i><b>2</b> Numerical Linear Algebra I</a><ul>
<li class="chapter" data-level="2.1" data-path="2.1-system-of-linear-equations.html"><a href="2.1-system-of-linear-equations.html"><i class="fa fa-check"></i><b>2.1</b> System of Linear Equations</a></li>
<li class="chapter" data-level="2.2" data-path="2.2-scalar-vector-and-matrix-tensor.html"><a href="2.2-scalar-vector-and-matrix-tensor.html"><i class="fa fa-check"></i><b>2.2</b> Scalar, Vector, and Matrix, Tensor</a></li>
<li class="chapter" data-level="2.3" data-path="2.3-transposition-and-multiplication.html"><a href="2.3-transposition-and-multiplication.html"><i class="fa fa-check"></i><b>2.3</b> Transposition and Multiplication</a><ul>
<li class="chapter" data-level="2.3.1" data-path="2.3-transposition-and-multiplication.html"><a href="2.3-transposition-and-multiplication.html#transposition"><i class="fa fa-check"></i><b>2.3.1</b> Transposition</a></li>
<li class="chapter" data-level="2.3.2" data-path="2.3-transposition-and-multiplication.html"><a href="2.3-transposition-and-multiplication.html#dot-product"><i class="fa fa-check"></i><b>2.3.2</b> Dot Product</a></li>
<li class="chapter" data-level="2.3.3" data-path="2.3-transposition-and-multiplication.html"><a href="2.3-transposition-and-multiplication.html#hadamard-product"><i class="fa fa-check"></i><b>2.3.3</b> Hadamard Product</a></li>
<li class="chapter" data-level="2.3.4" data-path="2.3-transposition-and-multiplication.html"><a href="2.3-transposition-and-multiplication.html#kronecker-product"><i class="fa fa-check"></i><b>2.3.4</b> Kronecker Product</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="2.4-magnitude-direction-unit-vectors.html"><a href="2.4-magnitude-direction-unit-vectors.html"><i class="fa fa-check"></i><b>2.4</b> Magnitude, Direction, Unit Vectors</a></li>
<li class="chapter" data-level="2.5" data-path="2.5-linear-combination-and-independence.html"><a href="2.5-linear-combination-and-independence.html"><i class="fa fa-check"></i><b>2.5</b> Linear Combination and Independence</a></li>
<li class="chapter" data-level="2.6" data-path="2.6-space-span-and-basis.html"><a href="2.6-space-span-and-basis.html"><i class="fa fa-check"></i><b>2.6</b> Space, Span, and Basis</a></li>
<li class="chapter" data-level="2.7" data-path="2.7-determinants.html"><a href="2.7-determinants.html"><i class="fa fa-check"></i><b>2.7</b> Determinants </a></li>
<li class="chapter" data-level="2.8" data-path="2.8-minors-cofactors-and-adjugate-forms.html"><a href="2.8-minors-cofactors-and-adjugate-forms.html"><i class="fa fa-check"></i><b>2.8</b> Minors, Cofactors, and Adjugate Forms</a></li>
<li class="chapter" data-level="2.9" data-path="2.9-inverse-form-and-row-echelon-form.html"><a href="2.9-inverse-form-and-row-echelon-form.html"><i class="fa fa-check"></i><b>2.9</b> Inverse Form and Row-Echelon Form</a></li>
<li class="chapter" data-level="2.10" data-path="2.10-linear-transformations.html"><a href="2.10-linear-transformations.html"><i class="fa fa-check"></i><b>2.10</b> Linear Transformations</a><ul>
<li class="chapter" data-level="2.10.1" data-path="2.10-linear-transformations.html"><a href="2.10-linear-transformations.html#scaling"><i class="fa fa-check"></i><b>2.10.1</b> Scaling </a></li>
<li class="chapter" data-level="2.10.2" data-path="2.10-linear-transformations.html"><a href="2.10-linear-transformations.html#transvection-shearing"><i class="fa fa-check"></i><b>2.10.2</b> Transvection (Shearing)  </a></li>
<li class="chapter" data-level="2.10.3" data-path="2.10-linear-transformations.html"><a href="2.10-linear-transformations.html#rotation"><i class="fa fa-check"></i><b>2.10.3</b> Rotation </a></li>
<li class="chapter" data-level="2.10.4" data-path="2.10-linear-transformations.html"><a href="2.10-linear-transformations.html#reflection"><i class="fa fa-check"></i><b>2.10.4</b> Reflection </a></li>
<li class="chapter" data-level="2.10.5" data-path="2.10-linear-transformations.html"><a href="2.10-linear-transformations.html#projection"><i class="fa fa-check"></i><b>2.10.5</b> Projection </a></li>
<li class="chapter" data-level="2.10.6" data-path="2.10-linear-transformations.html"><a href="2.10-linear-transformations.html#translation"><i class="fa fa-check"></i><b>2.10.6</b> Translation </a></li>
<li class="chapter" data-level="2.10.7" data-path="2.10-linear-transformations.html"><a href="2.10-linear-transformations.html#dilation-and-composition"><i class="fa fa-check"></i><b>2.10.7</b> Dilation and Composition  </a></li>
</ul></li>
<li class="chapter" data-level="2.11" data-path="2.11-rank-and-nullity.html"><a href="2.11-rank-and-nullity.html"><i class="fa fa-check"></i><b>2.11</b> Rank and Nullity  </a></li>
<li class="chapter" data-level="2.12" data-path="2.12-singularity-and-triviality.html"><a href="2.12-singularity-and-triviality.html"><i class="fa fa-check"></i><b>2.12</b> Singularity and Triviality  </a></li>
<li class="chapter" data-level="2.13" data-path="2.13-orthogonality-and-orthonormality.html"><a href="2.13-orthogonality-and-orthonormality.html"><i class="fa fa-check"></i><b>2.13</b> Orthogonality and Orthonormality  </a></li>
<li class="chapter" data-level="2.14" data-path="2.14-eigenvectors-and-eigenvalues.html"><a href="2.14-eigenvectors-and-eigenvalues.html"><i class="fa fa-check"></i><b>2.14</b> Eigenvectors and Eigenvalues  </a></li>
<li class="chapter" data-level="2.15" data-path="2.15-matrix-reconstruction-using-eigenvalues-and-eigenvectors.html"><a href="2.15-matrix-reconstruction-using-eigenvalues-and-eigenvectors.html"><i class="fa fa-check"></i><b>2.15</b> Matrix Reconstruction using Eigenvalues and Eigenvectors</a></li>
<li class="chapter" data-level="2.16" data-path="2.16-diagonalizability-of-a-matrix.html"><a href="2.16-diagonalizability-of-a-matrix.html"><i class="fa fa-check"></i><b>2.16</b> Diagonalizability of a Matrix </a></li>
<li class="chapter" data-level="2.17" data-path="2.17-trace-of-a-square-matrix.html"><a href="2.17-trace-of-a-square-matrix.html"><i class="fa fa-check"></i><b>2.17</b> Trace of a Square Matrix </a></li>
<li class="chapter" data-level="2.18" data-path="2.18-algebraic-and-geometric-multiplicity.html"><a href="2.18-algebraic-and-geometric-multiplicity.html"><i class="fa fa-check"></i><b>2.18</b> Algebraic and Geometric Multiplicity</a></li>
<li class="chapter" data-level="2.19" data-path="2.19-types-of-matrices.html"><a href="2.19-types-of-matrices.html"><i class="fa fa-check"></i><b>2.19</b> Types of Matrices</a></li>
<li class="chapter" data-level="2.20" data-path="2.20-matrix-factorization.html"><a href="2.20-matrix-factorization.html"><i class="fa fa-check"></i><b>2.20</b> Matrix Factorization </a><ul>
<li class="chapter" data-level="2.20.1" data-path="2.20-matrix-factorization.html"><a href="2.20-matrix-factorization.html#eigen-spectral-decomposition"><i class="fa fa-check"></i><b>2.20.1</b> Eigen (Spectral) Decomposition  </a></li>
<li class="chapter" data-level="2.20.2" data-path="2.20-matrix-factorization.html"><a href="2.20-matrix-factorization.html#ludecomposition"><i class="fa fa-check"></i><b>2.20.2</b> LU Decomposition (Doolittle Algorithm)</a></li>
<li class="chapter" data-level="2.20.3" data-path="2.20-matrix-factorization.html"><a href="2.20-matrix-factorization.html#ldu-factorization"><i class="fa fa-check"></i><b>2.20.3</b> LDU Factorization </a></li>
<li class="chapter" data-level="2.20.4" data-path="2.20-matrix-factorization.html"><a href="2.20-matrix-factorization.html#qr-factorization-gram-schmidt-householder-and-givens"><i class="fa fa-check"></i><b>2.20.4</b> QR Factorization (Gram-Schmidt, Householder, and Givens) </a></li>
<li class="chapter" data-level="2.20.5" data-path="2.20-matrix-factorization.html"><a href="2.20-matrix-factorization.html#cholesky-factorization"><i class="fa fa-check"></i><b>2.20.5</b> Cholesky Factorization </a></li>
<li class="chapter" data-level="2.20.6" data-path="2.20-matrix-factorization.html"><a href="2.20-matrix-factorization.html#svd-factorization"><i class="fa fa-check"></i><b>2.20.6</b> SVD Factorization </a></li>
<li class="chapter" data-level="2.20.7" data-path="2.20-matrix-factorization.html"><a href="2.20-matrix-factorization.html#jordan-decomposition"><i class="fa fa-check"></i><b>2.20.7</b> Jordan Decomposition </a></li>
<li class="chapter" data-level="2.20.8" data-path="2.20-matrix-factorization.html"><a href="2.20-matrix-factorization.html#other-decomposition"><i class="fa fa-check"></i><b>2.20.8</b> Other Decomposition</a></li>
</ul></li>
<li class="chapter" data-level="2.21" data-path="2.21-software-libraries.html"><a href="2.21-software-libraries.html"><i class="fa fa-check"></i><b>2.21</b> Software libraries    </a></li>
<li class="chapter" data-level="2.22" data-path="2.22-summary.html"><a href="2.22-summary.html"><i class="fa fa-check"></i><b>2.22</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="3-numericallinearalgebra.html"><a href="3-numericallinearalgebra.html"><i class="fa fa-check"></i><b>3</b> Numerical Linear Algebra II</a><ul>
<li class="chapter" data-level="3.1" data-path="3.1-iteration-and-convergence.html"><a href="3.1-iteration-and-convergence.html"><i class="fa fa-check"></i><b>3.1</b> Iteration and Convergence </a></li>
<li class="chapter" data-level="3.2" data-path="3.2-approximating-eigenvalues-and-eigenvectors-by-iteration-av-lambda-v.html"><a href="3.2-approximating-eigenvalues-and-eigenvectors-by-iteration-av-lambda-v.html"><i class="fa fa-check"></i><b>3.2</b> Approximating Eigenvalues and EigenVectors by Iteration (<span class="math inline">\(Av = \lambda v\)</span>)</a><ul>
<li class="chapter" data-level="3.2.1" data-path="3.2-approximating-eigenvalues-and-eigenvectors-by-iteration-av-lambda-v.html"><a href="3.2-approximating-eigenvalues-and-eigenvectors-by-iteration-av-lambda-v.html#power-method"><i class="fa fa-check"></i><b>3.2.1</b> Power Method </a></li>
<li class="chapter" data-level="3.2.2" data-path="3.2-approximating-eigenvalues-and-eigenvectors-by-iteration-av-lambda-v.html"><a href="3.2-approximating-eigenvalues-and-eigenvectors-by-iteration-av-lambda-v.html#inverse-power-method-using-lu-decomposition"><i class="fa fa-check"></i><b>3.2.2</b> Inverse Power Method (using LU Decomposition)</a></li>
<li class="chapter" data-level="3.2.3" data-path="3.2-approximating-eigenvalues-and-eigenvectors-by-iteration-av-lambda-v.html"><a href="3.2-approximating-eigenvalues-and-eigenvectors-by-iteration-av-lambda-v.html#rayleigh-quotient-method-using-lu-decomposition"><i class="fa fa-check"></i><b>3.2.3</b> Rayleigh Quotient Method (using LU Decomposition)</a></li>
<li class="chapter" data-level="3.2.4" data-path="3.2-approximating-eigenvalues-and-eigenvectors-by-iteration-av-lambda-v.html"><a href="3.2-approximating-eigenvalues-and-eigenvectors-by-iteration-av-lambda-v.html#qr-method-using-qr-decomposition-by-givens"><i class="fa fa-check"></i><b>3.2.4</b> QR Method (using QR Decomposition by Givens)</a></li>
<li class="chapter" data-level="3.2.5" data-path="3.2-approximating-eigenvalues-and-eigenvectors-by-iteration-av-lambda-v.html"><a href="3.2-approximating-eigenvalues-and-eigenvectors-by-iteration-av-lambda-v.html#jacobi-eigenvalue-method-using-jacobi-rotation"><i class="fa fa-check"></i><b>3.2.5</b> Jacobi Eigenvalue Method (using Jacobi Rotation)</a></li>
<li class="chapter" data-level="3.2.6" data-path="3.2-approximating-eigenvalues-and-eigenvectors-by-iteration-av-lambda-v.html"><a href="3.2-approximating-eigenvalues-and-eigenvectors-by-iteration-av-lambda-v.html#arnoldi-method-using-gram-schmidt-in-krylov-subspace"><i class="fa fa-check"></i><b>3.2.6</b> Arnoldi Method (using Gram-Schmidt in Krylov Subspace) </a></li>
<li class="chapter" data-level="3.2.7" data-path="3.2-approximating-eigenvalues-and-eigenvectors-by-iteration-av-lambda-v.html"><a href="3.2-approximating-eigenvalues-and-eigenvectors-by-iteration-av-lambda-v.html#lanczos-method-using-gram-schmidt-in-krylov-subspace"><i class="fa fa-check"></i><b>3.2.7</b> Lanczos Method (using Gram-Schmidt in Krylov Subspace)</a></li>
<li class="chapter" data-level="3.2.8" data-path="3.2-approximating-eigenvalues-and-eigenvectors-by-iteration-av-lambda-v.html"><a href="3.2-approximating-eigenvalues-and-eigenvectors-by-iteration-av-lambda-v.html#fine-tuning-of-iteration-and-convergence"><i class="fa fa-check"></i><b>3.2.8</b> Fine-Tuning of Iteration and Convergence</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="3.3-approximating-root-and-fixed-point-by-iteration.html"><a href="3.3-approximating-root-and-fixed-point-by-iteration.html"><i class="fa fa-check"></i><b>3.3</b> Approximating Root and Fixed-Point by Iteration</a><ul>
<li class="chapter" data-level="3.3.1" data-path="3.3-approximating-root-and-fixed-point-by-iteration.html"><a href="3.3-approximating-root-and-fixed-point-by-iteration.html#root-finding-method-fx-0"><i class="fa fa-check"></i><b>3.3.1</b> Root-Finding Method (<span class="math inline">\(f(x) = 0\)</span>) </a></li>
<li class="chapter" data-level="3.3.2" data-path="3.3-approximating-root-and-fixed-point-by-iteration.html"><a href="3.3-approximating-root-and-fixed-point-by-iteration.html#fixed-point-method-fx-x"><i class="fa fa-check"></i><b>3.3.2</b> Fixed-Point Method (<span class="math inline">\(f(x) = x\)</span>) </a></li>
<li class="chapter" data-level="3.3.3" data-path="3.3-approximating-root-and-fixed-point-by-iteration.html"><a href="3.3-approximating-root-and-fixed-point-by-iteration.html#bisection-method"><i class="fa fa-check"></i><b>3.3.3</b> Bisection Method </a></li>
<li class="chapter" data-level="3.3.4" data-path="3.3-approximating-root-and-fixed-point-by-iteration.html"><a href="3.3-approximating-root-and-fixed-point-by-iteration.html#newton-raphson-method-using-the-tangent-line"><i class="fa fa-check"></i><b>3.3.4</b> Newton-Raphson Method (using the Tangent Line)</a></li>
<li class="chapter" data-level="3.3.5" data-path="3.3-approximating-root-and-fixed-point-by-iteration.html"><a href="3.3-approximating-root-and-fixed-point-by-iteration.html#secant-method-using-the-secant-line"><i class="fa fa-check"></i><b>3.3.5</b> Secant Method (using the Secant Line)</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="3.4-approximating-solutions-to-systems-of-eqns-by-iteration-ax-b.html"><a href="3.4-approximating-solutions-to-systems-of-eqns-by-iteration-ax-b.html"><i class="fa fa-check"></i><b>3.4</b> Approximating Solutions to Systems of Eqns by Iteration (<span class="math inline">\(Ax = b\)</span>)</a><ul>
<li class="chapter" data-level="3.4.1" data-path="3.4-approximating-solutions-to-systems-of-eqns-by-iteration-ax-b.html"><a href="3.4-approximating-solutions-to-systems-of-eqns-by-iteration-ax-b.html#krylovmethods"><i class="fa fa-check"></i><b>3.4.1</b> Krylov Methods</a></li>
<li class="chapter" data-level="3.4.2" data-path="3.4-approximating-solutions-to-systems-of-eqns-by-iteration-ax-b.html"><a href="3.4-approximating-solutions-to-systems-of-eqns-by-iteration-ax-b.html#gmres-generalized-minimal-residual"><i class="fa fa-check"></i><b>3.4.2</b> GMRES (Generalized Minimal Residual)  </a></li>
<li class="chapter" data-level="3.4.3" data-path="3.4-approximating-solutions-to-systems-of-eqns-by-iteration-ax-b.html"><a href="3.4-approximating-solutions-to-systems-of-eqns-by-iteration-ax-b.html#conjugate-gradient-method-cg"><i class="fa fa-check"></i><b>3.4.3</b> Conjugate Gradient Method (CG)  </a></li>
<li class="chapter" data-level="3.4.4" data-path="3.4-approximating-solutions-to-systems-of-eqns-by-iteration-ax-b.html"><a href="3.4-approximating-solutions-to-systems-of-eqns-by-iteration-ax-b.html#jacobi-and-gauss-seidel-method"><i class="fa fa-check"></i><b>3.4.4</b> Jacobi and Gauss-Seidel Method </a></li>
<li class="chapter" data-level="3.4.5" data-path="3.4-approximating-solutions-to-systems-of-eqns-by-iteration-ax-b.html"><a href="3.4-approximating-solutions-to-systems-of-eqns-by-iteration-ax-b.html#successive-over-relaxation-sor-method"><i class="fa fa-check"></i><b>3.4.5</b> Successive Over-Relaxation (SOR) Method  </a></li>
<li class="chapter" data-level="3.4.6" data-path="3.4-approximating-solutions-to-systems-of-eqns-by-iteration-ax-b.html"><a href="3.4-approximating-solutions-to-systems-of-eqns-by-iteration-ax-b.html#newtons-method"><i class="fa fa-check"></i><b>3.4.6</b> Newton’s Method </a></li>
<li class="chapter" data-level="3.4.7" data-path="3.4-approximating-solutions-to-systems-of-eqns-by-iteration-ax-b.html"><a href="3.4-approximating-solutions-to-systems-of-eqns-by-iteration-ax-b.html#broydens-method"><i class="fa fa-check"></i><b>3.4.7</b> Broyden’s Method </a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="3.5-polynomialregression.html"><a href="3.5-polynomialregression.html"><i class="fa fa-check"></i><b>3.5</b> Approximating Polynomial Functions by Regression</a><ul>
<li class="chapter" data-level="3.5.1" data-path="3.5-polynomialregression.html"><a href="3.5-polynomialregression.html#least-squares"><i class="fa fa-check"></i><b>3.5.1</b> Least-Squares </a></li>
<li class="chapter" data-level="3.5.2" data-path="3.5-polynomialregression.html"><a href="3.5-polynomialregression.html#linear-regression"><i class="fa fa-check"></i><b>3.5.2</b> Linear Regression </a></li>
<li class="chapter" data-level="3.5.3" data-path="3.5-polynomialregression.html"><a href="3.5-polynomialregression.html#higherdegreepolynomials"><i class="fa fa-check"></i><b>3.5.3</b> Higher Degree Polynomials</a></li>
<li class="chapter" data-level="3.5.4" data-path="3.5-polynomialregression.html"><a href="3.5-polynomialregression.html#non-linear-regression"><i class="fa fa-check"></i><b>3.5.4</b> Non-Linear Regression </a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="3.6-approximating-polynomial-functions-by-series-expansion.html"><a href="3.6-approximating-polynomial-functions-by-series-expansion.html"><i class="fa fa-check"></i><b>3.6</b> Approximating Polynomial Functions by Series Expansion </a></li>
<li class="chapter" data-level="3.7" data-path="3.7-polynomialinterpolation.html"><a href="3.7-polynomialinterpolation.html"><i class="fa fa-check"></i><b>3.7</b> Approximating Polynomial Functions by Interpolation</a><ul>
<li class="chapter" data-level="3.7.1" data-path="3.7-polynomialinterpolation.html"><a href="3.7-polynomialinterpolation.html#polynomial-interpolation"><i class="fa fa-check"></i><b>3.7.1</b> Polynomial interpolation </a></li>
<li class="chapter" data-level="3.7.2" data-path="3.7-polynomialinterpolation.html"><a href="3.7-polynomialinterpolation.html#lagrange-interpolation"><i class="fa fa-check"></i><b>3.7.2</b> Lagrange interpolation </a></li>
<li class="chapter" data-level="3.7.3" data-path="3.7-polynomialinterpolation.html"><a href="3.7-polynomialinterpolation.html#newton-interpolation"><i class="fa fa-check"></i><b>3.7.3</b> Newton interpolation </a></li>
<li class="chapter" data-level="3.7.4" data-path="3.7-polynomialinterpolation.html"><a href="3.7-polynomialinterpolation.html#newton-forward-interpolation"><i class="fa fa-check"></i><b>3.7.4</b> Newton Forward interpolation </a></li>
<li class="chapter" data-level="3.7.5" data-path="3.7-polynomialinterpolation.html"><a href="3.7-polynomialinterpolation.html#newton-backward-interpolation"><i class="fa fa-check"></i><b>3.7.5</b> Newton Backward interpolation </a></li>
<li class="chapter" data-level="3.7.6" data-path="3.7-polynomialinterpolation.html"><a href="3.7-polynomialinterpolation.html#interpolation-considerations"><i class="fa fa-check"></i><b>3.7.6</b> Interpolation Considerations</a></li>
<li class="chapter" data-level="3.7.7" data-path="3.7-polynomialinterpolation.html"><a href="3.7-polynomialinterpolation.html#lebesque-constant"><i class="fa fa-check"></i><b>3.7.7</b> Lebesque Constant </a></li>
<li class="chapter" data-level="3.7.8" data-path="3.7-polynomialinterpolation.html"><a href="3.7-polynomialinterpolation.html#horners-method"><i class="fa fa-check"></i><b>3.7.8</b> Horner’s method </a></li>
<li class="chapter" data-level="3.7.9" data-path="3.7-polynomialinterpolation.html"><a href="3.7-polynomialinterpolation.html#piecewise-polynomial-interpolation"><i class="fa fa-check"></i><b>3.7.9</b> Piecewise Polynomial Interpolation </a></li>
<li class="chapter" data-level="3.7.10" data-path="3.7-polynomialinterpolation.html"><a href="3.7-polynomialinterpolation.html#b-spline-interpolation"><i class="fa fa-check"></i><b>3.7.10</b> B-Spline interpolation </a></li>
<li class="chapter" data-level="3.7.11" data-path="3.7-polynomialinterpolation.html"><a href="3.7-polynomialinterpolation.html#bspline"><i class="fa fa-check"></i><b>3.7.11</b> B-Spline Regression</a></li>
<li class="chapter" data-level="3.7.12" data-path="3.7-polynomialinterpolation.html"><a href="3.7-polynomialinterpolation.html#p-spline-regression"><i class="fa fa-check"></i><b>3.7.12</b> P-Spline Regression </a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="3.8-polynomialsmoothing.html"><a href="3.8-polynomialsmoothing.html"><i class="fa fa-check"></i><b>3.8</b> Approximating Polynomial Functions by Smoothing</a><ul>
<li class="chapter" data-level="3.8.1" data-path="3.8-polynomialsmoothing.html"><a href="3.8-polynomialsmoothing.html#bin-smoothing"><i class="fa fa-check"></i><b>3.8.1</b> Bin Smoothing </a></li>
<li class="chapter" data-level="3.8.2" data-path="3.8-polynomialsmoothing.html"><a href="3.8-polynomialsmoothing.html#kernel-smoothing"><i class="fa fa-check"></i><b>3.8.2</b> Kernel Smoothing </a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="3.9-polynomial-optimization.html"><a href="3.9-polynomial-optimization.html"><i class="fa fa-check"></i><b>3.9</b> Polynomial Optimization </a><ul>
<li class="chapter" data-level="3.9.1" data-path="3.9-polynomial-optimization.html"><a href="3.9-polynomial-optimization.html#simplexmethod"><i class="fa fa-check"></i><b>3.9.1</b> Simplex Method</a></li>
<li class="chapter" data-level="3.9.2" data-path="3.9-polynomial-optimization.html"><a href="3.9-polynomial-optimization.html#dualsimplex"><i class="fa fa-check"></i><b>3.9.2</b> Dual Simplex</a></li>
<li class="chapter" data-level="3.9.3" data-path="3.9-polynomial-optimization.html"><a href="3.9-polynomial-optimization.html#primaldual"><i class="fa fa-check"></i><b>3.9.3</b> Primal-Dual Formulation</a></li>
<li class="chapter" data-level="3.9.4" data-path="3.9-polynomial-optimization.html"><a href="3.9-polynomial-optimization.html#lagrange-multiplier"><i class="fa fa-check"></i><b>3.9.4</b> Lagrange Multiplier </a></li>
<li class="chapter" data-level="3.9.5" data-path="3.9-polynomial-optimization.html"><a href="3.9-polynomial-optimization.html#karush-khun-tucker-conditions"><i class="fa fa-check"></i><b>3.9.5</b> Karush-Khun-Tucker Conditions </a></li>
</ul></li>
<li class="chapter" data-level="3.10" data-path="3.10-summary-1.html"><a href="3.10-summary-1.html"><i class="fa fa-check"></i><b>3.10</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="4-numericalcalculus.html"><a href="4-numericalcalculus.html"><i class="fa fa-check"></i><b>4</b> Numerical Calculus</a><ul>
<li class="chapter" data-level="4.1" data-path="4.1-introductory-calculus.html"><a href="4.1-introductory-calculus.html"><i class="fa fa-check"></i><b>4.1</b> Introductory Calculus</a><ul>
<li class="chapter" data-level="4.1.1" data-path="4.1-introductory-calculus.html"><a href="4.1-introductory-calculus.html#function"><i class="fa fa-check"></i><b>4.1.1</b> Function</a></li>
<li class="chapter" data-level="4.1.2" data-path="4.1-introductory-calculus.html"><a href="4.1-introductory-calculus.html#slopes"><i class="fa fa-check"></i><b>4.1.2</b> Slopes</a></li>
<li class="chapter" data-level="4.1.3" data-path="4.1-introductory-calculus.html"><a href="4.1-introductory-calculus.html#limits"><i class="fa fa-check"></i><b>4.1.3</b> Limits</a></li>
<li class="chapter" data-level="4.1.4" data-path="4.1-introductory-calculus.html"><a href="4.1-introductory-calculus.html#derivatives"><i class="fa fa-check"></i><b>4.1.4</b> Derivatives</a></li>
<li class="chapter" data-level="4.1.5" data-path="4.1-introductory-calculus.html"><a href="4.1-introductory-calculus.html#integrals"><i class="fa fa-check"></i><b>4.1.5</b> Integrals </a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="4.2-approximation-by-numerical-integration.html"><a href="4.2-approximation-by-numerical-integration.html"><i class="fa fa-check"></i><b>4.2</b> Approximation by Numerical Integration </a><ul>
<li class="chapter" data-level="4.2.1" data-path="4.2-approximation-by-numerical-integration.html"><a href="4.2-approximation-by-numerical-integration.html#newton-cotes-quadrature"><i class="fa fa-check"></i><b>4.2.1</b> Newton-Cotes Quadrature </a></li>
<li class="chapter" data-level="4.2.2" data-path="4.2-approximation-by-numerical-integration.html"><a href="4.2-approximation-by-numerical-integration.html#composite-and-adaptive-quadrature"><i class="fa fa-check"></i><b>4.2.2</b> Composite and Adaptive Quadrature </a></li>
<li class="chapter" data-level="4.2.3" data-path="4.2-approximation-by-numerical-integration.html"><a href="4.2-approximation-by-numerical-integration.html#gaussianquadrature"><i class="fa fa-check"></i><b>4.2.3</b> Gaussian Quadrature</a></li>
<li class="chapter" data-level="4.2.4" data-path="4.2-approximation-by-numerical-integration.html"><a href="4.2-approximation-by-numerical-integration.html#romberg-integration"><i class="fa fa-check"></i><b>4.2.4</b> Romberg integration </a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="4.3-approximation-by-numerical-differentiation.html"><a href="4.3-approximation-by-numerical-differentiation.html"><i class="fa fa-check"></i><b>4.3</b> Approximation by Numerical Differentiation </a><ul>
<li class="chapter" data-level="4.3.1" data-path="4.3-approximation-by-numerical-differentiation.html"><a href="4.3-approximation-by-numerical-differentiation.html#order-of-accuracy"><i class="fa fa-check"></i><b>4.3.1</b> Order of Accuracy</a></li>
<li class="chapter" data-level="4.3.2" data-path="4.3-approximation-by-numerical-differentiation.html"><a href="4.3-approximation-by-numerical-differentiation.html#finite-difference"><i class="fa fa-check"></i><b>4.3.2</b> Finite Difference </a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="4.4-approximation-using-ordinary-differential-equations.html"><a href="4.4-approximation-using-ordinary-differential-equations.html"><i class="fa fa-check"></i><b>4.4</b> Approximation using Ordinary Differential Equations  </a><ul>
<li class="chapter" data-level="4.4.1" data-path="4.4-approximation-using-ordinary-differential-equations.html"><a href="4.4-approximation-using-ordinary-differential-equations.html#eulers-method-explicit"><i class="fa fa-check"></i><b>4.4.1</b> Euler’s Method (Explicit) </a></li>
<li class="chapter" data-level="4.4.2" data-path="4.4-approximation-using-ordinary-differential-equations.html"><a href="4.4-approximation-using-ordinary-differential-equations.html#eulers-method-implicit"><i class="fa fa-check"></i><b>4.4.2</b> Euler’s Method (Implicit)</a></li>
<li class="chapter" data-level="4.4.3" data-path="4.4-approximation-using-ordinary-differential-equations.html"><a href="4.4-approximation-using-ordinary-differential-equations.html#heuns-method"><i class="fa fa-check"></i><b>4.4.3</b> Heun’s Method </a></li>
<li class="chapter" data-level="4.4.4" data-path="4.4-approximation-using-ordinary-differential-equations.html"><a href="4.4-approximation-using-ordinary-differential-equations.html#runge-kutta-method"><i class="fa fa-check"></i><b>4.4.4</b> Runge-Kutta Method </a></li>
<li class="chapter" data-level="4.4.5" data-path="4.4-approximation-using-ordinary-differential-equations.html"><a href="4.4-approximation-using-ordinary-differential-equations.html#shooting-method"><i class="fa fa-check"></i><b>4.4.5</b> Shooting Method </a></li>
<li class="chapter" data-level="4.4.6" data-path="4.4-approximation-using-ordinary-differential-equations.html"><a href="4.4-approximation-using-ordinary-differential-equations.html#finite-difference-method"><i class="fa fa-check"></i><b>4.4.6</b> Finite Difference Method  </a></li>
<li class="chapter" data-level="4.4.7" data-path="4.4-approximation-using-ordinary-differential-equations.html"><a href="4.4-approximation-using-ordinary-differential-equations.html#finite-element-method-based-on-wrm-and-vm"><i class="fa fa-check"></i><b>4.4.7</b> Finite Element Method (based on WRM and VM) </a></li>
<li class="chapter" data-level="4.4.8" data-path="4.4-approximation-using-ordinary-differential-equations.html"><a href="4.4-approximation-using-ordinary-differential-equations.html#least-square-method-using-wrm"><i class="fa fa-check"></i><b>4.4.8</b> Least-Square Method (using WRM)</a></li>
<li class="chapter" data-level="4.4.9" data-path="4.4-approximation-using-ordinary-differential-equations.html"><a href="4.4-approximation-using-ordinary-differential-equations.html#galerkin-method-using-wrm"><i class="fa fa-check"></i><b>4.4.9</b> Galerkin Method (using WRM)</a></li>
<li class="chapter" data-level="4.4.10" data-path="4.4-approximation-using-ordinary-differential-equations.html"><a href="4.4-approximation-using-ordinary-differential-equations.html#petrov-galerkin-method-using-wrm"><i class="fa fa-check"></i><b>4.4.10</b> Petrov-Galerkin Method (using WRM)</a></li>
<li class="chapter" data-level="4.4.11" data-path="4.4-approximation-using-ordinary-differential-equations.html"><a href="4.4-approximation-using-ordinary-differential-equations.html#rayleigh-ritz-method-using-wrm"><i class="fa fa-check"></i><b>4.4.11</b> Rayleigh-Ritz Method (using WRM)</a></li>
<li class="chapter" data-level="4.4.12" data-path="4.4-approximation-using-ordinary-differential-equations.html"><a href="4.4-approximation-using-ordinary-differential-equations.html#subdomain-method-using-subdomains"><i class="fa fa-check"></i><b>4.4.12</b> Subdomain Method (using subdomains)</a></li>
<li class="chapter" data-level="4.4.13" data-path="4.4-approximation-using-ordinary-differential-equations.html"><a href="4.4-approximation-using-ordinary-differential-equations.html#collocation-method-using-direct-location-points"><i class="fa fa-check"></i><b>4.4.13</b> Collocation Method (using direct location points) </a></li>
<li class="chapter" data-level="4.4.14" data-path="4.4-approximation-using-ordinary-differential-equations.html"><a href="4.4-approximation-using-ordinary-differential-equations.html#weighted-residual-summary"><i class="fa fa-check"></i><b>4.4.14</b> Weighted Residual Summary </a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="4.5-approximation-using-functional-differential-equations.html"><a href="4.5-approximation-using-functional-differential-equations.html"><i class="fa fa-check"></i><b>4.5</b> Approximation using Functional Differential Equations </a><ul>
<li class="chapter" data-level="4.5.1" data-path="4.5-approximation-using-functional-differential-equations.html"><a href="4.5-approximation-using-functional-differential-equations.html#variational-functions"><i class="fa fa-check"></i><b>4.5.1</b> Variational Functions </a></li>
<li class="chapter" data-level="4.5.2" data-path="4.5-approximation-using-functional-differential-equations.html"><a href="4.5-approximation-using-functional-differential-equations.html#variational-methods"><i class="fa fa-check"></i><b>4.5.2</b> Variational Methods </a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="4.6-approximation-using-partial-differential-equations.html"><a href="4.6-approximation-using-partial-differential-equations.html"><i class="fa fa-check"></i><b>4.6</b> Approximation using Partial Differential Equations </a><ul>
<li class="chapter" data-level="4.6.1" data-path="4.6-approximation-using-partial-differential-equations.html"><a href="4.6-approximation-using-partial-differential-equations.html#the-poisson-equation"><i class="fa fa-check"></i><b>4.6.1</b> The Poisson Equation </a></li>
<li class="chapter" data-level="4.6.2" data-path="4.6-approximation-using-partial-differential-equations.html"><a href="4.6-approximation-using-partial-differential-equations.html#the-laplace-equation-elliptic-pde"><i class="fa fa-check"></i><b>4.6.2</b> The Laplace Equation (Elliptic PDE)  </a></li>
<li class="chapter" data-level="4.6.3" data-path="4.6-approximation-using-partial-differential-equations.html"><a href="4.6-approximation-using-partial-differential-equations.html#the-heat-equation-parabolic-pde"><i class="fa fa-check"></i><b>4.6.3</b> The Heat equation (Parabolic PDE)  </a></li>
<li class="chapter" data-level="4.6.4" data-path="4.6-approximation-using-partial-differential-equations.html"><a href="4.6-approximation-using-partial-differential-equations.html#the-wave-equation-hyperbolic-pde"><i class="fa fa-check"></i><b>4.6.4</b> The Wave equation (Hyperbolic PDE)  </a></li>
<li class="chapter" data-level="4.6.5" data-path="4.6-approximation-using-partial-differential-equations.html"><a href="4.6-approximation-using-partial-differential-equations.html#the-crank-nicolson-equation"><i class="fa fa-check"></i><b>4.6.5</b> The Crank-Nicolson Equation </a></li>
<li class="chapter" data-level="4.6.6" data-path="4.6-approximation-using-partial-differential-equations.html"><a href="4.6-approximation-using-partial-differential-equations.html#the-burgers-equation"><i class="fa fa-check"></i><b>4.6.6</b> The Burger’s Equation </a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="4.7-approximation-using-fourier-series-and-transform.html"><a href="4.7-approximation-using-fourier-series-and-transform.html"><i class="fa fa-check"></i><b>4.7</b> Approximation using Fourier Series And Transform </a><ul>
<li class="chapter" data-level="4.7.1" data-path="4.7-approximation-using-fourier-series-and-transform.html"><a href="4.7-approximation-using-fourier-series-and-transform.html#discrete-fourier-transform-dft"><i class="fa fa-check"></i><b>4.7.1</b> Discrete Fourier Transform (DFT)  </a></li>
<li class="chapter" data-level="4.7.2" data-path="4.7-approximation-using-fourier-series-and-transform.html"><a href="4.7-approximation-using-fourier-series-and-transform.html#inverse-discrete-fourier-transformation-idft"><i class="fa fa-check"></i><b>4.7.2</b> Inverse Discrete Fourier Transformation (IDFT)  </a></li>
<li class="chapter" data-level="4.7.3" data-path="4.7-approximation-using-fourier-series-and-transform.html"><a href="4.7-approximation-using-fourier-series-and-transform.html#fast-fourier-transform-fft"><i class="fa fa-check"></i><b>4.7.3</b> Fast Fourier Transform (FFT)  </a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="4.8-summary-2.html"><a href="4.8-summary-2.html"><i class="fa fa-check"></i><b>4.8</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="5-numericalprobability.html"><a href="5-numericalprobability.html"><i class="fa fa-check"></i><b>5</b> Probability and Distribution</a><ul>
<li class="chapter" data-level="5.1" data-path="5.1-approximation-based-on-random-chances.html"><a href="5.1-approximation-based-on-random-chances.html"><i class="fa fa-check"></i><b>5.1</b> Approximation based on Random Chances </a></li>
<li class="chapter" data-level="5.2" data-path="5.2-distribution.html"><a href="5.2-distribution.html"><i class="fa fa-check"></i><b>5.2</b> Distribution</a></li>
<li class="chapter" data-level="5.3" data-path="5.3-mass-and-density.html"><a href="5.3-mass-and-density.html"><i class="fa fa-check"></i><b>5.3</b> Mass and Density  </a></li>
<li class="chapter" data-level="5.4" data-path="5.4-probability.html"><a href="5.4-probability.html"><i class="fa fa-check"></i><b>5.4</b> Probability  </a></li>
<li class="chapter" data-level="5.5" data-path="5.5-probability-density-function-pdf.html"><a href="5.5-probability-density-function-pdf.html"><i class="fa fa-check"></i><b>5.5</b> Probability Density Function (PDF)  </a></li>
<li class="chapter" data-level="5.6" data-path="5.6-probability-mass-function-pmf.html"><a href="5.6-probability-mass-function-pmf.html"><i class="fa fa-check"></i><b>5.6</b> Probability Mass function (PMF)  </a></li>
<li class="chapter" data-level="5.7" data-path="5.7-cumulative-distribution-function-cdf.html"><a href="5.7-cumulative-distribution-function-cdf.html"><i class="fa fa-check"></i><b>5.7</b> Cumulative Distribution Function (CDF)  </a></li>
<li class="chapter" data-level="5.8" data-path="5.8-special-functions.html"><a href="5.8-special-functions.html"><i class="fa fa-check"></i><b>5.8</b> Special Functions</a><ul>
<li class="chapter" data-level="5.8.1" data-path="5.8-special-functions.html"><a href="5.8-special-functions.html#gamma-function"><i class="fa fa-check"></i><b>5.8.1</b> Gamma function </a></li>
<li class="chapter" data-level="5.8.2" data-path="5.8-special-functions.html"><a href="5.8-special-functions.html#incomplete-gamma-function"><i class="fa fa-check"></i><b>5.8.2</b> Incomplete Gamma function </a></li>
<li class="chapter" data-level="5.8.3" data-path="5.8-special-functions.html"><a href="5.8-special-functions.html#digamma-function"><i class="fa fa-check"></i><b>5.8.3</b> Digamma Function </a></li>
<li class="chapter" data-level="5.8.4" data-path="5.8-special-functions.html"><a href="5.8-special-functions.html#beta-function"><i class="fa fa-check"></i><b>5.8.4</b> Beta function </a></li>
<li class="chapter" data-level="5.8.5" data-path="5.8-special-functions.html"><a href="5.8-special-functions.html#incomplete-beta-function"><i class="fa fa-check"></i><b>5.8.5</b> Incomplete Beta function </a></li>
<li class="chapter" data-level="5.8.6" data-path="5.8-special-functions.html"><a href="5.8-special-functions.html#regularized-beta-function"><i class="fa fa-check"></i><b>5.8.6</b> Regularized Beta function  </a></li>
<li class="chapter" data-level="5.8.7" data-path="5.8-special-functions.html"><a href="5.8-special-functions.html#hypergeometric-function"><i class="fa fa-check"></i><b>5.8.7</b> Hypergeometric function </a></li>
<li class="chapter" data-level="5.8.8" data-path="5.8-special-functions.html"><a href="5.8-special-functions.html#continued-fraction"><i class="fa fa-check"></i><b>5.8.8</b> Continued Fraction </a></li>
<li class="chapter" data-level="5.8.9" data-path="5.8-special-functions.html"><a href="5.8-special-functions.html#dirac-delta-function"><i class="fa fa-check"></i><b>5.8.9</b> Dirac Delta Function </a></li>
<li class="chapter" data-level="5.8.10" data-path="5.8-special-functions.html"><a href="5.8-special-functions.html#kronecker-delta-function"><i class="fa fa-check"></i><b>5.8.10</b> Kronecker Delta Function </a></li>
</ul></li>
<li class="chapter" data-level="5.9" data-path="5.9-distributiontypes.html"><a href="5.9-distributiontypes.html"><i class="fa fa-check"></i><b>5.9</b> Types of Distribution</a><ul>
<li class="chapter" data-level="5.9.1" data-path="5.9-distributiontypes.html"><a href="5.9-distributiontypes.html#bernoulli-distribution"><i class="fa fa-check"></i><b>5.9.1</b> Bernoulli distribution </a></li>
<li class="chapter" data-level="5.9.2" data-path="5.9-distributiontypes.html"><a href="5.9-distributiontypes.html#binomial-distribution"><i class="fa fa-check"></i><b>5.9.2</b> Binomial distribution </a></li>
<li class="chapter" data-level="5.9.3" data-path="5.9-distributiontypes.html"><a href="5.9-distributiontypes.html#multinomial-distribution"><i class="fa fa-check"></i><b>5.9.3</b> Multinomial distribution </a></li>
<li class="chapter" data-level="5.9.4" data-path="5.9-distributiontypes.html"><a href="5.9-distributiontypes.html#geometric-distribution"><i class="fa fa-check"></i><b>5.9.4</b> Geometric distribution </a></li>
<li class="chapter" data-level="5.9.5" data-path="5.9-distributiontypes.html"><a href="5.9-distributiontypes.html#beta-distribution"><i class="fa fa-check"></i><b>5.9.5</b> Beta distribution </a></li>
<li class="chapter" data-level="5.9.6" data-path="5.9-distributiontypes.html"><a href="5.9-distributiontypes.html#dirichlet-distribution"><i class="fa fa-check"></i><b>5.9.6</b> Dirichlet distribution </a></li>
<li class="chapter" data-level="5.9.7" data-path="5.9-distributiontypes.html"><a href="5.9-distributiontypes.html#exponential-distribution"><i class="fa fa-check"></i><b>5.9.7</b> Exponential distribution </a></li>
<li class="chapter" data-level="5.9.8" data-path="5.9-distributiontypes.html"><a href="5.9-distributiontypes.html#gamma-distribution"><i class="fa fa-check"></i><b>5.9.8</b> Gamma distribution </a></li>
<li class="chapter" data-level="5.9.9" data-path="5.9-distributiontypes.html"><a href="5.9-distributiontypes.html#inverse-gamma-distribution"><i class="fa fa-check"></i><b>5.9.9</b> Inverse Gamma distribution </a></li>
<li class="chapter" data-level="5.9.10" data-path="5.9-distributiontypes.html"><a href="5.9-distributiontypes.html#weibull-distribution"><i class="fa fa-check"></i><b>5.9.10</b> Weibull distribution </a></li>
<li class="chapter" data-level="5.9.11" data-path="5.9-distributiontypes.html"><a href="5.9-distributiontypes.html#poisson-distribution"><i class="fa fa-check"></i><b>5.9.11</b> Poisson distribution </a></li>
<li class="chapter" data-level="5.9.12" data-path="5.9-distributiontypes.html"><a href="5.9-distributiontypes.html#pareto-distribution"><i class="fa fa-check"></i><b>5.9.12</b> Pareto distribution </a></li>
<li class="chapter" data-level="5.9.13" data-path="5.9-distributiontypes.html"><a href="5.9-distributiontypes.html#normal-distribution"><i class="fa fa-check"></i><b>5.9.13</b> Normal distribution </a></li>
<li class="chapter" data-level="5.9.14" data-path="5.9-distributiontypes.html"><a href="5.9-distributiontypes.html#wald-distribution"><i class="fa fa-check"></i><b>5.9.14</b> Wald Distribution </a></li>
<li class="chapter" data-level="5.9.15" data-path="5.9-distributiontypes.html"><a href="5.9-distributiontypes.html#log-normal-distribution"><i class="fa fa-check"></i><b>5.9.15</b> Log-normal Distribution </a></li>
<li class="chapter" data-level="5.9.16" data-path="5.9-distributiontypes.html"><a href="5.9-distributiontypes.html#uniform-distribution"><i class="fa fa-check"></i><b>5.9.16</b> Uniform Distribution </a></li>
<li class="chapter" data-level="5.9.17" data-path="5.9-distributiontypes.html"><a href="5.9-distributiontypes.html#t-distribution"><i class="fa fa-check"></i><b>5.9.17</b> T-Distribution </a></li>
<li class="chapter" data-level="5.9.18" data-path="5.9-distributiontypes.html"><a href="5.9-distributiontypes.html#f-distribution"><i class="fa fa-check"></i><b>5.9.18</b> F-Distribution </a></li>
<li class="chapter" data-level="5.9.19" data-path="5.9-distributiontypes.html"><a href="5.9-distributiontypes.html#chi-square-distribution"><i class="fa fa-check"></i><b>5.9.19</b> Chi-square Distribution </a></li>
<li class="chapter" data-level="5.9.20" data-path="5.9-distributiontypes.html"><a href="5.9-distributiontypes.html#wishartdistribution"><i class="fa fa-check"></i><b>5.9.20</b> Wishart distribution</a></li>
<li class="chapter" data-level="5.9.21" data-path="5.9-distributiontypes.html"><a href="5.9-distributiontypes.html#lkj-distribution"><i class="fa fa-check"></i><b>5.9.21</b> LKJ distribution </a></li>
<li class="chapter" data-level="5.9.22" data-path="5.9-distributiontypes.html"><a href="5.9-distributiontypes.html#mixture-distribution"><i class="fa fa-check"></i><b>5.9.22</b> Mixture distribution </a></li>
<li class="chapter" data-level="5.9.23" data-path="5.9-distributiontypes.html"><a href="5.9-distributiontypes.html#non-parametric-distribution"><i class="fa fa-check"></i><b>5.9.23</b> Non-parametric distribution </a></li>
<li class="chapter" data-level="5.9.24" data-path="5.9-distributiontypes.html"><a href="5.9-distributiontypes.html#multi-dimensional-density"><i class="fa fa-check"></i><b>5.9.24</b> Multi-dimensional Density </a></li>
</ul></li>
<li class="chapter" data-level="5.10" data-path="5.10-summary-3.html"><a href="5.10-summary-3.html"><i class="fa fa-check"></i><b>5.10</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="6-statistics.html"><a href="6-statistics.html"><i class="fa fa-check"></i><b>6</b> Statistical Computation</a><ul>
<li class="chapter" data-level="6.1" data-path="6.1-descriptive-statistics.html"><a href="6.1-descriptive-statistics.html"><i class="fa fa-check"></i><b>6.1</b> Descriptive Statistics</a><ul>
<li class="chapter" data-level="6.1.1" data-path="6.1-descriptive-statistics.html"><a href="6.1-descriptive-statistics.html#visual-representation"><i class="fa fa-check"></i><b>6.1.1</b> Visual Representation</a></li>
<li class="chapter" data-level="6.1.2" data-path="6.1-descriptive-statistics.html"><a href="6.1-descriptive-statistics.html#central-tendency"><i class="fa fa-check"></i><b>6.1.2</b> Central Tendency </a></li>
<li class="chapter" data-level="6.1.3" data-path="6.1-descriptive-statistics.html"><a href="6.1-descriptive-statistics.html#variability"><i class="fa fa-check"></i><b>6.1.3</b> Variability </a></li>
<li class="chapter" data-level="6.1.4" data-path="6.1-descriptive-statistics.html"><a href="6.1-descriptive-statistics.html#kurtosis-and-skewness"><i class="fa fa-check"></i><b>6.1.4</b> Kurtosis and Skewness  </a></li>
<li class="chapter" data-level="6.1.5" data-path="6.1-descriptive-statistics.html"><a href="6.1-descriptive-statistics.html#five-number-summary"><i class="fa fa-check"></i><b>6.1.5</b> Five Number Summary  </a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="6.2-inferential-statistics.html"><a href="6.2-inferential-statistics.html"><i class="fa fa-check"></i><b>6.2</b> Inferential Statistics</a></li>
<li class="chapter" data-level="6.3" data-path="6.3-the-significance-of-difference.html"><a href="6.3-the-significance-of-difference.html"><i class="fa fa-check"></i><b>6.3</b> The Significance of Difference </a><ul>
<li class="chapter" data-level="6.3.1" data-path="6.3-the-significance-of-difference.html"><a href="6.3-the-significance-of-difference.html#hypothesis"><i class="fa fa-check"></i><b>6.3.1</b> Hypothesis</a></li>
<li class="chapter" data-level="6.3.2" data-path="6.3-the-significance-of-difference.html"><a href="6.3-the-significance-of-difference.html#t-test-true-variance-unknown"><i class="fa fa-check"></i><b>6.3.2</b> T-Test (True Variance unknown) </a></li>
<li class="chapter" data-level="6.3.3" data-path="6.3-the-significance-of-difference.html"><a href="6.3-the-significance-of-difference.html#z-test-true-variance-known"><i class="fa fa-check"></i><b>6.3.3</b> Z-Test (True Variance known)</a></li>
<li class="chapter" data-level="6.3.4" data-path="6.3-the-significance-of-difference.html"><a href="6.3-the-significance-of-difference.html#f-test-using-f-ratio"><i class="fa fa-check"></i><b>6.3.4</b> F-Test using F-ratio  </a></li>
<li class="chapter" data-level="6.3.5" data-path="6.3-the-significance-of-difference.html"><a href="6.3-the-significance-of-difference.html#f-test-with-one-way-anova"><i class="fa fa-check"></i><b>6.3.5</b> F-Test with One-Way ANOVA </a></li>
<li class="chapter" data-level="6.3.6" data-path="6.3-the-significance-of-difference.html"><a href="6.3-the-significance-of-difference.html#f-test-with-two-way-anova"><i class="fa fa-check"></i><b>6.3.6</b> F-Test with Two-Way ANOVA </a></li>
<li class="chapter" data-level="6.3.7" data-path="6.3-the-significance-of-difference.html"><a href="6.3-the-significance-of-difference.html#pearsons-chi-square-test"><i class="fa fa-check"></i><b>6.3.7</b> Pearson’s Chi-square Test </a></li>
<li class="chapter" data-level="6.3.8" data-path="6.3-the-significance-of-difference.html"><a href="6.3-the-significance-of-difference.html#wilcoxon-test"><i class="fa fa-check"></i><b>6.3.8</b> Wilcoxon Test  </a></li>
<li class="chapter" data-level="6.3.9" data-path="6.3-the-significance-of-difference.html"><a href="6.3-the-significance-of-difference.html#kruskal-wallis-test"><i class="fa fa-check"></i><b>6.3.9</b> Kruskal-Wallis Test </a></li>
<li class="chapter" data-level="6.3.10" data-path="6.3-the-significance-of-difference.html"><a href="6.3-the-significance-of-difference.html#friedman-test"><i class="fa fa-check"></i><b>6.3.10</b> Friedman Test </a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="6.4-post-hoc-analysis.html"><a href="6.4-post-hoc-analysis.html"><i class="fa fa-check"></i><b>6.4</b> Post-HOC Analysis </a><ul>
<li class="chapter" data-level="6.4.1" data-path="6.4-post-hoc-analysis.html"><a href="6.4-post-hoc-analysis.html#bonferroni-correction"><i class="fa fa-check"></i><b>6.4.1</b> Bonferroni Correction </a></li>
<li class="chapter" data-level="6.4.2" data-path="6.4-post-hoc-analysis.html"><a href="6.4-post-hoc-analysis.html#benjamini-hochberg-correction"><i class="fa fa-check"></i><b>6.4.2</b> Benjamini-Hochberg Correction </a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="6.5-multiple-comparison-tests.html"><a href="6.5-multiple-comparison-tests.html"><i class="fa fa-check"></i><b>6.5</b> Multiple Comparison Tests </a><ul>
<li class="chapter" data-level="6.5.1" data-path="6.5-multiple-comparison-tests.html"><a href="6.5-multiple-comparison-tests.html#scheffes-test"><i class="fa fa-check"></i><b>6.5.1</b> Scheffe’s Test </a></li>
<li class="chapter" data-level="6.5.2" data-path="6.5-multiple-comparison-tests.html"><a href="6.5-multiple-comparison-tests.html#fishers-test"><i class="fa fa-check"></i><b>6.5.2</b> Fisher’s Test </a></li>
<li class="chapter" data-level="6.5.3" data-path="6.5-multiple-comparison-tests.html"><a href="6.5-multiple-comparison-tests.html#tukeys-test"><i class="fa fa-check"></i><b>6.5.3</b> Tukey’s Test </a></li>
<li class="chapter" data-level="6.5.4" data-path="6.5-multiple-comparison-tests.html"><a href="6.5-multiple-comparison-tests.html#newman-keul-test"><i class="fa fa-check"></i><b>6.5.4</b> Newman-Keul Test  </a></li>
<li class="chapter" data-level="6.5.5" data-path="6.5-multiple-comparison-tests.html"><a href="6.5-multiple-comparison-tests.html#games-howell-test"><i class="fa fa-check"></i><b>6.5.5</b> Games-Howell Test </a></li>
<li class="chapter" data-level="6.5.6" data-path="6.5-multiple-comparison-tests.html"><a href="6.5-multiple-comparison-tests.html#dunnetts-test"><i class="fa fa-check"></i><b>6.5.6</b> Dunnett’s Test </a></li>
<li class="chapter" data-level="6.5.7" data-path="6.5-multiple-comparison-tests.html"><a href="6.5-multiple-comparison-tests.html#duncans-test"><i class="fa fa-check"></i><b>6.5.7</b> Duncan’s Test </a></li>
<li class="chapter" data-level="6.5.8" data-path="6.5-multiple-comparison-tests.html"><a href="6.5-multiple-comparison-tests.html#meta-analysis-test"><i class="fa fa-check"></i><b>6.5.8</b> Meta-Analysis Test </a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="6.6-statistical-modeling.html"><a href="6.6-statistical-modeling.html"><i class="fa fa-check"></i><b>6.6</b> Statistical Modeling </a><ul>
<li class="chapter" data-level="6.6.1" data-path="6.6-statistical-modeling.html"><a href="6.6-statistical-modeling.html#model-specification"><i class="fa fa-check"></i><b>6.6.1</b> Model Specification </a></li>
<li class="chapter" data-level="6.6.2" data-path="6.6-statistical-modeling.html"><a href="6.6-statistical-modeling.html#statistical-interaction"><i class="fa fa-check"></i><b>6.6.2</b> Statistical Interaction </a></li>
<li class="chapter" data-level="6.6.3" data-path="6.6-statistical-modeling.html"><a href="6.6-statistical-modeling.html#dummy-variables"><i class="fa fa-check"></i><b>6.6.3</b> Dummy Variables </a></li>
<li class="chapter" data-level="6.6.4" data-path="6.6-statistical-modeling.html"><a href="6.6-statistical-modeling.html#model-selection"><i class="fa fa-check"></i><b>6.6.4</b> Model Selection </a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="6.7-regression-analysis.html"><a href="6.7-regression-analysis.html"><i class="fa fa-check"></i><b>6.7</b> Regression Analysis </a><ul>
<li class="chapter" data-level="6.7.1" data-path="6.7-regression-analysis.html"><a href="6.7-regression-analysis.html#assumptions"><i class="fa fa-check"></i><b>6.7.1</b> Assumptions</a></li>
<li class="chapter" data-level="6.7.2" data-path="6.7-regression-analysis.html"><a href="6.7-regression-analysis.html#correlation-coefficients"><i class="fa fa-check"></i><b>6.7.2</b> Correlation Coefficients </a></li>
<li class="chapter" data-level="6.7.3" data-path="6.7-regression-analysis.html"><a href="6.7-regression-analysis.html#homoscedasticity-and-heteroscedasticity"><i class="fa fa-check"></i><b>6.7.3</b> Homoscedasticity and Heteroscedasticity  </a></li>
<li class="chapter" data-level="6.7.4" data-path="6.7-regression-analysis.html"><a href="6.7-regression-analysis.html#normality-and-leverage"><i class="fa fa-check"></i><b>6.7.4</b> Normality and Leverage  </a></li>
<li class="chapter" data-level="6.7.5" data-path="6.7-regression-analysis.html"><a href="6.7-regression-analysis.html#collinearity"><i class="fa fa-check"></i><b>6.7.5</b> Collinearity </a></li>
<li class="chapter" data-level="6.7.6" data-path="6.7-regression-analysis.html"><a href="6.7-regression-analysis.html#dispersion"><i class="fa fa-check"></i><b>6.7.6</b> Dispersion </a></li>
<li class="chapter" data-level="6.7.7" data-path="6.7-regression-analysis.html"><a href="6.7-regression-analysis.html#diagnostic-plots"><i class="fa fa-check"></i><b>6.7.7</b> Diagnostic Plots</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="6.8-the-significance-of-regression.html"><a href="6.8-the-significance-of-regression.html"><i class="fa fa-check"></i><b>6.8</b> The Significance of Regression </a><ul>
<li class="chapter" data-level="6.8.1" data-path="6.8-the-significance-of-regression.html"><a href="6.8-the-significance-of-regression.html#simple-linear-regression"><i class="fa fa-check"></i><b>6.8.1</b> Simple Linear Regression</a></li>
<li class="chapter" data-level="6.8.2" data-path="6.8-the-significance-of-regression.html"><a href="6.8-the-significance-of-regression.html#multilinear-regression"><i class="fa fa-check"></i><b>6.8.2</b> Multilinear Regression </a></li>
<li class="chapter" data-level="6.8.3" data-path="6.8-the-significance-of-regression.html"><a href="6.8-the-significance-of-regression.html#logistic-regression"><i class="fa fa-check"></i><b>6.8.3</b> Logistic Regression </a></li>
<li class="chapter" data-level="6.8.4" data-path="6.8-the-significance-of-regression.html"><a href="6.8-the-significance-of-regression.html#poisson-regression"><i class="fa fa-check"></i><b>6.8.4</b> Poisson Regression </a></li>
<li class="chapter" data-level="6.8.5" data-path="6.8-the-significance-of-regression.html"><a href="6.8-the-significance-of-regression.html#cox-regression"><i class="fa fa-check"></i><b>6.8.5</b> Cox Regression </a></li>
<li class="chapter" data-level="6.8.6" data-path="6.8-the-significance-of-regression.html"><a href="6.8-the-significance-of-regression.html#polynomial-regression"><i class="fa fa-check"></i><b>6.8.6</b> Polynomial Regression </a></li>
<li class="chapter" data-level="6.8.7" data-path="6.8-the-significance-of-regression.html"><a href="6.8-the-significance-of-regression.html#b-splines-and-natural-splines"><i class="fa fa-check"></i><b>6.8.7</b> B-Splines and Natural Splines  </a></li>
<li class="chapter" data-level="6.8.8" data-path="6.8-the-significance-of-regression.html"><a href="6.8-the-significance-of-regression.html#spline-smoothing"><i class="fa fa-check"></i><b>6.8.8</b> Spline Smoothing </a></li>
<li class="chapter" data-level="6.8.9" data-path="6.8-the-significance-of-regression.html"><a href="6.8-the-significance-of-regression.html#loess-and-lowess"><i class="fa fa-check"></i><b>6.8.9</b> LOESS and LOWESS  </a></li>
</ul></li>
<li class="chapter" data-level="6.9" data-path="6.9-inference-for-regression.html"><a href="6.9-inference-for-regression.html"><i class="fa fa-check"></i><b>6.9</b> Inference for Regression</a><ul>
<li class="chapter" data-level="6.9.1" data-path="6.9-inference-for-regression.html"><a href="6.9-inference-for-regression.html#goodness-of-fit-linear-regression"><i class="fa fa-check"></i><b>6.9.1</b> Goodness of Fit (Linear Regression) </a></li>
<li class="chapter" data-level="6.9.2" data-path="6.9-inference-for-regression.html"><a href="6.9-inference-for-regression.html#goodness-of-fit-non-linear-regression"><i class="fa fa-check"></i><b>6.9.2</b> Goodness of Fit (Non-Linear Regression) </a></li>
<li class="chapter" data-level="6.9.3" data-path="6.9-inference-for-regression.html"><a href="6.9-inference-for-regression.html#confidence-interval"><i class="fa fa-check"></i><b>6.9.3</b> Confidence interval </a></li>
</ul></li>
<li class="chapter" data-level="6.10" data-path="6.10-summary-4.html"><a href="6.10-summary-4.html"><i class="fa fa-check"></i><b>6.10</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="7-bayesian.html"><a href="7-bayesian.html"><i class="fa fa-check"></i><b>7</b> Bayesian Computation I</a><ul>
<li class="chapter" data-level="7.1" data-path="7.1-probability-1.html"><a href="7.1-probability-1.html"><i class="fa fa-check"></i><b>7.1</b> Probability </a><ul>
<li class="chapter" data-level="7.1.1" data-path="7.1-probability-1.html"><a href="7.1-probability-1.html#marginal-probability"><i class="fa fa-check"></i><b>7.1.1</b> Marginal Probability </a></li>
<li class="chapter" data-level="7.1.2" data-path="7.1-probability-1.html"><a href="7.1-probability-1.html#joint-probability"><i class="fa fa-check"></i><b>7.1.2</b> Joint Probability </a></li>
<li class="chapter" data-level="7.1.3" data-path="7.1-probability-1.html"><a href="7.1-probability-1.html#conditional-probability"><i class="fa fa-check"></i><b>7.1.3</b> Conditional Probability </a></li>
<li class="chapter" data-level="7.1.4" data-path="7.1-probability-1.html"><a href="7.1-probability-1.html#negation-probability"><i class="fa fa-check"></i><b>7.1.4</b> Negation Probability </a></li>
<li class="chapter" data-level="7.1.5" data-path="7.1-probability-1.html"><a href="7.1-probability-1.html#combination-of-probabilities"><i class="fa fa-check"></i><b>7.1.5</b> Combination of Probabilities</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="7.2-probability-rules.html"><a href="7.2-probability-rules.html"><i class="fa fa-check"></i><b>7.2</b> Probability Rules</a><ul>
<li class="chapter" data-level="7.2.1" data-path="7.2-probability-rules.html"><a href="7.2-probability-rules.html#law-of-total-probability"><i class="fa fa-check"></i><b>7.2.1</b> Law of Total Probability</a></li>
<li class="chapter" data-level="7.2.2" data-path="7.2-probability-rules.html"><a href="7.2-probability-rules.html#law-of-total-expectation"><i class="fa fa-check"></i><b>7.2.2</b> Law of Total Expectation </a></li>
<li class="chapter" data-level="7.2.3" data-path="7.2-probability-rules.html"><a href="7.2-probability-rules.html#law-of-total-variance"><i class="fa fa-check"></i><b>7.2.3</b> Law of Total Variance </a></li>
<li class="chapter" data-level="7.2.4" data-path="7.2-probability-rules.html"><a href="7.2-probability-rules.html#law-of-total-covariance"><i class="fa fa-check"></i><b>7.2.4</b> Law of Total Covariance </a></li>
<li class="chapter" data-level="7.2.5" data-path="7.2-probability-rules.html"><a href="7.2-probability-rules.html#law-of-large-numbers"><i class="fa fa-check"></i><b>7.2.5</b> Law of Large Numbers </a></li>
<li class="chapter" data-level="7.2.6" data-path="7.2-probability-rules.html"><a href="7.2-probability-rules.html#central-limit-theorem"><i class="fa fa-check"></i><b>7.2.6</b> Central Limit Theorem </a></li>
<li class="chapter" data-level="7.2.7" data-path="7.2-probability-rules.html"><a href="7.2-probability-rules.html#rule-of-independence"><i class="fa fa-check"></i><b>7.2.7</b> Rule of Independence </a></li>
<li class="chapter" data-level="7.2.8" data-path="7.2-probability-rules.html"><a href="7.2-probability-rules.html#rule-of-exchangeability"><i class="fa fa-check"></i><b>7.2.8</b> Rule of Exchangeability </a></li>
<li class="chapter" data-level="7.2.9" data-path="7.2-probability-rules.html"><a href="7.2-probability-rules.html#rule-of-expectation-and-variance"><i class="fa fa-check"></i><b>7.2.9</b> Rule of Expectation and Variance</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="7.3-bayes-theorem.html"><a href="7.3-bayes-theorem.html"><i class="fa fa-check"></i><b>7.3</b> Bayes Theorem </a><ul>
<li class="chapter" data-level="7.3.1" data-path="7.3-bayes-theorem.html"><a href="7.3-bayes-theorem.html#naïve-bayes"><i class="fa fa-check"></i><b>7.3.1</b> Naïve Bayes </a></li>
<li class="chapter" data-level="7.3.2" data-path="7.3-bayes-theorem.html"><a href="7.3-bayes-theorem.html#likelihood"><i class="fa fa-check"></i><b>7.3.2</b> Likelihood</a></li>
<li class="chapter" data-level="7.3.3" data-path="7.3-bayes-theorem.html"><a href="7.3-bayes-theorem.html#posterior-probability"><i class="fa fa-check"></i><b>7.3.3</b> Posterior Probability  </a></li>
<li class="chapter" data-level="7.3.4" data-path="7.3-bayes-theorem.html"><a href="7.3-bayes-theorem.html#prior-probability"><i class="fa fa-check"></i><b>7.3.4</b> Prior Probability  </a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="7.4-conjugacy.html"><a href="7.4-conjugacy.html"><i class="fa fa-check"></i><b>7.4</b> Conjugacy</a><ul>
<li class="chapter" data-level="7.4.1" data-path="7.4-conjugacy.html"><a href="7.4-conjugacy.html#precision-1"><i class="fa fa-check"></i><b>7.4.1</b> Precision </a></li>
<li class="chapter" data-level="7.4.2" data-path="7.4-conjugacy.html"><a href="7.4-conjugacy.html#conjugate-prior"><i class="fa fa-check"></i><b>7.4.2</b> Conjugate Prior </a></li>
<li class="chapter" data-level="7.4.3" data-path="7.4-conjugacy.html"><a href="7.4-conjugacy.html#normal-normal-conjugacy"><i class="fa fa-check"></i><b>7.4.3</b> Normal-Normal Conjugacy </a></li>
<li class="chapter" data-level="7.4.4" data-path="7.4-conjugacy.html"><a href="7.4-conjugacy.html#normal-inverse-gamma-conjugacy"><i class="fa fa-check"></i><b>7.4.4</b> Normal-Inverse Gamma Conjugacy </a></li>
<li class="chapter" data-level="7.4.5" data-path="7.4-conjugacy.html"><a href="7.4-conjugacy.html#multivariate-normal-conjugacy"><i class="fa fa-check"></i><b>7.4.5</b> Multivariate Normal Conjugacy </a></li>
<li class="chapter" data-level="7.4.6" data-path="7.4-conjugacy.html"><a href="7.4-conjugacy.html#normal-wishart-conjugacy"><i class="fa fa-check"></i><b>7.4.6</b> Normal Wishart Conjugacy </a></li>
<li class="chapter" data-level="7.4.7" data-path="7.4-conjugacy.html"><a href="7.4-conjugacy.html#normal-inverse-wishart-conjugacy"><i class="fa fa-check"></i><b>7.4.7</b> Normal-Inverse Wishart Conjugacy </a></li>
<li class="chapter" data-level="7.4.8" data-path="7.4-conjugacy.html"><a href="7.4-conjugacy.html#normal-lkj-conjugacy"><i class="fa fa-check"></i><b>7.4.8</b> Normal-LKJ Conjugacy </a></li>
<li class="chapter" data-level="7.4.9" data-path="7.4-conjugacy.html"><a href="7.4-conjugacy.html#binomial-beta-conjugacy"><i class="fa fa-check"></i><b>7.4.9</b> Binomial-Beta Conjugacy </a></li>
<li class="chapter" data-level="7.4.10" data-path="7.4-conjugacy.html"><a href="7.4-conjugacy.html#geometric-beta-conjugacy"><i class="fa fa-check"></i><b>7.4.10</b> Geometric-Beta Conjugacy </a></li>
<li class="chapter" data-level="7.4.11" data-path="7.4-conjugacy.html"><a href="7.4-conjugacy.html#poisson-gamma-conjugacy"><i class="fa fa-check"></i><b>7.4.11</b> Poisson-Gamma Conjugacy </a></li>
<li class="chapter" data-level="7.4.12" data-path="7.4-conjugacy.html"><a href="7.4-conjugacy.html#exponential-gamma-conjugacy"><i class="fa fa-check"></i><b>7.4.12</b> Exponential-Gamma Conjugacy </a></li>
<li class="chapter" data-level="7.4.13" data-path="7.4-conjugacy.html"><a href="7.4-conjugacy.html#multinomial-dirichlet-conjugacy"><i class="fa fa-check"></i><b>7.4.13</b> Multinomial-Dirichlet Conjugacy </a></li>
<li class="chapter" data-level="7.4.14" data-path="7.4-conjugacy.html"><a href="7.4-conjugacy.html#hyperparameters"><i class="fa fa-check"></i><b>7.4.14</b> Hyperparameters </a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="7.5-information-theory.html"><a href="7.5-information-theory.html"><i class="fa fa-check"></i><b>7.5</b> Information Theory </a><ul>
<li class="chapter" data-level="7.5.1" data-path="7.5-information-theory.html"><a href="7.5-information-theory.html#information"><i class="fa fa-check"></i><b>7.5.1</b> Information </a></li>
<li class="chapter" data-level="7.5.2" data-path="7.5-information-theory.html"><a href="7.5-information-theory.html#entropy"><i class="fa fa-check"></i><b>7.5.2</b> Entropy </a></li>
<li class="chapter" data-level="7.5.3" data-path="7.5-information-theory.html"><a href="7.5-information-theory.html#gini-index"><i class="fa fa-check"></i><b>7.5.3</b> Gini Index </a></li>
<li class="chapter" data-level="7.5.4" data-path="7.5-information-theory.html"><a href="7.5-information-theory.html#information-gain"><i class="fa fa-check"></i><b>7.5.4</b> Information Gain </a></li>
<li class="chapter" data-level="7.5.5" data-path="7.5-information-theory.html"><a href="7.5-information-theory.html#mutual-information"><i class="fa fa-check"></i><b>7.5.5</b> Mutual Information </a></li>
<li class="chapter" data-level="7.5.6" data-path="7.5-information-theory.html"><a href="7.5-information-theory.html#kullback-leibler-divergence"><i class="fa fa-check"></i><b>7.5.6</b> Kullback-Leibler Divergence  </a></li>
<li class="chapter" data-level="7.5.7" data-path="7.5-information-theory.html"><a href="7.5-information-theory.html#jensens-inequality"><i class="fa fa-check"></i><b>7.5.7</b> Jensen’s Inequality</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="7.6-bayesianinference.html"><a href="7.6-bayesianinference.html"><i class="fa fa-check"></i><b>7.6</b> Bayesian Inference</a><ul>
<li class="chapter" data-level="7.6.1" data-path="7.6-bayesianinference.html"><a href="7.6-bayesianinference.html#maximum-likelihood-mle"><i class="fa fa-check"></i><b>7.6.1</b> Maximum Likelihood (MLE)  </a></li>
<li class="chapter" data-level="7.6.2" data-path="7.6-bayesianinference.html"><a href="7.6-bayesianinference.html#maximum-a-posteriori-map"><i class="fa fa-check"></i><b>7.6.2</b> Maximum A-posteriori (MAP)  </a></li>
<li class="chapter" data-level="7.6.3" data-path="7.6-bayesianinference.html"><a href="7.6-bayesianinference.html#laplace-approximation"><i class="fa fa-check"></i><b>7.6.3</b> Laplace Approximation </a></li>
<li class="chapter" data-level="7.6.4" data-path="7.6-bayesianinference.html"><a href="7.6-bayesianinference.html#expectation-maximization-em"><i class="fa fa-check"></i><b>7.6.4</b> Expectation-Maximization (EM)  </a></li>
<li class="chapter" data-level="7.6.5" data-path="7.6-bayesianinference.html"><a href="7.6-bayesianinference.html#variational-inference"><i class="fa fa-check"></i><b>7.6.5</b> Variational Inference </a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="8-bayesian2.html"><a href="8-bayesian2.html"><i class="fa fa-check"></i><b>8</b> Bayesian Computation II</a><ul>
<li class="chapter" data-level="8.1" data-path="8.1-bayesian-models.html"><a href="8.1-bayesian-models.html"><i class="fa fa-check"></i><b>8.1</b> Bayesian Models </a><ul>
<li class="chapter" data-level="8.1.1" data-path="8.1-bayesian-models.html"><a href="8.1-bayesian-models.html#belief-propagation"><i class="fa fa-check"></i><b>8.1.1</b> Belief Propagation </a></li>
<li class="chapter" data-level="8.1.2" data-path="8.1-bayesian-models.html"><a href="8.1-bayesian-models.html#expectation-propagation"><i class="fa fa-check"></i><b>8.1.2</b> Expectation Propagation </a></li>
<li class="chapter" data-level="8.1.3" data-path="8.1-bayesian-models.html"><a href="8.1-bayesian-models.html#markov-chain"><i class="fa fa-check"></i><b>8.1.3</b> Markov Chain </a></li>
<li class="chapter" data-level="8.1.4" data-path="8.1-bayesian-models.html"><a href="8.1-bayesian-models.html#hidden-markov-model"><i class="fa fa-check"></i><b>8.1.4</b> Hidden Markov Model  </a></li>
<li class="chapter" data-level="8.1.5" data-path="8.1-bayesian-models.html"><a href="8.1-bayesian-models.html#dynamic-system-model"><i class="fa fa-check"></i><b>8.1.5</b> Dynamic System Model</a></li>
<li class="chapter" data-level="8.1.6" data-path="8.1-bayesian-models.html"><a href="8.1-bayesian-models.html#bayes-filter"><i class="fa fa-check"></i><b>8.1.6</b> Bayes Filter </a></li>
<li class="chapter" data-level="8.1.7" data-path="8.1-bayesian-models.html"><a href="8.1-bayesian-models.html#kalman-filter"><i class="fa fa-check"></i><b>8.1.7</b> Kalman Filter </a></li>
<li class="chapter" data-level="8.1.8" data-path="8.1-bayesian-models.html"><a href="8.1-bayesian-models.html#extended-kalman-filter"><i class="fa fa-check"></i><b>8.1.8</b> Extended Kalman Filter </a></li>
<li class="chapter" data-level="8.1.9" data-path="8.1-bayesian-models.html"><a href="8.1-bayesian-models.html#unscented-kalman-filter"><i class="fa fa-check"></i><b>8.1.9</b> Unscented Kalman Filter </a></li>
<li class="chapter" data-level="8.1.10" data-path="8.1-bayesian-models.html"><a href="8.1-bayesian-models.html#particle-filter"><i class="fa fa-check"></i><b>8.1.10</b> Particle Filter </a></li>
<li class="chapter" data-level="8.1.11" data-path="8.1-bayesian-models.html"><a href="8.1-bayesian-models.html#ensemble-kalman-filter"><i class="fa fa-check"></i><b>8.1.11</b> Ensemble Kalman Filter </a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="8.2-simulation-and-sampling.html"><a href="8.2-simulation-and-sampling.html"><i class="fa fa-check"></i><b>8.2</b> Simulation and Sampling</a><ul>
<li class="chapter" data-level="8.2.1" data-path="8.2-simulation-and-sampling.html"><a href="8.2-simulation-and-sampling.html#monte-carlo-estimation"><i class="fa fa-check"></i><b>8.2.1</b> Monte Carlo Estimation </a></li>
<li class="chapter" data-level="8.2.2" data-path="8.2-simulation-and-sampling.html"><a href="8.2-simulation-and-sampling.html#monte-carlo-simulation"><i class="fa fa-check"></i><b>8.2.2</b> Monte Carlo Simulation </a></li>
<li class="chapter" data-level="8.2.3" data-path="8.2-simulation-and-sampling.html"><a href="8.2-simulation-and-sampling.html#markov-chain-monte-carlo"><i class="fa fa-check"></i><b>8.2.3</b> Markov Chain Monte Carlo  </a></li>
<li class="chapter" data-level="8.2.4" data-path="8.2-simulation-and-sampling.html"><a href="8.2-simulation-and-sampling.html#metropolis-hastings-monte-carlo"><i class="fa fa-check"></i><b>8.2.4</b> Metropolis-Hastings Monte Carlo  </a></li>
<li class="chapter" data-level="8.2.5" data-path="8.2-simulation-and-sampling.html"><a href="8.2-simulation-and-sampling.html#hamiltonian-monte-carlo"><i class="fa fa-check"></i><b>8.2.5</b> Hamiltonian Monte Carlo  </a></li>
<li class="chapter" data-level="8.2.6" data-path="8.2-simulation-and-sampling.html"><a href="8.2-simulation-and-sampling.html#gibbs-sampling"><i class="fa fa-check"></i><b>8.2.6</b> Gibbs Sampling </a></li>
<li class="chapter" data-level="8.2.7" data-path="8.2-simulation-and-sampling.html"><a href="8.2-simulation-and-sampling.html#importance-sampling"><i class="fa fa-check"></i><b>8.2.7</b> Importance Sampling </a></li>
<li class="chapter" data-level="8.2.8" data-path="8.2-simulation-and-sampling.html"><a href="8.2-simulation-and-sampling.html#rejection-sampling"><i class="fa fa-check"></i><b>8.2.8</b> Rejection Sampling </a></li>
<li class="chapter" data-level="8.2.9" data-path="8.2-simulation-and-sampling.html"><a href="8.2-simulation-and-sampling.html#jags-modeling"><i class="fa fa-check"></i><b>8.2.9</b> JAGS Modeling </a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="8.3-bayesian-analysis.html"><a href="8.3-bayesian-analysis.html"><i class="fa fa-check"></i><b>8.3</b> Bayesian Analysis</a><ul>
<li class="chapter" data-level="8.3.1" data-path="8.3-bayesian-analysis.html"><a href="8.3-bayesian-analysis.html#autocorrelation"><i class="fa fa-check"></i><b>8.3.1</b> Autocorrelation </a></li>
<li class="chapter" data-level="8.3.2" data-path="8.3-bayesian-analysis.html"><a href="8.3-bayesian-analysis.html#predictive-probability"><i class="fa fa-check"></i><b>8.3.2</b> Predictive Probability </a></li>
<li class="chapter" data-level="8.3.3" data-path="8.3-bayesian-analysis.html"><a href="8.3-bayesian-analysis.html#posterior-interval"><i class="fa fa-check"></i><b>8.3.3</b> Posterior Interval </a></li>
<li class="chapter" data-level="8.3.4" data-path="8.3-bayesian-analysis.html"><a href="8.3-bayesian-analysis.html#bayes-factor"><i class="fa fa-check"></i><b>8.3.4</b> Bayes Factor </a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="8.4-summary-5.html"><a href="8.4-summary-5.html"><i class="fa fa-check"></i><b>8.4</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="9-machinelearning1.html"><a href="9-machinelearning1.html"><i class="fa fa-check"></i><b>9</b> Computational Learning I</a><ul>
<li class="chapter" data-level="9.1" data-path="9.1-observation-and-measurement.html"><a href="9.1-observation-and-measurement.html"><i class="fa fa-check"></i><b>9.1</b> Observation and Measurement</a><ul>
<li class="chapter" data-level="9.1.1" data-path="9.1-observation-and-measurement.html"><a href="9.1-observation-and-measurement.html#levels-of-measurements"><i class="fa fa-check"></i><b>9.1.1</b> Levels of Measurements</a></li>
<li class="chapter" data-level="9.1.2" data-path="9.1-observation-and-measurement.html"><a href="9.1-observation-and-measurement.html#levels-of-categorical-measurements"><i class="fa fa-check"></i><b>9.1.2</b> Levels of Categorical measurements</a></li>
<li class="chapter" data-level="9.1.3" data-path="9.1-observation-and-measurement.html"><a href="9.1-observation-and-measurement.html#levels-of-continuous-measurements"><i class="fa fa-check"></i><b>9.1.3</b> Levels of Continuous measurements</a></li>
<li class="chapter" data-level="9.1.4" data-path="9.1-observation-and-measurement.html"><a href="9.1-observation-and-measurement.html#discrete-vs-continuous-measurements"><i class="fa fa-check"></i><b>9.1.4</b> Discrete vs Continuous measurements</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="9.2-input-data.html"><a href="9.2-input-data.html"><i class="fa fa-check"></i><b>9.2</b> Input Data</a><ul>
<li class="chapter" data-level="9.2.1" data-path="9.2-input-data.html"><a href="9.2-input-data.html#structured-data"><i class="fa fa-check"></i><b>9.2.1</b> Structured Data</a></li>
<li class="chapter" data-level="9.2.2" data-path="9.2-input-data.html"><a href="9.2-input-data.html#non-structured-data"><i class="fa fa-check"></i><b>9.2.2</b> Non-Structured Data</a></li>
<li class="chapter" data-level="9.2.3" data-path="9.2-input-data.html"><a href="9.2-input-data.html#statistical-data"><i class="fa fa-check"></i><b>9.2.3</b> Statistical Data</a></li>
<li class="chapter" data-level="9.2.4" data-path="9.2-input-data.html"><a href="9.2-input-data.html#real-time-and-near-real-time-data"><i class="fa fa-check"></i><b>9.2.4</b> Real-Time and Near Real-Time Data</a></li>
<li class="chapter" data-level="9.2.5" data-path="9.2-input-data.html"><a href="9.2-input-data.html#oltp-and-datawarehouse"><i class="fa fa-check"></i><b>9.2.5</b> OLTP and Datawarehouse</a></li>
<li class="chapter" data-level="9.2.6" data-path="9.2-input-data.html"><a href="9.2-input-data.html#data-lake"><i class="fa fa-check"></i><b>9.2.6</b> Data lake</a></li>
<li class="chapter" data-level="9.2.7" data-path="9.2-input-data.html"><a href="9.2-input-data.html#natural-language-nl"><i class="fa fa-check"></i><b>9.2.7</b> Natural Language (NL)</a></li>
<li class="chapter" data-level="9.2.8" data-path="9.2-input-data.html"><a href="9.2-input-data.html#multimedia-md"><i class="fa fa-check"></i><b>9.2.8</b> Multimedia (MD)</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="9.3-primitive-methods.html"><a href="9.3-primitive-methods.html"><i class="fa fa-check"></i><b>9.3</b> Primitive Methods</a><ul>
<li class="chapter" data-level="9.3.1" data-path="9.3-primitive-methods.html"><a href="9.3-primitive-methods.html#weighting"><i class="fa fa-check"></i><b>9.3.1</b> Weighting</a></li>
<li class="chapter" data-level="9.3.2" data-path="9.3-primitive-methods.html"><a href="9.3-primitive-methods.html#smoothing"><i class="fa fa-check"></i><b>9.3.2</b> Smoothing</a></li>
<li class="chapter" data-level="9.3.3" data-path="9.3-primitive-methods.html"><a href="9.3-primitive-methods.html#normalizing"><i class="fa fa-check"></i><b>9.3.3</b> Normalizing</a></li>
<li class="chapter" data-level="9.3.4" data-path="9.3-primitive-methods.html"><a href="9.3-primitive-methods.html#standardizing"><i class="fa fa-check"></i><b>9.3.4</b> Standardizing </a></li>
<li class="chapter" data-level="9.3.5" data-path="9.3-primitive-methods.html"><a href="9.3-primitive-methods.html#centering"><i class="fa fa-check"></i><b>9.3.5</b> Centering </a></li>
<li class="chapter" data-level="9.3.6" data-path="9.3-primitive-methods.html"><a href="9.3-primitive-methods.html#scaling-1"><i class="fa fa-check"></i><b>9.3.6</b> Scaling </a></li>
<li class="chapter" data-level="9.3.7" data-path="9.3-primitive-methods.html"><a href="9.3-primitive-methods.html#transforming"><i class="fa fa-check"></i><b>9.3.7</b> Transforming</a></li>
<li class="chapter" data-level="9.3.8" data-path="9.3-primitive-methods.html"><a href="9.3-primitive-methods.html#clipping"><i class="fa fa-check"></i><b>9.3.8</b> Clipping </a></li>
<li class="chapter" data-level="9.3.9" data-path="9.3-primitive-methods.html"><a href="9.3-primitive-methods.html#regularizing"><i class="fa fa-check"></i><b>9.3.9</b> Regularizing</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="9.4-distance-metrics.html"><a href="9.4-distance-metrics.html"><i class="fa fa-check"></i><b>9.4</b> Distance Metrics</a><ul>
<li class="chapter" data-level="9.4.1" data-path="9.4-distance-metrics.html"><a href="9.4-distance-metrics.html#cosine-similarity"><i class="fa fa-check"></i><b>9.4.1</b> Cosine Similarity</a></li>
<li class="chapter" data-level="9.4.2" data-path="9.4-distance-metrics.html"><a href="9.4-distance-metrics.html#manhattan-and-euclidean-distance"><i class="fa fa-check"></i><b>9.4.2</b> Manhattan and Euclidean Distance  </a></li>
<li class="chapter" data-level="9.4.3" data-path="9.4-distance-metrics.html"><a href="9.4-distance-metrics.html#minkowski-and-chebyshev-supremum-distance"><i class="fa fa-check"></i><b>9.4.3</b> Minkowski and Chebyshev (Supremum) Distance  </a></li>
<li class="chapter" data-level="9.4.4" data-path="9.4-distance-metrics.html"><a href="9.4-distance-metrics.html#jaccard-similarity-and-distance"><i class="fa fa-check"></i><b>9.4.4</b> Jaccard (Similarity and Distance) </a></li>
<li class="chapter" data-level="9.4.5" data-path="9.4-distance-metrics.html"><a href="9.4-distance-metrics.html#hamming-distance"><i class="fa fa-check"></i><b>9.4.5</b> Hamming Distance </a></li>
<li class="chapter" data-level="9.4.6" data-path="9.4-distance-metrics.html"><a href="9.4-distance-metrics.html#mahalanobis-distance"><i class="fa fa-check"></i><b>9.4.6</b> Mahalanobis Distance </a></li>
<li class="chapter" data-level="9.4.7" data-path="9.4-distance-metrics.html"><a href="9.4-distance-metrics.html#precision-and-accuracy"><i class="fa fa-check"></i><b>9.4.7</b> Precision and Accuracy  </a></li>
<li class="chapter" data-level="9.4.8" data-path="9.4-distance-metrics.html"><a href="9.4-distance-metrics.html#auc-on-roc"><i class="fa fa-check"></i><b>9.4.8</b> AUC on ROC </a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="9.5-exploratory-data-analysis.html"><a href="9.5-exploratory-data-analysis.html"><i class="fa fa-check"></i><b>9.5</b> Exploratory Data Analysis</a><ul>
<li class="chapter" data-level="9.5.1" data-path="9.5-exploratory-data-analysis.html"><a href="9.5-exploratory-data-analysis.html#data-cleaning-wrangling"><i class="fa fa-check"></i><b>9.5.1</b> Data Cleaning (Wrangling)  </a></li>
<li class="chapter" data-level="9.5.2" data-path="9.5-exploratory-data-analysis.html"><a href="9.5-exploratory-data-analysis.html#association"><i class="fa fa-check"></i><b>9.5.2</b> Association</a></li>
<li class="chapter" data-level="9.5.3" data-path="9.5-exploratory-data-analysis.html"><a href="9.5-exploratory-data-analysis.html#pattern-discovery"><i class="fa fa-check"></i><b>9.5.3</b> Pattern Discovery</a></li>
<li class="chapter" data-level="9.5.4" data-path="9.5-exploratory-data-analysis.html"><a href="9.5-exploratory-data-analysis.html#null-invariance"><i class="fa fa-check"></i><b>9.5.4</b> Null Invariance </a></li>
<li class="chapter" data-level="9.5.5" data-path="9.5-exploratory-data-analysis.html"><a href="9.5-exploratory-data-analysis.html#correlation-and-collinearity"><i class="fa fa-check"></i><b>9.5.5</b> Correlation and Collinearity  </a></li>
<li class="chapter" data-level="9.5.6" data-path="9.5-exploratory-data-analysis.html"><a href="9.5-exploratory-data-analysis.html#covariance"><i class="fa fa-check"></i><b>9.5.6</b> Covariance </a></li>
<li class="chapter" data-level="9.5.7" data-path="9.5-exploratory-data-analysis.html"><a href="9.5-exploratory-data-analysis.html#outliers-leverage-influence"><i class="fa fa-check"></i><b>9.5.7</b> Outliers, Leverage, Influence   </a></li>
<li class="chapter" data-level="9.5.8" data-path="9.5-exploratory-data-analysis.html"><a href="9.5-exploratory-data-analysis.html#dominating-factors"><i class="fa fa-check"></i><b>9.5.8</b> Dominating Factors </a></li>
<li class="chapter" data-level="9.5.9" data-path="9.5-exploratory-data-analysis.html"><a href="9.5-exploratory-data-analysis.html#missingness-and-imputation"><i class="fa fa-check"></i><b>9.5.9</b> Missingness and Imputation  </a></li>
<li class="chapter" data-level="9.5.10" data-path="9.5-exploratory-data-analysis.html"><a href="9.5-exploratory-data-analysis.html#confounding-variable"><i class="fa fa-check"></i><b>9.5.10</b> Confounding Variable </a></li>
<li class="chapter" data-level="9.5.11" data-path="9.5-exploratory-data-analysis.html"><a href="9.5-exploratory-data-analysis.html#data-leakage"><i class="fa fa-check"></i><b>9.5.11</b> Data Leakage </a></li>
<li class="chapter" data-level="9.5.12" data-path="9.5-exploratory-data-analysis.html"><a href="9.5-exploratory-data-analysis.html#one-hot-encoding"><i class="fa fa-check"></i><b>9.5.12</b> One Hot Encoding </a></li>
<li class="chapter" data-level="9.5.13" data-path="9.5-exploratory-data-analysis.html"><a href="9.5-exploratory-data-analysis.html#winsorization-and-trimming"><i class="fa fa-check"></i><b>9.5.13</b> Winsorization and Trimming  </a></li>
<li class="chapter" data-level="9.5.14" data-path="9.5-exploratory-data-analysis.html"><a href="9.5-exploratory-data-analysis.html#discretization"><i class="fa fa-check"></i><b>9.5.14</b> Discretization </a></li>
<li class="chapter" data-level="9.5.15" data-path="9.5-exploratory-data-analysis.html"><a href="9.5-exploratory-data-analysis.html#stratification"><i class="fa fa-check"></i><b>9.5.15</b> Stratification </a></li>
<li class="chapter" data-level="9.5.16" data-path="9.5-exploratory-data-analysis.html"><a href="9.5-exploratory-data-analysis.html#fine-and-coarse-classing"><i class="fa fa-check"></i><b>9.5.16</b> Fine and Coarse Classing</a></li>
<li class="chapter" data-level="9.5.17" data-path="9.5-exploratory-data-analysis.html"><a href="9.5-exploratory-data-analysis.html#embedding"><i class="fa fa-check"></i><b>9.5.17</b> Embedding </a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="9.6-featureengineering.html"><a href="9.6-featureengineering.html"><i class="fa fa-check"></i><b>9.6</b> Feature Engineering</a><ul>
<li class="chapter" data-level="9.6.1" data-path="9.6-featureengineering.html"><a href="9.6-featureengineering.html#machine-learning-features"><i class="fa fa-check"></i><b>9.6.1</b> Machine Learning Features</a></li>
<li class="chapter" data-level="9.6.2" data-path="9.6-featureengineering.html"><a href="9.6-featureengineering.html#dimensionality-reduction"><i class="fa fa-check"></i><b>9.6.2</b> Dimensionality Reduction </a></li>
<li class="chapter" data-level="9.6.3" data-path="9.6-featureengineering.html"><a href="9.6-featureengineering.html#principal-component-analysis"><i class="fa fa-check"></i><b>9.6.3</b> Principal Component Analysis  </a></li>
<li class="chapter" data-level="9.6.4" data-path="9.6-featureengineering.html"><a href="9.6-featureengineering.html#linear-discriminant-analysis-lda"><i class="fa fa-check"></i><b>9.6.4</b> Linear Discriminant Analysis (LDA)  </a></li>
<li class="chapter" data-level="9.6.5" data-path="9.6-featureengineering.html"><a href="9.6-featureengineering.html#feature-construction"><i class="fa fa-check"></i><b>9.6.5</b> Feature Construction </a></li>
<li class="chapter" data-level="9.6.6" data-path="9.6-featureengineering.html"><a href="9.6-featureengineering.html#featureselection"><i class="fa fa-check"></i><b>9.6.6</b> Feature Selection</a></li>
<li class="chapter" data-level="9.6.7" data-path="9.6-featureengineering.html"><a href="9.6-featureengineering.html#feature-transformation"><i class="fa fa-check"></i><b>9.6.7</b> Feature Transformation </a></li>
<li class="chapter" data-level="9.6.8" data-path="9.6-featureengineering.html"><a href="9.6-featureengineering.html#model-specification-1"><i class="fa fa-check"></i><b>9.6.8</b> Model Specification </a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="9.7-general-modeling.html"><a href="9.7-general-modeling.html"><i class="fa fa-check"></i><b>9.7</b> General Modeling</a><ul>
<li class="chapter" data-level="9.7.1" data-path="9.7-general-modeling.html"><a href="9.7-general-modeling.html#training-learning"><i class="fa fa-check"></i><b>9.7.1</b> Training (Learning)</a></li>
<li class="chapter" data-level="9.7.2" data-path="9.7-general-modeling.html"><a href="9.7-general-modeling.html#validation-tuning"><i class="fa fa-check"></i><b>9.7.2</b> Validation (Tuning) </a></li>
<li class="chapter" data-level="9.7.3" data-path="9.7-general-modeling.html"><a href="9.7-general-modeling.html#testing-assessing"><i class="fa fa-check"></i><b>9.7.3</b> Testing (Assessing) </a></li>
<li class="chapter" data-level="9.7.4" data-path="9.7-general-modeling.html"><a href="9.7-general-modeling.html#cross-validation-cv"><i class="fa fa-check"></i><b>9.7.4</b> Cross-Validation (CV)  </a></li>
<li class="chapter" data-level="9.7.5" data-path="9.7-general-modeling.html"><a href="9.7-general-modeling.html#bias-and-variance"><i class="fa fa-check"></i><b>9.7.5</b> Bias and Variance </a></li>
<li class="chapter" data-level="9.7.6" data-path="9.7-general-modeling.html"><a href="9.7-general-modeling.html#loss-and-cost-functions"><i class="fa fa-check"></i><b>9.7.6</b> Loss and Cost Functions  </a></li>
<li class="chapter" data-level="9.7.7" data-path="9.7-general-modeling.html"><a href="9.7-general-modeling.html#global-and-local-minima"><i class="fa fa-check"></i><b>9.7.7</b> Global and Local Minima  </a></li>
<li class="chapter" data-level="9.7.8" data-path="9.7-general-modeling.html"><a href="9.7-general-modeling.html#regularization"><i class="fa fa-check"></i><b>9.7.8</b> Regularization</a></li>
</ul></li>
<li class="chapter" data-level="9.8" data-path="9.8-supervised-vs.unsupervised-learning.html"><a href="9.8-supervised-vs.unsupervised-learning.html"><i class="fa fa-check"></i><b>9.8</b> Supervised vs. Unsupervised Learning  </a></li>
<li class="chapter" data-level="9.9" data-path="9.9-summary-6.html"><a href="9.9-summary-6.html"><i class="fa fa-check"></i><b>9.9</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="10-machinelearning2.html"><a href="10-machinelearning2.html"><i class="fa fa-check"></i><b>10</b> Computational Learning II</a><ul>
<li class="chapter" data-level="10.1" data-path="10.1-regression.html"><a href="10.1-regression.html"><i class="fa fa-check"></i><b>10.1</b> Regression (Supervised)</a><ul>
<li class="chapter" data-level="10.1.1" data-path="10.1-regression.html"><a href="10.1-regression.html#regression-trees"><i class="fa fa-check"></i><b>10.1.1</b> Regression Trees </a></li>
<li class="chapter" data-level="10.1.2" data-path="10.1-regression.html"><a href="10.1-regression.html#ensemble-methods"><i class="fa fa-check"></i><b>10.1.2</b> Ensemble Methods </a></li>
<li class="chapter" data-level="10.1.3" data-path="10.1-regression.html"><a href="10.1-regression.html#random-forest"><i class="fa fa-check"></i><b>10.1.3</b> Random Forest </a></li>
<li class="chapter" data-level="10.1.4" data-path="10.1-regression.html"><a href="10.1-regression.html#Adaoost"><i class="fa fa-check"></i><b>10.1.4</b> AdaBoost</a></li>
<li class="chapter" data-level="10.1.5" data-path="10.1-regression.html"><a href="10.1-regression.html#gradient-boost"><i class="fa fa-check"></i><b>10.1.5</b> Gradient Boost </a></li>
<li class="chapter" data-level="10.1.6" data-path="10.1-regression.html"><a href="10.1-regression.html#xgboost"><i class="fa fa-check"></i><b>10.1.6</b> XGBoost </a></li>
<li class="chapter" data-level="10.1.7" data-path="10.1-regression.html"><a href="10.1-regression.html#generalized-linear-modeling-glm"><i class="fa fa-check"></i><b>10.1.7</b> Generalized Linear Modeling (GLM)  </a></li>
<li class="chapter" data-level="10.1.8" data-path="10.1-regression.html"><a href="10.1-regression.html#logisticregression"><i class="fa fa-check"></i><b>10.1.8</b> Logistic Regression (GLM)</a></li>
<li class="chapter" data-level="10.1.9" data-path="10.1-regression.html"><a href="10.1-regression.html#poisson"><i class="fa fa-check"></i><b>10.1.9</b> Poisson Regression (GLM)</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="10.2-binary-classification-supervised.html"><a href="10.2-binary-classification-supervised.html"><i class="fa fa-check"></i><b>10.2</b> Binary Classification (Supervised)</a><ul>
<li class="chapter" data-level="10.2.1" data-path="10.2-binary-classification-supervised.html"><a href="10.2-binary-classification-supervised.html#linear-svm-sgdpegasos"><i class="fa fa-check"></i><b>10.2.1</b> Linear SVM (SGD/PEGASOS)  </a></li>
<li class="chapter" data-level="10.2.2" data-path="10.2-binary-classification-supervised.html"><a href="10.2-binary-classification-supervised.html#kernel-svm-smo"><i class="fa fa-check"></i><b>10.2.2</b> Kernel SVM (SMO)  </a></li>
<li class="chapter" data-level="10.2.3" data-path="10.2-binary-classification-supervised.html"><a href="10.2-binary-classification-supervised.html#sdca-based-svm"><i class="fa fa-check"></i><b>10.2.3</b> SDCA-based SVM </a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="10.3-multi-class-classification-supervised.html"><a href="10.3-multi-class-classification-supervised.html"><i class="fa fa-check"></i><b>10.3</b> Multi-class Classification (Supervised) </a><ul>
<li class="chapter" data-level="10.3.1" data-path="10.3-multi-class-classification-supervised.html"><a href="10.3-multi-class-classification-supervised.html#bayesian-classification"><i class="fa fa-check"></i><b>10.3.1</b> Bayesian Classification </a></li>
<li class="chapter" data-level="10.3.2" data-path="10.3-multi-class-classification-supervised.html"><a href="10.3-multi-class-classification-supervised.html#classification-trees"><i class="fa fa-check"></i><b>10.3.2</b> Classification Trees </a></li>
<li class="chapter" data-level="10.3.3" data-path="10.3-multi-class-classification-supervised.html"><a href="10.3-multi-class-classification-supervised.html#ensemble-methods-1"><i class="fa fa-check"></i><b>10.3.3</b> Ensemble Methods </a></li>
<li class="chapter" data-level="10.3.4" data-path="10.3-multi-class-classification-supervised.html"><a href="10.3-multi-class-classification-supervised.html#random-forest-1"><i class="fa fa-check"></i><b>10.3.4</b> Random Forest </a></li>
<li class="chapter" data-level="10.3.5" data-path="10.3-multi-class-classification-supervised.html"><a href="10.3-multi-class-classification-supervised.html#AdaBoost"><i class="fa fa-check"></i><b>10.3.5</b> AdaBoost &amp; SAMME</a></li>
<li class="chapter" data-level="10.3.6" data-path="10.3-multi-class-classification-supervised.html"><a href="10.3-multi-class-classification-supervised.html#logitboost-j-classes"><i class="fa fa-check"></i><b>10.3.6</b> LogitBoost (J Classes)</a></li>
<li class="chapter" data-level="10.3.7" data-path="10.3-multi-class-classification-supervised.html"><a href="10.3-multi-class-classification-supervised.html#gradient-boost-1"><i class="fa fa-check"></i><b>10.3.7</b> Gradient Boost </a></li>
<li class="chapter" data-level="10.3.8" data-path="10.3-multi-class-classification-supervised.html"><a href="10.3-multi-class-classification-supervised.html#k-next-neighbors-knn"><i class="fa fa-check"></i><b>10.3.8</b> K-Next Neighbors (KNN)  </a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="11-machinelearning3.html"><a href="11-machinelearning3.html"><i class="fa fa-check"></i><b>11</b> Computational Learning III</a><ul>
<li class="chapter" data-level="11.1" data-path="11.1-clustering-unsupervised.html"><a href="11.1-clustering-unsupervised.html"><i class="fa fa-check"></i><b>11.1</b> Clustering (Unsupervised) </a><ul>
<li class="chapter" data-level="11.1.1" data-path="11.1-clustering-unsupervised.html"><a href="11.1-clustering-unsupervised.html#k-means-clustering"><i class="fa fa-check"></i><b>11.1.1</b> K-means (clustering) </a></li>
<li class="chapter" data-level="11.1.2" data-path="11.1-clustering-unsupervised.html"><a href="11.1-clustering-unsupervised.html#hierarchical-clustering"><i class="fa fa-check"></i><b>11.1.2</b> Hierarchical (clustering) </a></li>
<li class="chapter" data-level="11.1.3" data-path="11.1-clustering-unsupervised.html"><a href="11.1-clustering-unsupervised.html#dbscan-clustering"><i class="fa fa-check"></i><b>11.1.3</b> DBSCAN (clustering) </a></li>
<li class="chapter" data-level="11.1.4" data-path="11.1-clustering-unsupervised.html"><a href="11.1-clustering-unsupervised.html#quality-of-clustering"><i class="fa fa-check"></i><b>11.1.4</b> Quality of Clustering</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="11.2-meta-learning.html"><a href="11.2-meta-learning.html"><i class="fa fa-check"></i><b>11.2</b> Meta-Learning </a></li>
<li class="chapter" data-level="11.3" data-path="11.3-natural-language-processing-nlp.html"><a href="11.3-natural-language-processing-nlp.html"><i class="fa fa-check"></i><b>11.3</b> Natural Language Processing (NLP)  </a><ul>
<li class="chapter" data-level="11.3.1" data-path="11.3-natural-language-processing-nlp.html"><a href="11.3-natural-language-processing-nlp.html#pre-processing-texts"><i class="fa fa-check"></i><b>11.3.1</b> Pre-Processing Texts</a></li>
<li class="chapter" data-level="11.3.2" data-path="11.3-natural-language-processing-nlp.html"><a href="11.3-natural-language-processing-nlp.html#ranking-and-scoring"><i class="fa fa-check"></i><b>11.3.2</b> Ranking and Scoring </a></li>
<li class="chapter" data-level="11.3.3" data-path="11.3-natural-language-processing-nlp.html"><a href="11.3-natural-language-processing-nlp.html#document-similarity"><i class="fa fa-check"></i><b>11.3.3</b> Document Similarity </a></li>
<li class="chapter" data-level="11.3.4" data-path="11.3-natural-language-processing-nlp.html"><a href="11.3-natural-language-processing-nlp.html#linguistic-analysis"><i class="fa fa-check"></i><b>11.3.4</b> Linguistic Analysis </a></li>
<li class="chapter" data-level="11.3.5" data-path="11.3-natural-language-processing-nlp.html"><a href="11.3-natural-language-processing-nlp.html#lexical-analysis"><i class="fa fa-check"></i><b>11.3.5</b> Lexical Analysis </a></li>
<li class="chapter" data-level="11.3.6" data-path="11.3-natural-language-processing-nlp.html"><a href="11.3-natural-language-processing-nlp.html#semantic-analysis"><i class="fa fa-check"></i><b>11.3.6</b> Semantic Analysis </a></li>
<li class="chapter" data-level="11.3.7" data-path="11.3-natural-language-processing-nlp.html"><a href="11.3-natural-language-processing-nlp.html#named-entity-recognition-ner"><i class="fa fa-check"></i><b>11.3.7</b> Named Entity Recognition (NER)  </a></li>
<li class="chapter" data-level="11.3.8" data-path="11.3-natural-language-processing-nlp.html"><a href="11.3-natural-language-processing-nlp.html#sentiment-and-opinion-analysis"><i class="fa fa-check"></i><b>11.3.8</b> Sentiment and Opinion Analysis  </a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="11.4-time-series-forecasting.html"><a href="11.4-time-series-forecasting.html"><i class="fa fa-check"></i><b>11.4</b> Time-Series Forecasting </a><ul>
<li class="chapter" data-level="11.4.1" data-path="11.4-time-series-forecasting.html"><a href="11.4-time-series-forecasting.html#seasonal-trend-decomposition-using-loess-stl"><i class="fa fa-check"></i><b>11.4.1</b> Seasonal Trend Decomposition using LOESS (STL)  </a></li>
<li class="chapter" data-level="11.4.2" data-path="11.4-time-series-forecasting.html"><a href="11.4-time-series-forecasting.html#forecasting-models"><i class="fa fa-check"></i><b>11.4.2</b> Forecasting Models </a></li>
<li class="chapter" data-level="11.4.3" data-path="11.4-time-series-forecasting.html"><a href="11.4-time-series-forecasting.html#time-series-linear-model-tslm"><i class="fa fa-check"></i><b>11.4.3</b> Time-Series Linear Model (TSLM)  </a></li>
<li class="chapter" data-level="11.4.4" data-path="11.4-time-series-forecasting.html"><a href="11.4-time-series-forecasting.html#autoregressive-integrated-moving-average-arima"><i class="fa fa-check"></i><b>11.4.4</b> AutoRegressive Integrated Moving Average (ARIMA)  </a></li>
<li class="chapter" data-level="11.4.5" data-path="11.4-time-series-forecasting.html"><a href="11.4-time-series-forecasting.html#multiplicative-seasonal-arima-sarima"><i class="fa fa-check"></i><b>11.4.5</b> Multiplicative Seasonal ARIMA (SARIMA) </a></li>
<li class="chapter" data-level="11.4.6" data-path="11.4-time-series-forecasting.html"><a href="11.4-time-series-forecasting.html#time-series-decomposition"><i class="fa fa-check"></i><b>11.4.6</b> Time-Series Decomposition </a></li>
<li class="chapter" data-level="11.4.7" data-path="11.4-time-series-forecasting.html"><a href="11.4-time-series-forecasting.html#stl-with-aicbic"><i class="fa fa-check"></i><b>11.4.7</b> STL with AIC/BIC</a></li>
<li class="chapter" data-level="11.4.8" data-path="11.4-time-series-forecasting.html"><a href="11.4-time-series-forecasting.html#multivariate-time-series"><i class="fa fa-check"></i><b>11.4.8</b> Multivariate Time-Series</a></li>
<li class="chapter" data-level="11.4.9" data-path="11.4-time-series-forecasting.html"><a href="11.4-time-series-forecasting.html#forecasting-considerations"><i class="fa fa-check"></i><b>11.4.9</b> Forecasting Considerations</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="11.5-recommender-systems.html"><a href="11.5-recommender-systems.html"><i class="fa fa-check"></i><b>11.5</b> Recommender Systems </a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="12-deeplearning1.html"><a href="12-deeplearning1.html"><i class="fa fa-check"></i><b>12</b> Computational Deep Learning I</a><ul>
<li class="chapter" data-level="12.1" data-path="12.1-simple-perceptron.html"><a href="12.1-simple-perceptron.html"><i class="fa fa-check"></i><b>12.1</b> Simple Perceptron  </a></li>
<li class="chapter" data-level="12.2" data-path="12.2-adaptive-linear-neuron-adaline.html"><a href="12.2-adaptive-linear-neuron-adaline.html"><i class="fa fa-check"></i><b>12.2</b> Adaptive Linear Neuron (ADALINE)  </a></li>
<li class="chapter" data-level="12.3" data-path="12.3-multi-layer-perceptron-mlp.html"><a href="12.3-multi-layer-perceptron-mlp.html"><i class="fa fa-check"></i><b>12.3</b> Multi Layer Perceptron (MLP)  </a><ul>
<li class="chapter" data-level="12.3.1" data-path="12.3-multi-layer-perceptron-mlp.html"><a href="12.3-multi-layer-perceptron-mlp.html#forward-feed"><i class="fa fa-check"></i><b>12.3.1</b> Forward Feed </a></li>
<li class="chapter" data-level="12.3.2" data-path="12.3-multi-layer-perceptron-mlp.html"><a href="12.3-multi-layer-perceptron-mlp.html#backward-feed"><i class="fa fa-check"></i><b>12.3.2</b> Backward Feed </a></li>
<li class="chapter" data-level="12.3.3" data-path="12.3-multi-layer-perceptron-mlp.html"><a href="12.3-multi-layer-perceptron-mlp.html#backpropagation"><i class="fa fa-check"></i><b>12.3.3</b> BackPropagation </a></li>
<li class="chapter" data-level="12.3.4" data-path="12.3-multi-layer-perceptron-mlp.html"><a href="12.3-multi-layer-perceptron-mlp.html#mlp-example"><i class="fa fa-check"></i><b>12.3.4</b> MLP Example</a></li>
<li class="chapter" data-level="12.3.5" data-path="12.3-multi-layer-perceptron-mlp.html"><a href="12.3-multi-layer-perceptron-mlp.html#activation-function"><i class="fa fa-check"></i><b>12.3.5</b> Activation Function </a></li>
<li class="chapter" data-level="12.3.6" data-path="12.3-multi-layer-perceptron-mlp.html"><a href="12.3-multi-layer-perceptron-mlp.html#mlp-implementation"><i class="fa fa-check"></i><b>12.3.6</b> MLP Implementation</a></li>
<li class="chapter" data-level="12.3.7" data-path="12.3-multi-layer-perceptron-mlp.html"><a href="12.3-multi-layer-perceptron-mlp.html#deep-neural-network-dnn"><i class="fa fa-check"></i><b>12.3.7</b> Deep Neural Network (DNN)  </a></li>
<li class="chapter" data-level="12.3.8" data-path="12.3-multi-layer-perceptron-mlp.html"><a href="12.3-multi-layer-perceptron-mlp.html#vanishing-and-exploding-gradient"><i class="fa fa-check"></i><b>12.3.8</b> Vanishing and Exploding Gradient  </a></li>
<li class="chapter" data-level="12.3.9" data-path="12.3-multi-layer-perceptron-mlp.html"><a href="12.3-multi-layer-perceptron-mlp.html#dead-relu"><i class="fa fa-check"></i><b>12.3.9</b> Dead Relu </a></li>
<li class="chapter" data-level="12.3.10" data-path="12.3-multi-layer-perceptron-mlp.html"><a href="12.3-multi-layer-perceptron-mlp.html#gradient-clipping-gc"><i class="fa fa-check"></i><b>12.3.10</b> Gradient Clipping (GC) </a></li>
<li class="chapter" data-level="12.3.11" data-path="12.3-multi-layer-perceptron-mlp.html"><a href="12.3-multi-layer-perceptron-mlp.html#parameter-initialization"><i class="fa fa-check"></i><b>12.3.11</b> Parameter Initialization </a></li>
<li class="chapter" data-level="12.3.12" data-path="12.3-multi-layer-perceptron-mlp.html"><a href="12.3-multi-layer-perceptron-mlp.html#regularization-by-dropouts"><i class="fa fa-check"></i><b>12.3.12</b> Regularization by Dropouts </a></li>
<li class="chapter" data-level="12.3.13" data-path="12.3-multi-layer-perceptron-mlp.html"><a href="12.3-multi-layer-perceptron-mlp.html#batch-normalization"><i class="fa fa-check"></i><b>12.3.13</b> Batch Normalization </a></li>
<li class="chapter" data-level="12.3.14" data-path="12.3-multi-layer-perceptron-mlp.html"><a href="12.3-multi-layer-perceptron-mlp.html#optimization"><i class="fa fa-check"></i><b>12.3.14</b> Optimization </a></li>
<li class="chapter" data-level="12.3.15" data-path="12.3-multi-layer-perceptron-mlp.html"><a href="12.3-multi-layer-perceptron-mlp.html#interpretability"><i class="fa fa-check"></i><b>12.3.15</b> Interpretability</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="12.4-convolutional-neural-network-cnn.html"><a href="12.4-convolutional-neural-network-cnn.html"><i class="fa fa-check"></i><b>12.4</b> Convolutional Neural Network (CNN)  </a><ul>
<li class="chapter" data-level="12.4.1" data-path="12.4-convolutional-neural-network-cnn.html"><a href="12.4-convolutional-neural-network-cnn.html#computer-graphics"><i class="fa fa-check"></i><b>12.4.1</b> Computer Graphics</a></li>
<li class="chapter" data-level="12.4.2" data-path="12.4-convolutional-neural-network-cnn.html"><a href="12.4-convolutional-neural-network-cnn.html#convolution"><i class="fa fa-check"></i><b>12.4.2</b> Convolution </a></li>
<li class="chapter" data-level="12.4.3" data-path="12.4-convolutional-neural-network-cnn.html"><a href="12.4-convolutional-neural-network-cnn.html#stride-and-padding"><i class="fa fa-check"></i><b>12.4.3</b> Stride and Padding  </a></li>
<li class="chapter" data-level="12.4.4" data-path="12.4-convolutional-neural-network-cnn.html"><a href="12.4-convolutional-neural-network-cnn.html#kernels-and-filters"><i class="fa fa-check"></i><b>12.4.4</b> Kernels And Filters</a></li>
<li class="chapter" data-level="12.4.5" data-path="12.4-convolutional-neural-network-cnn.html"><a href="12.4-convolutional-neural-network-cnn.html#dilation"><i class="fa fa-check"></i><b>12.4.5</b> Dilation </a></li>
<li class="chapter" data-level="12.4.6" data-path="12.4-convolutional-neural-network-cnn.html"><a href="12.4-convolutional-neural-network-cnn.html#pooling"><i class="fa fa-check"></i><b>12.4.6</b> Pooling </a></li>
<li class="chapter" data-level="12.4.7" data-path="12.4-convolutional-neural-network-cnn.html"><a href="12.4-convolutional-neural-network-cnn.html#cnn-architectures"><i class="fa fa-check"></i><b>12.4.7</b> CNN Architectures</a></li>
<li class="chapter" data-level="12.4.8" data-path="12.4-convolutional-neural-network-cnn.html"><a href="12.4-convolutional-neural-network-cnn.html#forward-feed-1"><i class="fa fa-check"></i><b>12.4.8</b> Forward Feed </a></li>
<li class="chapter" data-level="12.4.9" data-path="12.4-convolutional-neural-network-cnn.html"><a href="12.4-convolutional-neural-network-cnn.html#backpropagation-1"><i class="fa fa-check"></i><b>12.4.9</b> BackPropagation </a></li>
<li class="chapter" data-level="12.4.10" data-path="12.4-convolutional-neural-network-cnn.html"><a href="12.4-convolutional-neural-network-cnn.html#optimization-1"><i class="fa fa-check"></i><b>12.4.10</b> Optimization</a></li>
<li class="chapter" data-level="12.4.11" data-path="12.4-convolutional-neural-network-cnn.html"><a href="12.4-convolutional-neural-network-cnn.html#normalization"><i class="fa fa-check"></i><b>12.4.11</b> Normalization</a></li>
<li class="chapter" data-level="12.4.12" data-path="12.4-convolutional-neural-network-cnn.html"><a href="12.4-convolutional-neural-network-cnn.html#step-decay"><i class="fa fa-check"></i><b>12.4.12</b> Step Decay</a></li>
<li class="chapter" data-level="12.4.13" data-path="12.4-convolutional-neural-network-cnn.html"><a href="12.4-convolutional-neural-network-cnn.html#gemm-matrix-multiplication"><i class="fa fa-check"></i><b>12.4.13</b> GEMM (Matrix Multiplication) </a></li>
<li class="chapter" data-level="12.4.14" data-path="12.4-convolutional-neural-network-cnn.html"><a href="12.4-convolutional-neural-network-cnn.html#depthwise-separable-convolution-dsc"><i class="fa fa-check"></i><b>12.4.14</b> Depthwise Separable Convolution (DSC)  </a></li>
<li class="chapter" data-level="12.4.15" data-path="12.4-convolutional-neural-network-cnn.html"><a href="12.4-convolutional-neural-network-cnn.html#cnn-implementation"><i class="fa fa-check"></i><b>12.4.15</b> CNN Implementation</a></li>
<li class="chapter" data-level="12.4.16" data-path="12.4-convolutional-neural-network-cnn.html"><a href="12.4-convolutional-neural-network-cnn.html#cnn-application"><i class="fa fa-check"></i><b>12.4.16</b> CNN Application</a></li>
<li class="chapter" data-level="12.4.17" data-path="12.4-convolutional-neural-network-cnn.html"><a href="12.4-convolutional-neural-network-cnn.html#summary-7"><i class="fa fa-check"></i><b>12.4.17</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="13-deeplearning2.html"><a href="13-deeplearning2.html"><i class="fa fa-check"></i><b>13</b> Computational Deep Learning II</a><ul>
<li class="chapter" data-level="13.1" data-path="13.1-residual-network-resnet.html"><a href="13.1-residual-network-resnet.html"><i class="fa fa-check"></i><b>13.1</b> Residual Network (ResNet)  </a></li>
<li class="chapter" data-level="13.2" data-path="13.2-recurrent-neural-network-rnn.html"><a href="13.2-recurrent-neural-network-rnn.html"><i class="fa fa-check"></i><b>13.2</b> Recurrent Neural Network (RNN)  </a><ul>
<li class="chapter" data-level="13.2.1" data-path="13.2-recurrent-neural-network-rnn.html"><a href="13.2-recurrent-neural-network-rnn.html#vanilla-rnn"><i class="fa fa-check"></i><b>13.2.1</b> Vanilla RNN</a></li>
<li class="chapter" data-level="13.2.2" data-path="13.2-recurrent-neural-network-rnn.html"><a href="13.2-recurrent-neural-network-rnn.html#long-short-term-memory-lstm"><i class="fa fa-check"></i><b>13.2.2</b> Long Short-Term Memory (LSTM)  </a></li>
<li class="chapter" data-level="13.2.3" data-path="13.2-recurrent-neural-network-rnn.html"><a href="13.2-recurrent-neural-network-rnn.html#gated-recurrent-units-gru"><i class="fa fa-check"></i><b>13.2.3</b> Gated Recurrent Units (GRU)  </a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="13.3-deep-stacked-rnn.html"><a href="13.3-deep-stacked-rnn.html"><i class="fa fa-check"></i><b>13.3</b> Deep Stacked RNN </a></li>
<li class="chapter" data-level="13.4" data-path="13.4-deep-stacked-bidirectional-rnn.html"><a href="13.4-deep-stacked-bidirectional-rnn.html"><i class="fa fa-check"></i><b>13.4</b> Deep Stacked Bidirectional RNN </a></li>
<li class="chapter" data-level="13.5" data-path="13.5-transformer-neural-network-tnn.html"><a href="13.5-transformer-neural-network-tnn.html"><i class="fa fa-check"></i><b>13.5</b> Transformer Neural Network (TNN)  </a><ul>
<li class="chapter" data-level="13.5.1" data-path="13.5-transformer-neural-network-tnn.html"><a href="13.5-transformer-neural-network-tnn.html#attention"><i class="fa fa-check"></i><b>13.5.1</b> Attention </a></li>
<li class="chapter" data-level="13.5.2" data-path="13.5-transformer-neural-network-tnn.html"><a href="13.5-transformer-neural-network-tnn.html#self-attention-and-trainability"><i class="fa fa-check"></i><b>13.5.2</b> Self-Attention and Trainability </a></li>
<li class="chapter" data-level="13.5.3" data-path="13.5-transformer-neural-network-tnn.html"><a href="13.5-transformer-neural-network-tnn.html#multi-head-attention"><i class="fa fa-check"></i><b>13.5.3</b> Multi-Head Attention </a></li>
<li class="chapter" data-level="13.5.4" data-path="13.5-transformer-neural-network-tnn.html"><a href="13.5-transformer-neural-network-tnn.html#word-embedding"><i class="fa fa-check"></i><b>13.5.4</b> Word Embedding </a></li>
<li class="chapter" data-level="13.5.5" data-path="13.5-transformer-neural-network-tnn.html"><a href="13.5-transformer-neural-network-tnn.html#positional-embedding"><i class="fa fa-check"></i><b>13.5.5</b> Positional Embedding </a></li>
<li class="chapter" data-level="13.5.6" data-path="13.5-transformer-neural-network-tnn.html"><a href="13.5-transformer-neural-network-tnn.html#sequence-alignment"><i class="fa fa-check"></i><b>13.5.6</b> Sequence Alignment</a></li>
<li class="chapter" data-level="13.5.7" data-path="13.5-transformer-neural-network-tnn.html"><a href="13.5-transformer-neural-network-tnn.html#transformer-architectures"><i class="fa fa-check"></i><b>13.5.7</b> Transformer Architectures </a></li>
</ul></li>
<li class="chapter" data-level="13.6" data-path="13.6-applications-using-tnn-and-rnn.html"><a href="13.6-applications-using-tnn-and-rnn.html"><i class="fa fa-check"></i><b>13.6</b> Applications using TNN (and RNN)</a><ul>
<li class="chapter" data-level="13.6.1" data-path="13.6-applications-using-tnn-and-rnn.html"><a href="13.6-applications-using-tnn-and-rnn.html#speech-recognition"><i class="fa fa-check"></i><b>13.6.1</b> Speech Recognition </a></li>
<li class="chapter" data-level="13.6.2" data-path="13.6-applications-using-tnn-and-rnn.html"><a href="13.6-applications-using-tnn-and-rnn.html#mel-coefficients-feature-extraction"><i class="fa fa-check"></i><b>13.6.2</b> Mel Coefficients (Feature Extraction) </a></li>
<li class="chapter" data-level="13.6.3" data-path="13.6-applications-using-tnn-and-rnn.html"><a href="13.6-applications-using-tnn-and-rnn.html#connectionist-temporal-classification-ctc"><i class="fa fa-check"></i><b>13.6.3</b> Connectionist Temporal Classification (CTC)  </a></li>
<li class="chapter" data-level="13.6.4" data-path="13.6-applications-using-tnn-and-rnn.html"><a href="13.6-applications-using-tnn-and-rnn.html#model-evaluation"><i class="fa fa-check"></i><b>13.6.4</b> Model Evaluation</a></li>
</ul></li>
<li class="chapter" data-level="13.7" data-path="13.7-generative-adversarial-network-gan.html"><a href="13.7-generative-adversarial-network-gan.html"><i class="fa fa-check"></i><b>13.7</b> Generative Adversarial Network (GAN)  </a></li>
<li class="chapter" data-level="13.8" data-path="13.8-deep-reinforcement-network-dqn.html"><a href="13.8-deep-reinforcement-network-dqn.html"><i class="fa fa-check"></i><b>13.8</b> Deep Reinforcement Network (DQN)  </a></li>
<li class="chapter" data-level="13.9" data-path="13.9-summary-8.html"><a href="13.9-summary-8.html"><i class="fa fa-check"></i><b>13.9</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="14-distributedcomputation.html"><a href="14-distributedcomputation.html"><i class="fa fa-check"></i><b>14</b> Distributed Computation</a><ul>
<li class="chapter" data-level="14.1" data-path="14.1-integration-and-interoperability.html"><a href="14.1-integration-and-interoperability.html"><i class="fa fa-check"></i><b>14.1</b> Integration and Interoperability</a></li>
<li class="chapter" data-level="14.2" data-path="14.2-ml-pipelines.html"><a href="14.2-ml-pipelines.html"><i class="fa fa-check"></i><b>14.2</b> ML Pipelines</a></li>
<li class="chapter" data-level="14.3" data-path="14.3-open-standards.html"><a href="14.3-open-standards.html"><i class="fa fa-check"></i><b>14.3</b> Open Standards</a><ul>
<li class="chapter" data-level="14.3.1" data-path="14.3-open-standards.html"><a href="14.3-open-standards.html#predictive-model-markup-language-pmml"><i class="fa fa-check"></i><b>14.3.1</b> Predictive Model Markup Language (PMML)</a></li>
<li class="chapter" data-level="14.3.2" data-path="14.3-open-standards.html"><a href="14.3-open-standards.html#portable-format-for-analytics-pfa"><i class="fa fa-check"></i><b>14.3.2</b> Portable Format for Analytics (PFA)</a></li>
<li class="chapter" data-level="14.3.3" data-path="14.3-open-standards.html"><a href="14.3-open-standards.html#open-neural-network-exchange-onnx"><i class="fa fa-check"></i><b>14.3.3</b> Open Neural Network Exchange (ONNX)</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="14.4-general-summary.html"><a href="14.4-general-summary.html"><i class="fa fa-check"></i><b>14.4</b> General Summary</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i>Appendix</a><ul>
<li class="chapter" data-level="" data-path="appendix-a.html"><a href="appendix-a.html"><i class="fa fa-check"></i>Appendix A</a><ul>
<li class="chapter" data-level="" data-path="appendix-a.html"><a href="appendix-a.html#trigonometry"><i class="fa fa-check"></i>Trigonometry</a></li>
<li class="chapter" data-level="" data-path="appendix-a.html"><a href="appendix-a.html#logarithms"><i class="fa fa-check"></i>Logarithms</a></li>
<li class="chapter" data-level="" data-path="appendix-a.html"><a href="appendix-a.html#category-theory"><i class="fa fa-check"></i>Category Theory</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-b.html"><a href="appendix-b.html"><i class="fa fa-check"></i>Appendix B</a><ul>
<li class="chapter" data-level="" data-path="appendix-b.html"><a href="appendix-b.html#on-random-chances"><i class="fa fa-check"></i>On Random chances</a></li>
<li class="chapter" data-level="" data-path="appendix-b.html"><a href="appendix-b.html#on-replacements"><i class="fa fa-check"></i>On Replacements</a></li>
<li class="chapter" data-level="" data-path="appendix-b.html"><a href="appendix-b.html#on-permutations-and-combinations"><i class="fa fa-check"></i>On Permutations and Combinations</a></li>
<li class="chapter" data-level="" data-path="appendix-b.html"><a href="appendix-b.html#on-conditional-probabilities"><i class="fa fa-check"></i>On Conditional Probabilities</a></li>
<li class="chapter" data-level="" data-path="appendix-b.html"><a href="appendix-b.html#the-arithmetic-of-probabilities"><i class="fa fa-check"></i>The Arithmetic of Probabilities</a></li>
<li class="chapter" data-level="" data-path="appendix-b.html"><a href="appendix-b.html#on-dependent-and-independent-events"><i class="fa fa-check"></i>On Dependent and Independent Events</a></li>
<li class="chapter" data-level="" data-path="appendix-b.html"><a href="appendix-b.html#on-mutual-exclusivity"><i class="fa fa-check"></i>On Mutual Exclusivity</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-c.html"><a href="appendix-c.html"><i class="fa fa-check"></i>Appendix C</a></li>
<li class="chapter" data-level="" data-path="appendix-d.html"><a href="appendix-d.html"><i class="fa fa-check"></i>Appendix D</a><ul>
<li class="chapter" data-level="" data-path="appendix-d.html"><a href="appendix-d.html#lubridate-library"><i class="fa fa-check"></i>Lubridate Library</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="bibliography.html"><a href="bibliography.html"><i class="fa fa-check"></i>Bibliography</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">The Power and Art of Approximation</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="distributiontypes" class="section level2 hasAnchor">
<h2><span class="header-section-number">5.9</span> Types of Distribution<a href="5.9-distributiontypes.html#distributiontypes" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Apart from summarizing data based on quantifying its moments (mean, variance, skewness, kurtosis), it helps characterize the <strong>distribution</strong> of data based on the geometric shape, size, and thickness of its tails. This section shows the <strong>PDF</strong> and <strong>CDF</strong> to describe the distribution. Here, we reference the great works of Walck C. <span class="citation">(<a href="bibliography.html#ref-ref685c">2007</a>)</span>, Press W.H et al. <span class="citation">(<a href="bibliography.html#ref-ref215w">2007</a>)</span>, pp. 321-339, Ross S. <span class="citation">(<a href="bibliography.html#ref-ref695s">2010</a>)</span>, Murphy K.P. <span class="citation">(<a href="bibliography.html#ref-ref224k">2012</a>)</span>, pp. 34-43, and McLaughlin M.P. <span class="citation">(<a href="bibliography.html#ref-ref705m">2016</a>)</span>.</p>
<p>Let us start with <strong>Bernoulli distribution</strong> - a single trial <strong>Binomial distribution</strong>. </p>
<div id="bernoulli-distribution" class="section level3 hasAnchor">
<h3><span class="header-section-number">5.9.1</span> Bernoulli distribution <a href="5.9-distributiontypes.html#bernoulli-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A <strong>Bernoulli distribution</strong>, named after <strong>Jacob Bernoulli</strong>, is a <strong>discrete</strong> probability distribution of a random variable taking a <strong>binary outcome</strong> which can be 0 or 1, true or false, head or tail of a coin, and is written as:</p>
<p><span class="math display" id="eq:equate1070047">\[\begin{align}
X \sim Bernoulli(\rho)\ \ \ or\ \ \ \ X \sim Ber(\rho) \tag{5.49} 
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(\rho\)</span> is the approximate probability of success</li>
<li><strong>X</strong> is the data (random variable).</li>
</ul>
<p>Here, we continue to emphasize the idea of approximation. We give two cases where we show approximation for random events.</p>
<p>For example, suppose we make a single attempt to toss a coin with an approximate 50% chance that the coin lands on heads. Here, we have a probability outcome denoted as <span class="math inline">\(\rho\)</span>. If <span class="math inline">\(\rho\)</span> is the probable outcome of the head, then <span class="math inline">\(q = 1 - \rho\)</span> is the probable outcome of tails.</p>
<p>Being a discrete distribution, the <strong>PMF</strong>, probability mass function, where <span class="math inline">\(\rho=0.50\)</span> is written as:</p>
<p><span class="math display" id="eq:eqnnumber17">\[\begin{align}
f(x) = 
\begin{cases}
\rho &amp; x = 1 \\
q = 1 - \rho &amp; x = 0
\end{cases} \tag{5.50}
\end{align}\]</span></p>
<p>which can also be written as:</p>
<p><span class="math display" id="eq:equate1070048">\[\begin{align}
f(x; \rho) = P(X=x|\rho) = \rho^xq^{1-x} = \rho^x(1-\rho)^{1-x} \tag{5.51} 
\end{align}\]</span></p>
<p>For another example, suppose we make just one attempt to roll a six-sided die with a 16% probability that it lands on one side with the number four. Here, let us use <span class="math inline">\(\mathbf{x=1}\)</span> if the die lands on number four, and <span class="math inline">\(\mathbf{x=0}\)</span> if the die lands on other numbers. Also, let us consider the following:</p>
<p><span class="math display">\[
\rho_{\{4\}} = 0.16\ \ \ \ \ \ \ \ q_{\{1,2,3,5,6\}} = 0.84
\]</span>
Using the equation, we get the following:</p>
<p><span class="math display">\[\begin{align*}
f(x; \rho) {}&amp;= P(X=x|\rho) = \rho^xq^{1-x} = \rho^x(1-\rho)^{1-x}\\
f(x=1; \rho=0.16) &amp;= P(X=1|\rho=0.16) = (0.16)^{1}(0.84)^{1-1} = 0.16\\
f(x=0; \rho=0.16) &amp;= P(X=0|\rho=0.16) = (0.16)^{0}(0.84)^{1-0} = 0.84\\
\end{align*}\]</span></p>
</div>
<div id="binomial-distribution" class="section level3 hasAnchor">
<h3><span class="header-section-number">5.9.2</span> Binomial distribution <a href="5.9-distributiontypes.html#binomial-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>On the other hand, a <strong>Binomial distribution</strong> is the sum of <strong>Bernoulli</strong> trials and is written as:</p>
<p><span class="math display" id="eq:equate1070049">\[\begin{align}
X \sim Bin(n, \rho) \tag{5.52} 
\end{align}\]</span></p>
<p>Note that a <strong>Bernoulli distribution</strong> is characterized by a single trial (n=1) and a <strong>Binomial distribution</strong> is characterized by multiple trials (n &gt; 1).</p>
<p>The <strong>PMF</strong> - probability mass function - for a <strong>discrete Binomial distribution</strong> is expressed as:</p>
<p><span class="math display" id="eq:equate1070050">\[\begin{align}
f(x; n, \rho)  = P(X = x|n,\rho) = \binom{n}{x}  \rho^xq^{n-x} = \binom{n}{x}  \rho^x(1-\rho)^{n-x} \tag{5.53} 
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li><strong>n</strong> is the number of independent trials (independent observations)</li>
<li><span class="math inline">\(\rho\)</span> is the probability of a state, e.g. probability of a coin landing on heads.</li>
<li><strong>X</strong> is data (random variable), where X <span class="math inline">\(\in\)</span> {0,1}.</li>
</ul>
<p>and:</p>
<p><span class="math display">\[
\binom{n}{x} = \frac{n!}{(n-x)!x!}\ \ \ \ \text{(this is a constant)}
\]</span></p>
<p>and:</p>
<p><span class="math display">\[
\rho^x(1-\rho)^{n-x}\ \ \ \ \ \text{(this describes the shape of curve)}
\]</span></p>
<p>The <strong>PMF</strong> is read as <strong>a function of random variable x with n and <span class="math inline">\(\rho\)</span> parameters.</strong></p>
<p>The <strong>CMF</strong> - cumulative mass function - for a <strong>discrete Binomial distribution</strong> is expressed as:</p>
<p><span class="math display" id="eq:equate1070051">\[\begin{align}
\mathcal{F}(x; n, \rho) = P( X \le x| n, \rho) = \sum_{k=0}^x \binom{n}{k}  \rho^k(1-\rho)^{n-k} \tag{5.54} 
\end{align}\]</span></p>
<p>Because <strong>Binomial distribution</strong> is discrete, we use summation instead of integration.</p>
<p>Note that we use the lowercase <strong>f</strong> function to indicate PDF/PMF for the rest of this section, and we use the uppercase <strong>F</strong> function to indicate CDF/CMF.</p>
<p>Now to illustrate, suppose we toss a coin ten times. Each time we toss, we record the outcome. In the end, we will be able to record ten outcomes of mixed tails and heads. However, there are two possibilities for each outcome: either a T or an H. Therefore, if we toss a coin ten times, the possible outcome would end up 2^10 = 1024 possible outcomes. That are many possibilities.</p>
<p>Let us try to visualize some of the combinations and see what the possible outcome of flipping an H is:</p>
<ul>
<li>Possibility that all ten flips end up to be Tails = 1 count out of 1024 possibilities</li>
</ul>
<p><span class="math display">\[
T T T T T T T T T T 
\]</span></p>
<ul>
<li>Possibility that all 10 flips end up to be Heads = 1 count out of 1024 possibilities</li>
</ul>
<p><span class="math display">\[
H H H H H H H H H H
\]</span></p>
<ul>
<li>Possibility that all 10 flips end up to be Tails except the first = 1 count / 1024</li>
</ul>
<p><span class="math display">\[
H T T T T T T T T T
\]</span></p>
<ul>
<li>Possibility that all 10 flips end up to be Tails except the second = 1 count / 1024</li>
</ul>
<p><span class="math display">\[
T H T T T T T T T T
\]</span></p>
<p>If we continue this, we will have to do it for all 1024 possibilities. Let us use combination formula:</p>

<p><span class="math display">\[\begin{align*}
P(Outcome = \ \ 0\ H) {}&amp; = nCr / 1024 = {}_{10}C_0 / 1024 = 1 / 1024\\
P(Outcome = \ \ 1\ H) &amp;= nCr / 1024 = {}_{10}C_1 / 1024 = 10 / 1024\\
P(Outcome = \ \ 2\ H) &amp;= nCr / 1024 = {}_{10}C_2 / 1024 = 45 / 1024\\
P(Outcome = \ \ 3\ H) &amp;= nCr / 1024 = {}_{10}C_3 / 1024 = 120 / 1024\\
P(Outcome = \ \ 4\ H) &amp;= nCr / 1024 = {}_{10}C_4 / 1024 = 210 / 1024\\
P(Outcome = \ \ 5\ H) &amp;= nCr / 1024 = {}_{10}C_5 / 1024 = 252 / 1024\\
P(Outcome = \ \ 6\ H) &amp;= nCr / 1024 = {}_{10}C_6 / 1024 = 210 / 1024\\
P(Outcome = \ \ 7\ H) &amp;= nCr / 1024 = {}_{10}C_7 / 1024 = 120 / 1024\\
P(Outcome = \ \ 8\ H) &amp;= nCr / 1024 = {}_{10}C_8 / 1024 = 45 / 1024\\
P(Outcome = \ \ 9\ H) &amp;= nCr / 1024 = {}_{10}C_9 / 1024 = 10 / 1024\\
P(Outcome = 10\ H) &amp;= nCr / 1024 = {}_{10}C_{10} / 1024 = 1 / 1024
\end{align*}\]</span>
</p>
<p>Now let us plot the distribution of these probable outcomes …</p>

<div class="sourceCode" id="cb220"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb220-1" data-line-number="1">random_x &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">10</span>,<span class="dv">45</span>,<span class="dv">120</span>,<span class="dv">210</span>,<span class="dv">252</span>,<span class="dv">210</span>,<span class="dv">120</span>,<span class="dv">45</span>,<span class="dv">10</span>,<span class="dv">1</span>) <span class="op">/</span><span class="st"> </span><span class="dv">1024</span></a>
<a class="sourceLine" id="cb220-2" data-line-number="2"><span class="kw">names</span>(random_x) &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">10</span>,<span class="dv">1</span>)</a>
<a class="sourceLine" id="cb220-3" data-line-number="3"><span class="kw">barplot</span>(random_x, <span class="dt">density=</span>T, <span class="dt">col=</span><span class="dv">2</span>, <span class="dt">xlab=</span><span class="st">&quot;H Outcome&quot;</span>,</a>
<a class="sourceLine" id="cb220-4" data-line-number="4">        <span class="dt">ylim=</span><span class="kw">range</span>(<span class="dv">0</span>, <span class="fl">0.25</span>), <span class="dt">xlim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="dv">12</span>),</a>
<a class="sourceLine" id="cb220-5" data-line-number="5">        <span class="dt">ylab=</span><span class="st">&quot;Probability&quot;</span>, <span class="dt">main=</span><span class="st">&quot;Flip A Fair Coin&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:statistics3"></span>
<img src="DS_files/figure-html/statistics3-1.png" alt="Statistics" width="70%" />
<p class="caption">
Figure 5.12: Statistics
</p>
</div>

<p>We can derive the same probability of a binomial case using the <strong>dbinom(.)</strong> function. For example, we can write the probability of getting two heads successfully out of 10 trials given a 0.20 probability threshold as:</p>
<div class="sourceCode" id="cb221"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb221-1" data-line-number="1"><span class="kw">dbinom</span>(<span class="dt">x =</span> <span class="dv">2</span>, <span class="dt">size=</span><span class="dv">10</span>, <span class="dt">prob=</span><span class="fl">0.20</span>)</a></code></pre></div>
<pre><code>## [1] 0.3019899</code></pre>
<p>For the expected value and variance of <strong>Binomial distribution</strong>, we use the following equations:</p>
<p><strong>Expected value:</strong></p>
<p><span class="math display" id="eq:equate1070053" id="eq:equate1070052">\[\begin{align}
\mathbb{E}(X) {}&amp;= \sum_{x=0}^{n} x(fx) = x \binom{n}{x}  p^n(1-p)^{n-x}  = np \tag{5.55} \\
\mathbb{E}(X^2) &amp;= \sum_{x=0}^{n} x^2(fx) = x^2 \binom{n}{x}  p^n(1-p)^{n-x}  
= n(n-1)p^2 + np \tag{5.56} 
\end{align}\]</span></p>
<p><strong>Variance:</strong></p>
<p><span class="math display" id="eq:equate1070054">\[\begin{align}
Var(X) = \mathbb{E}(X^2) - \mathbb{E}(X)^2 = 
\left[ n(n-1)p^2 + np \right] - (np)^2 = np(1-p) = npq \tag{5.57} 
\end{align}\]</span></p>
</div>
<div id="multinomial-distribution" class="section level3 hasAnchor">
<h3><span class="header-section-number">5.9.3</span> Multinomial distribution <a href="5.9-distributiontypes.html#multinomial-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A <strong>Multinomial distribution</strong>, also called <strong>Categorical distribution</strong>, models a <strong>discrete categorical</strong> probability distribution of a random variable taking an outcome with <strong>multiple categories</strong> which can be 0 to K states, e.g., a die has six possible states (or outcomes), and is written as:</p>
<p><span class="math display" id="eq:equate1070055">\[\begin{align}
X \sim Multi(n,\rho) \tag{5.58} 
\end{align}\]</span></p>
<p>The <strong>PMF</strong> for a <strong>Multinomial distribution</strong> is expressed as:</p>
<p><span class="math display" id="eq:equate1070057" id="eq:equate1070056">\[\begin{align}
f(x; n, \rho) = P(X= x|n, \rho) {}&amp;= 
\frac{n!}{x_1! \times ... \times x_k!} 
 \rho_1^{x_1} \times ... \times \rho_k^{x_k} \tag{5.59} \\
&amp;= \frac{n!}{\prod_{i=1}^k x_i!} \prod_{i=1}^k \rho_i^{x_i} \tag{5.60} 
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li><strong>n</strong> is the number of independent trials (independent observations)</li>
<li><span class="math inline">\(\rho\)</span> is the probability of a state, e.g., the probability of a die landing on 4.</li>
<li><span class="math inline">\(k\)</span> is the number of possible states (or outcomes), e.g., a die has six sides.</li>
<li><strong>X</strong> is a random variable with list of occurrences, e.g. X = ( <span class="math inline">\(x_1, x_2,..., x_k\)</span> )</li>
<li><span class="math inline">\(x_i\)</span> is the number of occurrences of a state (i); e.g. ‘x_1 = 3’ means there are three occurrences of drawing the first marble from an urn (assuming each marble is labeled with a number).</li>
<li><span class="math inline">\(\rho_i\)</span> is the probability of state (i), e.g., <span class="math inline">\(\rho_4 = 0.60\)</span> means a 60% probability of drawing the fourth marble from an urn (assuming each marble is labeled with a number).</li>
</ul>
<p>and:</p>
<p><span class="math display">\[
\frac{n!}{\prod_{i=1}^k x_i!}\ \ \ \ \  \ \text{( the number of possible arrangements)}
\]</span></p>
<p>Here are a few examples that allow a stochastic process to generate <strong>multinomial distribution</strong>:</p>
<ul>
<li>Probability of getting number 6 after rolling a 6-sided dice.</li>
<li>Probability of drawing a red marble out of 6 marbles from an urn.</li>
<li>Probability of drawing a blood type of ‘AB’ out of four blood types (e.g., O, A, B, AB) from a list of patients.</li>
</ul>
<p>To illustrate, let us use a typical example. Suppose we draw five marbles - with replacement - from an urn with four marbles - one red marble, two green marbles, and one blue marble. Let us calculate the probability of selecting two red and three green marbles.</p>
<p>We have the following:</p>
<ul>
<li><strong>n</strong> = 5 draws (trials)</li>
<li><strong>k</strong> = 3 states (red, green, blue)</li>
<li><strong>X</strong> = (2 red marbles, 3 green marbles, 0 blue marbles); <span class="math inline">\(x_1\)</span> = 2, <span class="math inline">\(x_2\)</span> = 3, <span class="math inline">\(x_3\)</span> = 0</li>
<li><span class="math inline">\(\rho\)</span> = probabilities: (<span class="math inline">\(1/4\)</span> red, <span class="math inline">\(2/4\)</span> green, <span class="math inline">\(1/4\)</span> blue); <span class="math inline">\(\rho_1\)</span> = 0.25, <span class="math inline">\(\rho_2\)</span> = 0.50, <span class="math inline">\(\rho_3\)</span> = 0.25</li>
</ul>
<p>Using the <strong>Multinomial distribution</strong> formula:</p>
<p><span class="math display">\[
f(x; n,p) = P(X= x|n,\rho) = \frac{5!}{2! \times 3! \times 0!} \times \left( 0.25^2 \times 0.50^3 \times 0.25^0  \right) 
\]</span>
let us implement in R code:</p>
<div class="sourceCode" id="cb223"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb223-1" data-line-number="1">multinomial.pdf &lt;-<span class="st"> </span><span class="cf">function</span>(x, n, p) {</a>
<a class="sourceLine" id="cb223-2" data-line-number="2">  ( <span class="kw">factorial</span>(n) <span class="op">/</span><span class="st"> </span><span class="kw">prod</span>(<span class="kw">factorial</span>(x)) ) <span class="op">*</span><span class="st"> </span><span class="kw">prod</span> ( p<span class="op">^</span>x )</a>
<a class="sourceLine" id="cb223-3" data-line-number="3">}</a>
<a class="sourceLine" id="cb223-4" data-line-number="4">n =<span class="st"> </span><span class="dv">5</span></a>
<a class="sourceLine" id="cb223-5" data-line-number="5">x =<span class="st"> </span><span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">0</span>)</a>
<a class="sourceLine" id="cb223-6" data-line-number="6">p =<span class="st"> </span><span class="kw">c</span>(<span class="fl">0.25</span>, <span class="fl">0.50</span>, <span class="fl">0.25</span>)</a>
<a class="sourceLine" id="cb223-7" data-line-number="7"><span class="kw">c</span>(<span class="st">&quot;probability&quot;</span>=<span class="kw">multinomial.pdf</span>(x, n, p))</a></code></pre></div>
<pre><code>## probability 
##    0.078125</code></pre>
<p>We can validate using a built-in R function called <strong>dmultinom()</strong>.</p>
<div class="sourceCode" id="cb225"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb225-1" data-line-number="1"><span class="kw">dmultinom</span>(x, <span class="dt">size=</span>n, <span class="dt">prob=</span>p)</a></code></pre></div>
<pre><code>## [1] 0.078125</code></pre>
</div>
<div id="geometric-distribution" class="section level3 hasAnchor">
<h3><span class="header-section-number">5.9.4</span> Geometric distribution <a href="5.9-distributiontypes.html#geometric-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Geometric distribution</strong> models a <strong>discrete distribution</strong> of a random variable <strong>X</strong>, considering the number of failed <strong>Bernoulli</strong> attempts prior to a successful one. It is written as:</p>
<p><span class="math display" id="eq:equate1070058">\[\begin{align}
X \sim Geo(\rho) \tag{5.61} 
\end{align}\]</span></p>
<p>The <strong>PMF</strong> for a <strong>Geometric distribution</strong> is expressed as:</p>
<p><span class="math display" id="eq:equate1070059">\[\begin{align}
f(x; \rho) = P(X=x|\rho) = q^{(x-1)}\rho = \rho(1-\rho)^{x-1} \tag{5.62} 
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(\rho\)</span> is the probability of success</li>
<li>q is the probability of failure (1-p)</li>
</ul>
<p>The <strong>CMF</strong> for a <strong>Geometric distribution</strong> is expressed as:</p>
<p><span class="math display" id="eq:eqnnumber18">\[\begin{align}
\mathcal{F}(x; \rho) = P(X \le x|\rho) = 
\begin{cases}
1 - (1-\rho)^{x} &amp; x \ge 0\\
0 &amp; x &lt; 0
\end{cases} \tag{5.63}
\end{align}\]</span></p>
<p>Note that other literature may have the following equations for geometric <strong>PDF</strong> and <strong>CDF</strong> respectively instead:</p>
<p><span class="math display" id="eq:equate1070060">\[\begin{align}
f(x; \rho)  = \rho(1-\rho)^{x}\ \ \ \ \ \ \ \ \
\mathcal{F}(x; \rho) = 1 - (1-\rho)^{x+1} \tag{5.64} 
\end{align}\]</span></p>
<p>To illustrate, in tossing a coin, compute for the probability that we miss the first four attempts before a successful fifth attempt, granting the probability of a successful attempt is 0.60.</p>
<p><span class="math display">\[
P(X = 5) = P(X \le 5)^{4}P(X=5) = (0.40)^3(0.60) = 0.01536
\]</span></p>
<p>where:</p>
<p><span class="math display">\[\begin{align*}
{}&amp;P(X \le 5)^4 \ \ \ \leftarrow\ \text{first four failed attempts}\\
&amp;P(X = 5) \ \ \ \leftarrow\ \text{fifth successful attempt}\\
\end{align*}\]</span></p>
<p>The <strong>expected value</strong> and <strong>variance</strong> is written respectively as:</p>
<p><span class="math display" id="eq:equate1070061">\[\begin{align}
\mathbb{E}(X) = 1/\rho\ \ \ \ \ \ \ \ \ \ \ Var(X) = \frac{q}{\rho^2} \tag{5.65} 
\end{align}\]</span></p>
</div>
<div id="beta-distribution" class="section level3 hasAnchor">
<h3><span class="header-section-number">5.9.5</span> Beta distribution <a href="5.9-distributiontypes.html#beta-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Beta distribution</strong> models a <strong>continuous distribution</strong> which is a special kind of <strong>Binomial distribution</strong> written as:</p>
<p><span class="math display" id="eq:equate1070062">\[\begin{align}
X \sim Beta(\alpha, \beta) \tag{5.66} 
\end{align}\]</span></p>
<p>with the following <strong>Beta PDF</strong> where <strong>support</strong> is <span class="math inline">\(0 \le x \le 1\)</span>:</p>
<p><span class="math display" id="eq:equate1070063">\[\begin{align}
f(x;\alpha,\beta) = P(X = x|\alpha,\beta)  = \frac{1}{\mathcal{B}(\alpha,\beta)} 
x ^{\alpha-1}(1-x)^{\beta - 1}  \tag{5.67} 
\end{align}\]</span></p>
<p>where <strong>Beta function</strong> has the following:</p>
<p><span class="math display" id="eq:equate1070065" id="eq:equate1070064">\[\begin{align}
\mathcal{B}(\alpha,\beta) {}&amp;= \int_0^1 x^{\alpha-1}(1-x)^{\beta-1}dx  \tag{5.68} \\
\mathcal{B}(\alpha,\beta) &amp;= \frac{\Gamma(\alpha)\Gamma(\beta)  }{\Gamma(\alpha + \beta) }  \tag{5.69} 
\end{align}\]</span></p>
<p>and where the <strong>Gamma function</strong> is as follows:</p>
<p><span class="math display" id="eq:equate1070066">\[\begin{align}
\Gamma(n) = (n-1)!\ \ \ \ \ \ \ \ \Gamma(n+1) = n\Gamma(n) = n(n-1)! \tag{5.70} 
\end{align}\]</span></p>
<p>On the other hand, the <strong>CDF</strong> of <strong>Beta distribution</strong> is expressed as:</p>
<p><span class="math display" id="eq:equate1070068" id="eq:equate1070067">\[\begin{align}
f(x;\alpha,\beta) {}&amp;= P(X \le x|\alpha,\beta) = \frac{1}{\mathcal{B}(\alpha,\beta)} 
\int_0^x x^{\alpha-1}(1-x)^{\beta - 1} dx \tag{5.71} \\
\nonumber \\
&amp;= I_x(\alpha,\beta) = \frac{B_x(x; \alpha, \beta)}{\mathcal{B}(\alpha,\beta)}. \tag{5.72} 
\end{align}\]</span></p>
<p>The <strong>CDF</strong> is a <strong>regularized beta function</strong> as introduced in the <strong>Special functions</strong> section.</p>
<p>Because <strong>Beta distribution</strong> is continuous, we use integration instead of summation (such as <strong>CMF</strong> for <strong>Binomial distribution</strong>).</p>
<p>Here is a naive implementation of <strong>PDF</strong> and <strong>CDF</strong> for <strong>Beta distribution</strong> with the different shapes, <span class="math inline">\(\{\alpha, \beta\}\)</span> (See also <strong>T-distribution</strong> in Chapter <strong>6</strong> (<strong>Statistical Computation</strong>) for an alternative implementation of <span class="math inline">\(\mathbf{Ix(\alpha,\beta)}\)</span>):</p>

<div class="sourceCode" id="cb227"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb227-1" data-line-number="1">Gamma &lt;-<span class="st"> </span><span class="cf">function</span>(n) { <span class="kw">factorial</span>(n<span class="dv">-1</span>)}</a>
<a class="sourceLine" id="cb227-2" data-line-number="2">B &lt;-<span class="st"> </span><span class="cf">function</span>(alpha, beta) { </a>
<a class="sourceLine" id="cb227-3" data-line-number="3">    <span class="co"># also can use built-in, beta(a,b)</span></a>
<a class="sourceLine" id="cb227-4" data-line-number="4">    (<span class="kw">Gamma</span>(alpha) <span class="op">*</span><span class="st"> </span><span class="kw">Gamma</span>(beta)) <span class="op">/</span><span class="st">  </span><span class="kw">Gamma</span>(alpha <span class="op">+</span><span class="st"> </span>beta )</a>
<a class="sourceLine" id="cb227-5" data-line-number="5">}</a>
<a class="sourceLine" id="cb227-6" data-line-number="6">incomplete_beta &lt;-<span class="st"> </span><span class="cf">function</span>(x,a,b) { </a>
<a class="sourceLine" id="cb227-7" data-line-number="7">    <span class="kw">pbeta</span>(x,a,b) <span class="op">*</span><span class="st"> </span><span class="kw">B</span>(a,b) </a>
<a class="sourceLine" id="cb227-8" data-line-number="8">}</a>
<a class="sourceLine" id="cb227-9" data-line-number="9">Ix &lt;-<span class="cf">function</span>(x, a, b) { <span class="co">#regulrized beta function, Ix(x; a, b)</span></a>
<a class="sourceLine" id="cb227-10" data-line-number="10">   <span class="kw">incomplete_beta</span>(x,a,b) <span class="op">/</span><span class="st"> </span><span class="kw">B</span>(a,b)</a>
<a class="sourceLine" id="cb227-11" data-line-number="11">}</a>
<a class="sourceLine" id="cb227-12" data-line-number="12">beta_pdf &lt;-<span class="st"> </span><span class="cf">function</span>(x, alpha, beta ) {</a>
<a class="sourceLine" id="cb227-13" data-line-number="13">   <span class="dv">1</span><span class="op">/</span><span class="kw">B</span>(alpha,beta) <span class="op">*</span><span class="st"> </span>( x<span class="op">^</span>(alpha<span class="dv">-1</span>) <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span><span class="op">-</span>x)<span class="op">^</span>(beta<span class="dv">-1</span>) )</a>
<a class="sourceLine" id="cb227-14" data-line-number="14">}</a>
<a class="sourceLine" id="cb227-15" data-line-number="15">beta_cdf &lt;-<span class="st"> </span><span class="cf">function</span>(x, alpha, beta ) {</a>
<a class="sourceLine" id="cb227-16" data-line-number="16">   <span class="kw">Ix</span>(x, alpha, beta)</a>
<a class="sourceLine" id="cb227-17" data-line-number="17">}</a>
<a class="sourceLine" id="cb227-18" data-line-number="18"></a>
<a class="sourceLine" id="cb227-19" data-line-number="19"><span class="co"># probability density</span></a>
<a class="sourceLine" id="cb227-20" data-line-number="20"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">1</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="dv">3</span>), </a>
<a class="sourceLine" id="cb227-21" data-line-number="21">     <span class="dt">xlab=</span><span class="st">&quot;support&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;probability density&quot;</span>,</a>
<a class="sourceLine" id="cb227-22" data-line-number="22">     <span class="dt">main=</span><span class="st">&quot;PDF (Beta Distribution)&quot;</span>,  <span class="dt">frame=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb227-23" data-line-number="23"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb227-24" data-line-number="24"><span class="kw">abline</span>(<span class="dt">h=</span><span class="dv">0</span>, <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb227-25" data-line-number="25">x =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>, <span class="dt">length.out=</span><span class="dv">20</span>)</a>
<a class="sourceLine" id="cb227-26" data-line-number="26"><span class="kw">curve</span>(<span class="kw">beta_pdf</span>(x, <span class="dt">alpha=</span><span class="dv">1</span>, <span class="dt">beta=</span><span class="dv">4</span>), <span class="dt">col=</span><span class="st">&quot;purple&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb227-27" data-line-number="27"><span class="kw">curve</span>(<span class="kw">beta_pdf</span>(x, <span class="dt">alpha=</span><span class="dv">2</span>, <span class="dt">beta=</span><span class="dv">2</span>), <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb227-28" data-line-number="28"><span class="kw">curve</span>(<span class="kw">beta_pdf</span>(x, <span class="dt">alpha=</span><span class="dv">2</span>, <span class="dt">beta=</span><span class="dv">4</span>), <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb227-29" data-line-number="29"><span class="kw">curve</span>(<span class="kw">beta_pdf</span>(x, <span class="dt">alpha=</span><span class="dv">5</span>, <span class="dt">beta=</span><span class="dv">1</span>), <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb227-30" data-line-number="30"><span class="kw">curve</span>(<span class="kw">beta_pdf</span>(x, <span class="dt">alpha=</span><span class="dv">5</span>, <span class="dt">beta=</span><span class="dv">3</span>), <span class="dt">col=</span><span class="st">&quot;brown&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:betadist1"></span>
<img src="DS_files/figure-html/betadist1-1.png" alt="Beta Distribution (Probability Density)" width="70%" />
<p class="caption">
Figure 5.13: Beta Distribution (Probability Density)
</p>
</div>
<div class="sourceCode" id="cb228"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb228-1" data-line-number="1"><span class="co"># cumulative density</span></a>
<a class="sourceLine" id="cb228-2" data-line-number="2"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">1</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="dv">1</span>), </a>
<a class="sourceLine" id="cb228-3" data-line-number="3">     <span class="dt">xlab=</span><span class="st">&quot;support&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;cumulative probability&quot;</span>,</a>
<a class="sourceLine" id="cb228-4" data-line-number="4">     <span class="dt">main=</span><span class="st">&quot;CDF (Beta Distribution)&quot;</span>,  <span class="dt">frame=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb228-5" data-line-number="5"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb228-6" data-line-number="6"><span class="kw">abline</span>(<span class="dt">h=</span><span class="dv">0</span>, <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb228-7" data-line-number="7">x =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>, <span class="dt">length.out=</span><span class="dv">20</span>)</a>
<a class="sourceLine" id="cb228-8" data-line-number="8"><span class="kw">curve</span>(<span class="kw">beta_cdf</span>(x, <span class="dt">alpha=</span><span class="dv">1</span>, <span class="dt">beta=</span><span class="dv">4</span>), <span class="dt">col=</span><span class="st">&quot;purple&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb228-9" data-line-number="9"><span class="kw">curve</span>(<span class="kw">beta_cdf</span>(x, <span class="dt">alpha=</span><span class="dv">2</span>, <span class="dt">beta=</span><span class="dv">2</span>), <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb228-10" data-line-number="10"><span class="kw">curve</span>(<span class="kw">beta_cdf</span>(x, <span class="dt">alpha=</span><span class="dv">2</span>, <span class="dt">beta=</span><span class="dv">4</span>), <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb228-11" data-line-number="11"><span class="kw">curve</span>(<span class="kw">beta_cdf</span>(x, <span class="dt">alpha=</span><span class="dv">5</span>, <span class="dt">beta=</span><span class="dv">1</span>), <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb228-12" data-line-number="12"><span class="kw">curve</span>(<span class="kw">beta_cdf</span>(x, <span class="dt">alpha=</span><span class="dv">5</span>, <span class="dt">beta=</span><span class="dv">3</span>), <span class="dt">col=</span><span class="st">&quot;brown&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:betadist2"></span>
<img src="DS_files/figure-html/betadist2-1.png" alt="Beta Distribution (Cumulative Density)" width="70%" />
<p class="caption">
Figure 5.14: Beta Distribution (Cumulative Density)
</p>
</div>

<p>Let us save further discussion of <strong>Beta distribution</strong> until we get to the <strong>Bayesian Computation</strong> to cover <strong>Conjugate and Joint distributions</strong> in which one distribution is chained to another.</p>
<p><span class="math display" id="eq:equate1070069">\[\begin{align}
X_{Pr} \sim Beta(\alpha, \beta)\ \ \ \rightarrow \ \ \ \ \ X \sim Bin(n, X_{Pr}) \tag{5.73} 
\end{align}\]</span></p>
<p>Also, we leave readers to investigate on <strong>Pert</strong> distribution which requires a minimum and a maximum parameter for <strong>Beta distribution</strong>:</p>
<p><span class="math display" id="eq:equate1070070">\[\begin{align}
X \sim Beta(min, max, \alpha, \beta) \equiv Pert(min, max, \alpha, \beta) \tag{5.74} 
\end{align}\]</span></p>
</div>
<div id="dirichlet-distribution" class="section level3 hasAnchor">
<h3><span class="header-section-number">5.9.6</span> Dirichlet distribution <a href="5.9-distributiontypes.html#dirichlet-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Dirichlet distribution</strong> models a <strong>continuous distribution</strong> and is a special kind of <strong>Multinomial distribution</strong> written as:</p>
<p><span class="math display" id="eq:equate1070071">\[\begin{align}
X_{Pr} \sim Dir(\alpha) \tag{5.75} 
\end{align}\]</span></p>
<p>Like dealing with <strong>Beta distribution</strong>, which is related to <strong>Binomial distribution</strong>, the <strong>Dirichlet distribution</strong> is related to <strong>Multinomial distribution</strong>.</p>
<p>The <strong>PDF</strong> for <strong>Dirichlet distribution</strong> with <strong>support</strong> <span class="math inline">\(\{x_1,..., x_k\}\)</span> and <span class="math inline">\(0 \le x_i \le 1\)</span> and <span class="math inline">\(\sum(X) = 1\)</span> is expressed as:</p>
<p><span class="math display" id="eq:equate1070072">\[\begin{align}
f(X_k;\alpha_k) = P(x_1,...,x_k|\alpha_1, ... \alpha_k)  = \frac{1}{\mathcal{B}(\alpha)}
\prod_{i=1}^k {x_i}^{\alpha_i-1}  \tag{5.76} 
\end{align}\]</span></p>
<p>where the <strong>Beta function</strong>, <span class="math inline">\(\mathbf{\mathcal{B}(\vec{\alpha})}\)</span>, is equivalent to that of <strong>Beta distribution</strong> :</p>
<p><span class="math display" id="eq:equate1070073">\[\begin{align}
\mathcal{B}(\alpha) &amp;= \frac{\prod_{i=1}^k \Gamma(\alpha_i)} {\Gamma(\sum_{i=1}^k \alpha_i)}
\ \ \ \ \ \ \leftarrow\ \ \ \ \ \ \ \ 
\mathcal{B}(\alpha_1, \alpha_2) = \frac{\Gamma(\alpha_1)\Gamma(\alpha_2)}{\Gamma(\alpha_1 + \alpha_2)}
\ \ \ \ \text{if k=2} \tag{5.77} 
\end{align}\]</span></p>
<p>and where the <strong>Gamma function</strong> is as follows:</p>
<p><span class="math display" id="eq:equate1070074">\[\begin{align}
\Gamma(n) = (n-1)!\ \ \ \ \ \ \ \ \Gamma(n+1) = n\Gamma(n) = n(n-1)! \tag{5.78} 
\end{align}\]</span></p>
<p>Note that <strong>Dirichlet distribution</strong> is a generalization of <strong>Beta distribution</strong>.</p>
<p>To illustrate, we can continue to use <strong>Dirichlet PDF</strong> against <strong>Binomial distribution</strong> where <span class="math inline">\(\{\alpha,\beta\} = \{ \alpha, \alpha \} = \{\vec{ \alpha} \}\)</span></p>
<p>Figure <a href="5.9-distributiontypes.html#fig:betadist1">5.13</a> illustrates graphs of the different shapes, <span class="math inline">\(\{\vec{ \alpha} \}\)</span>, of <strong>Dirichlet distribution</strong>.</p>

<div class="sourceCode" id="cb229"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb229-1" data-line-number="1">Gamma &lt;-<span class="st"> </span><span class="cf">function</span>(n) { <span class="kw">factorial</span>(n<span class="dv">-1</span>)}</a>
<a class="sourceLine" id="cb229-2" data-line-number="2">dirichlet_B &lt;-<span class="st"> </span><span class="cf">function</span>(alpha) { </a>
<a class="sourceLine" id="cb229-3" data-line-number="3">    <span class="kw">prod</span>(<span class="kw">Gamma</span>(alpha)) <span class="op">/</span><span class="st"> </span><span class="kw">Gamma</span>( <span class="kw">sum</span> (alpha))  </a>
<a class="sourceLine" id="cb229-4" data-line-number="4">}</a>
<a class="sourceLine" id="cb229-5" data-line-number="5">dirichlet_pdf &lt;-<span class="st"> </span><span class="cf">function</span>(x, alpha) { <span class="co"># naive implementation</span></a>
<a class="sourceLine" id="cb229-6" data-line-number="6">  <span class="co"># using binomial distribution, e.g. x (%success), 1-x (%fail)</span></a>
<a class="sourceLine" id="cb229-7" data-line-number="7">   <span class="dv">1</span><span class="op">/</span><span class="kw">dirichlet_B</span>(alpha) <span class="op">*</span><span class="st"> </span>( x<span class="op">^</span>(alpha[<span class="dv">1</span>]<span class="op">-</span><span class="dv">1</span>) <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span><span class="op">-</span>x)<span class="op">^</span>(alpha[<span class="dv">2</span>]<span class="op">-</span><span class="dv">1</span>) )</a>
<a class="sourceLine" id="cb229-8" data-line-number="8">}</a>
<a class="sourceLine" id="cb229-9" data-line-number="9"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">1</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="dv">3</span>), </a>
<a class="sourceLine" id="cb229-10" data-line-number="10">     <span class="dt">xlab=</span><span class="st">&quot;support&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;probability density&quot;</span>,</a>
<a class="sourceLine" id="cb229-11" data-line-number="11">     <span class="dt">main=</span><span class="st">&quot;PDF (Dirichlet Distribution)&quot;</span>,  <span class="dt">frame=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb229-12" data-line-number="12"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb229-13" data-line-number="13"><span class="kw">abline</span>(<span class="dt">h=</span><span class="dv">0</span>, <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb229-14" data-line-number="14">x =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>, <span class="dt">length.out=</span><span class="dv">20</span>)</a>
<a class="sourceLine" id="cb229-15" data-line-number="15"><span class="kw">curve</span>(<span class="kw">dirichlet_pdf</span>(x, <span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">4</span>)), <span class="dt">col=</span><span class="st">&quot;purple&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb229-16" data-line-number="16"><span class="kw">curve</span>(<span class="kw">dirichlet_pdf</span>(x, <span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>)), <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb229-17" data-line-number="17"><span class="kw">curve</span>(<span class="kw">dirichlet_pdf</span>(x, <span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">4</span>)), <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb229-18" data-line-number="18"><span class="kw">curve</span>(<span class="kw">dirichlet_pdf</span>(x, <span class="kw">c</span>(<span class="dv">5</span>,<span class="dv">1</span>)), <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb229-19" data-line-number="19"><span class="kw">curve</span>(<span class="kw">dirichlet_pdf</span>(x, <span class="kw">c</span>(<span class="dv">5</span>,<span class="dv">3</span>)), <span class="dt">col=</span><span class="st">&quot;brown&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:dirichletdist"></span>
<img src="DS_files/figure-html/dirichletdist-1.png" alt="Dirichlet Distribution" width="70%" />
<p class="caption">
Figure 5.15: Dirichlet Distribution
</p>
</div>

<p>Similarly, we further cover <strong>Dirichlet distribution</strong> in Chapter <strong>7</strong> (<strong>Bayesian Computation I</strong>) when discussing <strong>Conjugate distribution</strong>. Also, the idea is about one distribution in which the parameters are based on the outcome of another distribution.</p>
<p><span class="math display" id="eq:equate1070075">\[\begin{align}
X \sim Mult(n, \rho)\ \ \ \leftarrow \ \ \ \  \  \rho \sim Dir(\alpha) \tag{5.79} 
\end{align}\]</span></p>
</div>
<div id="exponential-distribution" class="section level3 hasAnchor">
<h3><span class="header-section-number">5.9.7</span> Exponential distribution <a href="5.9-distributiontypes.html#exponential-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Exponential distribution</strong> models a <strong>continuous distribution</strong> of a random variable <strong>X</strong>, taking into account the <strong>waiting (or elapsed) time</strong> between events. It is written as:</p>
<p><span class="math display" id="eq:equate1070076">\[\begin{align}
X \sim Expo(\lambda) \tag{5.80} 
\end{align}\]</span></p>
<p>The <strong>PDF</strong> of an <strong>Exponential distribution</strong> has the <strong>support</strong> condition:</p>
<p><span class="math display" id="eq:eqnnumber19">\[\begin{align}
f(x;\lambda) = \begin{cases} \lambda e^{-\lambda x} &amp; x \ge 0\\ 0 &amp; x &lt; 0 \end{cases}. \tag{5.81}
\end{align}\]</span></p>
<p>Therefore, with <strong>support</strong> <span class="math inline">\(0 \le x \le \infty\)</span>, we get:</p>
<p><span class="math display" id="eq:equate1070077">\[\begin{align}
 P(X = x|\lambda) =  \lambda e^{-\lambda x} \tag{5.82} 
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(\lambda\)</span> is a shape parameter describing event rate, <span class="math inline">\(\lambda = 1/t\)</span>, e.g. 1 event per avg. time.</li>
<li>t is the average wait time (or average elapsed time prior to an event occurring)</li>
</ul>
<p>and the <strong>CDF</strong> of an <strong>Exponential distribution</strong> is expressed as:</p>
<p><span class="math display" id="eq:equate1070078">\[\begin{align}
\mathcal{F}(x; \lambda) = P(X \le x|\lambda) =  1 - e^{-\lambda x} \tag{5.83} 
\end{align}\]</span></p>
<p>Exponential growth and decay are two typical events in which we can use <strong>Exponential distribution</strong> to measure the expected time. To illustrate, here are three examples of events in which we can form an <strong>Exponential distribution</strong>:</p>
<ul>
<li>Suppose we plant a pumpkin seed about an inch into fertile soil. Then, we compute the time it takes for the seed to germinate. Hint: does a pumpkin seed germinate in a week?</li>
<li>Suppose we procure a piece of enterprise-grade computer equipment. Then, we compute the time it takes before the equipment starts to fail. Hint: does it take three to five years for equipment support to expire?</li>
<li>Suppose we arrive at a gas station but have to wait for our turn to fill up gas. Then, we compute the time it takes to wait.</li>
</ul>
<p>Here, <span class="math inline">\(\lambda\)</span> (lambda) is the expected time for events to occur. It answers the question: <strong>How long?</strong></p>
<p>Below is a naive implementation of <strong>PDF</strong> and <strong>CDF</strong> of <strong>Exponential distribution</strong> in R code. Here we use <span class="math inline">\(\lambda = 0.5\)</span> and <span class="math inline">\(x = 4\)</span> to show a larger area. See Figure <a href="5.9-distributiontypes.html#fig:expdist2">5.17</a>.</p>

<div class="sourceCode" id="cb230"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb230-1" data-line-number="1">exp_pdf &lt;-<span class="st"> </span><span class="cf">function</span>(x, lambda ) {</a>
<a class="sourceLine" id="cb230-2" data-line-number="2">    lambda <span class="op">*</span><span class="st"> </span><span class="kw">exp</span>(<span class="op">-</span>lambda <span class="op">*</span><span class="st"> </span>x)</a>
<a class="sourceLine" id="cb230-3" data-line-number="3">}</a>
<a class="sourceLine" id="cb230-4" data-line-number="4">exp_cdf &lt;-<span class="st"> </span><span class="cf">function</span>(x, lambda) {</a>
<a class="sourceLine" id="cb230-5" data-line-number="5">    <span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">exp</span>(<span class="op">-</span>lambda <span class="op">*</span><span class="st"> </span>x)</a>
<a class="sourceLine" id="cb230-6" data-line-number="6">}</a>
<a class="sourceLine" id="cb230-7" data-line-number="7">exp_area &lt;-<span class="st"> </span><span class="cf">function</span>(x, lambda) {</a>
<a class="sourceLine" id="cb230-8" data-line-number="8">    a =<span class="st"> </span><span class="dv">0</span>; b =<span class="st"> </span>x  <span class="co"># boundaries</span></a>
<a class="sourceLine" id="cb230-9" data-line-number="9">    area =<span class="st"> </span><span class="kw">seq</span>(a, b, <span class="dt">length.out=</span><span class="dv">50</span>) <span class="co"># area</span></a>
<a class="sourceLine" id="cb230-10" data-line-number="10">    x =<span class="st"> </span><span class="kw">c</span>(a, area , b)</a>
<a class="sourceLine" id="cb230-11" data-line-number="11">    y =<span class="st"> </span><span class="kw">c</span>(<span class="dv">0</span>, <span class="kw">exp_pdf</span>(area, lambda), <span class="dv">0</span>)</a>
<a class="sourceLine" id="cb230-12" data-line-number="12">    <span class="kw">polygon</span>(x, y, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>)    </a>
<a class="sourceLine" id="cb230-13" data-line-number="13">}</a>
<a class="sourceLine" id="cb230-14" data-line-number="14"><span class="co">#Plotting PDF and CDF (Area for lambda=0.5)</span></a>
<a class="sourceLine" id="cb230-15" data-line-number="15"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">5</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="fl">2.0</span>), </a>
<a class="sourceLine" id="cb230-16" data-line-number="16">     <span class="dt">xlab=</span><span class="st">&quot;support&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;probability density&quot;</span>,</a>
<a class="sourceLine" id="cb230-17" data-line-number="17">     <span class="dt">main=</span><span class="st">&quot;PDF (Exponential Distribution)&quot;</span>,  <span class="dt">frame=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb230-18" data-line-number="18"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb230-19" data-line-number="19"><span class="kw">abline</span>(<span class="dt">h=</span><span class="dv">0</span>, <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb230-20" data-line-number="20">p =<span class="st"> </span><span class="kw">exp_cdf</span>(<span class="dt">x=</span><span class="dv">4</span>, <span class="dt">lambda=</span><span class="fl">0.5</span>)</a>
<a class="sourceLine" id="cb230-21" data-line-number="21"><span class="kw">exp_area</span>(<span class="dt">x=</span><span class="dv">4</span>, <span class="dt">lambda=</span><span class="fl">0.5</span>)</a>
<a class="sourceLine" id="cb230-22" data-line-number="22"><span class="kw">curve</span>(<span class="kw">exp_pdf</span>(x, <span class="dt">lambda=</span><span class="fl">0.5</span>), <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb230-23" data-line-number="23"><span class="kw">curve</span>(<span class="kw">exp_pdf</span>(x, <span class="dt">lambda=</span><span class="fl">1.0</span>), <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb230-24" data-line-number="24"><span class="kw">curve</span>(<span class="kw">exp_pdf</span>(x, <span class="dt">lambda=</span><span class="fl">1.5</span>), <span class="dt">col=</span><span class="st">&quot;brown&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb230-25" data-line-number="25"><span class="kw">curve</span>(<span class="kw">exp_pdf</span>(x, <span class="dt">lambda=</span><span class="fl">2.0</span>), <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb230-26" data-line-number="26"><span class="kw">text</span>(<span class="dv">3</span>,<span class="fl">0.3</span>, <span class="dt">label=</span><span class="kw">expression</span>(<span class="kw">paste</span>(<span class="st">&quot;pdf=&quot;</span>, lambda <span class="op">*</span><span class="st"> </span>e<span class="op">^</span>(<span class="op">-</span>lambda <span class="op">*</span><span class="st"> </span>x))))</a>
<a class="sourceLine" id="cb230-27" data-line-number="27"><span class="kw">text</span>(<span class="fl">0.6</span>, <span class="fl">0.2</span>, <span class="dt">label=</span><span class="st">&quot;(cdf)&quot;</span>, <span class="dt">col=</span><span class="st">&quot;black&quot;</span>)</a>
<a class="sourceLine" id="cb230-28" data-line-number="28"><span class="kw">text</span>(<span class="fl">0.7</span>, <span class="fl">0.1</span>, <span class="dt">label=</span><span class="kw">paste</span>(<span class="st">&quot;Area = &quot;</span>, <span class="kw">round</span>(p,<span class="dv">5</span>), <span class="dt">sep=</span><span class="st">&quot;&quot;</span>), </a>
<a class="sourceLine" id="cb230-29" data-line-number="29">     <span class="dt">ce=</span><span class="dv">1</span>, <span class="dt">col=</span><span class="st">&quot;black&quot;</span>)</a>
<a class="sourceLine" id="cb230-30" data-line-number="30"><span class="kw">text</span>(<span class="fl">4.2</span>, <span class="fl">0.12</span>, <span class="dt">label=</span><span class="st">&quot;x=4&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:expdist1"></span>
<img src="DS_files/figure-html/expdist1-1.png" alt="Exponential Distribution (PDF)" width="70%" />
<p class="caption">
Figure 5.16: Exponential Distribution (PDF)
</p>
</div>
<div class="sourceCode" id="cb231"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb231-1" data-line-number="1"><span class="co">#Plotting CDF </span></a>
<a class="sourceLine" id="cb231-2" data-line-number="2"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">5</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="fl">1.0</span>), </a>
<a class="sourceLine" id="cb231-3" data-line-number="3">     <span class="dt">xlab=</span><span class="st">&quot;support&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;cumulative density&quot;</span>,</a>
<a class="sourceLine" id="cb231-4" data-line-number="4">     <span class="dt">main=</span><span class="st">&quot;CDF (Exponential Distribution)&quot;</span>,  <span class="dt">frame=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb231-5" data-line-number="5"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb231-6" data-line-number="6"><span class="kw">abline</span>(<span class="dt">h=</span><span class="dv">0</span>, <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb231-7" data-line-number="7">x =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">5</span>, <span class="dt">length.out=</span><span class="dv">500</span>)</a>
<a class="sourceLine" id="cb231-8" data-line-number="8"><span class="kw">curve</span>(<span class="kw">exp_cdf</span>(x, <span class="dt">lambda=</span><span class="fl">0.5</span>), <span class="dt">col=</span><span class="st">&quot;brown&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb231-9" data-line-number="9"><span class="kw">curve</span>(<span class="kw">exp_cdf</span>(x, <span class="dt">lambda=</span><span class="fl">1.0</span>), <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb231-10" data-line-number="10"><span class="kw">curve</span>(<span class="kw">exp_cdf</span>(x, <span class="dt">lambda=</span><span class="fl">1.5</span>), <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb231-11" data-line-number="11"><span class="kw">curve</span>(<span class="kw">exp_cdf</span>(x, <span class="dt">lambda=</span><span class="fl">2.0</span>), <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:expdist2"></span>
<img src="DS_files/figure-html/expdist2-1.png" alt="Exponential Distribution (CDF)" width="70%" />
<p class="caption">
Figure 5.17: Exponential Distribution (CDF)
</p>
</div>

<p>To illustrate further, let us use one of the examples given. Suppose we wait to fill up gas at a gas station. Let us compute the probability of waiting for less than 5 minutes given that <span class="math inline">\(\lambda = 1/2\)</span>. That gives us the following problem statement:</p>
<p><span class="math display" id="eq:equate1070079">\[\begin{align}
P(X \le x) = P(X \le 5) = 1 - e^{-\lambda x} \tag{5.84} 
\end{align}\]</span></p>
<p>were average time to wait = 2 minutes.</p>
<p>Here is the implementation of <strong>CDF</strong> in R code:</p>

<div class="sourceCode" id="cb232"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb232-1" data-line-number="1"><span class="kw">sum</span> ( <span class="kw">exp_cdf</span>(<span class="dt">x=</span><span class="kw">c</span>(<span class="dv">4</span>),<span class="dt">lambda=</span><span class="fl">0.5</span>) )  <span class="co"># our code</span></a></code></pre></div>
<pre><code>## [1] 0.8646647</code></pre>
<div class="sourceCode" id="cb234"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb234-1" data-line-number="1">(<span class="dt">p =</span> <span class="kw">sum</span>(<span class="kw">pexp</span>(<span class="dt">q=</span><span class="kw">c</span>(<span class="dv">4</span>), <span class="dt">rate=</span><span class="fl">0.5</span>))) <span class="co"># R&#39;s built-in package</span></a></code></pre></div>
<pre><code>## [1] 0.8646647</code></pre>

<p>Both outcomes give around 86.47% probability for us to wait for 4 minutes only.</p>
<p>On the other hand, if the average wait time is 10 minutes instead. Then we get:</p>

<div class="sourceCode" id="cb236"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb236-1" data-line-number="1"><span class="kw">sum</span> ( <span class="kw">exp_cdf</span>(<span class="dt">x=</span><span class="kw">c</span>(<span class="dv">4</span>),<span class="dt">lambda=</span><span class="fl">0.2</span>) )  <span class="co"># our code</span></a></code></pre></div>
<pre><code>## [1] 0.550671</code></pre>
<div class="sourceCode" id="cb238"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb238-1" data-line-number="1">(<span class="dt">p =</span> <span class="kw">sum</span>(<span class="kw">pexp</span>(<span class="dt">q=</span><span class="kw">c</span>(<span class="dv">4</span>), <span class="dt">rate=</span><span class="fl">0.2</span>))) <span class="co"># R&#39;s built-in package</span></a></code></pre></div>
<pre><code>## [1] 0.550671</code></pre>

<p>Both outcomes give around 55.07% probability for us to wait for 4 minutes only.</p>
<p>In terms of expected value and variance, we have the following expression:</p>
<p><strong>Expected value</strong>:</p>
<p><span class="math display" id="eq:equate1070080">\[\begin{align}
\mathbb{E}(X) = \int_0^\infty x\lambda e^{-\lambda x} dx = 
\left[\frac{e^{-\lambda x}}{\lambda}\right]_0^\infty =
\frac{1}{\lambda} \tag{5.85} 
\end{align}\]</span></p>
<p><strong>Variance:</strong></p>
<p><span class="math display" id="eq:equate1070081">\[\begin{align}
Var(X) = \mathbb{E}({X}^2) - \mathbb{E}(X)^2 
= \frac{2}{\lambda^2} - \frac{1}{\lambda^2} = \frac{1}{\lambda^2} \tag{5.86} 
\end{align}\]</span></p>
<p>We now discuss the next type of distribution - the <strong>Gamma distribution</strong>. It is notable to mention that <strong>Exponential distribution</strong> and <strong>Gamma distribution</strong> are somewhat related. While <strong>Exponential distribution</strong> is about <strong>waiting time</strong> between events of interest, <strong>Gamma distribution</strong> is <strong>waiting time</strong> taken for <strong>number of events</strong>.</p>
</div>
<div id="gamma-distribution" class="section level3 hasAnchor">
<h3><span class="header-section-number">5.9.8</span> Gamma distribution <a href="5.9-distributiontypes.html#gamma-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Gamma distribution</strong> models a <strong>continuous distribution</strong> of a random variable <strong>X</strong> taking into account the number of events that occurred after <strong>wait (or elapse) time</strong> and is written as:</p>
<p><span class="math display" id="eq:equate1070082">\[\begin{align}
X \sim Gamma(\alpha, \beta)\ \ \ \ or\ \ \ \ \ X \sim \Gamma(\alpha, \beta)  \tag{5.87} 
\end{align}\]</span></p>
<p>Any queueing system involving wait times or any events that can be measured in terms of elapsed time are two common examples in which using <strong>Gamma distribution</strong> is helpful.
The <strong>PDF</strong> of a <strong>Gamma distribution</strong> with <strong>support</strong> <span class="math inline">\(x \ge 0\)</span> is expressed as:</p>
<p><span class="math display" id="eq:equate1070083">\[\begin{align}
f(x; \alpha,\beta) = P(X = x|\alpha, \beta) =  \frac{1}{\beta^{\alpha}\Gamma(\alpha)}x^{\alpha-1}e^{-\frac{x}{\beta}} =
\frac{\beta^{\alpha}}{\Gamma(\alpha)}x^{\alpha-1}e^{-\beta x} \tag{5.88} 
\end{align}\]</span></p>
<p>where the <strong>Gamma function</strong> is expressed as:</p>
<p><span class="math display" id="eq:equate1070086" id="eq:equate1070085" id="eq:equate1070084">\[\begin{align}
\Gamma(\alpha) {}&amp;= \int_0^\infty x^{\alpha-1} e^{-x} dx  \tag{5.89} \\
\Gamma(n) &amp;= (n-1)!  \tag{5.90} \\
\Gamma(n+1) &amp;= n\Gamma(n) = n(n-1)! \tag{5.91} 
\end{align}\]</span></p>
<p>also where:</p>
<ul>
<li><span class="math inline">\(\alpha\)</span> is the number of events that occurred</li>
<li><span class="math inline">\(\beta\)</span> is the average number of events per time. It is equivalent to <span class="math inline">\(1/\lambda\)</span> in which <span class="math inline">\(\lambda\)</span> denotes the average time between events.</li>
</ul>
<p>The inverse of <strong>Gamma distribution</strong> is expressed as:</p>
<p><span class="math display" id="eq:equate1070087">\[\begin{align}
g(x; \alpha,\beta) = P(X = x|\alpha, \beta) = 
\frac{\beta^{\alpha}}{\Gamma(\alpha)}x^{-(\alpha+1)}e^{-\frac{\beta}{ x}}\ \ \text{(inverse)} \tag{5.92} 
\end{align}\]</span></p>
<p>Note that if the average time between events (e.g. bathroom breaks) is two hours <span class="math inline">\(\rightarrow \lambda = 2\ hrs\)</span>, then <span class="math inline">\(\beta = 1/2 = 0.5\)</span>.</p>
<p>The <strong>CDF</strong> of a <strong>Gamma distribution</strong> where <span class="math inline">\(x \ge 0\)</span> is expressed as:</p>
<p><span class="math display" id="eq:equate1070088">\[\begin{align}
\mathcal{F}(x; \alpha, \beta) = P(X \le x|\alpha, \beta) = 1 - \sum_{i=0}^{\alpha-1} \frac{(\lambda x)^i}{i!}e^{-\lambda x}  \tag{5.93} 
\end{align}\]</span></p>
<p>Below is a naive implementation of <strong>Gamma Distribution</strong> in R code:</p>

<div class="sourceCode" id="cb240"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb240-1" data-line-number="1">Gamma &lt;-<span class="st"> </span><span class="cf">function</span>(n) { <span class="kw">factorial</span>(n<span class="dv">-1</span>)}</a>
<a class="sourceLine" id="cb240-2" data-line-number="2">gamma_pdf &lt;-<span class="st"> </span><span class="cf">function</span>(x, alpha, beta ) {</a>
<a class="sourceLine" id="cb240-3" data-line-number="3">    <span class="dv">1</span> <span class="op">/</span><span class="st"> </span>(beta <span class="op">^</span>alpha <span class="op">*</span><span class="st"> </span><span class="kw">Gamma</span>(alpha)) <span class="op">*</span><span class="st"> </span>x<span class="op">^</span>(alpha <span class="op">-</span><span class="st"> </span><span class="dv">1</span>) <span class="op">*</span><span class="st"> </span><span class="kw">exp</span>(<span class="op">-</span>x<span class="op">/</span>beta)</a>
<a class="sourceLine" id="cb240-4" data-line-number="4">}</a>
<a class="sourceLine" id="cb240-5" data-line-number="5">gamma_cdf &lt;-<span class="st"> </span><span class="cf">function</span>(x, alpha, beta) {</a>
<a class="sourceLine" id="cb240-6" data-line-number="6">    constant =<span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb240-7" data-line-number="7">    lambda =<span class="st"> </span><span class="dv">1</span><span class="op">/</span>beta</a>
<a class="sourceLine" id="cb240-8" data-line-number="8">    <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">0</span><span class="op">:</span>(alpha<span class="dv">-1</span>)) { </a>
<a class="sourceLine" id="cb240-9" data-line-number="9">      constant =<span class="st"> </span>constant <span class="op">+</span><span class="st"> </span>((lambda<span class="op">*</span>x)<span class="op">^</span>i)<span class="op">/</span><span class="kw">factorial</span>(i)<span class="op">*</span><span class="kw">exp</span>(<span class="op">-</span>lambda<span class="op">*</span>x)</a>
<a class="sourceLine" id="cb240-10" data-line-number="10">    }</a>
<a class="sourceLine" id="cb240-11" data-line-number="11">    <span class="dv">1</span> <span class="op">-</span><span class="st"> </span>constant</a>
<a class="sourceLine" id="cb240-12" data-line-number="12">}</a>
<a class="sourceLine" id="cb240-13" data-line-number="13">gamma_area &lt;-<span class="st"> </span><span class="cf">function</span>(x, alpha, beta) {</a>
<a class="sourceLine" id="cb240-14" data-line-number="14">    a =<span class="st"> </span><span class="dv">0</span>; b =<span class="st"> </span>x     <span class="co"># boundaries</span></a>
<a class="sourceLine" id="cb240-15" data-line-number="15">    area =<span class="st"> </span><span class="kw">seq</span>(a, b, <span class="dt">length.out=</span><span class="dv">50</span>)     <span class="co"># area</span></a>
<a class="sourceLine" id="cb240-16" data-line-number="16">    x =<span class="st"> </span><span class="kw">c</span>(a, area , b)</a>
<a class="sourceLine" id="cb240-17" data-line-number="17">    y =<span class="st"> </span><span class="kw">c</span>(<span class="dv">0</span>, <span class="kw">gamma_pdf</span>(area, alpha, beta), <span class="dv">0</span>)</a>
<a class="sourceLine" id="cb240-18" data-line-number="18">    <span class="kw">polygon</span>(x, y, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>)    </a>
<a class="sourceLine" id="cb240-19" data-line-number="19">}</a>
<a class="sourceLine" id="cb240-20" data-line-number="20"></a>
<a class="sourceLine" id="cb240-21" data-line-number="21"><span class="co">#Plotting PDF and CDF(Area for alpha=5, beta=1)</span></a>
<a class="sourceLine" id="cb240-22" data-line-number="22"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">15</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="fl">0.5</span>), </a>
<a class="sourceLine" id="cb240-23" data-line-number="23">     <span class="dt">xlab=</span><span class="st">&quot;support&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;probability density&quot;</span>,</a>
<a class="sourceLine" id="cb240-24" data-line-number="24">     <span class="dt">main=</span><span class="st">&quot;PDF and CDF (Gamma Distribution)&quot;</span>,  <span class="dt">frame=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb240-25" data-line-number="25"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb240-26" data-line-number="26"><span class="kw">abline</span>(<span class="dt">h=</span><span class="dv">0</span>, <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb240-27" data-line-number="27">p =<span class="st"> </span><span class="kw">gamma_cdf</span>(<span class="dt">x=</span><span class="dv">6</span>, <span class="dt">alpha=</span><span class="dv">5</span>, <span class="dt">beta=</span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb240-28" data-line-number="28"><span class="kw">gamma_area</span>(<span class="dt">x=</span><span class="dv">6</span>, <span class="dt">alpha=</span><span class="dv">5</span>, <span class="dt">beta=</span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb240-29" data-line-number="29"><span class="kw">curve</span>(<span class="kw">gamma_pdf</span>(x, <span class="dt">alpha=</span><span class="dv">1</span>, <span class="dt">beta=</span><span class="dv">2</span>), <span class="dt">col=</span><span class="st">&quot;brown&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb240-30" data-line-number="30"><span class="kw">curve</span>(<span class="kw">gamma_pdf</span>(x, <span class="dt">alpha=</span><span class="dv">2</span>, <span class="dt">beta=</span><span class="dv">2</span>), <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb240-31" data-line-number="31"><span class="kw">curve</span>(<span class="kw">gamma_pdf</span>(x, <span class="dt">alpha=</span><span class="dv">5</span>, <span class="dt">beta=</span><span class="dv">1</span>), <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb240-32" data-line-number="32"><span class="kw">curve</span>(<span class="kw">gamma_pdf</span>(x, <span class="dt">alpha=</span><span class="dv">10</span>, <span class="dt">beta=</span><span class="fl">0.5</span>), <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb240-33" data-line-number="33"><span class="kw">text</span>(<span class="dv">4</span>,<span class="fl">0.06</span>, <span class="dt">label=</span><span class="st">&quot;(cdf)&quot;</span>, <span class="dt">col=</span><span class="st">&quot;black&quot;</span>)</a>
<a class="sourceLine" id="cb240-34" data-line-number="34"><span class="kw">text</span>(<span class="dv">4</span>, <span class="fl">0.02</span>, <span class="dt">label=</span><span class="kw">paste</span>(<span class="st">&quot;Area = &quot;</span>, <span class="kw">round</span>(p,<span class="dv">5</span>), <span class="dt">sep=</span><span class="st">&quot;&quot;</span>), </a>
<a class="sourceLine" id="cb240-35" data-line-number="35">     <span class="dt">ce=</span><span class="fl">0.80</span>, <span class="dt">col=</span><span class="st">&quot;black&quot;</span>)</a>
<a class="sourceLine" id="cb240-36" data-line-number="36"><span class="kw">text</span>(<span class="fl">6.5</span>, <span class="fl">0.04</span>, <span class="dt">label=</span><span class="st">&quot;x=6&quot;</span>)</a>
<a class="sourceLine" id="cb240-37" data-line-number="37"></a>
<a class="sourceLine" id="cb240-38" data-line-number="38"><span class="co">#Plotting CDF</span></a>
<a class="sourceLine" id="cb240-39" data-line-number="39"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">15</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="dv">1</span>), </a>
<a class="sourceLine" id="cb240-40" data-line-number="40">     <span class="dt">xlab=</span><span class="st">&quot;support&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;cumulative density&quot;</span>,</a>
<a class="sourceLine" id="cb240-41" data-line-number="41">     <span class="dt">main=</span><span class="st">&quot;CDF (Gamma Distribution)&quot;</span>,  <span class="dt">frame=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb240-42" data-line-number="42"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb240-43" data-line-number="43"><span class="kw">abline</span>(<span class="dt">h=</span><span class="dv">0</span>, <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb240-44" data-line-number="44">x =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">15</span>, <span class="dt">length.out=</span><span class="dv">500</span>)</a>
<a class="sourceLine" id="cb240-45" data-line-number="45"><span class="kw">curve</span>(<span class="kw">gamma_cdf</span>(x, <span class="dt">alpha=</span><span class="dv">1</span>, <span class="dt">beta=</span><span class="dv">2</span>), <span class="dt">col=</span><span class="st">&quot;brown&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb240-46" data-line-number="46"><span class="kw">curve</span>(<span class="kw">gamma_cdf</span>(x, <span class="dt">alpha=</span><span class="dv">2</span>, <span class="dt">beta=</span><span class="dv">2</span>), <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb240-47" data-line-number="47"><span class="kw">curve</span>(<span class="kw">gamma_cdf</span>(x, <span class="dt">alpha=</span><span class="dv">5</span>, <span class="dt">beta=</span><span class="dv">1</span>), <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb240-48" data-line-number="48"><span class="kw">curve</span>(<span class="kw">gamma_cdf</span>(x, <span class="dt">alpha=</span><span class="dv">10</span>, <span class="dt">beta=</span><span class="fl">0.5</span>), <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:gammapdf-1"></span>
<img src="DS_files/figure-html/gammapdf-1.png" alt="Gamma Distribution" width="70%" />
<p class="caption">
Figure 5.18: Gamma Distribution
</p>
</div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:gammapdf-2"></span>
<img src="DS_files/figure-html/gammapdf-2.png" alt="Gamma Distribution" width="70%" />
<p class="caption">
Figure 5.19: Gamma Distribution
</p>
</div>

<p>Note that if <span class="math inline">\(\alpha = 1\)</span>, the inverse of <span class="math inline">\(\beta\)</span> makes the <strong>Gamma distribution</strong> equivalent to <strong>Exponential distribution</strong>. Meaning, use <span class="math inline">\(\alpha=1, \beta=1/\lambda\)</span> to mimic <strong>Exponential distribution</strong> using <strong>Gamma PDF</strong>.</p>
<p>One way to illustrate the relation between <strong>Gamma and Exponential distribution</strong> is shown in figure <a href="5.9-distributiontypes.html#fig:gammadist">5.20</a>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:gammadist"></span>
<img src="gamma.png" alt="Gamma and Exponential Distribution" width="80%" />
<p class="caption">
Figure 5.20: Gamma and Exponential Distribution
</p>
</div>
<p>In Figure <a href="5.9-distributiontypes.html#fig:gammadist">5.20</a>, there are four events, <span class="math inline">\(\{ e1, e2, e3, e4\}\)</span>. Event <strong>e1</strong> happens between times 0 and 1. The time taken is one second, <strong>x1</strong>. Event <strong>e2</strong> happens between times 1 and 2. The time taken is also one second, <strong>x2</strong>. Event <strong>e3</strong> happens between times 2 and 4. The time taken is two seconds, <strong>x3</strong>. Moreover, event <strong>e4</strong> happens between times 4 and 7. The time taken is three seconds, <strong>x4</strong>. Here, <strong>Exponential distribution</strong> focuses on the time taken between events.</p>
<p>On the other hand, at time 1, event <strong>e1</strong> happens after waiting for one second, <strong>G1</strong>. There is only one event that happens after one second. At time 2, events <strong>e1, e2</strong> happen after two seconds elapsed, <strong>G2</strong>. Two events happen after two seconds. At time 4, after four seconds ,<strong>G3</strong>, events <strong>e1, e2, e3</strong> happen. Three events happen after four seconds. Finally, at time 7, seven seconds, <strong>G4</strong>, events <strong>e1, e2, e3, e4</strong> happen. Four events happen after seven seconds. Here, <strong>Gamma distribution</strong> focuses on the number of events after some <strong>elapsed time</strong>.</p>
<p>To illustrate practically, suppose a shuttle bus in an airport’s long-term parking lot arrives every 30 minutes at the airport to pick up travelers. Let us compute the probability of expecting three buses to arrive after waiting between 1 hour and 2 hours.</p>
<p>A shuttle bus arriving every 30 minutes means we expect to see <span class="math inline">\(\beta = 1/0.5= 2\)</span> buses arriving every hour on average.</p>
<p>Using <span class="math inline">\(\alpha = 3\)</span> and <span class="math inline">\(\beta = 2\)</span>, we can compute this as follows:</p>
<p><span class="math display" id="eq:equate1070089">\[\begin{align}
P(1 \le X \le 2) = \sum_{x=1}^{\alpha-1} \frac {1}{\beta^\alpha\Gamma(\alpha)}x^{(\alpha-1)}e^{-\frac{x}{\beta}}
= \sum_{x=1}^{3-1} \frac {1}{\Gamma(3)2^3}x^{(3-1)}e^{-\frac{x}{2}}
= 0.129878 \tag{5.94} 
\end{align}\]</span></p>
<p>Here is the implementation of <strong>PDF</strong> in R code:</p>

<div class="sourceCode" id="cb241"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb241-1" data-line-number="1">gamma_pdf &lt;-<span class="st"> </span><span class="cf">function</span>(x, alpha, beta) { </a>
<a class="sourceLine" id="cb241-2" data-line-number="2">  <span class="dv">1</span><span class="op">/</span>( <span class="kw">factorial</span>(alpha<span class="dv">-1</span>)<span class="op">*</span><span class="st"> </span>beta<span class="op">^</span>alpha ) <span class="op">*</span><span class="st"> </span>x<span class="op">^</span>(alpha<span class="dv">-1</span>) <span class="op">*</span><span class="st"> </span><span class="kw">exp</span>(<span class="op">-</span>x<span class="op">/</span>beta)</a>
<a class="sourceLine" id="cb241-3" data-line-number="3">}</a>
<a class="sourceLine" id="cb241-4" data-line-number="4"><span class="kw">sum</span> ( <span class="kw">gamma_pdf</span>(<span class="dt">x=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>), <span class="dt">alpha=</span><span class="dv">3</span>, <span class="dt">beta=</span><span class="dv">2</span>) )  <span class="co"># our code</span></a></code></pre></div>
<pre><code>## [1] 0.129878</code></pre>
<div class="sourceCode" id="cb243"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb243-1" data-line-number="1"><span class="kw">sum</span>(<span class="kw">dgamma</span>(<span class="dt">x=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>), <span class="dt">shape=</span><span class="dv">3</span>, <span class="dt">rate=</span><span class="fl">0.5</span>)) <span class="co"># R&#39;s built-in package</span></a></code></pre></div>
<pre><code>## [1] 0.129878</code></pre>

<p>Note that <span class="math inline">\(\alpha = shape\)</span> and <span class="math inline">\(\beta = 1 / rate\)</span>.</p>
<p>In terms of expected value and variance, we have the following formulas:</p>
<p><strong>Expected value</strong>:</p>
<p><span class="math display" id="eq:equate1070090">\[\begin{align}
\mathbb{E}(X) = \alpha \beta \tag{5.95} 
\end{align}\]</span></p>
<p><strong>Variance:</strong></p>
<p><span class="math display" id="eq:equate1070091">\[\begin{align}
Var(X) = \mathbb{E}({X}^2) - \mathbb{E}(X)^2   =  \alpha \beta^2 \tag{5.96} 
\end{align}\]</span></p>
</div>
<div id="inverse-gamma-distribution" class="section level3 hasAnchor">
<h3><span class="header-section-number">5.9.9</span> Inverse Gamma distribution <a href="5.9-distributiontypes.html#inverse-gamma-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Inverse Gamma distribution</strong> models a <strong>continuous distribution</strong> whose <strong>PDF</strong> is inverse of <strong>Gamma distribution</strong> where <strong>support</strong> <span class="math inline">\(x \ge 0\)</span> and is written as:</p>
<p><span class="math display" id="eq:equate1070092">\[\begin{align}
f(x; \alpha,\beta) = P(X = x|\alpha, \beta) = \frac{1}{\beta^{\alpha}\Gamma(\alpha)}x^{-(\alpha+1)}e^{-\frac{1}{x\beta}} \tag{5.97} 
\end{align}\]</span></p>
<p>and its <strong>CDF</strong> is:</p>
<p><span class="math display" id="eq:equate1070093">\[\begin{align}
\mathcal{F}(x; \alpha,\beta) = P(X &lt;= x|\alpha, \beta) = \frac{\Gamma(\alpha, \frac{\beta}{x})}{\Gamma(\alpha)}  \tag{5.98} 
\end{align}\]</span></p>
<p>where the upper <strong>incomplete Gamma function</strong> is written as:</p>
<p><span class="math display" id="eq:equate1070094">\[\begin{align}
\Gamma(\alpha, \frac{\beta}{x}) = \int_0^x t^{\alpha - 1}e^{-t}dt \tag{5.99} 
\end{align}\]</span></p>
<p><strong>Expected value</strong>:</p>
<p><span class="math display" id="eq:equate1070095">\[\begin{align}
\mathbb{E}(X) = \frac{\beta}{(\alpha - 1 )} \tag{5.100} 
\end{align}\]</span></p>
<p><strong>Variance:</strong></p>
<p><span class="math display" id="eq:equate1070096">\[\begin{align}
Var(X) = \mathbb{E}({X}^2) - \mathbb{E}(X)^2   =  \frac{\beta^2}{(\alpha-1)^2(\alpha - 2)} \tag{5.101} 
\end{align}\]</span></p>
</div>
<div id="weibull-distribution" class="section level3 hasAnchor">
<h3><span class="header-section-number">5.9.10</span> Weibull distribution <a href="5.9-distributiontypes.html#weibull-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>For an alternative to <strong>Gamma distribution</strong>, we leave readers to investigate <strong>Weibull distribution</strong>, which offers simplicity and reliability and is written as:</p>
<p><span class="math display" id="eq:equate1070097">\[\begin{align}
X \sim Weib(\alpha, \beta) \tag{5.102} 
\end{align}\]</span></p>
<p>with the following 2-parameter <strong>PDF</strong> for <strong>Weibull distribution</strong>, where <strong>support</strong> <span class="math inline">\(x \ge 0\)</span> :</p>
<p><span class="math display" id="eq:equate1070098">\[\begin{align}
f(x; \tau, \lambda) = P(X = x|\tau, \lambda) =  \frac{\tau}{\lambda}\left(\frac{x}{\lambda}\right)^{\tau - 1} e^{ -\left(\frac{x}{\lambda}\right)^{\tau}} \tag{5.103} 
\end{align}\]</span></p>
<p>and with the 2-parameter <strong>CDF</strong> for <strong>Weibull distribution</strong>:</p>
<p><span class="math display" id="eq:equate1070099">\[\begin{align}
\mathcal{F}(x; \tau, \lambda) = P(X \le x| \tau, \lambda) = 1 - e^{ -\left(\frac{x}{\lambda}\right)^{\tau}} \tag{5.104} 
\end{align}\]</span></p>
<p>We also note exploring the 3-parameter <strong>Weibull PDF</strong> and the 1-parameter <strong>Weibull PDF</strong>.</p>
<p>We now discuss the next type of distribution - the <strong>Poisson distribution</strong>. It is notable to mention that <strong>Gamma distribution</strong> and <strong>Poisson distribution</strong> are also somewhat interrelated. While <strong>Gamma distribution</strong> is about the number of events <strong>after wait time</strong>, <strong>Poisson distribution</strong> is about the number of events <strong>between fixed times</strong>.</p>
</div>
<div id="poisson-distribution" class="section level3 hasAnchor">
<h3><span class="header-section-number">5.9.11</span> Poisson distribution <a href="5.9-distributiontypes.html#poisson-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Poisson distribution</strong> is also called <strong>Count distribution</strong> as it describes a <strong>discrete distribution</strong> of data based on the number of times events are occurring in some given fixed time-intervals and is expressed as:</p>
<p><span class="math display" id="eq:equate1070100">\[\begin{align}
X \sim Pois(\lambda )\ \ \ \ \ or \ \ \ \ \  \ X \sim Po(\lambda ) \tag{5.105} 
\end{align}\]</span></p>
<p>As examples:</p>
<ul>
<li>How many words are typed every minute?</li>
<li>How many drops of rainfall on a basin every second?</li>
<li>How many cars pass by the highway every minute?</li>
</ul>
<p>Here, the expected number of occurrences is <span class="math inline">\(\lambda\)</span> (lambda). It answers the question, <strong>How many?</strong>.</p>
<p>The <strong>PMF</strong> of a <strong>discrete Poisson distribution</strong> is expressed as:</p>
<p><span class="math display" id="eq:eqnnumber6001">\[\begin{align}
f(x; \lambda) = P(X = x|\lambda) = \frac{\lambda^xe^{-\lambda}}{x!} \tag{5.106}
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li>k is the number of events occurring successfully</li>
<li><span class="math inline">\(\lambda\)</span> is a shape parameter describing event rate, <span class="math inline">\(\lambda = rt\)</span>, e.g., number of events per fixed interval of time.</li>
<li>r is the number of occurrences.</li>
<li>t is the fixed interval time.</li>
</ul>
<p>The <strong>CMF</strong> of a <strong>discrete Poisson distribution</strong> is expressed as:</p>
<p><span class="math display" id="eq:equate1070101">\[\begin{align}
\mathcal{F}(x; \lambda) = P(X \le x|\lambda) = \sum_{k=0}^{x} \frac{\lambda^k}{k!}e^{-\lambda} \tag{5.107} 
\end{align}\]</span></p>
<p>Below is a naive implementation of <strong>Poisson Distribution</strong> in R code:</p>

<div class="sourceCode" id="cb245"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb245-1" data-line-number="1">poisson_pmf &lt;-<span class="st"> </span><span class="cf">function</span>(x, lambda ) {</a>
<a class="sourceLine" id="cb245-2" data-line-number="2">    lambda<span class="op">^</span>x <span class="op">*</span><span class="st"> </span><span class="kw">exp</span>(<span class="op">-</span>lambda) <span class="op">/</span><span class="st"> </span><span class="kw">factorial</span>(x)</a>
<a class="sourceLine" id="cb245-3" data-line-number="3">}</a>
<a class="sourceLine" id="cb245-4" data-line-number="4">poisson_cmf &lt;-<span class="st"> </span><span class="cf">function</span>(x, lambda) {</a>
<a class="sourceLine" id="cb245-5" data-line-number="5">    poisson =<span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb245-6" data-line-number="6">    <span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">0</span><span class="op">:</span>x) { </a>
<a class="sourceLine" id="cb245-7" data-line-number="7">      poisson =<span class="st"> </span>poisson <span class="op">+</span><span class="st"> </span>(lambda<span class="op">^</span>k)<span class="op">/</span><span class="kw">factorial</span>(k) <span class="op">*</span><span class="st"> </span><span class="kw">exp</span>(<span class="op">-</span>lambda)</a>
<a class="sourceLine" id="cb245-8" data-line-number="8">    }</a>
<a class="sourceLine" id="cb245-9" data-line-number="9">    poisson</a>
<a class="sourceLine" id="cb245-10" data-line-number="10">}</a>
<a class="sourceLine" id="cb245-11" data-line-number="11">poisson_area &lt;-<span class="st"> </span><span class="cf">function</span>(x, lambda) {</a>
<a class="sourceLine" id="cb245-12" data-line-number="12">    a =<span class="st"> </span><span class="dv">0</span>; b =<span class="st"> </span>x     <span class="co"># boundaries</span></a>
<a class="sourceLine" id="cb245-13" data-line-number="13">    area =<span class="st"> </span><span class="kw">seq</span>(a, b, <span class="dt">length.out=</span><span class="dv">50</span>) <span class="co"># area</span></a>
<a class="sourceLine" id="cb245-14" data-line-number="14">    x =<span class="st"> </span><span class="kw">c</span>(a, area , b)</a>
<a class="sourceLine" id="cb245-15" data-line-number="15">    y =<span class="st"> </span><span class="kw">c</span>(<span class="dv">0</span>, <span class="kw">poisson_pmf</span>(area, lambda), <span class="dv">0</span>)</a>
<a class="sourceLine" id="cb245-16" data-line-number="16">    <span class="kw">polygon</span>(x, y, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>)</a>
<a class="sourceLine" id="cb245-17" data-line-number="17">    bars =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">20</span>, <span class="dt">length.out=</span><span class="dv">21</span>)</a>
<a class="sourceLine" id="cb245-18" data-line-number="18">    y =<span class="st"> </span><span class="kw">poisson_pmf</span>(bars, lambda) </a>
<a class="sourceLine" id="cb245-19" data-line-number="19">}</a>
<a class="sourceLine" id="cb245-20" data-line-number="20"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">20</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="op">-</span><span class="fl">0.01</span>,<span class="fl">0.6</span>), </a>
<a class="sourceLine" id="cb245-21" data-line-number="21">     <span class="dt">xlab=</span><span class="st">&quot;support&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;probability mass&quot;</span>,</a>
<a class="sourceLine" id="cb245-22" data-line-number="22">     <span class="dt">main=</span><span class="st">&quot;PMF and CMF (Poisson Distribution)&quot;</span>,  <span class="dt">frame=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb245-23" data-line-number="23"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb245-24" data-line-number="24"><span class="kw">abline</span>(<span class="dt">h=</span><span class="dv">0</span>, <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb245-25" data-line-number="25">p =<span class="st"> </span><span class="kw">poisson_cmf</span>(<span class="dt">x=</span><span class="dv">10</span>, <span class="dt">lambda=</span><span class="dv">9</span>)</a>
<a class="sourceLine" id="cb245-26" data-line-number="26"><span class="kw">poisson_area</span>(<span class="dt">x=</span><span class="dv">10</span>, <span class="dt">lambda=</span><span class="dv">9</span>)</a>
<a class="sourceLine" id="cb245-27" data-line-number="27"><span class="co"># use n=550 to smoothen curves</span></a>
<a class="sourceLine" id="cb245-28" data-line-number="28"><span class="kw">curve</span>(<span class="kw">poisson_pmf</span>(x, <span class="dt">lambda=</span><span class="fl">0.5</span>), <span class="dt">n=</span><span class="dv">550</span>, <span class="dt">col=</span><span class="st">&quot;brown&quot;</span>, </a>
<a class="sourceLine" id="cb245-29" data-line-number="29">      <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb245-30" data-line-number="30"><span class="kw">curve</span>(<span class="kw">poisson_pmf</span>(x, <span class="dt">lambda=</span><span class="dv">1</span>), <span class="dt">n=</span><span class="dv">550</span>, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, </a>
<a class="sourceLine" id="cb245-31" data-line-number="31">      <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb245-32" data-line-number="32"><span class="kw">curve</span>(<span class="kw">poisson_pmf</span>(x, <span class="dt">lambda=</span><span class="dv">5</span>), <span class="dt">n=</span><span class="dv">550</span>, <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, </a>
<a class="sourceLine" id="cb245-33" data-line-number="33">      <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb245-34" data-line-number="34"><span class="kw">curve</span>(<span class="kw">poisson_pmf</span>(x, <span class="dt">lambda=</span><span class="dv">9</span>), <span class="dt">n=</span><span class="dv">550</span>, <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb245-35" data-line-number="35">x =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">20</span>, <span class="dt">length=</span><span class="dv">21</span>)</a>
<a class="sourceLine" id="cb245-36" data-line-number="36">y =<span class="st"> </span><span class="kw">poisson_pmf</span>(x, <span class="dt">lambda=</span><span class="dv">9</span>)</a>
<a class="sourceLine" id="cb245-37" data-line-number="37"><span class="kw">points</span>(x,y, <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>, <span class="dt">pch=</span><span class="dv">16</span>, <span class="dt">cex=</span><span class="fl">0.8</span>)</a>
<a class="sourceLine" id="cb245-38" data-line-number="38"><span class="kw">text</span>(<span class="dv">7</span>,<span class="fl">0.06</span>, <span class="dt">label=</span><span class="st">&quot;(cmf)&quot;</span>, <span class="dt">col=</span><span class="st">&quot;black&quot;</span>)</a>
<a class="sourceLine" id="cb245-39" data-line-number="39"><span class="kw">text</span>(<span class="dv">7</span>, <span class="fl">0.02</span>, <span class="dt">label=</span><span class="kw">paste</span>(<span class="st">&quot;Area = &quot;</span>, <span class="kw">round</span>(p,<span class="dv">5</span>), <span class="dt">sep=</span><span class="st">&quot;&quot;</span>), </a>
<a class="sourceLine" id="cb245-40" data-line-number="40">     <span class="dt">ce=</span><span class="fl">0.80</span>, <span class="dt">col=</span><span class="st">&quot;black&quot;</span>)</a>
<a class="sourceLine" id="cb245-41" data-line-number="41"><span class="kw">text</span>(<span class="dv">10</span>, <span class="fl">-0.01</span>, <span class="dt">label=</span><span class="st">&quot;x=10&quot;</span>, <span class="dt">cex=</span><span class="fl">0.8</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:poissonpdf"></span>
<img src="DS_files/figure-html/poissonpdf-1.png" alt="Poisson (PMF and CMF)" width="70%" />
<p class="caption">
Figure 5.21: Poisson (PMF and CMF)
</p>
</div>

<p>Our <strong>CMF</strong> for the <strong>Poisson distribution</strong> in figure <a href="5.9-distributiontypes.html#fig:poissonpdf">5.21</a> is 0.70599.</p>
<p>Note that the <strong>PMF</strong> and <strong>CMF</strong> may appear continuous in figure <a href="5.9-distributiontypes.html#fig:poissonpdf">5.21</a>. However, we focus more on the discrete points along the curves generated by <strong>PMF</strong>. Equivalently, <strong>CMF</strong> generates a set of discrete bars up to <span class="math inline">\(x\)</span> instead of a continuously filled region.</p>
<p>To illustrate further, suppose that a software developer types an average of 40 words per minute on a computer keyboard. Calculate the probability of k = (0,1,2,3,..6) in an interval of 1-minute.</p>
<p><span class="math display">\[
P(X\ \in\ \{0,1,2,3,4,5,6\}) = \frac{\lambda^x e^{-\lambda}}{x!}
\]</span></p>
<p>where:</p>
<ul>
<li><strong>r</strong> is 40 words typed on the average.</li>
<li><strong>t</strong> is 1 minute interval.</li>
<li><span class="math inline">\(\lambda\)</span> is 40 words / minute</li>
</ul>
<p>Here is the implementation of <strong>PMF</strong> in R code:</p>
<div class="sourceCode" id="cb246"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb246-1" data-line-number="1">k =<span class="st"> </span><span class="kw">c</span>(<span class="dv">30</span>,<span class="dv">35</span>,<span class="dv">40</span>,<span class="dv">45</span>,<span class="dv">50</span>)</a>
<a class="sourceLine" id="cb246-2" data-line-number="2"><span class="kw">round</span>(<span class="kw">poisson_pmf</span>(<span class="dt">x=</span>k,<span class="dt">lambda=</span><span class="dv">40</span>), <span class="dv">5</span>)   <span class="co"># our code</span></a></code></pre></div>
<pre><code>## [1] 0.01847 0.04854 0.06295 0.04397 0.01771</code></pre>
<div class="sourceCode" id="cb248"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb248-1" data-line-number="1">(<span class="dt">p =</span> <span class="kw">round</span>(<span class="kw">dpois</span>(<span class="dt">x=</span>k, <span class="dt">lambda=</span><span class="dv">40</span>), <span class="dv">5</span>)) <span class="co"># R&#39;s built-in package</span></a></code></pre></div>
<pre><code>## [1] 0.01847 0.04854 0.06295 0.04397 0.01771</code></pre>
<div class="sourceCode" id="cb250"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb250-1" data-line-number="1"><span class="kw">names</span>(p) &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">4</span>,<span class="dv">1</span>)</a>
<a class="sourceLine" id="cb250-2" data-line-number="2"><span class="kw">barplot</span>(p, <span class="dt">density=</span>T, <span class="dt">col=</span><span class="dv">2</span>, <span class="dt">xlab=</span><span class="st">&quot;Events&quot;</span>,</a>
<a class="sourceLine" id="cb250-3" data-line-number="3">        <span class="dt">ylab=</span><span class="st">&quot;Probability&quot;</span>, <span class="dt">main=</span><span class="st">&quot;Rate of Typed Words&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:rpoipmf1"></span>
<img src="DS_files/figure-html/rpoipmf1-1.png" alt="(PMF) Poisson Distribution" width="60%" />
<p class="caption">
Figure 5.22: (PMF) Poisson Distribution
</p>
</div>
<p>Here, the probability of typing 30 words per minute with an average of 40 words per minute is 1.85%. The probability of typing 40 words per minute is 6.30% if the average is 40 words per minute.</p>
<p>For the <strong>expected value</strong> and <strong>variance</strong>, respectively, we have:</p>
<p><span class="math display" id="eq:equate1070102">\[\begin{align}
\mathbb{E}(X) = Var(X) = \lambda = rt \tag{5.108} 
\end{align}\]</span></p>
</div>
<div id="pareto-distribution" class="section level3 hasAnchor">
<h3><span class="header-section-number">5.9.12</span> Pareto distribution <a href="5.9-distributiontypes.html#pareto-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Pareto distribution</strong> models a skewed and heavy-tailed <strong>continuous distribution</strong> written as:</p>
<p><span class="math display" id="eq:equate1070103">\[\begin{align}
X \sim Pareto(\lambda, \alpha) \tag{5.109} 
\end{align}\]</span></p>
<p>This distribution is commonly known to model the distribution of incomes.
The <strong>Pareto PDF</strong> of a <strong>Pareto distribution</strong> with <strong>support</strong>, <span class="math inline">\(x &gt; \lambda\)</span>, is expressed as:</p>
<p><span class="math display" id="eq:equate1070104">\[\begin{align}
f(x; \lambda, \alpha) = P(X = x) = \frac{\alpha \cdot \lambda^\alpha}{X^{\alpha+1}} \tag{5.110} 
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(\lambda\)</span> represents the minimum wage</li>
<li><span class="math inline">\(\alpha\)</span> is the <strong>shape parameter</strong> modeling an income distribution</li>
</ul>
<p>The <strong>Pareto CDF</strong> is expressed in the below equation, where <span class="math inline">\(x &gt; \lambda\)</span>:</p>
<p><span class="math display" id="eq:equate1070105">\[\begin{align}
f(x; \lambda, \alpha) = P(X \le x) = 1 - \left(\frac{\lambda}{x}^\alpha\right) \tag{5.111} 
\end{align}\]</span></p>
<p>The mean and variance are expressed as such:</p>
<p><span class="math display" id="eq:equate1070106">\[\begin{align}
\mathbb{E}(X) = \frac{\alpha\lambda}{\alpha - 1}, \alpha &gt; 1
\ \ \ \ \ \ \ \ \ \ \ \
VAR(X) = \frac{\alpha\lambda^2}{(\alpha - 1)^2(\alpha - 2)}, \alpha &gt; 2 \tag{5.112} 
\end{align}\]</span></p>
<p>Below is a naive implementation of <strong>Pareto Distribution</strong> in R code (See Figures <a href="5.9-distributiontypes.html#fig:paretopdf1">5.23</a> and <a href="5.9-distributiontypes.html#fig:paretopdf2">5.24</a>):</p>

<div class="sourceCode" id="cb251"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb251-1" data-line-number="1">pareto_pdf &lt;-<span class="st"> </span><span class="cf">function</span>(x, lambda,  alpha ) {</a>
<a class="sourceLine" id="cb251-2" data-line-number="2">    (alpha <span class="op">*</span><span class="st"> </span>lambda<span class="op">^</span>alpha) <span class="op">/</span><span class="st"> </span>(x<span class="op">^</span>(alpha <span class="op">+</span><span class="st"> </span><span class="dv">1</span>))</a>
<a class="sourceLine" id="cb251-3" data-line-number="3">}</a>
<a class="sourceLine" id="cb251-4" data-line-number="4">pareto_cdf &lt;-<span class="st"> </span><span class="cf">function</span>(x, lambda, alpha) {</a>
<a class="sourceLine" id="cb251-5" data-line-number="5">    <span class="dv">1</span> <span class="op">-</span><span class="st"> </span>(lambda<span class="op">^</span>alpha <span class="op">/</span><span class="st"> </span>x)</a>
<a class="sourceLine" id="cb251-6" data-line-number="6">}</a>
<a class="sourceLine" id="cb251-7" data-line-number="7">pareto_area &lt;-<span class="st"> </span><span class="cf">function</span>(x, lambda, alpha) {</a>
<a class="sourceLine" id="cb251-8" data-line-number="8">    a =<span class="st"> </span><span class="dv">1</span>; b =<span class="st"> </span>x     <span class="co"># boundaries</span></a>
<a class="sourceLine" id="cb251-9" data-line-number="9">    area =<span class="st"> </span><span class="kw">seq</span>(a, b, <span class="dt">length.out=</span><span class="dv">50</span>)     <span class="co"># area</span></a>
<a class="sourceLine" id="cb251-10" data-line-number="10">    x =<span class="st"> </span><span class="kw">c</span>(a, area , b)</a>
<a class="sourceLine" id="cb251-11" data-line-number="11">    y =<span class="st"> </span><span class="kw">c</span>(<span class="dv">0</span>, <span class="kw">pareto_pdf</span>(area, lambda, alpha), <span class="dv">0</span>)</a>
<a class="sourceLine" id="cb251-12" data-line-number="12">    <span class="kw">polygon</span>(x, y, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>)    </a>
<a class="sourceLine" id="cb251-13" data-line-number="13">}</a>
<a class="sourceLine" id="cb251-14" data-line-number="14"><span class="co">#Plotting PDF and CDF (Area for alpha=1, beta=1)</span></a>
<a class="sourceLine" id="cb251-15" data-line-number="15"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">8</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="dv">2</span>), </a>
<a class="sourceLine" id="cb251-16" data-line-number="16">     <span class="dt">xlab=</span><span class="st">&quot;support&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;probability density&quot;</span>,</a>
<a class="sourceLine" id="cb251-17" data-line-number="17">     <span class="dt">main=</span><span class="st">&quot;PDF (Pareto Distribution)&quot;</span>,  <span class="dt">frame=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb251-18" data-line-number="18"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb251-19" data-line-number="19"><span class="kw">abline</span>(<span class="dt">h=</span><span class="dv">0</span>, <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb251-20" data-line-number="20">p =<span class="st"> </span><span class="kw">pareto_cdf</span>(<span class="dt">x=</span><span class="dv">2</span>, <span class="dt">lambda=</span><span class="fl">0.5</span>, <span class="dt">alpha=</span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb251-21" data-line-number="21"><span class="kw">pareto_area</span>(<span class="dt">x=</span><span class="dv">2</span>, <span class="dt">lambda=</span><span class="fl">0.5</span>, <span class="dt">alpha=</span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb251-22" data-line-number="22"><span class="kw">curve</span>(<span class="kw">pareto_pdf</span>(x, <span class="dt">lambda=</span><span class="fl">0.5</span>, <span class="dt">alpha=</span><span class="dv">1</span>), <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb251-23" data-line-number="23"><span class="kw">curve</span>(<span class="kw">pareto_pdf</span>(x, <span class="dt">lambda=</span><span class="dv">1</span>, <span class="dt">alpha=</span><span class="dv">1</span>),   <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, </a>
<a class="sourceLine" id="cb251-24" data-line-number="24">      <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb251-25" data-line-number="25"><span class="kw">curve</span>(<span class="kw">pareto_pdf</span>(x, <span class="dt">lambda=</span><span class="fl">1.5</span>, <span class="dt">alpha=</span><span class="dv">1</span>), <span class="dt">col=</span><span class="st">&quot;brown&quot;</span>, </a>
<a class="sourceLine" id="cb251-26" data-line-number="26">      <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb251-27" data-line-number="27"><span class="kw">curve</span>(<span class="kw">pareto_pdf</span>(x, <span class="dt">lambda=</span><span class="dv">2</span>, <span class="dt">alpha=</span><span class="dv">1</span>),   <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb251-28" data-line-number="28"></a>
<a class="sourceLine" id="cb251-29" data-line-number="29"><span class="kw">text</span>(<span class="fl">1.2</span>,<span class="fl">0.2</span>, <span class="dt">label=</span><span class="st">&quot;(cdf)&quot;</span>, <span class="dt">col=</span><span class="st">&quot;black&quot;</span>)</a>
<a class="sourceLine" id="cb251-30" data-line-number="30"><span class="kw">text</span>(<span class="fl">1.5</span>, <span class="fl">0.1</span>, <span class="dt">label=</span><span class="kw">paste</span>(<span class="st">&quot;Area = &quot;</span>, <span class="kw">round</span>(p,<span class="dv">5</span>), <span class="dt">sep=</span><span class="st">&quot;&quot;</span>), </a>
<a class="sourceLine" id="cb251-31" data-line-number="31">     <span class="dt">ce=</span><span class="fl">0.80</span>, <span class="dt">col=</span><span class="st">&quot;black&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:paretopdf1"></span>
<img src="DS_files/figure-html/paretopdf1-1.png" alt="Pareto Distribution (PDF)" width="70%" />
<p class="caption">
Figure 5.23: Pareto Distribution (PDF)
</p>
</div>
<div class="sourceCode" id="cb252"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb252-1" data-line-number="1"><span class="co">#Plotting CDF</span></a>
<a class="sourceLine" id="cb252-2" data-line-number="2"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="dv">2</span><span class="op">:</span><span class="dv">30</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="dv">1</span>), </a>
<a class="sourceLine" id="cb252-3" data-line-number="3">     <span class="dt">xlab=</span><span class="st">&quot;support&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;cumulative density&quot;</span>,</a>
<a class="sourceLine" id="cb252-4" data-line-number="4">     <span class="dt">main=</span><span class="st">&quot;CDF (Pareto Distribution)&quot;</span>,  <span class="dt">frame=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb252-5" data-line-number="5"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb252-6" data-line-number="6"><span class="kw">abline</span>(<span class="dt">h=</span><span class="dv">0</span>, <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb252-7" data-line-number="7">x =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">15</span>, <span class="dt">length.out=</span><span class="dv">500</span>)</a>
<a class="sourceLine" id="cb252-8" data-line-number="8"><span class="kw">curve</span>(<span class="kw">pareto_cdf</span>(x, <span class="dt">lambda=</span><span class="fl">0.5</span>, <span class="dt">alpha=</span><span class="dv">1</span>), <span class="dt">col=</span><span class="st">&quot;brown&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb252-9" data-line-number="9"><span class="kw">curve</span>(<span class="kw">pareto_cdf</span>(x, <span class="dt">lambda=</span><span class="dv">1</span>, <span class="dt">alpha=</span><span class="dv">1</span>), <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>,   <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb252-10" data-line-number="10"><span class="kw">curve</span>(<span class="kw">pareto_cdf</span>(x, <span class="dt">lambda=</span><span class="fl">1.5</span>, <span class="dt">alpha=</span><span class="dv">1</span>), <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb252-11" data-line-number="11"><span class="kw">curve</span>(<span class="kw">pareto_cdf</span>(x, <span class="dt">lambda=</span><span class="dv">2</span>, <span class="dt">alpha=</span><span class="dv">1</span>), <span class="dt">col=</span><span class="st">&quot;red&quot;</span>,   <span class="dt">add=</span><span class="ot">TRUE</span> )</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:paretopdf2"></span>
<img src="DS_files/figure-html/paretopdf2-1.png" alt="Pareto Distribution (CDF)" width="70%" />
<p class="caption">
Figure 5.24: Pareto Distribution (CDF)
</p>
</div>

</div>
<div id="normal-distribution" class="section level3 hasAnchor">
<h3><span class="header-section-number">5.9.13</span> Normal distribution <a href="5.9-distributiontypes.html#normal-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Normal distribution</strong>, also called <strong>Gaussian distribution</strong>, models a <strong>continuous distribution</strong> written as:</p>
<p><span class="math display" id="eq:equate1070107">\[\begin{align}
X \sim \mathcal{N}(\mu, \sigma^2) \tag{5.113} 
\end{align}\]</span></p>
<p>The <strong>Normal PDF</strong> of a <strong>Normal distribution</strong> with <strong>support</strong> <span class="math inline">\(x \in \mathbb{R}\)</span> is expressed as:</p>
<p><span class="math display" id="eq:equate1070108">\[\begin{align}
f(x; \mu, \sigma) = P(X =  x) = \frac{1}{\sigma \sqrt{2\pi}} exp\left[-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2\right] \tag{5.114} 
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(\mu\)</span> is the average or mean of the distribution, where <span class="math inline">\(-\infty &lt; \mu &lt; \infty\)</span></li>
<li><span class="math inline">\(\sigma^2\)</span> is the variance</li>
<li><span class="math inline">\(\sigma\)</span> is the standard deviation.</li>
</ul>
<p>Note that, geometrically, <span class="math inline">\(\mu\)</span> controls the location of the <strong>bell-shaped</strong> curve, and <span class="math inline">\(\sigma\)</span> controls the shape or scale of the curve. We discuss this further in Chapter <strong>7</strong> (<strong>Bayesian Computation I</strong>) under <strong>Likelihood</strong> Subsection under <strong>Bayes Theorem</strong> Section.</p>
<p>See Figure <a href="5.5-probability-density-function-pdf.html#fig:gaussianpdf">5.8</a> for the bell-shaped curve of standard normal distribution.</p>
<p>The <span class="math inline">\(\frac{1}{\sqrt{2\pi}}\)</span> is a normalizing constant that helps bring the probability equal to one. That is because if we remove the normalizing constant, then the <strong>probability area</strong> will not integrate into one; instead, we get (<span class="math inline">\(\sqrt{2\pi}\)</span>):</p>
<p><span class="math display" id="eq:equate1070109">\[\begin{align}
\int_{-\infty}^\infty  exp\left[-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2\right] dx = \sqrt{2\pi} \tag{5.115} 
\end{align}\]</span></p>
<p>To understand the derivation, investigate <strong>Gaussian integrals with polar coordinates</strong>.</p>
<p>Now, if we add the normalizing constant based on the following integration (for continuous distribution), we get:</p>
<p><span class="math display" id="eq:equate1070110">\[\begin{align}
\frac{1}{\sqrt{2\pi}} \int_{-\infty}^\infty exp\left[-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2\right] dx =
\frac{1}{\sqrt{2\pi}} \left(\sqrt{2\pi}\right) = 1 \tag{5.116} 
\end{align}\]</span></p>
<p>On the other hand, the fraction <span class="math inline">\(\frac{1}{2}\)</span> in the exponent exists to transform the variance into a unit variance (and effectively into a unit standard deviation).</p>
<p>Additionally, the negative sign in the exponent exists to flip the quadratic parabola so that its vertex points upwards geometrically, making the shape a bell shape.</p>
<p>Finally, the exponent expression describes the shape of the curve (e.g., bell shape). If we drop the constant, this does not affect the shape or proportionality described by the exponent.</p>
<p>The <strong>Normal CDF</strong> is expressed in the below equation (wikipedia 2020), where <span class="math inline">\(x \ge 0\)</span> and <span class="math inline">\(\sigma &gt; 0\)</span>:</p>
<p><span class="math display" id="eq:equate1070111">\[\begin{align}
\mathcal{F}(x; \mu, \sigma^2) = P(X \le x) = \frac{1}{2} + \frac{1}{2} 
erf\left(  \frac{( x-\mu)}{2\sqrt{\sigma}} \right) \tag{5.117} 
\end{align}\]</span></p>
<p>where <strong>erf</strong>, <strong>error function</strong>, is written as:</p>
<p><span class="math display" id="eq:equate1070112">\[\begin{align}
erf(x) = \frac{2}{\sqrt{\pi}}\int_0^x e^{-t^2} dt \tag{5.118} 
\end{align}\]</span></p>
<p>here we can use an approximation for <strong>erf</strong>:</p>
<p><span class="math display" id="eq:equate1070113">\[\begin{align}
erf(x) \approx tanh\left(\frac{x\pi}{\sqrt{6}}\right) \tag{5.119} 
\end{align}\]</span></p>
<p>See Figure <a href="5.9-distributiontypes.html#fig:erf">5.28</a> for <strong>Gauss error function</strong>.</p>
<p>The R code below draws a scattered plot and normal distribution. See Figure <a href="5.9-distributiontypes.html#fig:statistics1">5.25</a>.</p>

<div class="sourceCode" id="cb253"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb253-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">142</span>)</a>
<a class="sourceLine" id="cb253-2" data-line-number="2"><span class="co"># Generate random values for random variable x </span></a>
<a class="sourceLine" id="cb253-3" data-line-number="3"><span class="co"># using standard normal distribution.</span></a>
<a class="sourceLine" id="cb253-4" data-line-number="4">size=<span class="dv">500</span></a>
<a class="sourceLine" id="cb253-5" data-line-number="5">x =<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n=</span>size, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb253-6" data-line-number="6"><span class="co"># Draw the scattered plot.</span></a>
<a class="sourceLine" id="cb253-7" data-line-number="7"><span class="kw">plot</span>(x, <span class="dt">lwd=</span><span class="dv">1</span>, <span class="dt">pch=</span><span class="dv">16</span>, <span class="dt">col=</span><span class="st">&quot;black&quot;</span>, <span class="dt">main=</span><span class="st">&quot;Scattered Plot&quot;</span>,</a>
<a class="sourceLine" id="cb253-8" data-line-number="8"><span class="dt">ylab=</span><span class="st">&quot;Response (Y)&quot;</span>, <span class="dt">xlab=</span><span class="st">&quot;Predictor (X)&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:statistics1"></span>
<img src="DS_files/figure-html/statistics1-1.png" alt="Normal Distribution" width="60%" />
<p class="caption">
Figure 5.25: Normal Distribution
</p>
</div>
<div class="sourceCode" id="cb254"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb254-1" data-line-number="1">breaks=<span class="dv">20</span></a>
<a class="sourceLine" id="cb254-2" data-line-number="2"><span class="co"># Draw the standard normal distribution.</span></a>
<a class="sourceLine" id="cb254-3" data-line-number="3"><span class="kw">hist</span>(x, <span class="dt">breaks=</span>breaks, <span class="dt">prob=</span><span class="ot">TRUE</span>,   <span class="dt">xlim=</span><span class="kw">range</span>(<span class="op">-</span><span class="dv">4</span>,<span class="dv">4</span>),</a>
<a class="sourceLine" id="cb254-4" data-line-number="4">       <span class="dt">main=</span><span class="st">&#39;Standard Normal Distribution&#39;</span>, <span class="dt">xlab=</span><span class="st">&#39;Standard Deviation&#39;</span>)</a>
<a class="sourceLine" id="cb254-5" data-line-number="5"><span class="kw">curve</span>(<span class="kw">dnorm</span>(x, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span><span class="dv">1</span>), <span class="dt">add=</span><span class="ot">TRUE</span>, <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:statistics2"></span>
<img src="DS_files/figure-html/statistics2-1.png" alt="Normal Distribution" width="60%" />
<p class="caption">
Figure 5.26: Normal Distribution
</p>
</div>

<p>Note that a normal distribution with mean = 0 and standard deviation = 1 is also called a <strong>unit normal</strong>.</p>
<p>For <strong>multivariate normal distribution (MVN)</strong>, we can use the following similar notation but with vectorized parameters:</p>
<p><span class="math display" id="eq:equate1070114">\[\begin{align}
X_{(p)} \sim \mathcal{N}\left(\mu_{(p)}, \Sigma_{(pxp)}\right) \tag{5.120} 
\end{align}\]</span></p>
<p><span class="math display">\[\begin{align*}
\mu_{(p)} = \left(\begin{array}{cc}\mu_1 \\ \mu_2 \\ \vdots \\ \mu_p \end{array}\right)
\ \ \ \ \ \ \
\Sigma_{(pxp)} = 
\left(\begin{array}{cccc}
\sigma^2_{11} &amp; \sigma^2_{12} &amp; \cdots &amp;\sigma^2_{1p} \\ 
\sigma^2_{21} &amp; \sigma^2_{22} &amp; \cdots &amp;\sigma^2_{2p} \\ 
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ 
\sigma^2_{p1} &amp; \sigma^2_{p2} &amp; \cdots &amp;\sigma^2_{pp} \\ 
\end{array}\right)_{pxp}
\end{align*}\]</span></p>
<p>where: <span class="math inline">\(\Sigma_{(pxp)}\)</span> is <strong>symmetric positive-definite</strong>.</p>
<p>An <strong>MVN PDF</strong> is written as:</p>
<p><span class="math display" id="eq:equate1070116" id="eq:equate1070115">\[\begin{align}
f(x_{(p)}; \mu_{(p)}, \Sigma_{(pxp)}) 
&amp;= P(X = x_{(p)}) \tag{5.121} \\
&amp;=  \frac{1}{|\Sigma_{(pxp)}|^\frac{1}{2} (2\pi)^{\frac{p}{2}}} exp\left[-\frac{1}{2}(x-\mu)^T\Sigma^{-1}_{(pxp)}( x - \mu)\right] \tag{5.122} 
\end{align}\]</span></p>
<p>For example, given a bivariate normal distribution:</p>
<p><span class="math display">\[\begin{align}
f(x_{(p)}; \mu_{(p)}, \Sigma_{(pxp)}) &amp;= 
\frac{1}{2\pi \left[\begin{array}{llll} \sigma_{11}^2 &amp; \sigma_{12}^2 \\ \sigma_{21}^2 &amp; \sigma_{22}^2 \end{array}\right]_{(2x1)}^{\frac{1}{2}}} \times \nonumber \\
&amp;\exp\left[-\frac{1}{2}
 \left[\begin{array}{l} x_1 - \mu_1 \\ x_2 - \mu_2 \end{array}\right]^T_{(2x1)}
 \left[\begin{array}{ll} \sigma_{11}^2 &amp; \sigma_{12}^2 \\ \sigma_{21}^2 &amp; \sigma_{22}^2 \end{array}\right]^{-1}_{(2x2)}
 \left[\begin{array}{l} x_1 - \mu_1 \\ x_2 - \mu_2 \end{array}\right]_{(2x1)}
\right]  \nonumber
\end{align}\]</span></p>
<p>Note that a vector <strong>x</strong> may follow a set of independent Gaussian normal distributions. Thus, we also can write this way:</p>
<p><span class="math display" id="eq:equate1070117">\[\begin{align}
f(x_{(p)}; \mu_{(p)}, \Sigma_{(pxp)}) = 
\prod_{i=1}^n
\frac{1}{ \sqrt{2\pi\sigma_i}} exp\left[-\frac{1}{2}\frac{(x_1-\mu_1)^2}{\sigma_i^2}\right] \tag{5.123} 
\end{align}\]</span></p>
<p>Here is a simple implementation of multivariate normal (MVN) distribution (specifically, bivariate):</p>

<div class="sourceCode" id="cb255"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb255-1" data-line-number="1"><span class="kw">library</span>(mvtnorm)</a>
<a class="sourceLine" id="cb255-2" data-line-number="2"><span class="kw">set.seed</span>(<span class="dv">142</span>)</a>
<a class="sourceLine" id="cb255-3" data-line-number="3">sample_size =<span class="st"> </span>n =<span class="st"> </span><span class="dv">40</span></a>
<a class="sourceLine" id="cb255-4" data-line-number="4">x =<span class="st"> </span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">5</span>,<span class="dv">5</span>, <span class="dt">length.out =</span> <span class="dv">40</span>)</a>
<a class="sourceLine" id="cb255-5" data-line-number="5">y =<span class="st"> </span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">5</span>,<span class="dv">5</span>, <span class="dt">length.out =</span> <span class="dv">40</span>)</a>
<a class="sourceLine" id="cb255-6" data-line-number="6">mu =<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>,<span class="dv">2</span>); sigma =<span class="st"> </span><span class="kw">diag</span>(<span class="dv">1</span>,<span class="dv">2</span>)</a>
<a class="sourceLine" id="cb255-7" data-line-number="7">g =<span class="st"> </span><span class="kw">expand.grid</span>(x, y)</a>
<a class="sourceLine" id="cb255-8" data-line-number="8">z &lt;-<span class="st"> </span><span class="kw">matrix</span> ( <span class="kw">dmvnorm</span>(<span class="kw">as.matrix</span>(g), <span class="dt">mean=</span>mu, <span class="dt">sigma=</span>sigma), <span class="dt">nrow =</span> n )</a>
<a class="sourceLine" id="cb255-9" data-line-number="9"><span class="kw">persp</span>(x,y,z, <span class="dt">phi=</span><span class="dv">30</span>, <span class="dt">theta=</span><span class="dv">25</span>,</a>
<a class="sourceLine" id="cb255-10" data-line-number="10">      <span class="dt">expand =</span> <span class="fl">0.5</span>, <span class="dt">shade =</span> <span class="fl">0.10</span>,</a>
<a class="sourceLine" id="cb255-11" data-line-number="11">      <span class="dt">main=</span><span class="st">&quot;Bivariate Normal Distribution&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:multinormal"></span>
<img src="embed0069.1.png" alt="Bivariate Normal Distribution" width="80%" />
<p class="caption">
Figure 5.27: Bivariate Normal Distribution
</p>
</div>

</div>
<div id="wald-distribution" class="section level3 hasAnchor">
<h3><span class="header-section-number">5.9.14</span> Wald Distribution <a href="5.9-distributiontypes.html#wald-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Wald Distribution</strong> is also known as <strong>Inverse Gaussian Distribution</strong> and is written as:</p>
<p><span class="math display" id="eq:equate1070118">\[\begin{align}
X \sim  \mathcal{IG}(\mu, \lambda) \tag{5.124} 
\end{align}\]</span></p>
<p>The <strong>Wald PDF</strong> of a <strong>Normal distribution</strong> with <strong>support</strong> <span class="math inline">\((0, \infty)\)</span> is expressed as:</p>
<p><span class="math display" id="eq:equate1070119">\[\begin{align}
f(x; \mu, \lambda) = P(X =  x) = \sqrt{\frac{\lambda}{2\pi x^3}} exp\left(-\frac{\lambda(x-\mu)^2}{2\mu^2 x}\right) \tag{5.125} 
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(\mu\)</span> is the average or mean of the distribution (location),</li>
<li><span class="math inline">\(\lambda\)</span> is the standard deviation (shape).</li>
</ul>
<p>The <strong>Wald CDF</strong> is expressed in the below equation:</p>
<p><span class="math display" id="eq:equate1070120">\[\begin{align}
\mathcal{F}(x; \mu, \lambda) = 
\Phi \left(\sqrt{\frac{\lambda}{x}}\left(\frac{x}{\mu} - 1\right) \right)
+ exp\left(\frac{2\lambda}{\mu}\right)\Phi \left(
\sqrt{\frac{\lambda}{x}}\left(\frac{x}{\mu} + 1\right)
\right) \tag{5.126} 
\end{align}\]</span></p>
<p><strong>Wald distribution</strong> tends to be a skewed <strong>Gaussian</strong> distribution, such that if <span class="math inline">\(\lambda\)</span> increases to infinity, the <strong>Wald</strong> distribution eventually becomes a <strong>Gaussian</strong> distribution.</p>
</div>
<div id="log-normal-distribution" class="section level3 hasAnchor">
<h3><span class="header-section-number">5.9.15</span> Log-normal Distribution <a href="5.9-distributiontypes.html#log-normal-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A <strong>Log-normal distribution</strong> models a <strong>continuous distribution</strong> in which the logarithm of its random variable models a <strong>Normal (Gaussian) distribution</strong> and is written as:</p>
<p><span class="math display" id="eq:equate1070121">\[\begin{align}
X \sim ln\ \mathcal{N}(\mu, \sigma^2) \tag{5.127} 
\end{align}\]</span></p>
<p>The <strong>Log-normal PDF</strong> is expressed in the below equation, where <span class="math inline">\(x \ge 0\)</span>:</p>
<p><span class="math display" id="eq:equate1070122">\[\begin{align}
f(x; \mu, \sigma^2) = \frac{1}{x\sqrt{2\pi\sigma^2}} e^{-\frac{(ln\ x-\mu)^2}{2\sigma^2}} \tag{5.128} 
\end{align}\]</span></p>
<p>The <strong>Log-normal CDF</strong> is expressed in the below equation:</p>
<p><span class="math display" id="eq:equate1070123">\[\begin{align}
\mathcal{F}(x; \mu, \sigma^2) = P(X \le x) = \frac{1}{2} + \frac{1}{2} erf\left(  \frac{ln\ x-\mu}{\sigma\sqrt{2}} \right) \tag{5.129} 
\end{align}\]</span></p>
<p>where <strong>erf</strong>, <strong>error function</strong>, is written as:</p>
<p><span class="math display" id="eq:equate1070125" id="eq:equate1070124">\[\begin{align}
erf(x) {}&amp;= \frac{2}{\sqrt{\pi}}\int_0^x e^{-t^2} dt  \tag{5.130} \\
&amp;\approx tanh\left(\frac{x\pi}{\sqrt{6}}\right) \tag{5.131} 
\end{align}\]</span></p>
<p><strong>ERF</strong> is a sigmoid function as shown in Figure <a href="5.9-distributiontypes.html#fig:erf">5.28</a>. Note that we use <strong>tanh</strong> as an approximation only to the integral equation.</p>

<div class="sourceCode" id="cb256"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb256-1" data-line-number="1">erf &lt;-<span class="st"> </span><span class="cf">function</span>(x) {</a>
<a class="sourceLine" id="cb256-2" data-line-number="2">    <span class="kw">tanh</span>(x<span class="op">*</span>pi<span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">6</span>))</a>
<a class="sourceLine" id="cb256-3" data-line-number="3">}</a>
<a class="sourceLine" id="cb256-4" data-line-number="4">x =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">length.out=</span><span class="dv">100</span>)</a>
<a class="sourceLine" id="cb256-5" data-line-number="5"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="op">-</span><span class="dv">2</span>,<span class="dv">2</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>), </a>
<a class="sourceLine" id="cb256-6" data-line-number="6">     <span class="dt">xlab=</span><span class="st">&quot;x&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;y&quot;</span>,</a>
<a class="sourceLine" id="cb256-7" data-line-number="7">     <span class="dt">main=</span><span class="st">&quot;Gauss Error Function&quot;</span>)</a>
<a class="sourceLine" id="cb256-8" data-line-number="8"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb256-9" data-line-number="9"><span class="kw">curve</span>(<span class="kw">erf</span>(x), <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>, <span class="dt">lwd=</span><span class="dv">2</span>,<span class="dt">add=</span><span class="ot">TRUE</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:erf"></span>
<img src="DS_files/figure-html/erf-1.png" alt="Gauss Error Function" width="70%" />
<p class="caption">
Figure 5.28: Gauss Error Function
</p>
</div>

<p>Note that <strong>Log-normal distribution</strong> is more advantageous over <strong>Normal distribution</strong> for situations where the distribution cannot take a negative value.</p>
<p>Below is a naive implementation of <strong>Log-normal distribution</strong> in R code:</p>

<div class="sourceCode" id="cb257"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb257-1" data-line-number="1">erf &lt;-<span class="st"> </span><span class="cf">function</span>(x, a, b ) { </a>
<a class="sourceLine" id="cb257-2" data-line-number="2">    <span class="kw">tanh</span>(x<span class="op">*</span>pi<span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">6</span>)) <span class="co"># an approximation.</span></a>
<a class="sourceLine" id="cb257-3" data-line-number="3">}</a>
<a class="sourceLine" id="cb257-4" data-line-number="4">logpdf &lt;-<span class="st"> </span><span class="cf">function</span>(x, mean, sd ) {</a>
<a class="sourceLine" id="cb257-5" data-line-number="5">    <span class="co"># Log-normal Distribution</span></a>
<a class="sourceLine" id="cb257-6" data-line-number="6">    ( <span class="dv">1</span> <span class="op">/</span><span class="st"> </span>(x<span class="op">*</span><span class="kw">sqrt</span>(<span class="dv">2</span><span class="op">*</span>pi<span class="op">*</span>sd))) <span class="op">*</span><span class="st"> </span><span class="kw">exp</span>( <span class="op">-</span><span class="st"> </span>(<span class="kw">log</span>(x)<span class="op">-</span>mean)<span class="op">^</span><span class="dv">2</span><span class="op">/</span>(<span class="dv">2</span><span class="op">*</span>sd))</a>
<a class="sourceLine" id="cb257-7" data-line-number="7">}</a>
<a class="sourceLine" id="cb257-8" data-line-number="8">logcdf &lt;-<span class="st"> </span><span class="cf">function</span>(x, mean, sd) {</a>
<a class="sourceLine" id="cb257-9" data-line-number="9">    <span class="dv">1</span><span class="op">/</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span><span class="dv">1</span><span class="op">/</span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="kw">erf</span>((<span class="kw">log</span>(x) <span class="op">-</span><span class="st"> </span>mean)<span class="op">/</span>(<span class="kw">sqrt</span>(<span class="dv">2</span><span class="op">*</span>sd)))</a>
<a class="sourceLine" id="cb257-10" data-line-number="10">}</a>
<a class="sourceLine" id="cb257-11" data-line-number="11">logarea &lt;-<span class="st"> </span><span class="cf">function</span>(x, mean, sd) {</a>
<a class="sourceLine" id="cb257-12" data-line-number="12">    a =<span class="st"> </span><span class="fl">0.01</span>; b =<span class="st"> </span>x <span class="co"># boundaries</span></a>
<a class="sourceLine" id="cb257-13" data-line-number="13">    area =<span class="st"> </span><span class="kw">seq</span>(a, b, <span class="dt">length.out=</span><span class="dv">50</span>) <span class="co"># area</span></a>
<a class="sourceLine" id="cb257-14" data-line-number="14">    x =<span class="st"> </span><span class="kw">c</span>(a, area , b)</a>
<a class="sourceLine" id="cb257-15" data-line-number="15">    y =<span class="st"> </span><span class="kw">c</span>(<span class="dv">0</span>, <span class="kw">logpdf</span>(area, <span class="dv">0</span>, <span class="dv">1</span>), <span class="dv">0</span>)</a>
<a class="sourceLine" id="cb257-16" data-line-number="16">    <span class="kw">polygon</span>(x, y, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>)</a>
<a class="sourceLine" id="cb257-17" data-line-number="17">}</a></code></pre></div>
<p>And we plot the distribution as shown in Figure <a href="5.9-distributiontypes.html#fig:lognormal">5.29</a>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:lognormal"></span>
<img src="DS_files/figure-html/lognormal-1.png" alt="Log-normal Distribution" width="70%" />
<p class="caption">
Figure 5.29: Log-normal Distribution
</p>
</div>
<div class="sourceCode" id="cb258"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb258-1" data-line-number="1"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="dv">10</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="op">-</span><span class="fl">0.01</span>,<span class="fl">0.8</span>), </a>
<a class="sourceLine" id="cb258-2" data-line-number="2">     <span class="dt">xlab=</span><span class="st">&quot;spread (variance)&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;probability density&quot;</span>,</a>
<a class="sourceLine" id="cb258-3" data-line-number="3">     <span class="dt">main=</span><span class="st">&quot;Log-normal Distribution&quot;</span> )</a>
<a class="sourceLine" id="cb258-4" data-line-number="4"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb258-5" data-line-number="5"><span class="kw">abline</span>(<span class="dt">h=</span><span class="dv">0</span>, <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>)</a>
<a class="sourceLine" id="cb258-6" data-line-number="6">p =<span class="st"> </span><span class="kw">logcdf</span>(<span class="dt">x=</span><span class="dv">4</span>, <span class="dv">0</span>, <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb258-7" data-line-number="7"><span class="kw">logarea</span>(<span class="dt">x=</span><span class="dv">4</span>, <span class="dv">0</span>, <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb258-8" data-line-number="8"><span class="kw">curve</span>(<span class="kw">logpdf</span>(x, <span class="dv">0</span>, <span class="fl">1.0</span>), <span class="dt">n=</span><span class="dv">500</span>, <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb258-9" data-line-number="9"><span class="kw">curve</span>(<span class="kw">logpdf</span>(x, <span class="dv">1</span>, <span class="fl">0.7</span>), <span class="dt">n=</span><span class="dv">500</span>, <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb258-10" data-line-number="10"><span class="kw">curve</span>(<span class="kw">logpdf</span>(x, <span class="dv">2</span>, <span class="fl">0.5</span>), <span class="dt">n=</span><span class="dv">500</span>, <span class="dt">col=</span><span class="st">&quot;brown&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb258-11" data-line-number="11"><span class="kw">text</span>(<span class="fl">1.5</span>,<span class="fl">0.09</span>, <span class="dt">label=</span><span class="st">&quot;(cdf)&quot;</span>, <span class="dt">col=</span><span class="st">&quot;black&quot;</span>)</a>
<a class="sourceLine" id="cb258-12" data-line-number="12"><span class="kw">text</span>(<span class="fl">1.5</span>, <span class="fl">0.05</span>, <span class="dt">label=</span><span class="kw">paste</span>(<span class="st">&quot;Area = &quot;</span>, <span class="kw">round</span>(p, <span class="dv">5</span>), <span class="dt">sep=</span><span class="st">&quot;&quot;</span>), </a>
<a class="sourceLine" id="cb258-13" data-line-number="13">     <span class="dt">ce=</span><span class="dv">1</span>, <span class="dt">col=</span><span class="st">&quot;black&quot;</span>)</a>
<a class="sourceLine" id="cb258-14" data-line-number="14"><span class="kw">text</span>(<span class="dv">4</span>, <span class="fl">-0.01</span>, <span class="dt">label=</span><span class="st">&quot;q=2&quot;</span>)</a></code></pre></div>

</div>
<div id="uniform-distribution" class="section level3 hasAnchor">
<h3><span class="header-section-number">5.9.16</span> Uniform Distribution <a href="5.9-distributiontypes.html#uniform-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A <strong>Uniform distribution</strong> models a <strong>continuous distribution</strong> and is written as:</p>
<p><span class="math display" id="eq:equate1070126">\[\begin{align}
X \sim U(a,b) \tag{5.132} 
\end{align}\]</span></p>
<p>The <strong>PDF</strong> for a <strong>Uniform distribution</strong> with <strong>support</strong> <span class="math inline">\(\{a,b\} \in \mathbb{R}\)</span> and <span class="math inline">\(a &lt; b\)</span> is expressed as:</p>
<p><span class="math display" id="eq:eqnnumber20">\[\begin{align}
f(x) = \begin{cases}
\frac{1}{b - a} &amp; a \le x \le b \\
0 &amp; otherwise
\end{cases} \tag{5.133}
\end{align}\]</span></p>
<p>The <strong>CDF</strong> for a <strong>Uniform distribution</strong> is expressed as:</p>
<p><span class="math display" id="eq:eqnnumber21">\[\begin{align}
F(x) = \begin{cases}
0 &amp; x &lt; a \\
1 &amp; x &gt; b \\
\frac{x-a}{b - a} &amp; otherwise
\end{cases} \tag{5.134}
\end{align}\]</span></p>
<p>For the <strong>expected value</strong> and <strong>variance</strong> respectively, we have:</p>
<p><span class="math display" id="eq:equate1070127">\[\begin{align}
\mu = \frac{a+b}{2}\ \ \ \ \ \ \ \ \ \ \ \ \ \sigma = \sqrt{\frac{(b-a)^2}{12}} \tag{5.135} 
\end{align}\]</span></p>
<p>Given the simple formula above, the <strong>PDF</strong> and <strong>CDF</strong> for <strong>Uniform distribution</strong> should be simple to implement in R code (we skip the implementation).</p>
<p>The next few sections cover <strong>T-distribution</strong>, <strong>F-distribution</strong>, <strong>Chi-Square distribution</strong>, <strong>Wishart distribution</strong>, and <strong>Mixture distribution</strong> among a few others. We introduce the <strong>CDF</strong> of the subsequent distributions, which come with complexity because of special functions such as <strong>Gamma, Beta, Continued Fraction, and HyperGeometric functions</strong>. While these complex <strong>CDFs</strong> are known or used in practice, continued efforts may still be ongoing to explore better alternatives.</p>
</div>
<div id="t-distribution" class="section level3 hasAnchor">
<h3><span class="header-section-number">5.9.17</span> T-Distribution <a href="5.9-distributiontypes.html#t-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A <strong>T-distribution</strong>, also called <strong>Student’s distribution</strong>, models a <strong>continuous distribution</strong> sampled from a <strong>Normal distribution</strong> and is written as:</p>
<p><span class="math display" id="eq:equate1070128">\[\begin{align}
X_s \sim T(\nu)\ \ \ \ \leftarrow\ \ \ \ \ X_p \sim iid\ N(\mu, \sigma^2) \tag{5.136} 
\end{align}\]</span></p>
<p>The <strong>T-distribution</strong> is used for <strong>T-statistic tests</strong> to analyze samples of data with smaller sample size - typical suggested size is 30 or less. We discuss the <strong>T-Test</strong> in later sections.  </p>
<p>It can be said that a <strong>T-distribution</strong> is independently and identically distributed as a <strong>normal distribution</strong> whose <strong>PDF</strong> follows a much shorter and fatter curve.</p>
<p>The <strong>PDF</strong> for a <strong>T-distribution</strong> with <strong>support</strong> <span class="math inline">\(x \in \mathbb{R}\)</span> is expressed as:</p>
<p><span class="math display" id="eq:equate1070129">\[\begin{align}
f(x; \nu) = \frac{1} {\Gamma(\frac{\nu}{2})\sqrt{\nu\pi}} 
\Gamma\left(\frac{\nu+1}{2}\right) \left(1 + \frac{x^2}{\nu}\right)^{-\frac{\nu+1}{2}} \tag{5.137} 
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(\nu\)</span> is the degrees of freedom.</li>
</ul>
<p>Here is a naive implementation of <strong>PDF</strong> for a symmetric (central) <strong>T-Distribution</strong> in R code:</p>

<div class="sourceCode" id="cb259"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb259-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">1</span>)</a>
<a class="sourceLine" id="cb259-2" data-line-number="2">Gamma &lt;-<span class="st"> </span><span class="cf">function</span>(n) { <span class="kw">factorial</span>(n<span class="dv">-1</span>) }</a>
<a class="sourceLine" id="cb259-3" data-line-number="3">t_pdf &lt;-<span class="st"> </span><span class="cf">function</span>(x, df) {</a>
<a class="sourceLine" id="cb259-4" data-line-number="4">    <span class="kw">Gamma</span>((df<span class="op">+</span><span class="dv">1</span>)<span class="op">/</span><span class="dv">2</span>) <span class="op">/</span><span class="st"> </span>( <span class="kw">Gamma</span>(df<span class="op">/</span><span class="dv">2</span>) <span class="op">*</span><span class="st"> </span><span class="kw">sqrt</span>(df <span class="op">*</span><span class="st"> </span>pi) ) <span class="op">*</span><span class="st"> </span></a>
<a class="sourceLine" id="cb259-5" data-line-number="5"><span class="st">    </span>( <span class="dv">1</span> <span class="op">+</span><span class="st"> </span>x<span class="op">^</span><span class="dv">2</span><span class="op">/</span>df )<span class="op">^</span>(<span class="op">-</span>(df<span class="op">+</span><span class="dv">1</span>)<span class="op">/</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb259-6" data-line-number="6">}</a>
<a class="sourceLine" id="cb259-7" data-line-number="7">population =<span class="st"> </span><span class="kw">round</span>(<span class="kw">seq</span>(<span class="dv">4</span>,<span class="dv">7</span>, <span class="dt">length.out=</span><span class="dv">10</span>),<span class="dv">1</span>)</a>
<a class="sourceLine" id="cb259-8" data-line-number="8">x =<span class="st"> </span><span class="kw">sample</span>(population, <span class="dt">size=</span><span class="dv">20</span>, <span class="dt">replace=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb259-9" data-line-number="9"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="op">-</span><span class="dv">4</span>,<span class="dv">4</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="fl">0.5</span>), </a>
<a class="sourceLine" id="cb259-10" data-line-number="10">     <span class="dt">xlab=</span><span class="st">&quot;T value&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;probability density&quot;</span>,</a>
<a class="sourceLine" id="cb259-11" data-line-number="11">     <span class="dt">main=</span><span class="st">&quot;T Distribution (PDF)&quot;</span>)</a>
<a class="sourceLine" id="cb259-12" data-line-number="12"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb259-13" data-line-number="13"><span class="kw">curve</span>(<span class="kw">dnorm</span>(x, <span class="dv">0</span>, <span class="dv">1</span>), <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb259-14" data-line-number="14"><span class="kw">curve</span>(<span class="kw">t_pdf</span>(x, <span class="dv">10</span>), <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb259-15" data-line-number="15"><span class="kw">curve</span>(<span class="kw">t_pdf</span>(x, <span class="dv">2</span>), <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb259-16" data-line-number="16"><span class="kw">curve</span>(<span class="kw">t_pdf</span>(x, <span class="dv">1</span>), <span class="dt">col=</span><span class="st">&quot;brown&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">add=</span><span class="ot">TRUE</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:tdist"></span>
<img src="DS_files/figure-html/tdist-1.png" alt="T-Distribution (PDF)" width="70%" />
<p class="caption">
Figure 5.30: T-Distribution (PDF)
</p>
</div>

<p>It can be noticed that as the degree of freedom, <span class="math inline">\(\mathbf{\nu}\)</span>, gets larger, the <strong>T-distribution</strong> gets closer to that of a <strong>Normal distribution</strong> based on <strong>PDF</strong>.</p>
<p>The <strong>CDF</strong> for a symmetric (central) <strong>T-distribution</strong> is expressed as:</p>
<p><span class="math display" id="eq:equate1070130">\[\begin{align}
F(x; \nu) = \frac{1}{2} + \frac{1}{2} sign(x) \left[
I\left(1; \frac{\nu}{2},\frac{1}{2}\right) -  
I\left(\frac{\nu}{\nu + x^2}; \frac{\nu}{2},\frac{1}{2}\right) \right] \tag{5.138} 
\end{align}\]</span></p>
<p>where:</p>
<p><span class="math display" id="eq:equate1070131">\[\begin{align}
I_x(\alpha,\beta) = \frac{\mathcal{B}_x(\alpha,\beta)}{\mathcal{B}(\alpha,\beta)}\ \ \leftarrow\ \ \text{regularized beta function} \tag{5.139} 
\end{align}\]</span></p>
<p>Moreover, as complementary, we can explore the use of <strong>continued fraction</strong> for <strong>regularized beta function</strong> instead of <strong>hypergeometric function</strong>.</p>
<p>Example, if x &lt; (a+1) / (a+b+2):</p>
<p><span class="math display" id="eq:equate1070132">\[\begin{align}
Bx(\alpha,\beta) = \frac{ Kx(\alpha,\beta) }{a} \left[1+\frac{d_1}{1+}\frac{d_2}{1+}\frac{d_3}{1+}...\right] \tag{5.140} 
\end{align}\]</span></p>
<p>where:</p>
<p><span class="math display" id="eq:equate1070133">\[\begin{align}
Kx(\alpha,\beta) = \frac{1}{\mathcal{B}(\alpha,\beta)}x^\alpha(1-x)^\beta  \tag{5.141} 
\end{align}\]</span></p>
<p>and</p>
<p><span class="math display" id="eq:equate1070134">\[\begin{align}
d_{2m} = \frac{m(\beta-m)x}{(\alpha+2m - 1)(\alpha+2m)}\ \ \ \ \ \ \ \ \
d_{2m+1} =  -\frac{(\alpha+m)(\alpha+\beta+m)x}{(\alpha+2m)(\alpha+2m+1)} \tag{5.142} 
\end{align}\]</span></p>
<p>Let us first show an implementation of <strong>continued fraction</strong> in R code (see Numerical Recipes (W.H. Press et al., 1992) in C code): </p>

<div class="sourceCode" id="cb260"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb260-1" data-line-number="1">Gamma &lt;-<span class="st"> </span><span class="cf">function</span>(n) { <span class="kw">factorial</span>(n<span class="dv">-1</span>) }</a>
<a class="sourceLine" id="cb260-2" data-line-number="2">Beta &lt;-<span class="st"> </span><span class="cf">function</span>(a,b) { <span class="kw">Gamma</span>(a)<span class="op">*</span><span class="kw">Gamma</span>(b) <span class="op">/</span><span class="st"> </span><span class="kw">Gamma</span>(a<span class="op">+</span>b)}</a>
<a class="sourceLine" id="cb260-3" data-line-number="3">even &lt;-<span class="st"> </span><span class="cf">function</span>(x, a, b, m) {</a>
<a class="sourceLine" id="cb260-4" data-line-number="4">  (m<span class="op">*</span>(b<span class="op">-</span>m)<span class="op">*</span>x) <span class="op">/</span><span class="st"> </span>((a <span class="op">+</span><span class="st"> </span><span class="dv">2</span><span class="op">*</span>m <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)<span class="op">*</span>(a<span class="op">+</span><span class="dv">2</span><span class="op">*</span>m))</a>
<a class="sourceLine" id="cb260-5" data-line-number="5">}</a>
<a class="sourceLine" id="cb260-6" data-line-number="6">odd &lt;-<span class="st"> </span><span class="cf">function</span>(x, a, b, m) {</a>
<a class="sourceLine" id="cb260-7" data-line-number="7">  <span class="op">-</span>((a<span class="op">+</span>m)<span class="op">*</span>(a<span class="op">+</span>b<span class="op">+</span>m)<span class="op">*</span>x) <span class="op">/</span><span class="st"> </span>((a<span class="op">+</span><span class="dv">2</span><span class="op">*</span>m)<span class="op">*</span>(a<span class="op">+</span><span class="dv">2</span><span class="op">*</span>m<span class="op">+</span><span class="dv">1</span>))</a>
<a class="sourceLine" id="cb260-8" data-line-number="8">}</a>
<a class="sourceLine" id="cb260-9" data-line-number="9">tiny &lt;-<span class="st"> </span><span class="cf">function</span>(z) {</a>
<a class="sourceLine" id="cb260-10" data-line-number="10">    eps =<span class="st"> </span><span class="fl">1e-30</span></a>
<a class="sourceLine" id="cb260-11" data-line-number="11">    <span class="cf">if</span> (z <span class="op">&lt;</span><span class="st"> </span>eps) { <span class="kw">return</span>(eps) }</a>
<a class="sourceLine" id="cb260-12" data-line-number="12">    z</a>
<a class="sourceLine" id="cb260-13" data-line-number="13">}</a>
<a class="sourceLine" id="cb260-14" data-line-number="14">betacf &lt;-<span class="st"> </span><span class="cf">function</span>(x, a, b, m) {</a>
<a class="sourceLine" id="cb260-15" data-line-number="15">    limit =<span class="st"> </span><span class="dv">200</span></a>
<a class="sourceLine" id="cb260-16" data-line-number="16">    epsilon =<span class="st"> </span><span class="fl">3e-14</span></a>
<a class="sourceLine" id="cb260-17" data-line-number="17">    c =<span class="st"> </span><span class="dv">1</span></a>
<a class="sourceLine" id="cb260-18" data-line-number="18">    d =<span class="st"> </span><span class="dv">1</span> <span class="op">/</span><span class="st"> </span><span class="kw">tiny</span>(<span class="dv">1</span><span class="op">-</span>(a<span class="op">+</span>b)<span class="op">*</span>x<span class="op">/</span>(a<span class="op">+</span><span class="dv">1</span>)) </a>
<a class="sourceLine" id="cb260-19" data-line-number="19">    cf =<span class="st"> </span>d</a>
<a class="sourceLine" id="cb260-20" data-line-number="20">    <span class="cf">for</span> (m <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>limit) {</a>
<a class="sourceLine" id="cb260-21" data-line-number="21">       num =<span class="st"> </span><span class="kw">even</span>(x, a, b, m)</a>
<a class="sourceLine" id="cb260-22" data-line-number="22">       d =<span class="st"> </span><span class="dv">1</span> <span class="op">/</span><span class="st"> </span><span class="kw">tiny</span>(<span class="dv">1</span><span class="op">+</span>num <span class="op">*</span><span class="st"> </span>d ) </a>
<a class="sourceLine" id="cb260-23" data-line-number="23">       c =<span class="st"> </span><span class="kw">tiny</span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>num <span class="op">/</span><span class="st"> </span>c)</a>
<a class="sourceLine" id="cb260-24" data-line-number="24">       cf =<span class="st"> </span>cf <span class="op">*</span><span class="st"> </span>d<span class="op">*</span>c</a>
<a class="sourceLine" id="cb260-25" data-line-number="25">       num =<span class="st"> </span><span class="kw">odd</span>(x, a, b, m)</a>
<a class="sourceLine" id="cb260-26" data-line-number="26">       d =<span class="st"> </span><span class="dv">1</span> <span class="op">/</span><span class="st"> </span><span class="kw">tiny</span>(<span class="dv">1</span><span class="op">+</span>num <span class="op">*</span><span class="st"> </span>d ) </a>
<a class="sourceLine" id="cb260-27" data-line-number="27">       c =<span class="st"> </span><span class="kw">tiny</span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>num<span class="op">/</span>c)</a>
<a class="sourceLine" id="cb260-28" data-line-number="28">       cf =<span class="st"> </span>cf <span class="op">*</span><span class="st"> </span>d<span class="op">*</span>c</a>
<a class="sourceLine" id="cb260-29" data-line-number="29">       <span class="cf">if</span> (<span class="kw">abs</span>(d<span class="op">*</span>c<span class="dv">-1</span>) <span class="op">&lt;</span><span class="st"> </span>epsilon) {</a>
<a class="sourceLine" id="cb260-30" data-line-number="30">           <span class="kw">return</span>(cf)</a>
<a class="sourceLine" id="cb260-31" data-line-number="31">       }</a>
<a class="sourceLine" id="cb260-32" data-line-number="32">    }</a>
<a class="sourceLine" id="cb260-33" data-line-number="33">    <span class="kw">return</span> (<span class="ot">Inf</span>)</a>
<a class="sourceLine" id="cb260-34" data-line-number="34">}</a>
<a class="sourceLine" id="cb260-35" data-line-number="35">Bx &lt;-<span class="st"> </span><span class="cf">function</span>(x, a, b) {</a>
<a class="sourceLine" id="cb260-36" data-line-number="36">   n =<span class="st"> </span><span class="kw">length</span>(x)</a>
<a class="sourceLine" id="cb260-37" data-line-number="37">   bx =<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, n)</a>
<a class="sourceLine" id="cb260-38" data-line-number="38">   <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n) {</a>
<a class="sourceLine" id="cb260-39" data-line-number="39">     <span class="cf">if</span> (x[i] <span class="op">&lt;</span><span class="st"> </span><span class="dv">0</span> <span class="op">||</span><span class="st"> </span>x[i] <span class="op">&gt;</span><span class="st"> </span><span class="dv">1</span>) {bx[i] =<span class="st"> </span><span class="dv">0</span>; <span class="cf">next</span>  }</a>
<a class="sourceLine" id="cb260-40" data-line-number="40">     k =<span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb260-41" data-line-number="41">     <span class="cf">if</span> ( <span class="dv">0</span> <span class="op">&lt;</span><span class="st"> </span>x[i] <span class="op">&amp;&amp;</span><span class="st"> </span>x[i] <span class="op">&lt;</span><span class="st"> </span><span class="dv">1</span> ) {</a>
<a class="sourceLine" id="cb260-42" data-line-number="42">        k =<span class="st"> </span><span class="dv">1</span> <span class="op">/</span><span class="st"> </span><span class="kw">Beta</span>(a,b) <span class="op">*</span><span class="st"> </span>(x[i]<span class="op">^</span>a <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span><span class="op">-</span>x[i])<span class="op">^</span>(b) )</a>
<a class="sourceLine" id="cb260-43" data-line-number="43">     }</a>
<a class="sourceLine" id="cb260-44" data-line-number="44">     <span class="cf">if</span> (x[i] <span class="op">&lt;</span><span class="st"> </span>(a<span class="op">+</span><span class="dv">1</span>) <span class="op">/</span><span class="st"> </span>(a<span class="op">+</span>b<span class="op">+</span><span class="dv">2</span>)) {</a>
<a class="sourceLine" id="cb260-45" data-line-number="45">        <span class="co"># For I(x, a, b)</span></a>
<a class="sourceLine" id="cb260-46" data-line-number="46">        bx[i] =<span class="st"> </span>(k <span class="op">/</span><span class="st"> </span>a <span class="op">*</span><span class="st"> </span><span class="kw">betacf</span>( x[i], a, b, <span class="dv">1</span>))<span class="op">*</span><span class="kw">Beta</span>(a,b)</a>
<a class="sourceLine" id="cb260-47" data-line-number="47">     } <span class="cf">else</span> {</a>
<a class="sourceLine" id="cb260-48" data-line-number="48">        <span class="co"># For I(1-x, b, a)</span></a>
<a class="sourceLine" id="cb260-49" data-line-number="49">        bx[i] =<span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>k <span class="op">/</span><span class="st"> </span>b <span class="op">*</span><span class="st"> </span><span class="kw">betacf</span>( <span class="dv">1</span><span class="op">-</span>x[i], b, a, <span class="dv">1</span>))<span class="op">*</span><span class="kw">Beta</span>(a,b)</a>
<a class="sourceLine" id="cb260-50" data-line-number="50">     }</a>
<a class="sourceLine" id="cb260-51" data-line-number="51">   }</a>
<a class="sourceLine" id="cb260-52" data-line-number="52">   <span class="kw">return</span>(bx)</a>
<a class="sourceLine" id="cb260-53" data-line-number="53">}</a>
<a class="sourceLine" id="cb260-54" data-line-number="54"><span class="co"># replaces original implementation from beta distribution section</span></a>
<a class="sourceLine" id="cb260-55" data-line-number="55">Ix &lt;-<span class="st"> </span><span class="cf">function</span>(x, a, b) { </a>
<a class="sourceLine" id="cb260-56" data-line-number="56">   <span class="kw">Bx</span>(x, a, b) <span class="op">/</span><span class="st"> </span><span class="kw">Beta</span>(a, b)</a>
<a class="sourceLine" id="cb260-57" data-line-number="57">}</a>
<a class="sourceLine" id="cb260-58" data-line-number="58">incomplete_beta &lt;-<span class="st"> </span><span class="cf">function</span>(x,a,b) { </a>
<a class="sourceLine" id="cb260-59" data-line-number="59">    <span class="kw">pbeta</span>(x,a,b) <span class="op">*</span><span class="st"> </span><span class="kw">beta</span>(a,b) <span class="co"># using built-in R package &quot;pbeta&quot;.</span></a>
<a class="sourceLine" id="cb260-60" data-line-number="60">}</a>
<a class="sourceLine" id="cb260-61" data-line-number="61">Ix_alt &lt;-<span class="cf">function</span>(x, a, b) { <span class="co"># see beta distribution chapter</span></a>
<a class="sourceLine" id="cb260-62" data-line-number="62">   <span class="kw">incomplete_beta</span>(x,a,b) <span class="op">/</span><span class="st"> </span><span class="kw">Beta</span>(a,b)</a>
<a class="sourceLine" id="cb260-63" data-line-number="63">}</a>
<a class="sourceLine" id="cb260-64" data-line-number="64">x =<span class="st"> </span><span class="kw">c</span>(<span class="fl">0.50</span>, <span class="fl">-0.50</span>)</a>
<a class="sourceLine" id="cb260-65" data-line-number="65"><span class="kw">list</span>(<span class="st">&quot;Ix&quot;</span>=<span class="kw">Ix</span>(x, <span class="dv">3</span>, <span class="dv">2</span>), <span class="st">&quot;pbeta&quot;</span>=<span class="kw">pbeta</span>(x, <span class="dv">3</span>, <span class="dv">2</span>))</a></code></pre></div>
<pre><code>## $Ix
## [1] 0.3125 0.0000
## 
## $pbeta
## [1] 0.3125 0.0000</code></pre>
<div class="sourceCode" id="cb262"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb262-1" data-line-number="1"><span class="kw">list</span>(<span class="st">&quot;Ix&quot;</span>=<span class="kw">Ix</span>(x, <span class="dv">2</span>, <span class="dv">3</span>), <span class="st">&quot;pbeta&quot;</span>=<span class="kw">pbeta</span>(x, <span class="dv">2</span>, <span class="dv">3</span>))</a></code></pre></div>
<pre><code>## $Ix
## [1] 0.6875 0.0000
## 
## $pbeta
## [1] 0.6875 0.0000</code></pre>

<p>Note that to avoid overflows or underflows, or to avoid using multiplication and division, we use exponential and logarithmic functions (as shown in the original C code from Numerical Recipes). So that for the constant, K, we have:</p>
<p><span class="math display" id="eq:equate1070135">\[\begin{align}
Kx(\alpha,\beta) {}&amp;= exp( log(\Gamma(\alpha)) -  log(\Gamma(\beta)) 
- log(\Gamma(\alpha +\beta)) \nonumber \\
&amp;+ a \times log(x) + b \times log(1-x)) \tag{5.143} 
\end{align}\]</span></p>
<p>However, in our R code, we intentionally use the original beta function instead of the exponential and logarithmic function to focus on the notation.</p>
<p><span class="math display" id="eq:equate1070136">\[\begin{align}
\mathcal{K}x(\alpha,\beta) = \frac{1}{\mathcal{B}(\alpha,\beta)}x^\alpha(1-x)^\beta  \tag{5.144} 
\end{align}\]</span></p>
<p>Also, the <strong>regular beta function</strong> keeps the common notation in the R code:</p>
<p><span class="math display" id="eq:equate1070137">\[\begin{align}
\mathcal{I}_x(\alpha,\beta) = \frac{ \mathcal{B}_x(\alpha,\beta) }{ \mathcal{B}(\alpha, \beta)} \tag{5.145} 
\end{align}\]</span></p>
<p>Given all that, here is a naive implementation of <strong>CDF</strong> for <strong>T-Distribution</strong> in R code:</p>

<div class="sourceCode" id="cb264"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb264-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">1</span>)</a>
<a class="sourceLine" id="cb264-2" data-line-number="2">t_cdf  &lt;-<span class="st"> </span><span class="cf">function</span>(x, df) {</a>
<a class="sourceLine" id="cb264-3" data-line-number="3">  <span class="dv">1</span><span class="op">/</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span><span class="dv">1</span><span class="op">/</span><span class="dv">2</span> <span class="op">*</span><span class="st">  </span><span class="kw">sign</span>(x) <span class="op">*</span><span class="st"> </span></a>
<a class="sourceLine" id="cb264-4" data-line-number="4"><span class="st">               </span>( <span class="kw">Ix</span>(<span class="dv">1</span>,df<span class="op">/</span><span class="dv">2</span>, <span class="dv">1</span><span class="op">/</span><span class="dv">2</span>) <span class="op">-</span><span class="st"> </span><span class="kw">Ix</span>(df<span class="op">/</span>(df<span class="op">+</span>x<span class="op">^</span><span class="dv">2</span>), df<span class="op">/</span><span class="dv">2</span>, <span class="dv">1</span><span class="op">/</span><span class="dv">2</span>) ) </a>
<a class="sourceLine" id="cb264-5" data-line-number="5">}</a>
<a class="sourceLine" id="cb264-6" data-line-number="6">population =<span class="st"> </span><span class="kw">round</span>(<span class="kw">seq</span>(<span class="dv">4</span>,<span class="dv">7</span>, <span class="dt">length.out=</span><span class="dv">10</span>),<span class="dv">1</span>)</a>
<a class="sourceLine" id="cb264-7" data-line-number="7">x =<span class="st"> </span><span class="kw">sample</span>(population, <span class="dt">size=</span><span class="dv">20</span>, <span class="dt">replace=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb264-8" data-line-number="8"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="op">-</span><span class="dv">5</span>,<span class="dv">5</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="dv">1</span>), </a>
<a class="sourceLine" id="cb264-9" data-line-number="9">     <span class="dt">xlab=</span><span class="st">&quot;T value&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;cumulative probability&quot;</span>,</a>
<a class="sourceLine" id="cb264-10" data-line-number="10">     <span class="dt">main=</span><span class="st">&quot;T Distribution (CDF)&quot;</span>)</a>
<a class="sourceLine" id="cb264-11" data-line-number="11"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb264-12" data-line-number="12"><span class="kw">curve</span>(<span class="kw">pnorm</span>(x, <span class="dv">0</span>, <span class="dv">1</span>), <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>, <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb264-13" data-line-number="13"><span class="kw">curve</span>(<span class="kw">t_cdf</span>(x, <span class="dv">10</span>), <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb264-14" data-line-number="14"><span class="kw">curve</span>(<span class="kw">t_cdf</span>(x, <span class="dv">2</span>), <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb264-15" data-line-number="15"><span class="kw">curve</span>(<span class="kw">t_cdf</span>(x, <span class="dv">1</span>), <span class="dt">col=</span><span class="st">&quot;brown&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">add=</span><span class="ot">TRUE</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:ptdist"></span>
<img src="DS_files/figure-html/ptdist-1.png" alt="T-Distribution (CDF)" width="70%" />
<p class="caption">
Figure 5.31: T-Distribution (CDF)
</p>
</div>

<p>An alternative solution to the <strong>CDF</strong> for the <strong>T-distribution</strong> uses the <strong>Hypergeometric function</strong> as follows:</p>
<p><span class="math display" id="eq:equate1070139" id="eq:equate1070138">\[\begin{align}
{}_2F_1(a,b;c; x) {}&amp;= (1-x)^{-b} {}_2F_1\left(c-a,b;c; z\right)
\ \ \ \ \ where\ \ \ z = \frac{x}{x-1} \tag{5.146} \\
&amp;= 
\frac{1}{(1-x)^{b}}\sum_{n=0}^\infty\frac{(c-a)_n (b)_n}{(c)_n} \frac{z^n}{n!} \tag{5.147} 
\end{align}\]</span></p>
<p>Note that we use the first transformation form of the <strong>Hypergeometric function</strong> as listed in Chapter <strong>5</strong> (<strong>Probability and Distribution</strong>) under the <strong>Special Functions</strong> Section:</p>
<p>Also, note that we use the <strong>Rising Factorial</strong> for the symbol <span class="math inline">\((...)_n\)</span>. </p>
<p>Here is a naive implementation of the <strong>Hypergeometric function</strong> for our t-distribution <strong>CDF</strong> (Note that in this implementation, the alternative function, <strong>t_cdf_alt</strong>, is limited to the t-distribution support range, <span class="math inline">\(-4 \le x \le 4\)</span>): </p>

<div class="sourceCode" id="cb265"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb265-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">1</span>)</a>
<a class="sourceLine" id="cb265-2" data-line-number="2">Gamma &lt;-<span class="st"> </span><span class="cf">function</span>(n) { <span class="kw">factorial</span>(n<span class="dv">-1</span>) }</a>
<a class="sourceLine" id="cb265-3" data-line-number="3">rise_factorial &lt;-<span class="st"> </span><span class="cf">function</span>(x, n) {</a>
<a class="sourceLine" id="cb265-4" data-line-number="4">    <span class="cf">if</span> (n<span class="op">==</span><span class="dv">0</span>) <span class="kw">return</span>(<span class="dv">1</span>)</a>
<a class="sourceLine" id="cb265-5" data-line-number="5">    prod =<span class="st"> </span><span class="dv">1</span></a>
<a class="sourceLine" id="cb265-6" data-line-number="6">    <span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">0</span><span class="op">:</span>(n<span class="dv">-1</span>)) {</a>
<a class="sourceLine" id="cb265-7" data-line-number="7">        prod =<span class="st"> </span>prod <span class="op">*</span><span class="st"> </span>(x <span class="op">+</span><span class="st"> </span>k)</a>
<a class="sourceLine" id="cb265-8" data-line-number="8">    }</a>
<a class="sourceLine" id="cb265-9" data-line-number="9">    prod</a>
<a class="sourceLine" id="cb265-10" data-line-number="10">}</a>
<a class="sourceLine" id="cb265-11" data-line-number="11">hypergeometric  &lt;-<span class="st"> </span><span class="cf">function</span>(a, b, c, x) { <span class="co"># only for 2F1(a,b;c;x)</span></a>
<a class="sourceLine" id="cb265-12" data-line-number="12">    hyperG_1st_form =<span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb265-13" data-line-number="13">    limit =<span class="st"> </span><span class="dv">50</span></a>
<a class="sourceLine" id="cb265-14" data-line-number="14">    z =<span class="st"> </span>x <span class="op">/</span><span class="st"> </span>( x <span class="op">-</span><span class="st"> </span><span class="dv">1</span>) </a>
<a class="sourceLine" id="cb265-15" data-line-number="15">    <span class="cf">for</span> (n <span class="cf">in</span>  <span class="dv">0</span><span class="op">:</span>limit) {</a>
<a class="sourceLine" id="cb265-16" data-line-number="16">        hyperG_1st_form =<span class="st"> </span>hyperG_1st_form <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb265-17" data-line-number="17"><span class="st">        </span>(( <span class="kw">rise_factorial</span>(c<span class="op">-</span>a , n) <span class="op">*</span><span class="st"> </span><span class="kw">rise_factorial</span>(b, n) ) <span class="op">/</span><span class="st"> </span></a>
<a class="sourceLine" id="cb265-18" data-line-number="18"><span class="st">           </span><span class="kw">rise_factorial</span>(c, n)) <span class="op">*</span><span class="st"> </span>( z<span class="op">^</span>n <span class="op">/</span><span class="st"> </span><span class="kw">factorial</span>(n))</a>
<a class="sourceLine" id="cb265-19" data-line-number="19">    }</a>
<a class="sourceLine" id="cb265-20" data-line-number="20">    hyperG_1st_form <span class="op">/</span><span class="st"> </span>(<span class="dv">1</span><span class="op">-</span>x)<span class="op">^</span>b</a>
<a class="sourceLine" id="cb265-21" data-line-number="21">}</a>
<a class="sourceLine" id="cb265-22" data-line-number="22">t_cdf_alt &lt;-<span class="st"> </span><span class="cf">function</span>(x, df) {</a>
<a class="sourceLine" id="cb265-23" data-line-number="23">   <span class="dv">1</span><span class="op">/</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span>x <span class="op">*</span><span class="st"> </span><span class="kw">Gamma</span>((df<span class="op">+</span><span class="dv">1</span>)<span class="op">/</span><span class="dv">2</span>) <span class="op">/</span><span class="st"> </span>( <span class="kw">Gamma</span>(df<span class="op">/</span><span class="dv">2</span>) <span class="op">*</span><span class="st"> </span><span class="kw">sqrt</span>(df <span class="op">*</span><span class="st"> </span>pi) ) <span class="op">*</span><span class="st"> </span></a>
<a class="sourceLine" id="cb265-24" data-line-number="24"><span class="st">   </span><span class="kw">hypergeometric</span>(<span class="dv">1</span><span class="op">/</span><span class="dv">2</span>, (df<span class="op">+</span><span class="dv">1</span>)<span class="op">/</span><span class="dv">2</span>, <span class="dv">3</span><span class="op">/</span><span class="dv">2</span>, <span class="op">-</span>(x<span class="op">^</span><span class="dv">2</span><span class="op">/</span>df)) </a>
<a class="sourceLine" id="cb265-25" data-line-number="25">}</a></code></pre></div>

<p>Now in terms of the <strong>expected value</strong> and <strong>variance</strong> respectively, we have:</p>
<p><span class="math display" id="eq:equate1070140">\[\begin{align}
\mu = 0\ \ \ \ \ \ \ \ \ \ \ \ \ \sigma = \frac{v}{v-2} \tag{5.148} 
\end{align}\]</span></p>
<p>We leave readers to investigate the non-central (asymmetric) <strong>T-distribution</strong>.</p>
</div>
<div id="f-distribution" class="section level3 hasAnchor">
<h3><span class="header-section-number">5.9.18</span> F-Distribution <a href="5.9-distributiontypes.html#f-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>An <strong>F-distribution</strong>, also known as <strong>Fisher-Snedecor distribution</strong>, models a <strong>continuous distribution</strong> and is written as:</p>
<p><span class="math display" id="eq:equate1070141">\[\begin{align}
X \sim F(\nu_1, \nu_2) \tag{5.149} 
\end{align}\]</span></p>
<p>The distribution is used for <strong>F-statistic test</strong> by comparing two populations which we discuss in later section.  </p>
<p>The <strong>PDF</strong> for an <strong>F-distribution</strong> with <strong>support</strong> <span class="math inline">\(x \ge 0\)</span> is expressed as:</p>
<p><span class="math display" id="eq:equate1070143" id="eq:equate1070142">\[\begin{align}
f(x; \nu_1, \nu_2) {}&amp;= 
\left[
\Gamma\left(\frac{\nu_1 + \nu_2}{2}\right)
\nu_1^{\frac{\nu_1}{2}}  \nu_2^{\frac{\nu_2}{2}}  x^{\frac{\nu_1}{2} - 1}
 \right]
\left[
\Gamma\left(\frac{\nu_1}{2}\right) \Gamma\left(\frac{\nu_2}{2}\right) 
( \nu_1  x + \nu_2)^{\frac{\nu1 + \nu_2}{2}}
\right]^{-1}  \tag{5.150} \\
&amp;=\left[
\nu_1^{\frac{\nu_1}{2}}  \nu_2^{\frac{\nu_2}{2}}  x^{\frac{\nu_1}{2} - 1}
 \right]
\left[
B\left(\frac{\nu_1}{2},  \frac{\nu_2}{2} \right) 
( \nu_1  x + \nu_2)^{\frac{\nu1 + \nu_2}{2}}
\right]^{-1}  \tag{5.151} 
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(\nu_1\ and\ \nu_2\)</span> are the degrees of freedom.</li>
</ul>
<p>The <strong>CDF</strong> for an <strong>F-distribution</strong> with <strong>support</strong> <span class="math inline">\(x \ge 0\)</span> is expressed as:</p>
<p><span class="math display" id="eq:equate1070144">\[\begin{align}
F(x; \nu_1, \nu_2)  = I_z(\alpha, \beta) = I(z; \alpha, \beta)\ \ \rightarrow\ \ \text{regularized beta function} \tag{5.152} 
\end{align}\]</span></p>
<p>where:</p>
<p><span class="math display" id="eq:equate1070145">\[\begin{align}
z = \left(\frac{\nu_1 x}{\nu_1 x + \nu_2}\right) \tag{5.153} 
\end{align}\]</span></p>
<p>Here is a naive implementation of <strong>PDF</strong> and <strong>CDF</strong> for <strong>F-distribution</strong> in R code (Note that we use the built-in R package <strong>pbeta()</strong> for the regularized beta function):</p>

<div class="sourceCode" id="cb266"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb266-1" data-line-number="1">Gamma &lt;-<span class="st"> </span><span class="cf">function</span>(n) {<span class="kw">factorial</span>(n<span class="dv">-1</span>)}</a>
<a class="sourceLine" id="cb266-2" data-line-number="2">Beta &lt;-<span class="st"> </span><span class="cf">function</span>(a, b) {</a>
<a class="sourceLine" id="cb266-3" data-line-number="3">    ( <span class="kw">Gamma</span>(a) <span class="op">*</span><span class="st"> </span><span class="kw">Gamma</span>(b)) <span class="op">/</span><span class="st"> </span><span class="kw">Gamma</span>(a<span class="op">+</span>b)</a>
<a class="sourceLine" id="cb266-4" data-line-number="4">}</a>
<a class="sourceLine" id="cb266-5" data-line-number="5">f_pdf &lt;-<span class="st"> </span><span class="cf">function</span>(x, df1, df2) {</a>
<a class="sourceLine" id="cb266-6" data-line-number="6">   n =<span class="st">  </span>df1<span class="op">^</span>(df1<span class="op">/</span><span class="dv">2</span>) <span class="op">*</span><span class="st"> </span>df2<span class="op">^</span>(df2<span class="op">/</span><span class="dv">2</span>) <span class="op">*</span><span class="st"> </span>x<span class="op">^</span>((df1<span class="op">/</span><span class="dv">2</span>) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb266-7" data-line-number="7">   d =<span class="st">  </span>(df1<span class="op">*</span>x <span class="op">+</span><span class="st"> </span>df2)<span class="op">^</span>((df1<span class="op">+</span>df2)<span class="op">/</span><span class="dv">2</span>)  </a>
<a class="sourceLine" id="cb266-8" data-line-number="8">   n <span class="op">/</span><span class="st"> </span>( <span class="kw">Beta</span>(df1<span class="op">/</span><span class="dv">2</span>, df2<span class="op">/</span><span class="dv">2</span>) <span class="op">*</span><span class="st"> </span>d )</a>
<a class="sourceLine" id="cb266-9" data-line-number="9">}</a>
<a class="sourceLine" id="cb266-10" data-line-number="10">f_cdf &lt;-<span class="st"> </span><span class="cf">function</span>(x, df1, df2) {</a>
<a class="sourceLine" id="cb266-11" data-line-number="11">   z =<span class="st"> </span>(df1 <span class="op">*</span><span class="st"> </span>x) <span class="op">/</span><span class="st"> </span>( df1 <span class="op">*</span><span class="st"> </span>x <span class="op">+</span><span class="st"> </span>df2)</a>
<a class="sourceLine" id="cb266-12" data-line-number="12">   <span class="kw">pbeta</span> ( z, df1<span class="op">/</span><span class="dv">2</span>, df2<span class="op">/</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb266-13" data-line-number="13">}</a></code></pre></div>
<p>And we plot the distribution as shown in Figures <a href="5.9-distributiontypes.html#fig:pfdist1">5.32</a> and <a href="5.9-distributiontypes.html#fig:pfdist2">5.33</a>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:pfdist1"></span>
<img src="DS_files/figure-html/pfdist1-1.png" alt="F-Distribution (PDF)" width="70%" />
<p class="caption">
Figure 5.32: F-Distribution (PDF)
</p>
</div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:pfdist2"></span>
<img src="DS_files/figure-html/pfdist2-1.png" alt="F-Distribution (CDF)" width="70%" />
<p class="caption">
Figure 5.33: F-Distribution (CDF)
</p>
</div>
<div class="sourceCode" id="cb267"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb267-1" data-line-number="1"><span class="co"># Probability Density</span></a>
<a class="sourceLine" id="cb267-2" data-line-number="2">x =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">6</span>)</a>
<a class="sourceLine" id="cb267-3" data-line-number="3"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="dv">6</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="dv">1</span>), </a>
<a class="sourceLine" id="cb267-4" data-line-number="4">     <span class="dt">xlab=</span><span class="st">&quot;F value&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;probability density&quot;</span>,</a>
<a class="sourceLine" id="cb267-5" data-line-number="5">     <span class="dt">main=</span><span class="st">&quot;F Distribution (PDF)&quot;</span>)</a>
<a class="sourceLine" id="cb267-6" data-line-number="6"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb267-7" data-line-number="7"><span class="kw">curve</span>(<span class="kw">f_pdf</span>(x, <span class="dv">2</span>, <span class="dv">5</span>), <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>,  <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb267-8" data-line-number="8"><span class="kw">curve</span>(<span class="kw">f_pdf</span>(x, <span class="dv">10</span>, <span class="dv">5</span>), <span class="dt">col=</span><span class="st">&quot;brown&quot;</span>,  <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb267-9" data-line-number="9"><span class="kw">curve</span>(<span class="kw">f_pdf</span>(x, <span class="dv">50</span>, <span class="dv">10</span>), <span class="dt">col=</span><span class="st">&quot;red&quot;</span>,  <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb267-10" data-line-number="10"></a>
<a class="sourceLine" id="cb267-11" data-line-number="11"><span class="co"># Cumulative Density</span></a>
<a class="sourceLine" id="cb267-12" data-line-number="12">x =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">6</span>)</a>
<a class="sourceLine" id="cb267-13" data-line-number="13"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="dv">6</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="dv">1</span>), </a>
<a class="sourceLine" id="cb267-14" data-line-number="14">     <span class="dt">xlab=</span><span class="st">&quot;F value&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;cumulative probability&quot;</span>,</a>
<a class="sourceLine" id="cb267-15" data-line-number="15">     <span class="dt">main=</span><span class="st">&quot;F Distribution (CDF)&quot;</span>)</a>
<a class="sourceLine" id="cb267-16" data-line-number="16"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb267-17" data-line-number="17"><span class="kw">curve</span>(<span class="kw">f_cdf</span>(x, <span class="dv">2</span>, <span class="dv">5</span>), <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>,  <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb267-18" data-line-number="18"><span class="kw">curve</span>(<span class="kw">f_cdf</span>(x, <span class="dv">10</span>, <span class="dv">5</span>), <span class="dt">col=</span><span class="st">&quot;brown&quot;</span>,  <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb267-19" data-line-number="19"><span class="kw">curve</span>(<span class="kw">f_cdf</span>(x, <span class="dv">50</span>, <span class="dv">10</span>), <span class="dt">col=</span><span class="st">&quot;red&quot;</span>,  <span class="dt">add=</span><span class="ot">TRUE</span>)</a></code></pre></div>

</div>
<div id="chi-square-distribution" class="section level3 hasAnchor">
<h3><span class="header-section-number">5.9.19</span> Chi-square Distribution <a href="5.9-distributiontypes.html#chi-square-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A <strong>Chi-square distribution</strong>, also called <span class="math inline">\(X^2\)</span><strong>-distribution</strong>, models a <strong>continuous distribution</strong> formed by squaring and summing the <strong>standard normal deviation</strong> of <span class="math inline">\(\mathbf{\nu}\)</span> independent variables that follow a standard normal distribution. The distribution can be expressed as follows:</p>
<p><span class="math display" id="eq:equate1070146">\[\begin{align}
Q \sim X^2(\nu)\ \ \ \ \ \ \ where\ \mathbf{\nu}\ = \text{degrees of freedom} \tag{5.154} 
\end{align}\]</span></p>
<p>The <strong>PDF</strong> for a <strong>Chi-squared distribution</strong> with <strong>support</strong> <span class="math inline">\(x \ge 0\)</span> is expressed as:</p>
<p><span class="math display" id="eq:equate1070147">\[\begin{align}
f(x; \nu) = \frac{1}{2^{\frac{\nu}{2}}\Gamma\left(\frac{\nu}{2}\right)} 
x^{\frac{\nu}{2}-1} e^{-\frac{x}{2}} \tag{5.155} 
\end{align}\]</span></p>
<p>The <strong>CDF</strong> for a <strong>Chi-square distribution</strong> with <strong>support</strong> <span class="math inline">\(x \ge 0\)</span> is expressed as:</p>
<p><span class="math display" id="eq:equate1070148">\[\begin{align}
F(x; \nu) = \frac{1}{\Gamma\left(\frac{\nu}{2}\right)} \gamma \left(\frac{\nu}{2},\frac{x}{2}\right) = P(\frac{\nu}{2},\frac{x}{2}) \tag{5.156} 
\end{align}\]</span></p>
<p>where <span class="math inline">\(\gamma(\nu, x)\)</span> is the <strong>lower incomplete gamma function</strong> and <span class="math inline">\(P(\nu, x)\)</span> is the <strong>lower regularized gamma function</strong>.</p>
<p>Here is a naive implementation of <strong>PDF and CDF</strong> for <strong>Chi-square distribution</strong> in R code:</p>

<div class="sourceCode" id="cb268"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb268-1" data-line-number="1">Gamma &lt;-<span class="st"> </span><span class="cf">function</span>(n) {<span class="kw">factorial</span>(n<span class="dv">-1</span>)}</a>
<a class="sourceLine" id="cb268-2" data-line-number="2">Beta &lt;-<span class="st"> </span><span class="cf">function</span>(a, b) {</a>
<a class="sourceLine" id="cb268-3" data-line-number="3">    ( <span class="kw">Gamma</span>(a) <span class="op">*</span><span class="st"> </span><span class="kw">Gamma</span>(b)) <span class="op">/</span><span class="st"> </span><span class="kw">Gamma</span>(a<span class="op">+</span>b)</a>
<a class="sourceLine" id="cb268-4" data-line-number="4">}</a>
<a class="sourceLine" id="cb268-5" data-line-number="5">chi_pdf &lt;-<span class="st"> </span><span class="cf">function</span>(x, df) {</a>
<a class="sourceLine" id="cb268-6" data-line-number="6">   <span class="dv">1</span> <span class="op">/</span><span class="st"> </span>( <span class="dv">2</span><span class="op">^</span>(df<span class="op">/</span><span class="dv">2</span>) <span class="op">*</span><span class="st"> </span><span class="kw">Gamma</span>(df<span class="op">/</span><span class="dv">2</span>)) <span class="op">*</span><span class="st"> </span>x<span class="op">^</span>(df<span class="op">/</span><span class="dv">2-1</span>) <span class="op">*</span><span class="st"> </span><span class="kw">exp</span>(<span class="op">-</span>x<span class="op">/</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb268-7" data-line-number="7">}</a>
<a class="sourceLine" id="cb268-8" data-line-number="8"><span class="co"># Probability Density</span></a>
<a class="sourceLine" id="cb268-9" data-line-number="9">x =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">10</span>)</a>
<a class="sourceLine" id="cb268-10" data-line-number="10"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="dv">10</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="dv">1</span>), </a>
<a class="sourceLine" id="cb268-11" data-line-number="11">     <span class="dt">xlab=</span><span class="st">&quot;Chi-square value&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;probability density&quot;</span>,</a>
<a class="sourceLine" id="cb268-12" data-line-number="12">     <span class="dt">main=</span><span class="st">&quot;Chi-squared Distribution (PDF)&quot;</span>)</a>
<a class="sourceLine" id="cb268-13" data-line-number="13"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb268-14" data-line-number="14"><span class="kw">curve</span>(<span class="kw">chi_pdf</span>(x, <span class="dv">1</span>), <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>,  <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb268-15" data-line-number="15"><span class="kw">curve</span>(<span class="kw">chi_pdf</span>(x, <span class="dv">2</span>), <span class="dt">col=</span><span class="st">&quot;brown&quot;</span>,  <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb268-16" data-line-number="16"><span class="kw">curve</span>(<span class="kw">chi_pdf</span>(x, <span class="dv">4</span>), <span class="dt">col=</span><span class="st">&quot;red&quot;</span>,  <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb268-17" data-line-number="17"><span class="kw">curve</span>(<span class="kw">chi_pdf</span>(x, <span class="dv">6</span>), <span class="dt">col=</span><span class="st">&quot;purple&quot;</span>,  <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb268-18" data-line-number="18"><span class="kw">curve</span>(<span class="kw">chi_pdf</span>(x, <span class="dv">9</span>), <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>,  <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb268-19" data-line-number="19"></a>
<a class="sourceLine" id="cb268-20" data-line-number="20">GammaInc &lt;-<span class="st"> </span><span class="cf">function</span>(alpha, z) {</a>
<a class="sourceLine" id="cb268-21" data-line-number="21">    s =<span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb268-22" data-line-number="22">    limit =<span class="st"> </span><span class="dv">300</span></a>
<a class="sourceLine" id="cb268-23" data-line-number="23">    flimit =<span class="st"> </span><span class="dv">172</span>  <span class="co"># R&#39;s gamma limit</span></a>
<a class="sourceLine" id="cb268-24" data-line-number="24">    <span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">0</span><span class="op">:</span>limit) {</a>
<a class="sourceLine" id="cb268-25" data-line-number="25">      <span class="cf">if</span> (z <span class="op">+</span><span class="st"> </span>k <span class="op">+</span><span class="st"> </span><span class="dv">1</span> <span class="op">&gt;</span><span class="st"> </span><span class="dv">171</span>) { <span class="cf">break</span> }</a>
<a class="sourceLine" id="cb268-26" data-line-number="26">      s =<span class="st"> </span>s <span class="op">+</span><span class="st"> </span>alpha<span class="op">^</span>k <span class="op">/</span><span class="st"> </span><span class="kw">Gamma</span>( z <span class="op">+</span><span class="st"> </span>k <span class="op">+</span><span class="st"> </span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb268-27" data-line-number="27">    }</a>
<a class="sourceLine" id="cb268-28" data-line-number="28">    lower =<span class="st"> </span>alpha<span class="op">^</span>z <span class="op">*</span><span class="st"> </span><span class="kw">Gamma</span>(z) <span class="op">*</span><span class="st"> </span><span class="kw">exp</span>(<span class="op">-</span>alpha) <span class="op">*</span><span class="st"> </span>s</a>
<a class="sourceLine" id="cb268-29" data-line-number="29">    upper =<span class="st"> </span><span class="kw">Gamma</span>(z) <span class="op">-</span><span class="st"> </span>lower</a>
<a class="sourceLine" id="cb268-30" data-line-number="30">    P =<span class="st"> </span>lower <span class="op">/</span><span class="st"> </span><span class="kw">Gamma</span>(z) <span class="co"># regular inc gamma</span></a>
<a class="sourceLine" id="cb268-31" data-line-number="31">    Q =<span class="st"> </span>upper <span class="op">/</span><span class="st"> </span><span class="kw">Gamma</span>(z)</a>
<a class="sourceLine" id="cb268-32" data-line-number="32">    <span class="kw">list</span>(<span class="st">&quot;lower&quot;</span>=<span class="st"> </span>lower, <span class="st">&quot;upper&quot;</span>=upper,  <span class="st">&quot;P&quot;</span>=P, <span class="st">&quot;Q&quot;</span>=Q )</a>
<a class="sourceLine" id="cb268-33" data-line-number="33">}</a>
<a class="sourceLine" id="cb268-34" data-line-number="34">chi_cdf &lt;-<span class="st"> </span><span class="cf">function</span>(x, v) {</a>
<a class="sourceLine" id="cb268-35" data-line-number="35">  <span class="dv">1</span> <span class="op">/</span><span class="st"> </span><span class="kw">Gamma</span>(v<span class="op">/</span><span class="dv">2</span>) <span class="op">*</span><span class="st"> </span><span class="kw">GammaInc</span>(x<span class="op">/</span><span class="dv">2</span>, v<span class="op">/</span><span class="dv">2</span>)<span class="op">$</span>lower</a>
<a class="sourceLine" id="cb268-36" data-line-number="36">}</a>
<a class="sourceLine" id="cb268-37" data-line-number="37"><span class="co"># Cumulative Density</span></a>
<a class="sourceLine" id="cb268-38" data-line-number="38">x =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">10</span>)</a>
<a class="sourceLine" id="cb268-39" data-line-number="39"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="dv">20</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="dv">0</span>,<span class="dv">1</span>), </a>
<a class="sourceLine" id="cb268-40" data-line-number="40">     <span class="dt">xlab=</span><span class="st">&quot;Chi-square value&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;cumulative probability&quot;</span>,</a>
<a class="sourceLine" id="cb268-41" data-line-number="41">     <span class="dt">main=</span><span class="st">&quot;Chi-squared Distribution (CDF)&quot;</span>)</a>
<a class="sourceLine" id="cb268-42" data-line-number="42"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>) </a>
<a class="sourceLine" id="cb268-43" data-line-number="43"><span class="kw">curve</span>(<span class="kw">chi_cdf</span>(x, <span class="dv">1</span>), <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>,  <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb268-44" data-line-number="44"><span class="kw">curve</span>(<span class="kw">chi_cdf</span>(x, <span class="dv">2</span>), <span class="dt">col=</span><span class="st">&quot;brown&quot;</span>,  <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb268-45" data-line-number="45"><span class="kw">curve</span>(<span class="kw">chi_cdf</span>(x, <span class="dv">4</span>), <span class="dt">col=</span><span class="st">&quot;red&quot;</span>,  <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb268-46" data-line-number="46"><span class="kw">curve</span>(<span class="kw">chi_cdf</span>(x, <span class="dv">6</span>), <span class="dt">col=</span><span class="st">&quot;purple&quot;</span>,  <span class="dt">add=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb268-47" data-line-number="47"><span class="kw">curve</span>(<span class="kw">chi_cdf</span>(x, <span class="dv">9</span>), <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>,  <span class="dt">add=</span><span class="ot">TRUE</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:pchidist-1"></span>
<img src="DS_files/figure-html/pchidist-1.png" alt="Chi-square Distribution (PDF and CDF)" width="70%" />
<p class="caption">
Figure 5.34: Chi-square Distribution (PDF and CDF)
</p>
</div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:pchidist-2"></span>
<img src="DS_files/figure-html/pchidist-2.png" alt="Chi-square Distribution (PDF and CDF)" width="70%" />
<p class="caption">
Figure 5.35: Chi-square Distribution (PDF and CDF)
</p>
</div>

<p>It helps to also reference the <strong>Chi-square table</strong> in the Appendix.</p>
<p><span class="math display">\[
\underbrace{P(x &gt; 2.7055, 1) = 0.100}_\text{df=1}\ \ \ \ \ \ \ \ \ \ \ \ \
\underbrace{P(x &gt; 4.6052, 2) = 0.100}_\text{df=2}
\]</span></p>
<div class="sourceCode" id="cb269"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb269-1" data-line-number="1"><span class="kw">c</span>(<span class="st">&quot;df=1&quot;</span>=<span class="kw">round</span>( <span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">pchisq</span>(<span class="fl">2.7055</span>,<span class="dv">1</span>),<span class="dv">3</span>), </a>
<a class="sourceLine" id="cb269-2" data-line-number="2">  <span class="st">&quot;df=2&quot;</span>=<span class="kw">round</span>( <span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">pchisq</span>(<span class="fl">4.6052</span>,<span class="dv">2</span>),<span class="dv">3</span>))</a></code></pre></div>
<pre><code>## df=1 df=2 
##  0.1  0.1</code></pre>
<p>Now in terms of the <strong>expected value</strong> and <strong>variance</strong> respectively, we have:</p>
<p><span class="math display" id="eq:equate1070149">\[\begin{align}
\mathbb{E}(X) = n\ \ \ \ \ \ \ \ \ \ \ \ \ Var(X) = 2n \tag{5.157} 
\end{align}\]</span></p>
<p>See <strong>Chi-square Test</strong> section for sample application of the distribution.</p>
</div>
<div id="wishartdistribution" class="section level3 hasAnchor">
<h3><span class="header-section-number">5.9.20</span> Wishart distribution<a href="5.9-distributiontypes.html#wishartdistribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Wishart distribution</strong> models a covariance <strong>continuous</strong> distribution drawn or sampled (as a <strong>precision</strong> or <strong>inverse covariance</strong> matrix, namely <strong>V</strong> ) from a <strong>multivariate normal distribution (MVN)</strong>. It is both an extension of gamma distribution and a generalization of the Chi-Square <span class="math inline">\(\mathcal{X}^2\)</span> distribution. To compare Chi-Square and Wishart structure in terms of multivariate distribution, see below <span class="citation">(Mathew T. <a href="bibliography.html#ref-ref1298t">1997</a>)</span>: </p>
<p><span class="math display" id="eq:eqnnumber22">\[\begin{align}
\underbrace{V = \sum_{i=1}^n X_i^2}_{
   \begin{array}{c}\text{chi-square}\ (V \in \mathbb{R}^n)\ dist\\ \ V\sim\ \mathcal{X}^2(\ \nu\ )\\ from \\ \text{univariate dist}\\ X \sim\  \mathcal{N}(\mu, \sigma^2)\end{array}
  }\ \ \ \ \ \ \ \ \ \ \
\underbrace{V = \sum_{i=1}^n X_i X_i^T}_{
   \begin{array}{c}\text{wishart} (V \in \mathbb{R}^{pxp})\ dist\\ \ \Sigma\ \sim\ \mathcal{W}(\ \nu, V)\\ from \\\text{multivariate dist}\\ X \sim\  \mathcal{N}_p(\mu, \Sigma)\end{array}
  } \tag{5.158}
\end{align}\]</span></p>
<p>Below is the structure of a <strong>multivariate distribution</strong>, namely <strong>X</strong>, with a corresponding <strong>covariance</strong> matrix, namely <span class="math inline">\(\Sigma\)</span>:</p>
<p><span class="math display">\[
X = \left[\begin{array}{rrrr}
    x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1p}\\ 
    x_{21} &amp; x_{22} &amp; \cdots &amp; x_{2p} \\ 
    \vdots &amp;  \vdots &amp; \ddots &amp;  \vdots \\ 
    x_{n1} &amp; x_{n2} &amp; \cdots &amp; x_{np} 
    \end{array}\right]_\text{(nxp)}
 \ \ \ 
\mu = \left[\begin{array}{c}\bar{x}_1 \\ \bar{x}_2 \\ \vdots \\ \bar{x}_p \end{array}\right]
= \left[\begin{array}{c}\mu_1 \\ \mu_2 \\ \vdots \\ \mu_p \end{array}\right]_\text{(1xp)}
\]</span></p>
<p><span class="math display">\[
\Sigma_{(pxp)} = \left[\begin{array}{rrrr}
   \sigma^2_{1} &amp; \sigma_{12} &amp; \cdots &amp; \sigma_{1p}\\
   \sigma_{21} &amp; \sigma^2_{2} &amp; \cdots &amp; \sigma_{2p} \\ 
   \vdots &amp;  \vdots &amp;  \ddots &amp;  \vdots \\ 
   \sigma_{p1} &amp; \sigma_{p2} &amp; \cdots &amp; \sigma^2_{p} 
   \end{array}\right]_\text{(pxp)} 
\]</span></p>
<p>Here, we cover three types of <strong>Wishart distributions</strong> using the following illustration:</p>
<p>The first distribution type is the <strong>Central Wishart distribution</strong> which is written as:</p>
<p><span class="math display" id="eq:equate1070150">\[\begin{align}
V \sim W_p \left(\nu, \Sigma_{(pxp)}\right) \equiv Wishart_p \left(\nu, \Sigma_{(pxp)} \right)  \tag{5.159} 
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li><strong>V</strong> is a <strong>precision</strong> or <strong>inverse</strong> covariance <strong>positive-definite</strong> matrix.</li>
<li><span class="math inline">\(\Sigma_{(pxp)}\)</span> is upper sigma describing a pxp <strong>non-inverse</strong> covariance <strong>positive-definite scale</strong> matrix</li>
<li><strong>p</strong> is number of random variables, e.g. p-variate distribution.</li>
<li><span class="math inline">\(\mathbf{\nu}\)</span> is degrees of freedom, where <span class="math inline">\(\nu\)</span> &gt; <strong>p</strong> - 1. Also, <span class="math inline">\(\nu = n\)</span>.</li>
</ul>
<p>The <strong>X</strong> is drawn from a multivariate normal distribution of which its covariance matrix is a positive-definite scale matrix with <strong>p</strong> random variables. We use a bivariate normal distribution for a shorter illustration where <strong>p</strong> = 2.</p>
<p><span class="math display" id="eq:eqnnumber23">\[\begin{align}
X \sim \mathcal{N}_2(\mu_{(2)}, \Sigma_{(2x2)}),\ \ \ \ \ \ 
\mu_{(2)} = \left[\begin{array}{cc}\mu_1 \\ \mu_2  \end{array}\right],\ \ \ \ \ \ 
\Sigma_{(2x2)} = 
\underbrace{\left[\begin{array}{cc}
\sigma^2_{11} &amp; \sigma^2_{12} \\ 
\sigma^2_{21} &amp; \sigma^2_{22}  \\ 
\end{array}\right]_{2x2}}_\text{scale matrix} \tag{5.160}
\end{align}\]</span></p>
<p>Given <strong>X</strong>, we generate a sum square covariance <strong>V</strong> distribution written as:</p>
<p><span class="math display" id="eq:equate1070151">\[\begin{align}
V = \sum_{i=1}^n\left(x_i -\mu)(x_i - \mu\right)^T \ \ \ \ \ where\ \mu = \bar{x} \tag{5.161} 
\end{align}\]</span></p>
<p>The <strong>PDF</strong> for a <strong>Central Wishart distribution</strong> is expressed as:</p>
<p><span class="math display" id="eq:eqnnumber24">\[\begin{align}
f_p(V; \nu, \Sigma_{(pxp)}) = 
    \frac{|V|^{\frac{\nu-p-1}{2}} exp\left[-\frac{1}{2}tr(\Sigma^{-1}V)\right]}
    {2^{\frac{\nu p}{2}}|\Sigma|^{\frac{\nu}{2}}\ \Gamma_p\left(\frac{\nu}{2}\right)}\ \ \ 
\begin{array}{ll}
\text{(see matrix trace in Linear}\\
\text{ Algebra chapter)}\\
\end{array} \tag{5.162}
\end{align}\]</span></p>
<p>where <strong>multivariate Gamma function</strong> is:</p>
<p><span class="math display" id="eq:equate1070152">\[\begin{align}
\Gamma_p\left(\frac{\nu}{2}\right) = \pi^{\frac{p(p-1)}{4}} \prod_{i=1}^p \Gamma\left[\frac{\nu - (i - 1)}{2}\right] \tag{5.163} 
\end{align}\]</span></p>
<p>and</p>
<p><span class="math display" id="eq:equate1070153">\[\begin{align}
mean =  n \times \Sigma_{(pxp)}\ \ \ \ \ \ \ |V| = \text{det}(V) \tag{5.164} 
\end{align}\]</span></p>
<p>The second distribution type is the <strong>Non-Central Wishart distribution</strong> which is written as:</p>
<p><span class="math display" id="eq:equate1070154">\[\begin{align}
U \sim W_p(\nu, \Sigma_{(pxp)}, \Upsilon) \equiv Wishart_p(\nu, \Sigma_{(pxp)}, \Upsilon)  \tag{5.165} 
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li><strong>U</strong> is a <strong>precision</strong> or <strong>inverse</strong> covariance <strong>positive-definite</strong> matrix.</li>
<li><span class="math inline">\(\Sigma_{(pxp)}\)</span> is a pxp <strong>non-inverse</strong> covariance <strong>positive-definite scale</strong> matrix</li>
<li><strong>p</strong> is the number of random variables, e.g. p-variate distribution.</li>
<li><span class="math inline">\(\mathbf{\nu}\)</span> is degrees of freedom, where <span class="math inline">\(\nu\)</span> &gt; <strong>p</strong> - 1.</li>
</ul>
<p>The <strong>X</strong> is drawn from a multivariate normal distribution of which its covariance matrix is a positive-definite scale matrix with <strong>p</strong> random variables. For illustration, we use bivariate normal distribution where <strong>p</strong> = 2.</p>
<p><span class="math display" id="eq:eqnnumber25">\[\begin{align}
X \sim \mathcal{N}(\mu_{(2)}, \Sigma_{(2x2)}),\ \ \ \ \ \ 
\mu_{(2)} = \left(\begin{array}{cc}\mu_1 \\ \mu_2  \end{array}\right),\ \ \ \ \ \ 
\Sigma_{(2x2)} = 
\underbrace{\left(\begin{array}{cc}
\sigma^2_{11} &amp; \sigma^2_{12} \\  
\sigma^2_{21} &amp; \sigma^2_{22}  \\ 
\end{array}\right)_{2x2}}_\text{scale matrix} \tag{5.166}
\end{align}\]</span></p>
<p>Here we extend the <strong>Central Wishart</strong> equation with two other factors:</p>
<p><span class="math display" id="eq:equate1070155">\[\begin{align}
U = \sum_{i=1}^n X_i X_k^T\ \ \ \ \ \ \ \ \ \ \ \ \ \Upsilon = N\Sigma^{-1}\mu\mu^T \tag{5.167} 
\end{align}\]</span></p>
<p>The <strong>PDF</strong> for a <strong>Non-Central Wishart distribution</strong> is expressed as:</p>
<p><span class="math display" id="eq:equate1070156">\[\begin{align}
f_p(U; \nu, \Sigma_{(pxp)}, \Upsilon) = 
    \frac{|U|^{\frac{\nu-p-1}{2}} exp\left[-\frac{1}{2}tr(\Sigma^{-1}U)\right]}
    {2^{\frac{\nu p}{2}}|\Sigma|^{\frac{\nu}{2}}\ \Gamma_p\left(\frac{\nu}{2}\right)}exp\left[-\frac{1}{2}\Upsilon\right]{}_0F_1\left(\frac{\nu}{1}; \frac{1}{4}\Upsilon \Sigma^{-1} U\right) \tag{5.168} 
\end{align}\]</span></p>
<p>The third distribution type is the <strong>Inverse Wishart distribution</strong> which is written as:</p>
<p><span class="math display" id="eq:equate1070157">\[\begin{align}
\Sigma_{pxp} =  \sim \mathcal{IW}_p(\nu, V) \equiv \mathcal{W}_p^{-1}(\nu, V)  \tag{5.169} 
\end{align}\]</span></p>
<p>where</p>
<ul>
<li><strong>V</strong> is a <strong>inverse</strong> covariance <strong>positive-definite scale</strong> matrix.</li>
<li><span class="math inline">\(\Sigma_{(pxp)}\)</span> is a pxp <strong>non-inverse</strong> covariance <strong>positive-definite</strong> matrix</li>
<li><strong>p</strong> is the number of random variables, e.g. p-variate distribution.</li>
<li><span class="math inline">\(\mathbf{\nu}\)</span> is degrees of freedom, where <span class="math inline">\(\nu\)</span> &gt; <strong>p</strong> - 1.</li>
</ul>
<p>The <strong>PDF</strong> for an <strong>Inverse Wishart distribution</strong> is expressed as:</p>
<p><span class="math display" id="eq:equate1070158">\[\begin{align}
f_p(\Sigma_{(pxp)}; \nu,  V) = 
    \frac{ |\Sigma|^{-\frac{\nu +p+1}{2}}  exp\left[-\frac{1}{2}tr(\Sigma^{-1}V)\right]}
    {2^{\frac{\nu p}{2}}|V|^{-\frac{\nu}{2}}\ \Gamma_p\left(\frac{\nu}{2}\right)} \tag{5.170} 
\end{align}\]</span></p>
<p>and</p>
<p><span class="math display" id="eq:equate1070159">\[\begin{align}
mean = \frac{V}{v - p - 1} \tag{5.171} 
\end{align}\]</span></p>
<p>It may help to point out that to optimize matrix computation, recall <strong>Cholesky factorization</strong> in Chapter <strong>2</strong> (<strong>Numerical Linear Algebra I</strong>) for <strong>invertible positive definite square matrix</strong> using the upper Cholesky factor. We leave readers to investigate this topic. </p>
</div>
<div id="lkj-distribution" class="section level3 hasAnchor">
<h3><span class="header-section-number">5.9.21</span> LKJ distribution <a href="5.9-distributiontypes.html#lkj-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Lewandowski-Kurowicka-Joe (LKJ) distribution</strong> models a distribution around correlations of parameters, treated as random variables. In <strong>Bayesian inference</strong>, we often deal with events as uncertainty (and thus are treated as random). Such correlation is formed as a positive definite correlation matrix.</p>
<p>We leave readers to investigate this distribution as a modern alternative to <strong>Wishart distribution</strong>.</p>
</div>
<div id="mixture-distribution" class="section level3 hasAnchor">
<h3><span class="header-section-number">5.9.22</span> Mixture distribution <a href="5.9-distributiontypes.html#mixture-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A <strong>Mixture distribution</strong> is a parent distribution formed from the weighted <span class="math inline">\(\lambda k\)</span> combination of more than one child distribution called components of the parent distribution.</p>
<p>Note that it is possible to plot the individual components. Figure <a href="5.9-distributiontypes.html#fig:mixture1b">5.36</a> illustrates 3 components (K=3). The overall mixing proportions, <span class="math inline">\(\pi_{k}\)</span>, equates to 1, e.g., (<span class="math inline">\(\sum_{k}\pi_k = 1\)</span>).</p>
<p>A mixture model has the following <strong>PDF</strong> formula:</p>
<p><span class="math display" id="eq:equate1070160">\[\begin{align}
f(x) = \sum_k \pi_k f(x|\theta_k) \tag{5.172} 
\end{align}\]</span></p>
<p>where <span class="math inline">\(\pi_k\)</span> is the mixing proportion.</p>
<p>Below is a sample implementation of a <strong>Mixture distribution</strong> using a built-in <strong>KDE</strong> function called <strong>density()</strong> which we briefly introduce under <strong>Non-parametric distribution</strong> section (See Figure <a href="5.9-distributiontypes.html#fig:mixture1b">5.36</a>).</p>

<div class="sourceCode" id="cb271"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb271-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">142</span>)</a>
<a class="sourceLine" id="cb271-2" data-line-number="2">n=<span class="dv">500</span></a>
<a class="sourceLine" id="cb271-3" data-line-number="3">x =<span class="st"> </span><span class="kw">c</span>( <span class="kw">rnorm</span>(<span class="dt">n=</span>n<span class="op">/</span><span class="fl">2.5</span>,  <span class="dv">4</span>,  <span class="fl">1.5</span>),</a>
<a class="sourceLine" id="cb271-4" data-line-number="4">           <span class="kw">rnorm</span>(<span class="dt">n=</span>n<span class="op">/</span><span class="fl">2.5</span>, <span class="fl">7.5</span>, <span class="fl">0.4</span>),</a>
<a class="sourceLine" id="cb271-5" data-line-number="5">           <span class="kw">rnorm</span>(<span class="dt">n=</span>n<span class="op">/</span><span class="fl">2.5</span>, <span class="dv">8</span>, <span class="dv">1</span>))</a>
<a class="sourceLine" id="cb271-6" data-line-number="6"></a>
<a class="sourceLine" id="cb271-7" data-line-number="7"><span class="co"># Plotting the main (parent) mixture distribution</span></a>
<a class="sourceLine" id="cb271-8" data-line-number="8"><span class="kw">plot</span>(<span class="kw">density</span>(x),  </a>
<a class="sourceLine" id="cb271-9" data-line-number="9">     <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>, <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">main=</span><span class="st">&quot;Mixture Density&quot;</span>,</a>
<a class="sourceLine" id="cb271-10" data-line-number="10">     <span class="dt">xlab=</span><span class="st">&quot;Three Independent Normal Distributions&quot;</span>)</a>
<a class="sourceLine" id="cb271-11" data-line-number="11"><span class="kw">grid</span>()</a>
<a class="sourceLine" id="cb271-12" data-line-number="12"></a>
<a class="sourceLine" id="cb271-13" data-line-number="13"><span class="co"># Let us use scale for plotting convenience only</span></a>
<a class="sourceLine" id="cb271-14" data-line-number="14"><span class="co"># to fit the components along the mixture distribution</span></a>
<a class="sourceLine" id="cb271-15" data-line-number="15">scale=<span class="fl">3.5</span></a>
<a class="sourceLine" id="cb271-16" data-line-number="16"></a>
<a class="sourceLine" id="cb271-17" data-line-number="17"><span class="co"># Plotting the 1st component distribution</span></a>
<a class="sourceLine" id="cb271-18" data-line-number="18">x =<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n=</span>n<span class="op">/</span><span class="fl">2.5</span>,  <span class="dv">4</span>,  <span class="fl">1.5</span>)</a>
<a class="sourceLine" id="cb271-19" data-line-number="19">c1 =<span class="st"> </span><span class="kw">curve</span>(<span class="kw">dnorm</span>(x, <span class="dv">4</span>, <span class="fl">1.5</span>)<span class="op">/</span>scale, <span class="dt">add=</span><span class="ot">TRUE</span>, <span class="dt">col=</span><span class="st">&quot;green&quot;</span> )</a>
<a class="sourceLine" id="cb271-20" data-line-number="20"></a>
<a class="sourceLine" id="cb271-21" data-line-number="21"><span class="co"># Plotting the 2nd component distribution</span></a>
<a class="sourceLine" id="cb271-22" data-line-number="22">x =<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n=</span>n<span class="op">/</span><span class="fl">2.5</span>, <span class="fl">7.5</span> , <span class="fl">0.4</span>)</a>
<a class="sourceLine" id="cb271-23" data-line-number="23">c2 =<span class="kw">curve</span>(<span class="kw">dnorm</span>(x, <span class="fl">7.5</span>, <span class="fl">0.4</span>)<span class="op">/</span>scale, <span class="dt">add=</span><span class="ot">TRUE</span>, <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>  )</a>
<a class="sourceLine" id="cb271-24" data-line-number="24"></a>
<a class="sourceLine" id="cb271-25" data-line-number="25"><span class="co"># Plotting the 3rd component distribution</span></a>
<a class="sourceLine" id="cb271-26" data-line-number="26">x =<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n=</span>n<span class="op">/</span><span class="fl">2.5</span>, <span class="dv">8</span>, <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb271-27" data-line-number="27">c3 =<span class="st"> </span><span class="kw">curve</span>(<span class="kw">dnorm</span>(x, <span class="dv">8</span>, <span class="dv">1</span>)<span class="op">/</span>scale, <span class="dt">add=</span><span class="ot">TRUE</span>, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>  )</a>
<a class="sourceLine" id="cb271-28" data-line-number="28"></a>
<a class="sourceLine" id="cb271-29" data-line-number="29"><span class="kw">rug</span>(<span class="kw">rnorm</span>(<span class="dt">n=</span><span class="dv">15</span>,  <span class="dv">4</span>,  <span class="fl">1.5</span>), <span class="dt">col=</span><span class="st">&quot;brown&quot;</span>)</a>
<a class="sourceLine" id="cb271-30" data-line-number="30"><span class="kw">rug</span>(<span class="kw">rnorm</span>(<span class="dt">n=</span><span class="dv">15</span>,  <span class="fl">7.5</span>,  <span class="fl">0.4</span>), <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>)</a>
<a class="sourceLine" id="cb271-31" data-line-number="31"><span class="kw">rug</span>(<span class="kw">rnorm</span>(<span class="dt">n=</span><span class="dv">15</span>,  <span class="dv">8</span>,  <span class="dv">1</span>), <span class="dt">col=</span><span class="st">&quot;red&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:mixture1b"></span>
<img src="DS_files/figure-html/mixture1b-1.png" alt="Mixture Distribution" width="80%" />
<p class="caption">
Figure 5.36: Mixture Distribution
</p>
</div>

<p>Note that <strong>mixture gaussian models</strong> are covered under <strong>Expectation-Maximization (EM)</strong> section in Chapter <strong>7</strong> (<strong>Bayesian Computation I</strong>) as extension to <strong>mixture distribution</strong> discussion.</p>
</div>
<div id="non-parametric-distribution" class="section level3 hasAnchor">
<h3><span class="header-section-number">5.9.23</span> Non-parametric distribution <a href="5.9-distributiontypes.html#non-parametric-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The previous section discusses about common <strong>PDFs</strong> and <strong>CDFs</strong>. For example, recall the following normal <strong>PDF</strong> function.</p>
<p><span class="math display" id="eq:equate1070161">\[\begin{align}
f(x; \mu, \sigma) = \frac{1}{\sqrt{2 \pi \sigma^2 }}e^{\frac{(x-\mu)^2}{2\sigma^2}} \tag{5.173} 
\end{align}\]</span></p>
<p>The function is parametric, e.g. for <strong>normal</strong> distribution, we use the <strong>mean</strong> and <strong>variance</strong> parameters. In a case in which our data set cannot follow any of the formal distributions that we discussed to represent specific <strong>PDFs</strong> and <strong>CDFs</strong>, we then resort to an estimation of a distribution. We want to simulate a <strong>non-parametric</strong> density function by which our data set can follow some <strong>estimated</strong> distribution. To do that, we use what we call <strong>Kernel Density Estimators (KDE)</strong>. <strong>KDE</strong> and the math involved are introduced in Chapter <strong>3</strong> (<strong>Numerical Linear Algebra II</strong>) under <strong>Kernel Smoothing</strong> Subsection along with a list of <strong>kernel functions and kernel estimators</strong>.</p>
<p>Our guide to being able to construct such an estimated <strong>PDF</strong> is by visualizing a histogram and perhaps drawing a curve that matches it.</p>
<p>Here is a naive implementation of <strong>KDE</strong> (see Figure <a href="5.9-distributiontypes.html#fig:kde">5.37</a>) to show the curve and histogram. For our function <strong>K()</strong> implementation, refer to Chapter <strong>3</strong> (<strong>Numerical Linear Algebra II</strong>) under <strong>Kernel Smoothing</strong> Subsection.</p>

<div class="sourceCode" id="cb272"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb272-1" data-line-number="1">kde &lt;-<span class="st"> </span><span class="cf">function</span>( x,  h, kernel) {</a>
<a class="sourceLine" id="cb272-2" data-line-number="2">      X =<span class="st"> </span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">10</span>, <span class="dv">15</span>, <span class="dt">length.out =</span> <span class="dv">200</span>)</a>
<a class="sourceLine" id="cb272-3" data-line-number="3">      m =<span class="st"> </span><span class="kw">length</span>(X); n =<span class="st"> </span><span class="kw">length</span>(x)</a>
<a class="sourceLine" id="cb272-4" data-line-number="4">      y =<span class="st"> </span><span class="kw">c</span>()</a>
<a class="sourceLine" id="cb272-5" data-line-number="5">      <span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>m) {</a>
<a class="sourceLine" id="cb272-6" data-line-number="6">          w =<span class="st"> </span><span class="kw">c</span>()</a>
<a class="sourceLine" id="cb272-7" data-line-number="7">          <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n) {</a>
<a class="sourceLine" id="cb272-8" data-line-number="8">              x_ =<span class="st"> </span>(<span class="dv">1</span> <span class="op">/</span><span class="st"> </span>h) <span class="op">*</span><span class="st"> </span><span class="kw">K</span> ( ( X[k] <span class="op">-</span><span class="st"> </span>x[i] ) <span class="op">/</span><span class="st"> </span>h , kernel )</a>
<a class="sourceLine" id="cb272-9" data-line-number="9">              w =<span class="st"> </span><span class="kw">c</span>(w, x_ )</a>
<a class="sourceLine" id="cb272-10" data-line-number="10">          }</a>
<a class="sourceLine" id="cb272-11" data-line-number="11">          y =<span class="st"> </span><span class="kw">c</span>(y, <span class="kw">sum</span>(w) <span class="op">/</span><span class="st"> </span>n  )</a>
<a class="sourceLine" id="cb272-12" data-line-number="12">      }</a>
<a class="sourceLine" id="cb272-13" data-line-number="13">      <span class="kw">list</span>(<span class="st">&quot;x&quot;</span>=X, <span class="st">&quot;y&quot;</span> =<span class="st"> </span>y)  </a>
<a class="sourceLine" id="cb272-14" data-line-number="14">}</a>
<a class="sourceLine" id="cb272-15" data-line-number="15">x =<span class="st"> </span><span class="kw">c</span>(  <span class="fl">-3.0</span>, <span class="fl">1.0</span>, <span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">7</span>, <span class="dv">9</span>, <span class="dv">10</span> )</a>
<a class="sourceLine" id="cb272-16" data-line-number="16"><span class="co"># Silverman Rule of Thumb (optimal bandwidth)</span></a>
<a class="sourceLine" id="cb272-17" data-line-number="17">h =<span class="st"> </span><span class="kw">bw.nrd</span>(x) <span class="op">-</span><span class="st"> </span><span class="fl">0.2</span></a>
<a class="sourceLine" id="cb272-18" data-line-number="18">kde.our.model =<span class="st"> </span><span class="kw">kde</span>( x, h, <span class="st">&quot;normal&quot;</span>) </a>
<a class="sourceLine" id="cb272-19" data-line-number="19">kde.sj.model =<span class="st"> </span><span class="kw">density</span>(x, <span class="dt">bw=</span><span class="st">&quot;sj&quot;</span>) <span class="co"># Sheather and Jones (1991)</span></a>
<a class="sourceLine" id="cb272-20" data-line-number="20">kde.nrd.model =<span class="st"> </span><span class="kw">density</span>(x, <span class="dt">bw=</span><span class="st">&quot;nrd&quot;</span>) <span class="co"># silverman rule</span></a>
<a class="sourceLine" id="cb272-21" data-line-number="21"></a>
<a class="sourceLine" id="cb272-22" data-line-number="22"><span class="kw">plot</span>(<span class="ot">NULL</span>, <span class="dt">xlim =</span> <span class="kw">range</span>(<span class="op">-</span><span class="dv">6</span>, <span class="dv">12</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="dv">0</span>, <span class="fl">3.2</span> ),</a>
<a class="sourceLine" id="cb272-23" data-line-number="23">     <span class="dt">xlab=</span><span class="st">&quot;x-axis&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;y-axis&quot;</span>,</a>
<a class="sourceLine" id="cb272-24" data-line-number="24">     <span class="dt">main=</span><span class="st">&quot;Kernel Density Estimation&quot;</span>)</a>
<a class="sourceLine" id="cb272-25" data-line-number="25"><span class="kw">grid</span>(<span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;lightgrey&quot;</span>)</a>
<a class="sourceLine" id="cb272-26" data-line-number="26"></a>
<a class="sourceLine" id="cb272-27" data-line-number="27"><span class="kw">hist</span>(x, <span class="dt">add=</span><span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb272-28" data-line-number="28">scale =<span class="st"> </span><span class="dv">28</span></a>
<a class="sourceLine" id="cb272-29" data-line-number="29"><span class="kw">lines</span>(kde.our.model<span class="op">$</span>x, kde.our.model<span class="op">$</span>y <span class="op">*</span><span class="st"> </span>scale, <span class="dt">col=</span><span class="st">&quot;navyblue&quot;</span>, </a>
<a class="sourceLine" id="cb272-30" data-line-number="30">      <span class="dt">lwd=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb272-31" data-line-number="31"><span class="kw">lines</span>(kde.sj.model<span class="op">$</span>x, kde.sj.model<span class="op">$</span>y <span class="op">*</span><span class="st"> </span>scale, <span class="dt">col=</span><span class="st">&quot;darksalmon&quot;</span>, </a>
<a class="sourceLine" id="cb272-32" data-line-number="32">      <span class="dt">lwd=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb272-33" data-line-number="33"><span class="kw">lines</span>(kde.nrd.model<span class="op">$</span>x, kde.nrd.model<span class="op">$</span>y <span class="op">*</span><span class="st"> </span>scale, <span class="dt">col=</span><span class="st">&quot;brown&quot;</span>, </a>
<a class="sourceLine" id="cb272-34" data-line-number="34">      <span class="dt">lwd=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb272-35" data-line-number="35"></a>
<a class="sourceLine" id="cb272-36" data-line-number="36">n =<span class="st"> </span><span class="kw">length</span>(x)</a>
<a class="sourceLine" id="cb272-37" data-line-number="37"><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n) {</a>
<a class="sourceLine" id="cb272-38" data-line-number="38">    mu =<span class="st"> </span>x[i]</a>
<a class="sourceLine" id="cb272-39" data-line-number="39">    x_ =<span class="st"> </span><span class="kw">seq</span>( mu <span class="op">-</span><span class="st"> </span><span class="dv">3</span>, mu <span class="op">+</span><span class="st"> </span><span class="dv">3</span>, <span class="dt">length.out =</span> <span class="dv">50</span>)</a>
<a class="sourceLine" id="cb272-40" data-line-number="40">    y_ =<span class="st"> </span><span class="kw">dnorm</span>(x_, <span class="dt">mean=</span>mu, <span class="dt">sd =</span> <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb272-41" data-line-number="41">    <span class="kw">lines</span>(x_, y_, <span class="dt">col=</span><span class="st">&quot;brown&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb272-42" data-line-number="42">}</a>
<a class="sourceLine" id="cb272-43" data-line-number="43"><span class="kw">rug</span>(x, <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>)</a>
<a class="sourceLine" id="cb272-44" data-line-number="44"><span class="kw">legend</span>(<span class="op">-</span><span class="dv">6</span>, <span class="dv">3</span>, </a>
<a class="sourceLine" id="cb272-45" data-line-number="45">    <span class="dt">legend=</span><span class="kw">c</span>( <span class="st">&quot;our kde (h=1.5)&quot;</span>, </a>
<a class="sourceLine" id="cb272-46" data-line-number="46">              <span class="st">&quot;built-in density(bw=sj)&quot;</span>,</a>
<a class="sourceLine" id="cb272-47" data-line-number="47">              <span class="st">&quot;build-in density(bw=nrd)&quot;</span>),</a>
<a class="sourceLine" id="cb272-48" data-line-number="48">    <span class="dt">col=</span><span class="kw">c</span>( <span class="st">&quot;navyblue&quot;</span>, <span class="st">&quot;darksalmon&quot;</span>, <span class="st">&quot;brown&quot;</span>), <span class="dt">lty=</span><span class="dv">1</span>,  <span class="dt">cex=</span><span class="fl">0.7</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:kde"></span>
<img src="DS_files/figure-html/kde-1.png" alt="Kernel Density Estimation" width="80%" />
<p class="caption">
Figure 5.37: Kernel Density Estimation
</p>
</div>

<p>Notice that our implementation of KDE exactly matches the output of the built-in R function <strong>density()</strong>. The bandwidth is intentionally adjusted with an offset of 0.2 so that the curve produced by our KDE implementation is demonstratively visible and does not overlap with the built-in estimate.</p>
<p>For <strong>bandwidth selection</strong>, we can use the built-in R function <strong>bw.&lt;choices&gt;()</strong>:</p>
<div class="sourceCode" id="cb273"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb273-1" data-line-number="1">(<span class="dt">optimal_bandwidth =</span> <span class="kw">bw.nrd</span>(x)) <span class="co"># Silverman&#39;s Rule of Thumb</span></a></code></pre></div>
<pre><code>## [1] 2.038978</code></pre>
<p>Alternatively, we can use <strong>unbiased cross-validation</strong> with a list of random bandwidths between 2 and 5. With that, we use a tolerance scaled at 0.1 (using the sample provided in the documentation of the built-in R function <strong>bw.ucv()</strong>):</p>
<div class="sourceCode" id="cb275"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb275-1" data-line-number="1"><span class="co"># unbiased cross-validation </span></a>
<a class="sourceLine" id="cb275-2" data-line-number="2">lower =<span class="st"> </span><span class="dv">2</span>; upper =<span class="st"> </span><span class="dv">5</span></a>
<a class="sourceLine" id="cb275-3" data-line-number="3">(<span class="dt">optimal_h =</span> <span class="kw">bw.ucv</span>(x, <span class="dt">nb =</span> <span class="dv">1000</span>, <span class="dt">lower =</span> <span class="fl">0.1</span> <span class="op">*</span><span class="st"> </span>upper, <span class="dt">upper =</span> upper, </a>
<a class="sourceLine" id="cb275-4" data-line-number="4">                    <span class="dt">tol =</span> <span class="fl">0.1</span> <span class="op">*</span><span class="st"> </span>lower))</a></code></pre></div>
<pre><code>## [1] 4.730645</code></pre>
</div>
<div id="multi-dimensional-density" class="section level3 hasAnchor">
<h3><span class="header-section-number">5.9.24</span> Multi-dimensional Density <a href="5.9-distributiontypes.html#multi-dimensional-density" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Most of the <strong>parametric</strong> distributions discussed are <strong>unimodal</strong> - a distribution with only one peak. In <strong>mixture distribution</strong>, we begin to show <strong>multimodal</strong> characteristics of the distribution in which we see multiple peaks. The individual peak follows an individual normal distribution. Then finally, in <strong>KDE</strong>, we continue to show <strong>multimodal</strong> behavior; however, high peaks represent stacks of weights (summation of weights) computed based on a choice of <strong>kernel functions</strong>. </p>
<p>Whether the distribution is <strong>unimodal</strong> or <strong>multimodal</strong>, it represents a <strong>univariate</strong> distribution - meaning, we deal with only one random independent variable.</p>
<p>In this section, we show two examples of <strong>multivariate</strong> distribution:</p>
<p><strong>First</strong>, we introduce <strong>multivariate unimodal distribution</strong>, which deals with multiple independent variables with one peak.</p>
<p>We start by using a 3rd-party library called <strong>mvtnorm</strong> and then generate a data set that follows a <strong>multivariate normal distribution</strong> with noise:</p>

<div class="sourceCode" id="cb277"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb277-1" data-line-number="1"><span class="kw">library</span>(mvtnorm)</a>
<a class="sourceLine" id="cb277-2" data-line-number="2"><span class="kw">set.seed</span>(<span class="dv">142</span>)</a>
<a class="sourceLine" id="cb277-3" data-line-number="3">sample_size =<span class="st"> </span>n =<span class="st"> </span><span class="dv">200</span></a>
<a class="sourceLine" id="cb277-4" data-line-number="4">e =<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n=</span>sample_size, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span><span class="dv">1</span>) <span class="op">/</span><span class="st"> </span><span class="dv">30</span>  <span class="co"># Noise/Gaussian Residual</span></a>
<a class="sourceLine" id="cb277-5" data-line-number="5">x =<span class="st">  </span><span class="kw">sample</span>(<span class="kw">seq</span>(<span class="op">-</span><span class="dv">5</span>,<span class="dv">5</span>), <span class="dt">size=</span>n, <span class="dt">replace=</span><span class="ot">TRUE</span>) </a>
<a class="sourceLine" id="cb277-6" data-line-number="6">y =<span class="st">  </span><span class="kw">sample</span>(<span class="kw">seq</span>(<span class="op">-</span><span class="dv">5</span>,<span class="dv">5</span>), <span class="dt">size=</span>n, <span class="dt">replace=</span><span class="ot">TRUE</span>) </a>
<a class="sourceLine" id="cb277-7" data-line-number="7">mu =<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>,<span class="dv">2</span>); sigma =<span class="st"> </span><span class="kw">diag</span>(<span class="dv">1</span>,<span class="dv">2</span>)</a>
<a class="sourceLine" id="cb277-8" data-line-number="8">z =<span class="st"> </span><span class="kw">dmvnorm</span>(<span class="kw">cbind</span>(x, y), <span class="dt">mean =</span> mu,  <span class="dt">sigma=</span>sigma ) <span class="op">+</span><span class="st"> </span>e</a></code></pre></div>

<p>We then use an R function called <strong>loess()</strong> to fit a two-dimensional model to our data using a span of 0.5 and a polynomial degree of 2 - a parabolic polynomial.</p>

<div class="sourceCode" id="cb278"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb278-1" data-line-number="1"><span class="co"># Because we added noise, our goal is to demonstrate how to fit</span></a>
<a class="sourceLine" id="cb278-2" data-line-number="2"><span class="co"># a 2D loess model.</span></a>
<a class="sourceLine" id="cb278-3" data-line-number="3">loess.model =<span class="st"> </span><span class="kw">loess</span>(z <span class="op">~</span><span class="st"> </span>x <span class="op">+</span><span class="st"> </span>y, <span class="dt">degree=</span><span class="dv">2</span>, <span class="dt">span=</span><span class="fl">0.5</span>)</a>
<a class="sourceLine" id="cb278-4" data-line-number="4"><span class="co"># Perform smooth fit by prediction</span></a>
<a class="sourceLine" id="cb278-5" data-line-number="5">x =<span class="st"> </span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">5</span>,<span class="dv">5</span>, <span class="dt">length.out =</span> <span class="dv">50</span>)</a>
<a class="sourceLine" id="cb278-6" data-line-number="6">y =<span class="st"> </span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">5</span>,<span class="dv">5</span>, <span class="dt">length.out =</span> <span class="dv">50</span>)</a>
<a class="sourceLine" id="cb278-7" data-line-number="7">xy.grid =<span class="st"> </span><span class="kw">as.matrix</span>( <span class="kw">expand.grid</span>(x,y))</a>
<a class="sourceLine" id="cb278-8" data-line-number="8">z.fit =<span class="st"> </span>stats<span class="op">::</span><span class="kw">predict</span>(loess.model, <span class="dt">newdata =</span> xy.grid)</a>
<a class="sourceLine" id="cb278-9" data-line-number="9">z.fit =<span class="st"> </span><span class="kw">matrix</span>(<span class="dt">data =</span> z.fit, <span class="dt">nrow=</span><span class="kw">length</span>(x), <span class="dt">ncol=</span><span class="kw">length</span>(y))</a></code></pre></div>

<p>Finally, we plot a <strong>3D perspective view</strong> (See Figure <a href="5.9-distributiontypes.html#fig:multiloess">5.38</a>).</p>
<div class="sourceCode" id="cb279"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb279-1" data-line-number="1"><span class="kw">persp</span>(x, y, z.fit, <span class="dt">phi=</span><span class="dv">30</span>, <span class="dt">theta=</span><span class="dv">25</span>, </a>
<a class="sourceLine" id="cb279-2" data-line-number="2">      <span class="dt">xlim=</span><span class="kw">range</span>(<span class="op">-</span><span class="dv">5</span>,<span class="dv">5</span>), <span class="dt">ylim=</span><span class="kw">range</span>(<span class="op">-</span><span class="dv">5</span>,<span class="dv">5</span>),</a>
<a class="sourceLine" id="cb279-3" data-line-number="3">      <span class="dt">main=</span><span class="st">&quot;Fitting LOESS with Multi-Dimensional data&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:multiloess"></span>
<img src="embed0080.1.png" alt="Fitting LOESS with Multi-Dimensional data" width="80%" />
<p class="caption">
Figure 5.38: Fitting LOESS with Multi-Dimensional data
</p>
</div>
<p>In <strong>Statistical Computation</strong>, we extend our discussion on <strong>LOESS</strong> under <strong>Statistical Regression and Statistical Inference</strong>.</p>
<p><strong>Second</strong>, we introduce <strong>multivariate multimodal distribution</strong>, which deals with multiple independent variables with multiple peaks.</p>
<p>We start by using a 3rd-party library called <strong>KernSmooth</strong> and then construct some random sample datasets.</p>
<div class="sourceCode" id="cb280"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb280-1" data-line-number="1"><span class="kw">library</span>(KernSmooth)</a></code></pre></div>
<pre><code>## KernSmooth 2.23 loaded
## Copyright M. P. Wand 1997-2009</code></pre>
<div class="sourceCode" id="cb282"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb282-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">142</span>)</a>
<a class="sourceLine" id="cb282-2" data-line-number="2">sample_size =<span class="st"> </span>n =<span class="st"> </span><span class="dv">40</span> </a>
<a class="sourceLine" id="cb282-3" data-line-number="3">y =<span class="st">  </span><span class="kw">sample</span>(<span class="kw">seq</span>(<span class="dv">1</span>,<span class="dv">9</span>), <span class="dt">size=</span>sample_size, <span class="dt">replace=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb282-4" data-line-number="4">x =<span class="st">  </span><span class="kw">sample</span>(<span class="kw">seq</span>(<span class="dv">1</span>,<span class="dv">9</span>), <span class="dt">size=</span>sample_size, <span class="dt">replace=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb282-5" data-line-number="5">data =<span class="st"> </span><span class="kw">cbind</span>(x, y)</a></code></pre></div>
<p>We then use an R function called <strong>bkde2d()</strong> to fit a two-dimensional <strong>KDE</strong> model to our data with an optimal bandwidth obtained from <strong>bw.nrd()</strong>. Note that <strong>bkde2d()</strong> uses a <strong>bivariate gaussian kernel</strong>. </p>
<div class="sourceCode" id="cb283"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb283-1" data-line-number="1">h =<span class="st"> </span><span class="kw">bw.nrd</span>(x)</a>
<a class="sourceLine" id="cb283-2" data-line-number="2">kde.grid =<span class="st"> </span><span class="kw">bkde2D</span>(<span class="dt">x =</span> data, <span class="dt">bandwidth=</span> h)</a></code></pre></div>
<p>Finally, let us plot a <strong>3D perspective view</strong> of our <strong>multi-dimensional KDE</strong> distribution (See Figure <a href="5.9-distributiontypes.html#fig:kde2dpersp">5.39</a>).</p>
<div class="sourceCode" id="cb284"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb284-1" data-line-number="1"><span class="kw">persp</span>(kde.grid<span class="op">$</span>fhat, </a>
<a class="sourceLine" id="cb284-2" data-line-number="2">       <span class="dt">phi=</span><span class="dv">30</span>, <span class="dt">theta=</span><span class="dv">25</span>,</a>
<a class="sourceLine" id="cb284-3" data-line-number="3">       <span class="dt">zlab =</span> <span class="st">&quot;z-axis&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;y-axis&quot;</span>, <span class="dt">xlab =</span> <span class="st">&quot;x-axis&quot;</span>,</a>
<a class="sourceLine" id="cb284-4" data-line-number="4">       <span class="dt">main=</span><span class="st">&quot;Multi-dimensional density estimate (3D perspective)&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:kde2dpersp"></span>
<img src="embed0081.1.png" alt="Multi-dimensional KDE (3D Perspective)" width="80%" />
<p class="caption">
Figure 5.39: Multi-dimensional KDE (3D Perspective)
</p>
</div>
<p>Additionally, we also can show the <strong>contour</strong> of our <strong>3D view</strong> (See Figure <a href="5.9-distributiontypes.html#fig:kde2dcontour">5.40</a>).</p>
<div class="sourceCode" id="cb285"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb285-1" data-line-number="1"><span class="kw">contour</span>(kde.grid<span class="op">$</span>x1, kde.grid<span class="op">$</span>x2, kde.grid<span class="op">$</span>fhat,</a>
<a class="sourceLine" id="cb285-2" data-line-number="2">        <span class="dt">xlab=</span><span class="st">&quot;x-axis&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;y-axis&quot;</span>,</a>
<a class="sourceLine" id="cb285-3" data-line-number="3">        <span class="dt">main=</span><span class="st">&quot;Multi-dimensional density estimate (Contour)&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:kde2dcontour"></span>
<img src="DS_files/figure-html/kde2dcontour-1.png" alt="Multi-dimensional KDE (Contour)" width="70%" />
<p class="caption">
Figure 5.40: Multi-dimensional KDE (Contour)
</p>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="5.8-special-functions.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="5.10-summary-3.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "sepia",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["DS.pdf", "DS.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
