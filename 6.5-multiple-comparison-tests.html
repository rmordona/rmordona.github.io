<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>6.5 Multiple Comparison Tests  | The Power and Art of Approximation</title>
  <meta name="description" content="Enthused by the promising future of self-learning machines and the continuous advancement of technology, we write this book to cover a compendium of analytical and numerical techniques conflated into a common idea that highlights the fundamental requirements of Data Science and Machine Learning (ML) Engineering. In this book, we review and give brief insights into numerous fundamental ideas around methods of approximation conceived by great experts. We aim to share them with those new to Data Science who are just beginning to develop an inclination toward this field but may not know where to begin. In addition, we hope to introduce some essential aspects of Data Science in a more progressive and possibly structured manner. This book avoids being specific to a target audience depending on interest. The premise is that Data Science can be for everybody, whether one is an engineer, a researcher within a particular domain, or, for that matter, an undergraduate student just trying to get into this field. While we note that our common theme across the book is intuition, contemplating more on basic operations than mathematical rigor, it is essential to revive our understanding of mathematical concepts first. That is founded upon the idea that we express most of what we do in Data Science in the language of mathematics, more numerically inclined in fact than analytical - meaning, we live to decide based on close approximation in many situations. Therefore, it is just right to have a historical perspective of the mathematical foundations which Machine Learning algorithms may have come about - if not at least what they depend upon fundamentally. For that reason, we cover a list of mathematical concepts that are no doubt valuable to eventually get us to Machine Learning concepts. However, only a particular elementary and introductory portion of each field of mathematics is covered as we emphasize only relevant and essential areas. That said, this book comes in three volumes. Volumes I and II of this book briefly cover common topics in Linear Algebra, Numerical Analysis, Statistical Analysis, and Bayesian Analysis. The third part (or volume III) of this book covers Machine Learning and Deep Learning in detail." />
  <meta name="generator" content="bookdown 0.32 and GitBook 2.6.7" />

  <meta property="og:title" content="6.5 Multiple Comparison Tests  | The Power and Art of Approximation" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Enthused by the promising future of self-learning machines and the continuous advancement of technology, we write this book to cover a compendium of analytical and numerical techniques conflated into a common idea that highlights the fundamental requirements of Data Science and Machine Learning (ML) Engineering. In this book, we review and give brief insights into numerous fundamental ideas around methods of approximation conceived by great experts. We aim to share them with those new to Data Science who are just beginning to develop an inclination toward this field but may not know where to begin. In addition, we hope to introduce some essential aspects of Data Science in a more progressive and possibly structured manner. This book avoids being specific to a target audience depending on interest. The premise is that Data Science can be for everybody, whether one is an engineer, a researcher within a particular domain, or, for that matter, an undergraduate student just trying to get into this field. While we note that our common theme across the book is intuition, contemplating more on basic operations than mathematical rigor, it is essential to revive our understanding of mathematical concepts first. That is founded upon the idea that we express most of what we do in Data Science in the language of mathematics, more numerically inclined in fact than analytical - meaning, we live to decide based on close approximation in many situations. Therefore, it is just right to have a historical perspective of the mathematical foundations which Machine Learning algorithms may have come about - if not at least what they depend upon fundamentally. For that reason, we cover a list of mathematical concepts that are no doubt valuable to eventually get us to Machine Learning concepts. However, only a particular elementary and introductory portion of each field of mathematics is covered as we emphasize only relevant and essential areas. That said, this book comes in three volumes. Volumes I and II of this book briefly cover common topics in Linear Algebra, Numerical Analysis, Statistical Analysis, and Bayesian Analysis. The third part (or volume III) of this book covers Machine Learning and Deep Learning in detail." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="6.5 Multiple Comparison Tests  | The Power and Art of Approximation" />
  
  <meta name="twitter:description" content="Enthused by the promising future of self-learning machines and the continuous advancement of technology, we write this book to cover a compendium of analytical and numerical techniques conflated into a common idea that highlights the fundamental requirements of Data Science and Machine Learning (ML) Engineering. In this book, we review and give brief insights into numerous fundamental ideas around methods of approximation conceived by great experts. We aim to share them with those new to Data Science who are just beginning to develop an inclination toward this field but may not know where to begin. In addition, we hope to introduce some essential aspects of Data Science in a more progressive and possibly structured manner. This book avoids being specific to a target audience depending on interest. The premise is that Data Science can be for everybody, whether one is an engineer, a researcher within a particular domain, or, for that matter, an undergraduate student just trying to get into this field. While we note that our common theme across the book is intuition, contemplating more on basic operations than mathematical rigor, it is essential to revive our understanding of mathematical concepts first. That is founded upon the idea that we express most of what we do in Data Science in the language of mathematics, more numerically inclined in fact than analytical - meaning, we live to decide based on close approximation in many situations. Therefore, it is just right to have a historical perspective of the mathematical foundations which Machine Learning algorithms may have come about - if not at least what they depend upon fundamentally. For that reason, we cover a list of mathematical concepts that are no doubt valuable to eventually get us to Machine Learning concepts. However, only a particular elementary and introductory portion of each field of mathematics is covered as we emphasize only relevant and essential areas. That said, this book comes in three volumes. Volumes I and II of this book briefly cover common topics in Linear Algebra, Numerical Analysis, Statistical Analysis, and Bayesian Analysis. The third part (or volume III) of this book covers Machine Learning and Deep Learning in detail." />
  

<meta name="author" content="Raymond Michael Ofiaza OrdoÃ±a" />


<meta name="date" content="2023-02-19" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="6.4-post-hoc-analysis.html"/>
<link rel="next" href="6.6-statistical-modeling.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Minimal Book Example</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="" data-path="acknowledgment-and-motivations.html"><a href="acknowledgment-and-motivations.html"><i class="fa fa-check"></i>Acknowledgment and Motivations</a></li>
<li class="chapter" data-level="" data-path="caveat.html"><a href="caveat.html"><i class="fa fa-check"></i>Caveat</a></li>
<li class="chapter" data-level="" data-path="about-the-author.html"><a href="about-the-author.html"><i class="fa fa-check"></i>About the Author</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="" data-path="mathematical-notation.html"><a href="mathematical-notation.html"><i class="fa fa-check"></i>Mathematical Notation</a><ul>
<li class="chapter" data-level="0.1" data-path="0.1-notation.html"><a href="0.1-notation.html"><i class="fa fa-check"></i><b>0.1</b> Notation</a></li>
<li class="chapter" data-level="0.2" data-path="0.2-number-system.html"><a href="0.2-number-system.html"><i class="fa fa-check"></i><b>0.2</b> Number System</a></li>
<li class="chapter" data-level="0.3" data-path="0.3-implementation.html"><a href="0.3-implementation.html"><i class="fa fa-check"></i><b>0.3</b> Implementation</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="1-numericalmethods.html"><a href="1-numericalmethods.html"><i class="fa fa-check"></i><b>1</b> Direct and Indirect Methods</a><ul>
<li class="chapter" data-level="1.1" data-path="1.1-closed-form-equation.html"><a href="1.1-closed-form-equation.html"><i class="fa fa-check"></i><b>1.1</b> Closed-form equation</a></li>
<li class="chapter" data-level="1.2" data-path="1.2-analytical-and-numerical-solutions.html"><a href="1.2-analytical-and-numerical-solutions.html"><i class="fa fa-check"></i><b>1.2</b> Analytical and Numerical solutions  </a></li>
<li class="chapter" data-level="1.3" data-path="1.3-significant-figures.html"><a href="1.3-significant-figures.html"><i class="fa fa-check"></i><b>1.3</b> Significant figures</a></li>
<li class="chapter" data-level="1.4" data-path="1.4-accuracy.html"><a href="1.4-accuracy.html"><i class="fa fa-check"></i><b>1.4</b> Accuracy</a></li>
<li class="chapter" data-level="1.5" data-path="1.5-precision.html"><a href="1.5-precision.html"><i class="fa fa-check"></i><b>1.5</b> Precision </a></li>
<li class="chapter" data-level="1.6" data-path="1.6-stability-and-sensitivity.html"><a href="1.6-stability-and-sensitivity.html"><i class="fa fa-check"></i><b>1.6</b> Stability and Sensitivity  </a></li>
<li class="chapter" data-level="1.7" data-path="1.7-stiffness-and-implicitness.html"><a href="1.7-stiffness-and-implicitness.html"><i class="fa fa-check"></i><b>1.7</b> Stiffness and Implicitness  </a></li>
<li class="chapter" data-level="1.8" data-path="1.8-conditioning-and-posedness.html"><a href="1.8-conditioning-and-posedness.html"><i class="fa fa-check"></i><b>1.8</b> Conditioning and Posedness  </a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="2-linearalgebra.html"><a href="2-linearalgebra.html"><i class="fa fa-check"></i><b>2</b> Numerical Linear Algebra I</a><ul>
<li class="chapter" data-level="2.1" data-path="2.1-system-of-linear-equations.html"><a href="2.1-system-of-linear-equations.html"><i class="fa fa-check"></i><b>2.1</b> System of Linear Equations</a></li>
<li class="chapter" data-level="2.2" data-path="2.2-scalar-vector-and-matrix-tensor.html"><a href="2.2-scalar-vector-and-matrix-tensor.html"><i class="fa fa-check"></i><b>2.2</b> Scalar, Vector, and Matrix, Tensor</a></li>
<li class="chapter" data-level="2.3" data-path="2.3-transposition-and-multiplication.html"><a href="2.3-transposition-and-multiplication.html"><i class="fa fa-check"></i><b>2.3</b> Transposition and Multiplication</a><ul>
<li class="chapter" data-level="2.3.1" data-path="2.3-transposition-and-multiplication.html"><a href="2.3-transposition-and-multiplication.html#transposition"><i class="fa fa-check"></i><b>2.3.1</b> Transposition</a></li>
<li class="chapter" data-level="2.3.2" data-path="2.3-transposition-and-multiplication.html"><a href="2.3-transposition-and-multiplication.html#dot-product"><i class="fa fa-check"></i><b>2.3.2</b> Dot Product</a></li>
<li class="chapter" data-level="2.3.3" data-path="2.3-transposition-and-multiplication.html"><a href="2.3-transposition-and-multiplication.html#hadamard-product"><i class="fa fa-check"></i><b>2.3.3</b> Hadamard Product</a></li>
<li class="chapter" data-level="2.3.4" data-path="2.3-transposition-and-multiplication.html"><a href="2.3-transposition-and-multiplication.html#kronecker-product"><i class="fa fa-check"></i><b>2.3.4</b> Kronecker Product</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="2.4-magnitude-direction-unit-vectors.html"><a href="2.4-magnitude-direction-unit-vectors.html"><i class="fa fa-check"></i><b>2.4</b> Magnitude, Direction, Unit Vectors</a></li>
<li class="chapter" data-level="2.5" data-path="2.5-linear-combination-and-independence.html"><a href="2.5-linear-combination-and-independence.html"><i class="fa fa-check"></i><b>2.5</b> Linear Combination and Independence</a></li>
<li class="chapter" data-level="2.6" data-path="2.6-space-span-and-basis.html"><a href="2.6-space-span-and-basis.html"><i class="fa fa-check"></i><b>2.6</b> Space, Span, and Basis</a></li>
<li class="chapter" data-level="2.7" data-path="2.7-determinants.html"><a href="2.7-determinants.html"><i class="fa fa-check"></i><b>2.7</b> Determinants </a></li>
<li class="chapter" data-level="2.8" data-path="2.8-minors-cofactors-and-adjugate-forms.html"><a href="2.8-minors-cofactors-and-adjugate-forms.html"><i class="fa fa-check"></i><b>2.8</b> Minors, Cofactors, and Adjugate Forms</a></li>
<li class="chapter" data-level="2.9" data-path="2.9-inverse-form-and-row-echelon-form.html"><a href="2.9-inverse-form-and-row-echelon-form.html"><i class="fa fa-check"></i><b>2.9</b> Inverse Form and Row-Echelon Form</a></li>
<li class="chapter" data-level="2.10" data-path="2.10-linear-transformations.html"><a href="2.10-linear-transformations.html"><i class="fa fa-check"></i><b>2.10</b> Linear Transformations</a><ul>
<li class="chapter" data-level="2.10.1" data-path="2.10-linear-transformations.html"><a href="2.10-linear-transformations.html#scaling"><i class="fa fa-check"></i><b>2.10.1</b> Scaling </a></li>
<li class="chapter" data-level="2.10.2" data-path="2.10-linear-transformations.html"><a href="2.10-linear-transformations.html#transvection-shearing"><i class="fa fa-check"></i><b>2.10.2</b> Transvection (Shearing)  </a></li>
<li class="chapter" data-level="2.10.3" data-path="2.10-linear-transformations.html"><a href="2.10-linear-transformations.html#rotation"><i class="fa fa-check"></i><b>2.10.3</b> Rotation </a></li>
<li class="chapter" data-level="2.10.4" data-path="2.10-linear-transformations.html"><a href="2.10-linear-transformations.html#reflection"><i class="fa fa-check"></i><b>2.10.4</b> Reflection </a></li>
<li class="chapter" data-level="2.10.5" data-path="2.10-linear-transformations.html"><a href="2.10-linear-transformations.html#projection"><i class="fa fa-check"></i><b>2.10.5</b> Projection </a></li>
<li class="chapter" data-level="2.10.6" data-path="2.10-linear-transformations.html"><a href="2.10-linear-transformations.html#translation"><i class="fa fa-check"></i><b>2.10.6</b> Translation </a></li>
<li class="chapter" data-level="2.10.7" data-path="2.10-linear-transformations.html"><a href="2.10-linear-transformations.html#dilation-and-composition"><i class="fa fa-check"></i><b>2.10.7</b> Dilation and Composition  </a></li>
</ul></li>
<li class="chapter" data-level="2.11" data-path="2.11-rank-and-nullity.html"><a href="2.11-rank-and-nullity.html"><i class="fa fa-check"></i><b>2.11</b> Rank and Nullity  </a></li>
<li class="chapter" data-level="2.12" data-path="2.12-singularity-and-triviality.html"><a href="2.12-singularity-and-triviality.html"><i class="fa fa-check"></i><b>2.12</b> Singularity and Triviality  </a></li>
<li class="chapter" data-level="2.13" data-path="2.13-orthogonality-and-orthonormality.html"><a href="2.13-orthogonality-and-orthonormality.html"><i class="fa fa-check"></i><b>2.13</b> Orthogonality and Orthonormality  </a></li>
<li class="chapter" data-level="2.14" data-path="2.14-eigenvectors-and-eigenvalues.html"><a href="2.14-eigenvectors-and-eigenvalues.html"><i class="fa fa-check"></i><b>2.14</b> Eigenvectors and Eigenvalues  </a></li>
<li class="chapter" data-level="2.15" data-path="2.15-matrix-reconstruction-using-eigenvalues-and-eigenvectors.html"><a href="2.15-matrix-reconstruction-using-eigenvalues-and-eigenvectors.html"><i class="fa fa-check"></i><b>2.15</b> Matrix Reconstruction using Eigenvalues and Eigenvectors</a></li>
<li class="chapter" data-level="2.16" data-path="2.16-diagonalizability-of-a-matrix.html"><a href="2.16-diagonalizability-of-a-matrix.html"><i class="fa fa-check"></i><b>2.16</b> Diagonalizability of a Matrix </a></li>
<li class="chapter" data-level="2.17" data-path="2.17-trace-of-a-square-matrix.html"><a href="2.17-trace-of-a-square-matrix.html"><i class="fa fa-check"></i><b>2.17</b> Trace of a Square Matrix </a></li>
<li class="chapter" data-level="2.18" data-path="2.18-algebraic-and-geometric-multiplicity.html"><a href="2.18-algebraic-and-geometric-multiplicity.html"><i class="fa fa-check"></i><b>2.18</b> Algebraic and Geometric Multiplicity</a></li>
<li class="chapter" data-level="2.19" data-path="2.19-types-of-matrices.html"><a href="2.19-types-of-matrices.html"><i class="fa fa-check"></i><b>2.19</b> Types of Matrices</a></li>
<li class="chapter" data-level="2.20" data-path="2.20-matrix-factorization.html"><a href="2.20-matrix-factorization.html"><i class="fa fa-check"></i><b>2.20</b> Matrix Factorization </a><ul>
<li class="chapter" data-level="2.20.1" data-path="2.20-matrix-factorization.html"><a href="2.20-matrix-factorization.html#eigen-spectral-decomposition"><i class="fa fa-check"></i><b>2.20.1</b> Eigen (Spectral) Decomposition  </a></li>
<li class="chapter" data-level="2.20.2" data-path="2.20-matrix-factorization.html"><a href="2.20-matrix-factorization.html#ludecomposition"><i class="fa fa-check"></i><b>2.20.2</b> LU Decomposition (Doolittle Algorithm)</a></li>
<li class="chapter" data-level="2.20.3" data-path="2.20-matrix-factorization.html"><a href="2.20-matrix-factorization.html#ldu-factorization"><i class="fa fa-check"></i><b>2.20.3</b> LDU Factorization </a></li>
<li class="chapter" data-level="2.20.4" data-path="2.20-matrix-factorization.html"><a href="2.20-matrix-factorization.html#qr-factorization-gram-schmidt-householder-and-givens"><i class="fa fa-check"></i><b>2.20.4</b> QR Factorization (Gram-Schmidt, Householder, and Givens) </a></li>
<li class="chapter" data-level="2.20.5" data-path="2.20-matrix-factorization.html"><a href="2.20-matrix-factorization.html#cholesky-factorization"><i class="fa fa-check"></i><b>2.20.5</b> Cholesky Factorization </a></li>
<li class="chapter" data-level="2.20.6" data-path="2.20-matrix-factorization.html"><a href="2.20-matrix-factorization.html#svd-factorization"><i class="fa fa-check"></i><b>2.20.6</b> SVD Factorization </a></li>
<li class="chapter" data-level="2.20.7" data-path="2.20-matrix-factorization.html"><a href="2.20-matrix-factorization.html#jordan-decomposition"><i class="fa fa-check"></i><b>2.20.7</b> Jordan Decomposition </a></li>
<li class="chapter" data-level="2.20.8" data-path="2.20-matrix-factorization.html"><a href="2.20-matrix-factorization.html#other-decomposition"><i class="fa fa-check"></i><b>2.20.8</b> Other Decomposition</a></li>
</ul></li>
<li class="chapter" data-level="2.21" data-path="2.21-software-libraries.html"><a href="2.21-software-libraries.html"><i class="fa fa-check"></i><b>2.21</b> Software libraries    </a></li>
<li class="chapter" data-level="2.22" data-path="2.22-summary.html"><a href="2.22-summary.html"><i class="fa fa-check"></i><b>2.22</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="3-numericallinearalgebra.html"><a href="3-numericallinearalgebra.html"><i class="fa fa-check"></i><b>3</b> Numerical Linear Algebra II</a><ul>
<li class="chapter" data-level="3.1" data-path="3.1-iteration-and-convergence.html"><a href="3.1-iteration-and-convergence.html"><i class="fa fa-check"></i><b>3.1</b> Iteration and Convergence </a></li>
<li class="chapter" data-level="3.2" data-path="3.2-approximating-eigenvalues-and-eigenvectors-by-iteration-av-lambda-v.html"><a href="3.2-approximating-eigenvalues-and-eigenvectors-by-iteration-av-lambda-v.html"><i class="fa fa-check"></i><b>3.2</b> Approximating Eigenvalues and EigenVectors by Iteration (<span class="math inline">\(Av = \lambda v\)</span>)</a><ul>
<li class="chapter" data-level="3.2.1" data-path="3.2-approximating-eigenvalues-and-eigenvectors-by-iteration-av-lambda-v.html"><a href="3.2-approximating-eigenvalues-and-eigenvectors-by-iteration-av-lambda-v.html#power-method"><i class="fa fa-check"></i><b>3.2.1</b> Power Method </a></li>
<li class="chapter" data-level="3.2.2" data-path="3.2-approximating-eigenvalues-and-eigenvectors-by-iteration-av-lambda-v.html"><a href="3.2-approximating-eigenvalues-and-eigenvectors-by-iteration-av-lambda-v.html#inverse-power-method-using-lu-decomposition"><i class="fa fa-check"></i><b>3.2.2</b> Inverse Power Method (using LU Decomposition)</a></li>
<li class="chapter" data-level="3.2.3" data-path="3.2-approximating-eigenvalues-and-eigenvectors-by-iteration-av-lambda-v.html"><a href="3.2-approximating-eigenvalues-and-eigenvectors-by-iteration-av-lambda-v.html#rayleigh-quotient-method-using-lu-decomposition"><i class="fa fa-check"></i><b>3.2.3</b> Rayleigh Quotient Method (using LU Decomposition)</a></li>
<li class="chapter" data-level="3.2.4" data-path="3.2-approximating-eigenvalues-and-eigenvectors-by-iteration-av-lambda-v.html"><a href="3.2-approximating-eigenvalues-and-eigenvectors-by-iteration-av-lambda-v.html#qr-method-using-qr-decomposition-by-givens"><i class="fa fa-check"></i><b>3.2.4</b> QR Method (using QR Decomposition by Givens)</a></li>
<li class="chapter" data-level="3.2.5" data-path="3.2-approximating-eigenvalues-and-eigenvectors-by-iteration-av-lambda-v.html"><a href="3.2-approximating-eigenvalues-and-eigenvectors-by-iteration-av-lambda-v.html#jacobi-eigenvalue-method-using-jacobi-rotation"><i class="fa fa-check"></i><b>3.2.5</b> Jacobi Eigenvalue Method (using Jacobi Rotation)</a></li>
<li class="chapter" data-level="3.2.6" data-path="3.2-approximating-eigenvalues-and-eigenvectors-by-iteration-av-lambda-v.html"><a href="3.2-approximating-eigenvalues-and-eigenvectors-by-iteration-av-lambda-v.html#arnoldi-method-using-gram-schmidt-in-krylov-subspace"><i class="fa fa-check"></i><b>3.2.6</b> Arnoldi Method (using Gram-Schmidt in Krylov Subspace) </a></li>
<li class="chapter" data-level="3.2.7" data-path="3.2-approximating-eigenvalues-and-eigenvectors-by-iteration-av-lambda-v.html"><a href="3.2-approximating-eigenvalues-and-eigenvectors-by-iteration-av-lambda-v.html#lanczos-method-using-gram-schmidt-in-krylov-subspace"><i class="fa fa-check"></i><b>3.2.7</b> Lanczos Method (using Gram-Schmidt in Krylov Subspace)</a></li>
<li class="chapter" data-level="3.2.8" data-path="3.2-approximating-eigenvalues-and-eigenvectors-by-iteration-av-lambda-v.html"><a href="3.2-approximating-eigenvalues-and-eigenvectors-by-iteration-av-lambda-v.html#fine-tuning-of-iteration-and-convergence"><i class="fa fa-check"></i><b>3.2.8</b> Fine-Tuning of Iteration and Convergence</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="3.3-approximating-root-and-fixed-point-by-iteration.html"><a href="3.3-approximating-root-and-fixed-point-by-iteration.html"><i class="fa fa-check"></i><b>3.3</b> Approximating Root and Fixed-Point by Iteration</a><ul>
<li class="chapter" data-level="3.3.1" data-path="3.3-approximating-root-and-fixed-point-by-iteration.html"><a href="3.3-approximating-root-and-fixed-point-by-iteration.html#root-finding-method-fx-0"><i class="fa fa-check"></i><b>3.3.1</b> Root-Finding Method (<span class="math inline">\(f(x) = 0\)</span>) </a></li>
<li class="chapter" data-level="3.3.2" data-path="3.3-approximating-root-and-fixed-point-by-iteration.html"><a href="3.3-approximating-root-and-fixed-point-by-iteration.html#fixed-point-method-fx-x"><i class="fa fa-check"></i><b>3.3.2</b> Fixed-Point Method (<span class="math inline">\(f(x) = x\)</span>) </a></li>
<li class="chapter" data-level="3.3.3" data-path="3.3-approximating-root-and-fixed-point-by-iteration.html"><a href="3.3-approximating-root-and-fixed-point-by-iteration.html#bisection-method"><i class="fa fa-check"></i><b>3.3.3</b> Bisection Method </a></li>
<li class="chapter" data-level="3.3.4" data-path="3.3-approximating-root-and-fixed-point-by-iteration.html"><a href="3.3-approximating-root-and-fixed-point-by-iteration.html#newton-raphson-method-using-the-tangent-line"><i class="fa fa-check"></i><b>3.3.4</b> Newton-Raphson Method (using the Tangent Line)</a></li>
<li class="chapter" data-level="3.3.5" data-path="3.3-approximating-root-and-fixed-point-by-iteration.html"><a href="3.3-approximating-root-and-fixed-point-by-iteration.html#secant-method-using-the-secant-line"><i class="fa fa-check"></i><b>3.3.5</b> Secant Method (using the Secant Line)</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="3.4-approximating-solutions-to-systems-of-eqs-by-iteration-ax-b.html"><a href="3.4-approximating-solutions-to-systems-of-eqs-by-iteration-ax-b.html"><i class="fa fa-check"></i><b>3.4</b> Approximating Solutions to Systems of Eqs by Iteration (<span class="math inline">\(Ax = b\)</span>)</a><ul>
<li class="chapter" data-level="3.4.1" data-path="3.4-approximating-solutions-to-systems-of-eqs-by-iteration-ax-b.html"><a href="3.4-approximating-solutions-to-systems-of-eqs-by-iteration-ax-b.html#krylovmethods"><i class="fa fa-check"></i><b>3.4.1</b> Krylov Methods</a></li>
<li class="chapter" data-level="3.4.2" data-path="3.4-approximating-solutions-to-systems-of-eqs-by-iteration-ax-b.html"><a href="3.4-approximating-solutions-to-systems-of-eqs-by-iteration-ax-b.html#gmres-generalized-minimal-residual"><i class="fa fa-check"></i><b>3.4.2</b> GMRES (Generalized Minimal Residual)  </a></li>
<li class="chapter" data-level="3.4.3" data-path="3.4-approximating-solutions-to-systems-of-eqs-by-iteration-ax-b.html"><a href="3.4-approximating-solutions-to-systems-of-eqs-by-iteration-ax-b.html#conjugate-gradient-method-cg"><i class="fa fa-check"></i><b>3.4.3</b> Conjugate Gradient Method (CG)  </a></li>
<li class="chapter" data-level="3.4.4" data-path="3.4-approximating-solutions-to-systems-of-eqs-by-iteration-ax-b.html"><a href="3.4-approximating-solutions-to-systems-of-eqs-by-iteration-ax-b.html#jacobi-and-gauss-seidel-method"><i class="fa fa-check"></i><b>3.4.4</b> Jacobi and Gauss-Seidel Method </a></li>
<li class="chapter" data-level="3.4.5" data-path="3.4-approximating-solutions-to-systems-of-eqs-by-iteration-ax-b.html"><a href="3.4-approximating-solutions-to-systems-of-eqs-by-iteration-ax-b.html#successive-over-relaxation-sor-method"><i class="fa fa-check"></i><b>3.4.5</b> Successive Over-Relaxation (SOR) Method  </a></li>
<li class="chapter" data-level="3.4.6" data-path="3.4-approximating-solutions-to-systems-of-eqs-by-iteration-ax-b.html"><a href="3.4-approximating-solutions-to-systems-of-eqs-by-iteration-ax-b.html#newtons-method"><i class="fa fa-check"></i><b>3.4.6</b> Newtonâs Method </a></li>
<li class="chapter" data-level="3.4.7" data-path="3.4-approximating-solutions-to-systems-of-eqs-by-iteration-ax-b.html"><a href="3.4-approximating-solutions-to-systems-of-eqs-by-iteration-ax-b.html#broydens-method"><i class="fa fa-check"></i><b>3.4.7</b> Broydenâs Method </a></li>
<li class="chapter" data-level="3.4.8" data-path="3.4-approximating-solutions-to-systems-of-eqs-by-iteration-ax-b.html"><a href="3.4-approximating-solutions-to-systems-of-eqs-by-iteration-ax-b.html#bfgs-broyden-fletcher-goldfarb-shanno-method"><i class="fa fa-check"></i><b>3.4.8</b> BFGS (Broyden-Fletcher-Goldfarb-Shanno) method </a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="3.5-polynomialregression.html"><a href="3.5-polynomialregression.html"><i class="fa fa-check"></i><b>3.5</b> Approximating Polynomial Functions by Regression</a><ul>
<li class="chapter" data-level="3.5.1" data-path="3.5-polynomialregression.html"><a href="3.5-polynomialregression.html#least-squares"><i class="fa fa-check"></i><b>3.5.1</b> Least-Squares </a></li>
<li class="chapter" data-level="3.5.2" data-path="3.5-polynomialregression.html"><a href="3.5-polynomialregression.html#linear-regression"><i class="fa fa-check"></i><b>3.5.2</b> Linear Regression </a></li>
<li class="chapter" data-level="3.5.3" data-path="3.5-polynomialregression.html"><a href="3.5-polynomialregression.html#higherdegreepolynomials"><i class="fa fa-check"></i><b>3.5.3</b> Higher Degree Polynomials</a></li>
<li class="chapter" data-level="3.5.4" data-path="3.5-polynomialregression.html"><a href="3.5-polynomialregression.html#non-linear-regression"><i class="fa fa-check"></i><b>3.5.4</b> Non-Linear Regression </a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="3.6-approximating-polynomial-functions-by-series-expansion.html"><a href="3.6-approximating-polynomial-functions-by-series-expansion.html"><i class="fa fa-check"></i><b>3.6</b> Approximating Polynomial Functions by Series Expansion </a></li>
<li class="chapter" data-level="3.7" data-path="3.7-polynomialinterpolation.html"><a href="3.7-polynomialinterpolation.html"><i class="fa fa-check"></i><b>3.7</b> Approximating Polynomial Functions by Interpolation</a><ul>
<li class="chapter" data-level="3.7.1" data-path="3.7-polynomialinterpolation.html"><a href="3.7-polynomialinterpolation.html#polynomial-interpolation"><i class="fa fa-check"></i><b>3.7.1</b> Polynomial interpolation </a></li>
<li class="chapter" data-level="3.7.2" data-path="3.7-polynomialinterpolation.html"><a href="3.7-polynomialinterpolation.html#lagrange-interpolation"><i class="fa fa-check"></i><b>3.7.2</b> Lagrange interpolation </a></li>
<li class="chapter" data-level="3.7.3" data-path="3.7-polynomialinterpolation.html"><a href="3.7-polynomialinterpolation.html#newton-interpolation"><i class="fa fa-check"></i><b>3.7.3</b> Newton interpolation </a></li>
<li class="chapter" data-level="3.7.4" data-path="3.7-polynomialinterpolation.html"><a href="3.7-polynomialinterpolation.html#newton-forward-interpolation"><i class="fa fa-check"></i><b>3.7.4</b> Newton Forward interpolation </a></li>
<li class="chapter" data-level="3.7.5" data-path="3.7-polynomialinterpolation.html"><a href="3.7-polynomialinterpolation.html#newton-backward-interpolation"><i class="fa fa-check"></i><b>3.7.5</b> Newton Backward interpolation </a></li>
<li class="chapter" data-level="3.7.6" data-path="3.7-polynomialinterpolation.html"><a href="3.7-polynomialinterpolation.html#interpolation-considerations"><i class="fa fa-check"></i><b>3.7.6</b> Interpolation Considerations</a></li>
<li class="chapter" data-level="3.7.7" data-path="3.7-polynomialinterpolation.html"><a href="3.7-polynomialinterpolation.html#lebesque-constant"><i class="fa fa-check"></i><b>3.7.7</b> Lebesque Constant </a></li>
<li class="chapter" data-level="3.7.8" data-path="3.7-polynomialinterpolation.html"><a href="3.7-polynomialinterpolation.html#horners-method"><i class="fa fa-check"></i><b>3.7.8</b> Hornerâs method </a></li>
<li class="chapter" data-level="3.7.9" data-path="3.7-polynomialinterpolation.html"><a href="3.7-polynomialinterpolation.html#piecewise-polynomial-interpolation"><i class="fa fa-check"></i><b>3.7.9</b> Piecewise Polynomial Interpolation </a></li>
<li class="chapter" data-level="3.7.10" data-path="3.7-polynomialinterpolation.html"><a href="3.7-polynomialinterpolation.html#b-spline-interpolation"><i class="fa fa-check"></i><b>3.7.10</b> B-Spline interpolation </a></li>
<li class="chapter" data-level="3.7.11" data-path="3.7-polynomialinterpolation.html"><a href="3.7-polynomialinterpolation.html#bspline"><i class="fa fa-check"></i><b>3.7.11</b> B-Spline Regression</a></li>
<li class="chapter" data-level="3.7.12" data-path="3.7-polynomialinterpolation.html"><a href="3.7-polynomialinterpolation.html#p-spline-regression"><i class="fa fa-check"></i><b>3.7.12</b> P-Spline Regression </a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="3.8-polynomialsmoothing.html"><a href="3.8-polynomialsmoothing.html"><i class="fa fa-check"></i><b>3.8</b> Approximating Polynomial Functions by Smoothing</a><ul>
<li class="chapter" data-level="3.8.1" data-path="3.8-polynomialsmoothing.html"><a href="3.8-polynomialsmoothing.html#bin-smoothing"><i class="fa fa-check"></i><b>3.8.1</b> Bin Smoothing </a></li>
<li class="chapter" data-level="3.8.2" data-path="3.8-polynomialsmoothing.html"><a href="3.8-polynomialsmoothing.html#kernel-smoothing"><i class="fa fa-check"></i><b>3.8.2</b> Kernel Smoothing </a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="3.9-polynomial-optimization.html"><a href="3.9-polynomial-optimization.html"><i class="fa fa-check"></i><b>3.9</b> Polynomial Optimization </a><ul>
<li class="chapter" data-level="3.9.1" data-path="3.9-polynomial-optimization.html"><a href="3.9-polynomial-optimization.html#simplexmethod"><i class="fa fa-check"></i><b>3.9.1</b> Simplex Method</a></li>
<li class="chapter" data-level="3.9.2" data-path="3.9-polynomial-optimization.html"><a href="3.9-polynomial-optimization.html#dualsimplex"><i class="fa fa-check"></i><b>3.9.2</b> Dual Simplex</a></li>
<li class="chapter" data-level="3.9.3" data-path="3.9-polynomial-optimization.html"><a href="3.9-polynomial-optimization.html#primaldual"><i class="fa fa-check"></i><b>3.9.3</b> Primal-Dual Formulation</a></li>
<li class="chapter" data-level="3.9.4" data-path="3.9-polynomial-optimization.html"><a href="3.9-polynomial-optimization.html#lagrange-multiplier"><i class="fa fa-check"></i><b>3.9.4</b> Lagrange Multiplier </a></li>
<li class="chapter" data-level="3.9.5" data-path="3.9-polynomial-optimization.html"><a href="3.9-polynomial-optimization.html#karush-khun-tucker-conditions"><i class="fa fa-check"></i><b>3.9.5</b> Karush-Khun-Tucker Conditions </a></li>
</ul></li>
<li class="chapter" data-level="3.10" data-path="3.10-summary-1.html"><a href="3.10-summary-1.html"><i class="fa fa-check"></i><b>3.10</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="4-numericalcalculus.html"><a href="4-numericalcalculus.html"><i class="fa fa-check"></i><b>4</b> Numerical Calculus</a><ul>
<li class="chapter" data-level="4.1" data-path="4.1-introductory-calculus.html"><a href="4.1-introductory-calculus.html"><i class="fa fa-check"></i><b>4.1</b> Introductory Calculus</a><ul>
<li class="chapter" data-level="4.1.1" data-path="4.1-introductory-calculus.html"><a href="4.1-introductory-calculus.html#function"><i class="fa fa-check"></i><b>4.1.1</b> Function</a></li>
<li class="chapter" data-level="4.1.2" data-path="4.1-introductory-calculus.html"><a href="4.1-introductory-calculus.html#slopes"><i class="fa fa-check"></i><b>4.1.2</b> Slopes</a></li>
<li class="chapter" data-level="4.1.3" data-path="4.1-introductory-calculus.html"><a href="4.1-introductory-calculus.html#limits"><i class="fa fa-check"></i><b>4.1.3</b> Limits</a></li>
<li class="chapter" data-level="4.1.4" data-path="4.1-introductory-calculus.html"><a href="4.1-introductory-calculus.html#derivatives"><i class="fa fa-check"></i><b>4.1.4</b> Derivatives</a></li>
<li class="chapter" data-level="4.1.5" data-path="4.1-introductory-calculus.html"><a href="4.1-introductory-calculus.html#integrals"><i class="fa fa-check"></i><b>4.1.5</b> Integrals </a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="4.2-approximation-by-numerical-integration.html"><a href="4.2-approximation-by-numerical-integration.html"><i class="fa fa-check"></i><b>4.2</b> Approximation by Numerical Integration </a><ul>
<li class="chapter" data-level="4.2.1" data-path="4.2-approximation-by-numerical-integration.html"><a href="4.2-approximation-by-numerical-integration.html#newton-cotes-quadrature"><i class="fa fa-check"></i><b>4.2.1</b> Newton-Cotes Quadrature </a></li>
<li class="chapter" data-level="4.2.2" data-path="4.2-approximation-by-numerical-integration.html"><a href="4.2-approximation-by-numerical-integration.html#composite-and-adaptive-quadrature"><i class="fa fa-check"></i><b>4.2.2</b> Composite and Adaptive Quadrature </a></li>
<li class="chapter" data-level="4.2.3" data-path="4.2-approximation-by-numerical-integration.html"><a href="4.2-approximation-by-numerical-integration.html#gaussianquadrature"><i class="fa fa-check"></i><b>4.2.3</b> Gaussian Quadrature</a></li>
<li class="chapter" data-level="4.2.4" data-path="4.2-approximation-by-numerical-integration.html"><a href="4.2-approximation-by-numerical-integration.html#romberg-integration"><i class="fa fa-check"></i><b>4.2.4</b> Romberg integration </a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="4.3-approximation-by-numerical-differentiation.html"><a href="4.3-approximation-by-numerical-differentiation.html"><i class="fa fa-check"></i><b>4.3</b> Approximation by Numerical Differentiation </a><ul>
<li class="chapter" data-level="4.3.1" data-path="4.3-approximation-by-numerical-differentiation.html"><a href="4.3-approximation-by-numerical-differentiation.html#order-of-accuracy"><i class="fa fa-check"></i><b>4.3.1</b> Order of Accuracy</a></li>
<li class="chapter" data-level="4.3.2" data-path="4.3-approximation-by-numerical-differentiation.html"><a href="4.3-approximation-by-numerical-differentiation.html#finite-difference"><i class="fa fa-check"></i><b>4.3.2</b> Finite Difference </a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="4.4-approximation-using-ordinary-differential-equations.html"><a href="4.4-approximation-using-ordinary-differential-equations.html"><i class="fa fa-check"></i><b>4.4</b> Approximation using Ordinary Differential Equations  </a><ul>
<li class="chapter" data-level="4.4.1" data-path="4.4-approximation-using-ordinary-differential-equations.html"><a href="4.4-approximation-using-ordinary-differential-equations.html#eulers-method-explicit"><i class="fa fa-check"></i><b>4.4.1</b> Eulerâs Method (Explicit) </a></li>
<li class="chapter" data-level="4.4.2" data-path="4.4-approximation-using-ordinary-differential-equations.html"><a href="4.4-approximation-using-ordinary-differential-equations.html#eulers-method-implicit"><i class="fa fa-check"></i><b>4.4.2</b> Eulerâs Method (Implicit)</a></li>
<li class="chapter" data-level="4.4.3" data-path="4.4-approximation-using-ordinary-differential-equations.html"><a href="4.4-approximation-using-ordinary-differential-equations.html#heuns-method"><i class="fa fa-check"></i><b>4.4.3</b> Heunâs Method </a></li>
<li class="chapter" data-level="4.4.4" data-path="4.4-approximation-using-ordinary-differential-equations.html"><a href="4.4-approximation-using-ordinary-differential-equations.html#runge-kutta-method"><i class="fa fa-check"></i><b>4.4.4</b> Runge-Kutta Method </a></li>
<li class="chapter" data-level="4.4.5" data-path="4.4-approximation-using-ordinary-differential-equations.html"><a href="4.4-approximation-using-ordinary-differential-equations.html#shooting-method"><i class="fa fa-check"></i><b>4.4.5</b> Shooting Method </a></li>
<li class="chapter" data-level="4.4.6" data-path="4.4-approximation-using-ordinary-differential-equations.html"><a href="4.4-approximation-using-ordinary-differential-equations.html#finite-difference-method"><i class="fa fa-check"></i><b>4.4.6</b> Finite Difference Method  </a></li>
<li class="chapter" data-level="4.4.7" data-path="4.4-approximation-using-ordinary-differential-equations.html"><a href="4.4-approximation-using-ordinary-differential-equations.html#finite-element-method-based-on-wrm-and-vm"><i class="fa fa-check"></i><b>4.4.7</b> Finite Element Method (based on WRM and VM) </a></li>
<li class="chapter" data-level="4.4.8" data-path="4.4-approximation-using-ordinary-differential-equations.html"><a href="4.4-approximation-using-ordinary-differential-equations.html#least-square-method-using-wrm"><i class="fa fa-check"></i><b>4.4.8</b> Least-Square Method (using WRM)</a></li>
<li class="chapter" data-level="4.4.9" data-path="4.4-approximation-using-ordinary-differential-equations.html"><a href="4.4-approximation-using-ordinary-differential-equations.html#galerkin-method-using-wrm"><i class="fa fa-check"></i><b>4.4.9</b> Galerkin Method (using WRM)</a></li>
<li class="chapter" data-level="4.4.10" data-path="4.4-approximation-using-ordinary-differential-equations.html"><a href="4.4-approximation-using-ordinary-differential-equations.html#petrov-galerkin-method-using-wrm"><i class="fa fa-check"></i><b>4.4.10</b> Petrov-Galerkin Method (using WRM)</a></li>
<li class="chapter" data-level="4.4.11" data-path="4.4-approximation-using-ordinary-differential-equations.html"><a href="4.4-approximation-using-ordinary-differential-equations.html#rayleigh-ritz-method-using-wrm"><i class="fa fa-check"></i><b>4.4.11</b> Rayleigh-Ritz Method (using WRM)</a></li>
<li class="chapter" data-level="4.4.12" data-path="4.4-approximation-using-ordinary-differential-equations.html"><a href="4.4-approximation-using-ordinary-differential-equations.html#subdomain-method-using-subdomains"><i class="fa fa-check"></i><b>4.4.12</b> Subdomain Method (using subdomains)</a></li>
<li class="chapter" data-level="4.4.13" data-path="4.4-approximation-using-ordinary-differential-equations.html"><a href="4.4-approximation-using-ordinary-differential-equations.html#collocation-method-using-direct-location-points"><i class="fa fa-check"></i><b>4.4.13</b> Collocation Method (using direct location points) </a></li>
<li class="chapter" data-level="4.4.14" data-path="4.4-approximation-using-ordinary-differential-equations.html"><a href="4.4-approximation-using-ordinary-differential-equations.html#weighted-residual-summary"><i class="fa fa-check"></i><b>4.4.14</b> Weighted Residual Summary </a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="4.5-approximation-using-functional-differential-equations.html"><a href="4.5-approximation-using-functional-differential-equations.html"><i class="fa fa-check"></i><b>4.5</b> Approximation using Functional Differential Equations </a><ul>
<li class="chapter" data-level="4.5.1" data-path="4.5-approximation-using-functional-differential-equations.html"><a href="4.5-approximation-using-functional-differential-equations.html#variational-functions"><i class="fa fa-check"></i><b>4.5.1</b> Variational Functions </a></li>
<li class="chapter" data-level="4.5.2" data-path="4.5-approximation-using-functional-differential-equations.html"><a href="4.5-approximation-using-functional-differential-equations.html#variational-methods"><i class="fa fa-check"></i><b>4.5.2</b> Variational Methods </a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="4.6-approximation-using-partial-differential-equations.html"><a href="4.6-approximation-using-partial-differential-equations.html"><i class="fa fa-check"></i><b>4.6</b> Approximation using Partial Differential Equations </a><ul>
<li class="chapter" data-level="4.6.1" data-path="4.6-approximation-using-partial-differential-equations.html"><a href="4.6-approximation-using-partial-differential-equations.html#the-laplace-equation-elliptic-pde"><i class="fa fa-check"></i><b>4.6.1</b> The Laplace Equation (Elliptic PDE)  </a></li>
<li class="chapter" data-level="4.6.2" data-path="4.6-approximation-using-partial-differential-equations.html"><a href="4.6-approximation-using-partial-differential-equations.html#the-heat-equation-parabolic-pde"><i class="fa fa-check"></i><b>4.6.2</b> The Heat equation (Parabolic PDE)  </a></li>
<li class="chapter" data-level="4.6.3" data-path="4.6-approximation-using-partial-differential-equations.html"><a href="4.6-approximation-using-partial-differential-equations.html#the-wave-equation-hyperbolic-pde"><i class="fa fa-check"></i><b>4.6.3</b> The Wave equation (Hyperbolic PDE)  </a></li>
<li class="chapter" data-level="4.6.4" data-path="4.6-approximation-using-partial-differential-equations.html"><a href="4.6-approximation-using-partial-differential-equations.html#the-crank-nicolson-equation"><i class="fa fa-check"></i><b>4.6.4</b> The Crank-Nicolson Equation </a></li>
<li class="chapter" data-level="4.6.5" data-path="4.6-approximation-using-partial-differential-equations.html"><a href="4.6-approximation-using-partial-differential-equations.html#the-burgers-equation"><i class="fa fa-check"></i><b>4.6.5</b> The Burgerâs Equation </a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="4.7-approximation-using-fourier-series-and-transform.html"><a href="4.7-approximation-using-fourier-series-and-transform.html"><i class="fa fa-check"></i><b>4.7</b> Approximation using Fourier Series And Transform </a><ul>
<li class="chapter" data-level="4.7.1" data-path="4.7-approximation-using-fourier-series-and-transform.html"><a href="4.7-approximation-using-fourier-series-and-transform.html#discrete-fourier-transform-dft"><i class="fa fa-check"></i><b>4.7.1</b> Discrete Fourier Transform (DFT)  </a></li>
<li class="chapter" data-level="4.7.2" data-path="4.7-approximation-using-fourier-series-and-transform.html"><a href="4.7-approximation-using-fourier-series-and-transform.html#inverse-discrete-fourier-transformation-idft"><i class="fa fa-check"></i><b>4.7.2</b> Inverse Discrete Fourier Transformation (IDFT)  </a></li>
<li class="chapter" data-level="4.7.3" data-path="4.7-approximation-using-fourier-series-and-transform.html"><a href="4.7-approximation-using-fourier-series-and-transform.html#fast-fourier-transform-fft"><i class="fa fa-check"></i><b>4.7.3</b> Fast Fourier Transform (FFT)  </a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="4.8-summary-2.html"><a href="4.8-summary-2.html"><i class="fa fa-check"></i><b>4.8</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="5-numericalprobability.html"><a href="5-numericalprobability.html"><i class="fa fa-check"></i><b>5</b> Probability and Distribution</a><ul>
<li class="chapter" data-level="5.1" data-path="5.1-approximation-based-on-random-chances.html"><a href="5.1-approximation-based-on-random-chances.html"><i class="fa fa-check"></i><b>5.1</b> Approximation based on Random Chances </a></li>
<li class="chapter" data-level="5.2" data-path="5.2-distribution.html"><a href="5.2-distribution.html"><i class="fa fa-check"></i><b>5.2</b> Distribution</a></li>
<li class="chapter" data-level="5.3" data-path="5.3-mass-and-density.html"><a href="5.3-mass-and-density.html"><i class="fa fa-check"></i><b>5.3</b> Mass and Density  </a></li>
<li class="chapter" data-level="5.4" data-path="5.4-probability.html"><a href="5.4-probability.html"><i class="fa fa-check"></i><b>5.4</b> Probability  </a></li>
<li class="chapter" data-level="5.5" data-path="5.5-probability-density-function-pdf.html"><a href="5.5-probability-density-function-pdf.html"><i class="fa fa-check"></i><b>5.5</b> Probability Density Function (PDF)  </a></li>
<li class="chapter" data-level="5.6" data-path="5.6-probability-mass-function-pmf.html"><a href="5.6-probability-mass-function-pmf.html"><i class="fa fa-check"></i><b>5.6</b> Probability Mass function (PMF)  </a></li>
<li class="chapter" data-level="5.7" data-path="5.7-cumulative-distribution-function-cdf.html"><a href="5.7-cumulative-distribution-function-cdf.html"><i class="fa fa-check"></i><b>5.7</b> Cumulative Distribution Function (CDF)  </a></li>
<li class="chapter" data-level="5.8" data-path="5.8-special-functions.html"><a href="5.8-special-functions.html"><i class="fa fa-check"></i><b>5.8</b> Special Functions</a><ul>
<li class="chapter" data-level="5.8.1" data-path="5.8-special-functions.html"><a href="5.8-special-functions.html#gamma-function"><i class="fa fa-check"></i><b>5.8.1</b> Gamma function </a></li>
<li class="chapter" data-level="5.8.2" data-path="5.8-special-functions.html"><a href="5.8-special-functions.html#incomplete-gamma-function"><i class="fa fa-check"></i><b>5.8.2</b> Incomplete Gamma function </a></li>
<li class="chapter" data-level="5.8.3" data-path="5.8-special-functions.html"><a href="5.8-special-functions.html#digamma-function"><i class="fa fa-check"></i><b>5.8.3</b> Digamma Function </a></li>
<li class="chapter" data-level="5.8.4" data-path="5.8-special-functions.html"><a href="5.8-special-functions.html#beta-function"><i class="fa fa-check"></i><b>5.8.4</b> Beta function </a></li>
<li class="chapter" data-level="5.8.5" data-path="5.8-special-functions.html"><a href="5.8-special-functions.html#incomplete-beta-function"><i class="fa fa-check"></i><b>5.8.5</b> Incomplete Beta function </a></li>
<li class="chapter" data-level="5.8.6" data-path="5.8-special-functions.html"><a href="5.8-special-functions.html#regularized-beta-function"><i class="fa fa-check"></i><b>5.8.6</b> Regularized Beta function  </a></li>
<li class="chapter" data-level="5.8.7" data-path="5.8-special-functions.html"><a href="5.8-special-functions.html#hypergeometric-function"><i class="fa fa-check"></i><b>5.8.7</b> Hypergeometric function </a></li>
<li class="chapter" data-level="5.8.8" data-path="5.8-special-functions.html"><a href="5.8-special-functions.html#continued-fraction"><i class="fa fa-check"></i><b>5.8.8</b> Continued Fraction </a></li>
<li class="chapter" data-level="5.8.9" data-path="5.8-special-functions.html"><a href="5.8-special-functions.html#dirac-delta-function"><i class="fa fa-check"></i><b>5.8.9</b> Dirac Delta Function </a></li>
<li class="chapter" data-level="5.8.10" data-path="5.8-special-functions.html"><a href="5.8-special-functions.html#kronecker-delta-function"><i class="fa fa-check"></i><b>5.8.10</b> Kronecker Delta Function </a></li>
</ul></li>
<li class="chapter" data-level="5.9" data-path="5.9-distributiontypes.html"><a href="5.9-distributiontypes.html"><i class="fa fa-check"></i><b>5.9</b> Types of Distribution</a><ul>
<li class="chapter" data-level="5.9.1" data-path="5.9-distributiontypes.html"><a href="5.9-distributiontypes.html#bernoulli-distribution"><i class="fa fa-check"></i><b>5.9.1</b> Bernoulli distribution </a></li>
<li class="chapter" data-level="5.9.2" data-path="5.9-distributiontypes.html"><a href="5.9-distributiontypes.html#binomial-distribution"><i class="fa fa-check"></i><b>5.9.2</b> Binomial distribution </a></li>
<li class="chapter" data-level="5.9.3" data-path="5.9-distributiontypes.html"><a href="5.9-distributiontypes.html#multinomial-distribution"><i class="fa fa-check"></i><b>5.9.3</b> Multinomial distribution </a></li>
<li class="chapter" data-level="5.9.4" data-path="5.9-distributiontypes.html"><a href="5.9-distributiontypes.html#geometric-distribution"><i class="fa fa-check"></i><b>5.9.4</b> Geometric distribution </a></li>
<li class="chapter" data-level="5.9.5" data-path="5.9-distributiontypes.html"><a href="5.9-distributiontypes.html#beta-distribution"><i class="fa fa-check"></i><b>5.9.5</b> Beta distribution </a></li>
<li class="chapter" data-level="5.9.6" data-path="5.9-distributiontypes.html"><a href="5.9-distributiontypes.html#dirichlet-distribution"><i class="fa fa-check"></i><b>5.9.6</b> Dirichlet distribution </a></li>
<li class="chapter" data-level="5.9.7" data-path="5.9-distributiontypes.html"><a href="5.9-distributiontypes.html#exponential-distribution"><i class="fa fa-check"></i><b>5.9.7</b> Exponential distribution </a></li>
<li class="chapter" data-level="5.9.8" data-path="5.9-distributiontypes.html"><a href="5.9-distributiontypes.html#gamma-distribution"><i class="fa fa-check"></i><b>5.9.8</b> Gamma distribution </a></li>
<li class="chapter" data-level="5.9.9" data-path="5.9-distributiontypes.html"><a href="5.9-distributiontypes.html#inverse-gamma-distribution"><i class="fa fa-check"></i><b>5.9.9</b> Inverse Gamma distribution </a></li>
<li class="chapter" data-level="5.9.10" data-path="5.9-distributiontypes.html"><a href="5.9-distributiontypes.html#weibull-distribution"><i class="fa fa-check"></i><b>5.9.10</b> Weibull distribution </a></li>
<li class="chapter" data-level="5.9.11" data-path="5.9-distributiontypes.html"><a href="5.9-distributiontypes.html#poisson-distribution"><i class="fa fa-check"></i><b>5.9.11</b> Poisson distribution </a></li>
<li class="chapter" data-level="5.9.12" data-path="5.9-distributiontypes.html"><a href="5.9-distributiontypes.html#pareto-distribution"><i class="fa fa-check"></i><b>5.9.12</b> Pareto distribution </a></li>
<li class="chapter" data-level="5.9.13" data-path="5.9-distributiontypes.html"><a href="5.9-distributiontypes.html#normal-distribution"><i class="fa fa-check"></i><b>5.9.13</b> Normal distribution </a></li>
<li class="chapter" data-level="5.9.14" data-path="5.9-distributiontypes.html"><a href="5.9-distributiontypes.html#wald-distribution"><i class="fa fa-check"></i><b>5.9.14</b> Wald Distribution </a></li>
<li class="chapter" data-level="5.9.15" data-path="5.9-distributiontypes.html"><a href="5.9-distributiontypes.html#log-normal-distribution"><i class="fa fa-check"></i><b>5.9.15</b> Log-normal Distribution </a></li>
<li class="chapter" data-level="5.9.16" data-path="5.9-distributiontypes.html"><a href="5.9-distributiontypes.html#uniform-distribution"><i class="fa fa-check"></i><b>5.9.16</b> Uniform Distribution </a></li>
<li class="chapter" data-level="5.9.17" data-path="5.9-distributiontypes.html"><a href="5.9-distributiontypes.html#t-distribution"><i class="fa fa-check"></i><b>5.9.17</b> T-Distribution </a></li>
<li class="chapter" data-level="5.9.18" data-path="5.9-distributiontypes.html"><a href="5.9-distributiontypes.html#f-distribution"><i class="fa fa-check"></i><b>5.9.18</b> F-Distribution </a></li>
<li class="chapter" data-level="5.9.19" data-path="5.9-distributiontypes.html"><a href="5.9-distributiontypes.html#chi-square-distribution"><i class="fa fa-check"></i><b>5.9.19</b> Chi-square Distribution </a></li>
<li class="chapter" data-level="5.9.20" data-path="5.9-distributiontypes.html"><a href="5.9-distributiontypes.html#wishartdistribution"><i class="fa fa-check"></i><b>5.9.20</b> Wishart distribution</a></li>
<li class="chapter" data-level="5.9.21" data-path="5.9-distributiontypes.html"><a href="5.9-distributiontypes.html#lkj-distribution"><i class="fa fa-check"></i><b>5.9.21</b> LKJ distribution </a></li>
<li class="chapter" data-level="5.9.22" data-path="5.9-distributiontypes.html"><a href="5.9-distributiontypes.html#mixture-distribution"><i class="fa fa-check"></i><b>5.9.22</b> Mixture distribution </a></li>
<li class="chapter" data-level="5.9.23" data-path="5.9-distributiontypes.html"><a href="5.9-distributiontypes.html#non-parametric-distribution"><i class="fa fa-check"></i><b>5.9.23</b> Non-parametric distribution </a></li>
<li class="chapter" data-level="5.9.24" data-path="5.9-distributiontypes.html"><a href="5.9-distributiontypes.html#multi-dimensional-density"><i class="fa fa-check"></i><b>5.9.24</b> Multi-dimensional Density </a></li>
</ul></li>
<li class="chapter" data-level="5.10" data-path="5.10-summary-3.html"><a href="5.10-summary-3.html"><i class="fa fa-check"></i><b>5.10</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="6-statistics.html"><a href="6-statistics.html"><i class="fa fa-check"></i><b>6</b> Statistical Computation</a><ul>
<li class="chapter" data-level="6.1" data-path="6.1-descriptive-statistics.html"><a href="6.1-descriptive-statistics.html"><i class="fa fa-check"></i><b>6.1</b> Descriptive Statistics</a><ul>
<li class="chapter" data-level="6.1.1" data-path="6.1-descriptive-statistics.html"><a href="6.1-descriptive-statistics.html#visual-representation"><i class="fa fa-check"></i><b>6.1.1</b> Visual Representation</a></li>
<li class="chapter" data-level="6.1.2" data-path="6.1-descriptive-statistics.html"><a href="6.1-descriptive-statistics.html#central-tendency"><i class="fa fa-check"></i><b>6.1.2</b> Central Tendency </a></li>
<li class="chapter" data-level="6.1.3" data-path="6.1-descriptive-statistics.html"><a href="6.1-descriptive-statistics.html#variability"><i class="fa fa-check"></i><b>6.1.3</b> Variability </a></li>
<li class="chapter" data-level="6.1.4" data-path="6.1-descriptive-statistics.html"><a href="6.1-descriptive-statistics.html#kurtosis-and-skewness"><i class="fa fa-check"></i><b>6.1.4</b> Kurtosis and Skewness  </a></li>
<li class="chapter" data-level="6.1.5" data-path="6.1-descriptive-statistics.html"><a href="6.1-descriptive-statistics.html#five-number-summary"><i class="fa fa-check"></i><b>6.1.5</b> Five Number Summary  </a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="6.2-inferential-statistics.html"><a href="6.2-inferential-statistics.html"><i class="fa fa-check"></i><b>6.2</b> Inferential Statistics</a></li>
<li class="chapter" data-level="6.3" data-path="6.3-the-significance-of-difference.html"><a href="6.3-the-significance-of-difference.html"><i class="fa fa-check"></i><b>6.3</b> The Significance of Difference </a><ul>
<li class="chapter" data-level="6.3.1" data-path="6.3-the-significance-of-difference.html"><a href="6.3-the-significance-of-difference.html#hypothesis"><i class="fa fa-check"></i><b>6.3.1</b> Hypothesis</a></li>
<li class="chapter" data-level="6.3.2" data-path="6.3-the-significance-of-difference.html"><a href="6.3-the-significance-of-difference.html#t-test-true-variance-unknown"><i class="fa fa-check"></i><b>6.3.2</b> T-Test (True Variance unknown) </a></li>
<li class="chapter" data-level="6.3.3" data-path="6.3-the-significance-of-difference.html"><a href="6.3-the-significance-of-difference.html#z-test-true-variance-known"><i class="fa fa-check"></i><b>6.3.3</b> Z-Test (True Variance known)</a></li>
<li class="chapter" data-level="6.3.4" data-path="6.3-the-significance-of-difference.html"><a href="6.3-the-significance-of-difference.html#f-test-using-f-ratio"><i class="fa fa-check"></i><b>6.3.4</b> F-Test using F-ratio  </a></li>
<li class="chapter" data-level="6.3.5" data-path="6.3-the-significance-of-difference.html"><a href="6.3-the-significance-of-difference.html#f-test-with-one-way-anova"><i class="fa fa-check"></i><b>6.3.5</b> F-Test with One-Way ANOVA </a></li>
<li class="chapter" data-level="6.3.6" data-path="6.3-the-significance-of-difference.html"><a href="6.3-the-significance-of-difference.html#f-test-with-two-way-anova"><i class="fa fa-check"></i><b>6.3.6</b> F-Test with Two-Way ANOVA </a></li>
<li class="chapter" data-level="6.3.7" data-path="6.3-the-significance-of-difference.html"><a href="6.3-the-significance-of-difference.html#pearsons-chi-square-test"><i class="fa fa-check"></i><b>6.3.7</b> Pearsonâs Chi-square Test </a></li>
<li class="chapter" data-level="6.3.8" data-path="6.3-the-significance-of-difference.html"><a href="6.3-the-significance-of-difference.html#wilcoxon-test"><i class="fa fa-check"></i><b>6.3.8</b> Wilcoxon Test  </a></li>
<li class="chapter" data-level="6.3.9" data-path="6.3-the-significance-of-difference.html"><a href="6.3-the-significance-of-difference.html#kruskal-wallis-test"><i class="fa fa-check"></i><b>6.3.9</b> Kruskal-Wallis Test </a></li>
<li class="chapter" data-level="6.3.10" data-path="6.3-the-significance-of-difference.html"><a href="6.3-the-significance-of-difference.html#friedman-test"><i class="fa fa-check"></i><b>6.3.10</b> Friedman Test </a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="6.4-post-hoc-analysis.html"><a href="6.4-post-hoc-analysis.html"><i class="fa fa-check"></i><b>6.4</b> Post-HOC Analysis </a><ul>
<li class="chapter" data-level="6.4.1" data-path="6.4-post-hoc-analysis.html"><a href="6.4-post-hoc-analysis.html#bonferroni-correction"><i class="fa fa-check"></i><b>6.4.1</b> Bonferroni Correction </a></li>
<li class="chapter" data-level="6.4.2" data-path="6.4-post-hoc-analysis.html"><a href="6.4-post-hoc-analysis.html#benjamini-hochberg-correction"><i class="fa fa-check"></i><b>6.4.2</b> Benjamini-Hochberg Correction </a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="6.5-multiple-comparison-tests.html"><a href="6.5-multiple-comparison-tests.html"><i class="fa fa-check"></i><b>6.5</b> Multiple Comparison Tests </a><ul>
<li class="chapter" data-level="6.5.1" data-path="6.5-multiple-comparison-tests.html"><a href="6.5-multiple-comparison-tests.html#scheffes-test"><i class="fa fa-check"></i><b>6.5.1</b> Scheffeâs Test </a></li>
<li class="chapter" data-level="6.5.2" data-path="6.5-multiple-comparison-tests.html"><a href="6.5-multiple-comparison-tests.html#fishers-test"><i class="fa fa-check"></i><b>6.5.2</b> Fisherâs Test </a></li>
<li class="chapter" data-level="6.5.3" data-path="6.5-multiple-comparison-tests.html"><a href="6.5-multiple-comparison-tests.html#tukeys-test"><i class="fa fa-check"></i><b>6.5.3</b> Tukeyâs Test </a></li>
<li class="chapter" data-level="6.5.4" data-path="6.5-multiple-comparison-tests.html"><a href="6.5-multiple-comparison-tests.html#newman-keul-test"><i class="fa fa-check"></i><b>6.5.4</b> Newman-Keul Test  </a></li>
<li class="chapter" data-level="6.5.5" data-path="6.5-multiple-comparison-tests.html"><a href="6.5-multiple-comparison-tests.html#games-howell-test"><i class="fa fa-check"></i><b>6.5.5</b> Games-Howell Test </a></li>
<li class="chapter" data-level="6.5.6" data-path="6.5-multiple-comparison-tests.html"><a href="6.5-multiple-comparison-tests.html#dunnetts-test"><i class="fa fa-check"></i><b>6.5.6</b> Dunnettâs Test </a></li>
<li class="chapter" data-level="6.5.7" data-path="6.5-multiple-comparison-tests.html"><a href="6.5-multiple-comparison-tests.html#duncans-test"><i class="fa fa-check"></i><b>6.5.7</b> Duncanâs Test </a></li>
<li class="chapter" data-level="6.5.8" data-path="6.5-multiple-comparison-tests.html"><a href="6.5-multiple-comparison-tests.html#meta-analysis-test"><i class="fa fa-check"></i><b>6.5.8</b> Meta-Analysis Test </a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="6.6-statistical-modeling.html"><a href="6.6-statistical-modeling.html"><i class="fa fa-check"></i><b>6.6</b> Statistical Modeling </a><ul>
<li class="chapter" data-level="6.6.1" data-path="6.6-statistical-modeling.html"><a href="6.6-statistical-modeling.html#model-specification"><i class="fa fa-check"></i><b>6.6.1</b> Model Specification </a></li>
<li class="chapter" data-level="6.6.2" data-path="6.6-statistical-modeling.html"><a href="6.6-statistical-modeling.html#statistical-interaction"><i class="fa fa-check"></i><b>6.6.2</b> Statistical Interaction </a></li>
<li class="chapter" data-level="6.6.3" data-path="6.6-statistical-modeling.html"><a href="6.6-statistical-modeling.html#dummy-variables"><i class="fa fa-check"></i><b>6.6.3</b> Dummy Variables </a></li>
<li class="chapter" data-level="6.6.4" data-path="6.6-statistical-modeling.html"><a href="6.6-statistical-modeling.html#model-selection"><i class="fa fa-check"></i><b>6.6.4</b> Model Selection </a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="6.7-regression-analysis.html"><a href="6.7-regression-analysis.html"><i class="fa fa-check"></i><b>6.7</b> Regression Analysis </a><ul>
<li class="chapter" data-level="6.7.1" data-path="6.7-regression-analysis.html"><a href="6.7-regression-analysis.html#assumptions"><i class="fa fa-check"></i><b>6.7.1</b> Assumptions</a></li>
<li class="chapter" data-level="6.7.2" data-path="6.7-regression-analysis.html"><a href="6.7-regression-analysis.html#correlation-coefficients"><i class="fa fa-check"></i><b>6.7.2</b> Correlation Coefficients </a></li>
<li class="chapter" data-level="6.7.3" data-path="6.7-regression-analysis.html"><a href="6.7-regression-analysis.html#homoscedasticity-and-heteroscedasticity"><i class="fa fa-check"></i><b>6.7.3</b> Homoscedasticity and Heteroscedasticity  </a></li>
<li class="chapter" data-level="6.7.4" data-path="6.7-regression-analysis.html"><a href="6.7-regression-analysis.html#normality-and-leverage"><i class="fa fa-check"></i><b>6.7.4</b> Normality and Leverage  </a></li>
<li class="chapter" data-level="6.7.5" data-path="6.7-regression-analysis.html"><a href="6.7-regression-analysis.html#collinearity"><i class="fa fa-check"></i><b>6.7.5</b> Collinearity </a></li>
<li class="chapter" data-level="6.7.6" data-path="6.7-regression-analysis.html"><a href="6.7-regression-analysis.html#dispersion"><i class="fa fa-check"></i><b>6.7.6</b> Dispersion </a></li>
<li class="chapter" data-level="6.7.7" data-path="6.7-regression-analysis.html"><a href="6.7-regression-analysis.html#diagnostic-plots"><i class="fa fa-check"></i><b>6.7.7</b> Diagnostic Plots</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="6.8-the-significance-of-regression.html"><a href="6.8-the-significance-of-regression.html"><i class="fa fa-check"></i><b>6.8</b> The Significance of Regression </a><ul>
<li class="chapter" data-level="6.8.1" data-path="6.8-the-significance-of-regression.html"><a href="6.8-the-significance-of-regression.html#simple-linear-regression"><i class="fa fa-check"></i><b>6.8.1</b> Simple Linear Regression</a></li>
<li class="chapter" data-level="6.8.2" data-path="6.8-the-significance-of-regression.html"><a href="6.8-the-significance-of-regression.html#multilinear-regression"><i class="fa fa-check"></i><b>6.8.2</b> Multilinear Regression </a></li>
<li class="chapter" data-level="6.8.3" data-path="6.8-the-significance-of-regression.html"><a href="6.8-the-significance-of-regression.html#logistic-regression"><i class="fa fa-check"></i><b>6.8.3</b> Logistic Regression </a></li>
<li class="chapter" data-level="6.8.4" data-path="6.8-the-significance-of-regression.html"><a href="6.8-the-significance-of-regression.html#poisson-regression"><i class="fa fa-check"></i><b>6.8.4</b> Poisson Regression </a></li>
<li class="chapter" data-level="6.8.5" data-path="6.8-the-significance-of-regression.html"><a href="6.8-the-significance-of-regression.html#cox-regression"><i class="fa fa-check"></i><b>6.8.5</b> Cox Regression </a></li>
<li class="chapter" data-level="6.8.6" data-path="6.8-the-significance-of-regression.html"><a href="6.8-the-significance-of-regression.html#polynomial-regression"><i class="fa fa-check"></i><b>6.8.6</b> Polynomial Regression </a></li>
<li class="chapter" data-level="6.8.7" data-path="6.8-the-significance-of-regression.html"><a href="6.8-the-significance-of-regression.html#b-splines-and-natural-splines"><i class="fa fa-check"></i><b>6.8.7</b> B-Splines and Natural Splines  </a></li>
<li class="chapter" data-level="6.8.8" data-path="6.8-the-significance-of-regression.html"><a href="6.8-the-significance-of-regression.html#spline-smoothing"><i class="fa fa-check"></i><b>6.8.8</b> Spline Smoothing </a></li>
<li class="chapter" data-level="6.8.9" data-path="6.8-the-significance-of-regression.html"><a href="6.8-the-significance-of-regression.html#loess-and-lowess"><i class="fa fa-check"></i><b>6.8.9</b> LOESS and LOWESS  </a></li>
</ul></li>
<li class="chapter" data-level="6.9" data-path="6.9-inference-for-regression.html"><a href="6.9-inference-for-regression.html"><i class="fa fa-check"></i><b>6.9</b> Inference for Regression</a><ul>
<li class="chapter" data-level="6.9.1" data-path="6.9-inference-for-regression.html"><a href="6.9-inference-for-regression.html#goodness-of-fit-linear-regression"><i class="fa fa-check"></i><b>6.9.1</b> Goodness of Fit (Linear Regression) </a></li>
<li class="chapter" data-level="6.9.2" data-path="6.9-inference-for-regression.html"><a href="6.9-inference-for-regression.html#goodness-of-fit-non-linear-regression"><i class="fa fa-check"></i><b>6.9.2</b> Goodness of Fit (Non-Linear Regression) </a></li>
<li class="chapter" data-level="6.9.3" data-path="6.9-inference-for-regression.html"><a href="6.9-inference-for-regression.html#confidence-interval"><i class="fa fa-check"></i><b>6.9.3</b> Confidence interval </a></li>
</ul></li>
<li class="chapter" data-level="6.10" data-path="6.10-summary-4.html"><a href="6.10-summary-4.html"><i class="fa fa-check"></i><b>6.10</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="7-bayesian.html"><a href="7-bayesian.html"><i class="fa fa-check"></i><b>7</b> Bayesian Computation I</a><ul>
<li class="chapter" data-level="7.1" data-path="7.1-probability-1.html"><a href="7.1-probability-1.html"><i class="fa fa-check"></i><b>7.1</b> Probability </a><ul>
<li class="chapter" data-level="7.1.1" data-path="7.1-probability-1.html"><a href="7.1-probability-1.html#marginal-probability"><i class="fa fa-check"></i><b>7.1.1</b> Marginal Probability </a></li>
<li class="chapter" data-level="7.1.2" data-path="7.1-probability-1.html"><a href="7.1-probability-1.html#joint-probability"><i class="fa fa-check"></i><b>7.1.2</b> Joint Probability </a></li>
<li class="chapter" data-level="7.1.3" data-path="7.1-probability-1.html"><a href="7.1-probability-1.html#conditional-probability"><i class="fa fa-check"></i><b>7.1.3</b> Conditional Probability </a></li>
<li class="chapter" data-level="7.1.4" data-path="7.1-probability-1.html"><a href="7.1-probability-1.html#negation-probability"><i class="fa fa-check"></i><b>7.1.4</b> Negation Probability </a></li>
<li class="chapter" data-level="7.1.5" data-path="7.1-probability-1.html"><a href="7.1-probability-1.html#combination-of-probabilities"><i class="fa fa-check"></i><b>7.1.5</b> Combination of Probabilities</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="7.2-probability-rules.html"><a href="7.2-probability-rules.html"><i class="fa fa-check"></i><b>7.2</b> Probability Rules</a><ul>
<li class="chapter" data-level="7.2.1" data-path="7.2-probability-rules.html"><a href="7.2-probability-rules.html#law-of-total-probability"><i class="fa fa-check"></i><b>7.2.1</b> Law of Total Probability</a></li>
<li class="chapter" data-level="7.2.2" data-path="7.2-probability-rules.html"><a href="7.2-probability-rules.html#law-of-total-expectation"><i class="fa fa-check"></i><b>7.2.2</b> Law of Total Expectation </a></li>
<li class="chapter" data-level="7.2.3" data-path="7.2-probability-rules.html"><a href="7.2-probability-rules.html#law-of-total-variance"><i class="fa fa-check"></i><b>7.2.3</b> Law of Total Variance </a></li>
<li class="chapter" data-level="7.2.4" data-path="7.2-probability-rules.html"><a href="7.2-probability-rules.html#law-of-total-covariance"><i class="fa fa-check"></i><b>7.2.4</b> Law of Total Covariance </a></li>
<li class="chapter" data-level="7.2.5" data-path="7.2-probability-rules.html"><a href="7.2-probability-rules.html#law-of-large-numbers"><i class="fa fa-check"></i><b>7.2.5</b> Law of Large Numbers </a></li>
<li class="chapter" data-level="7.2.6" data-path="7.2-probability-rules.html"><a href="7.2-probability-rules.html#central-limit-theorem"><i class="fa fa-check"></i><b>7.2.6</b> Central Limit Theorem </a></li>
<li class="chapter" data-level="7.2.7" data-path="7.2-probability-rules.html"><a href="7.2-probability-rules.html#rule-of-independence"><i class="fa fa-check"></i><b>7.2.7</b> Rule of Independence </a></li>
<li class="chapter" data-level="7.2.8" data-path="7.2-probability-rules.html"><a href="7.2-probability-rules.html#rule-of-exchangeability"><i class="fa fa-check"></i><b>7.2.8</b> Rule of Exchangeability </a></li>
<li class="chapter" data-level="7.2.9" data-path="7.2-probability-rules.html"><a href="7.2-probability-rules.html#rule-of-expectation-and-variance"><i class="fa fa-check"></i><b>7.2.9</b> Rule of Expectation and Variance</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="7.3-bayes-theorem.html"><a href="7.3-bayes-theorem.html"><i class="fa fa-check"></i><b>7.3</b> Bayes Theorem </a><ul>
<li class="chapter" data-level="7.3.1" data-path="7.3-bayes-theorem.html"><a href="7.3-bayes-theorem.html#naÃ¯ve-bayes"><i class="fa fa-check"></i><b>7.3.1</b> NaÃ¯ve Bayes </a></li>
<li class="chapter" data-level="7.3.2" data-path="7.3-bayes-theorem.html"><a href="7.3-bayes-theorem.html#likelihood"><i class="fa fa-check"></i><b>7.3.2</b> Likelihood</a></li>
<li class="chapter" data-level="7.3.3" data-path="7.3-bayes-theorem.html"><a href="7.3-bayes-theorem.html#posterior-probability"><i class="fa fa-check"></i><b>7.3.3</b> Posterior Probability  </a></li>
<li class="chapter" data-level="7.3.4" data-path="7.3-bayes-theorem.html"><a href="7.3-bayes-theorem.html#prior-probability"><i class="fa fa-check"></i><b>7.3.4</b> Prior Probability  </a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="7.4-conjugacy.html"><a href="7.4-conjugacy.html"><i class="fa fa-check"></i><b>7.4</b> Conjugacy</a><ul>
<li class="chapter" data-level="7.4.1" data-path="7.4-conjugacy.html"><a href="7.4-conjugacy.html#precision-1"><i class="fa fa-check"></i><b>7.4.1</b> Precision </a></li>
<li class="chapter" data-level="7.4.2" data-path="7.4-conjugacy.html"><a href="7.4-conjugacy.html#conjugate-prior"><i class="fa fa-check"></i><b>7.4.2</b> Conjugate Prior </a></li>
<li class="chapter" data-level="7.4.3" data-path="7.4-conjugacy.html"><a href="7.4-conjugacy.html#normal-normal-conjugacy"><i class="fa fa-check"></i><b>7.4.3</b> Normal-Normal Conjugacy </a></li>
<li class="chapter" data-level="7.4.4" data-path="7.4-conjugacy.html"><a href="7.4-conjugacy.html#normal-inverse-gamma-conjugacy"><i class="fa fa-check"></i><b>7.4.4</b> Normal-Inverse Gamma Conjugacy </a></li>
<li class="chapter" data-level="7.4.5" data-path="7.4-conjugacy.html"><a href="7.4-conjugacy.html#multivariate-normal-conjugacy"><i class="fa fa-check"></i><b>7.4.5</b> Multivariate Normal Conjugacy </a></li>
<li class="chapter" data-level="7.4.6" data-path="7.4-conjugacy.html"><a href="7.4-conjugacy.html#normal-wishart-conjugacy"><i class="fa fa-check"></i><b>7.4.6</b> Normal Wishart Conjugacy </a></li>
<li class="chapter" data-level="7.4.7" data-path="7.4-conjugacy.html"><a href="7.4-conjugacy.html#normal-inverse-wishart-conjugacy"><i class="fa fa-check"></i><b>7.4.7</b> Normal-Inverse Wishart Conjugacy </a></li>
<li class="chapter" data-level="7.4.8" data-path="7.4-conjugacy.html"><a href="7.4-conjugacy.html#normal-lkj-conjugacy"><i class="fa fa-check"></i><b>7.4.8</b> Normal-LKJ Conjugacy </a></li>
<li class="chapter" data-level="7.4.9" data-path="7.4-conjugacy.html"><a href="7.4-conjugacy.html#binomial-beta-conjugacy"><i class="fa fa-check"></i><b>7.4.9</b> Binomial-Beta Conjugacy </a></li>
<li class="chapter" data-level="7.4.10" data-path="7.4-conjugacy.html"><a href="7.4-conjugacy.html#geometric-beta-conjugacy"><i class="fa fa-check"></i><b>7.4.10</b> Geometric-Beta Conjugacy </a></li>
<li class="chapter" data-level="7.4.11" data-path="7.4-conjugacy.html"><a href="7.4-conjugacy.html#poisson-gamma-conjugacy"><i class="fa fa-check"></i><b>7.4.11</b> Poisson-Gamma Conjugacy </a></li>
<li class="chapter" data-level="7.4.12" data-path="7.4-conjugacy.html"><a href="7.4-conjugacy.html#exponential-gamma-conjugacy"><i class="fa fa-check"></i><b>7.4.12</b> Exponential-Gamma Conjugacy </a></li>
<li class="chapter" data-level="7.4.13" data-path="7.4-conjugacy.html"><a href="7.4-conjugacy.html#multinomial-dirichlet-conjugacy"><i class="fa fa-check"></i><b>7.4.13</b> Multinomial-Dirichlet Conjugacy </a></li>
<li class="chapter" data-level="7.4.14" data-path="7.4-conjugacy.html"><a href="7.4-conjugacy.html#hyperparameters"><i class="fa fa-check"></i><b>7.4.14</b> Hyperparameters </a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="7.5-information-theory.html"><a href="7.5-information-theory.html"><i class="fa fa-check"></i><b>7.5</b> Information Theory </a><ul>
<li class="chapter" data-level="7.5.1" data-path="7.5-information-theory.html"><a href="7.5-information-theory.html#information"><i class="fa fa-check"></i><b>7.5.1</b> Information </a></li>
<li class="chapter" data-level="7.5.2" data-path="7.5-information-theory.html"><a href="7.5-information-theory.html#entropy"><i class="fa fa-check"></i><b>7.5.2</b> Entropy </a></li>
<li class="chapter" data-level="7.5.3" data-path="7.5-information-theory.html"><a href="7.5-information-theory.html#gini-index"><i class="fa fa-check"></i><b>7.5.3</b> Gini Index </a></li>
<li class="chapter" data-level="7.5.4" data-path="7.5-information-theory.html"><a href="7.5-information-theory.html#information-gain"><i class="fa fa-check"></i><b>7.5.4</b> Information Gain </a></li>
<li class="chapter" data-level="7.5.5" data-path="7.5-information-theory.html"><a href="7.5-information-theory.html#mutual-information"><i class="fa fa-check"></i><b>7.5.5</b> Mutual Information </a></li>
<li class="chapter" data-level="7.5.6" data-path="7.5-information-theory.html"><a href="7.5-information-theory.html#kullback-leibler-divergence"><i class="fa fa-check"></i><b>7.5.6</b> Kullback-Leibler Divergence  </a></li>
<li class="chapter" data-level="7.5.7" data-path="7.5-information-theory.html"><a href="7.5-information-theory.html#jensens-inequality"><i class="fa fa-check"></i><b>7.5.7</b> Jensenâs Inequality</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="7.6-bayesianinference.html"><a href="7.6-bayesianinference.html"><i class="fa fa-check"></i><b>7.6</b> Bayesian Inference</a><ul>
<li class="chapter" data-level="7.6.1" data-path="7.6-bayesianinference.html"><a href="7.6-bayesianinference.html#maximum-likelihood-mle"><i class="fa fa-check"></i><b>7.6.1</b> Maximum Likelihood (MLE)  </a></li>
<li class="chapter" data-level="7.6.2" data-path="7.6-bayesianinference.html"><a href="7.6-bayesianinference.html#maximum-a-posteriori-map"><i class="fa fa-check"></i><b>7.6.2</b> Maximum A-posteriori (MAP)  </a></li>
<li class="chapter" data-level="7.6.3" data-path="7.6-bayesianinference.html"><a href="7.6-bayesianinference.html#laplace-approximation"><i class="fa fa-check"></i><b>7.6.3</b> Laplace Approximation </a></li>
<li class="chapter" data-level="7.6.4" data-path="7.6-bayesianinference.html"><a href="7.6-bayesianinference.html#expectation-maximization-em"><i class="fa fa-check"></i><b>7.6.4</b> Expectation-Maximization (EM)  </a></li>
<li class="chapter" data-level="7.6.5" data-path="7.6-bayesianinference.html"><a href="7.6-bayesianinference.html#variational-inference"><i class="fa fa-check"></i><b>7.6.5</b> Variational Inference </a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="8-bayesian2.html"><a href="8-bayesian2.html"><i class="fa fa-check"></i><b>8</b> Bayesian Computation II</a><ul>
<li class="chapter" data-level="8.1" data-path="8.1-bayesian-models.html"><a href="8.1-bayesian-models.html"><i class="fa fa-check"></i><b>8.1</b> Bayesian Models </a><ul>
<li class="chapter" data-level="8.1.1" data-path="8.1-bayesian-models.html"><a href="8.1-bayesian-models.html#belief-propagation"><i class="fa fa-check"></i><b>8.1.1</b> Belief Propagation </a></li>
<li class="chapter" data-level="8.1.2" data-path="8.1-bayesian-models.html"><a href="8.1-bayesian-models.html#expectation-propagation"><i class="fa fa-check"></i><b>8.1.2</b> Expectation Propagation </a></li>
<li class="chapter" data-level="8.1.3" data-path="8.1-bayesian-models.html"><a href="8.1-bayesian-models.html#markov-chain"><i class="fa fa-check"></i><b>8.1.3</b> Markov Chain </a></li>
<li class="chapter" data-level="8.1.4" data-path="8.1-bayesian-models.html"><a href="8.1-bayesian-models.html#hidden-markov-model"><i class="fa fa-check"></i><b>8.1.4</b> Hidden Markov Model  </a></li>
<li class="chapter" data-level="8.1.5" data-path="8.1-bayesian-models.html"><a href="8.1-bayesian-models.html#dynamic-system-model"><i class="fa fa-check"></i><b>8.1.5</b> Dynamic System Model</a></li>
<li class="chapter" data-level="8.1.6" data-path="8.1-bayesian-models.html"><a href="8.1-bayesian-models.html#bayes-filter"><i class="fa fa-check"></i><b>8.1.6</b> Bayes Filter </a></li>
<li class="chapter" data-level="8.1.7" data-path="8.1-bayesian-models.html"><a href="8.1-bayesian-models.html#kalman-filter"><i class="fa fa-check"></i><b>8.1.7</b> Kalman Filter </a></li>
<li class="chapter" data-level="8.1.8" data-path="8.1-bayesian-models.html"><a href="8.1-bayesian-models.html#extended-kalman-filter"><i class="fa fa-check"></i><b>8.1.8</b> Extended Kalman Filter </a></li>
<li class="chapter" data-level="8.1.9" data-path="8.1-bayesian-models.html"><a href="8.1-bayesian-models.html#unscented-kalman-filter"><i class="fa fa-check"></i><b>8.1.9</b> Unscented Kalman Filter </a></li>
<li class="chapter" data-level="8.1.10" data-path="8.1-bayesian-models.html"><a href="8.1-bayesian-models.html#particle-filter"><i class="fa fa-check"></i><b>8.1.10</b> Particle Filter </a></li>
<li class="chapter" data-level="8.1.11" data-path="8.1-bayesian-models.html"><a href="8.1-bayesian-models.html#ensemble-kalman-filter"><i class="fa fa-check"></i><b>8.1.11</b> Ensemble Kalman Filter </a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="8.2-simulation-and-sampling.html"><a href="8.2-simulation-and-sampling.html"><i class="fa fa-check"></i><b>8.2</b> Simulation and Sampling</a><ul>
<li class="chapter" data-level="8.2.1" data-path="8.2-simulation-and-sampling.html"><a href="8.2-simulation-and-sampling.html#monte-carlo-estimation"><i class="fa fa-check"></i><b>8.2.1</b> Monte Carlo Estimation </a></li>
<li class="chapter" data-level="8.2.2" data-path="8.2-simulation-and-sampling.html"><a href="8.2-simulation-and-sampling.html#monte-carlo-simulation"><i class="fa fa-check"></i><b>8.2.2</b> Monte Carlo Simulation </a></li>
<li class="chapter" data-level="8.2.3" data-path="8.2-simulation-and-sampling.html"><a href="8.2-simulation-and-sampling.html#markov-chain-monte-carlo"><i class="fa fa-check"></i><b>8.2.3</b> Markov Chain Monte Carlo  </a></li>
<li class="chapter" data-level="8.2.4" data-path="8.2-simulation-and-sampling.html"><a href="8.2-simulation-and-sampling.html#metropolis-hastings-monte-carlo"><i class="fa fa-check"></i><b>8.2.4</b> Metropolis-Hastings Monte Carlo  </a></li>
<li class="chapter" data-level="8.2.5" data-path="8.2-simulation-and-sampling.html"><a href="8.2-simulation-and-sampling.html#hamiltonian-monte-carlo"><i class="fa fa-check"></i><b>8.2.5</b> Hamiltonian Monte Carlo  </a></li>
<li class="chapter" data-level="8.2.6" data-path="8.2-simulation-and-sampling.html"><a href="8.2-simulation-and-sampling.html#gibbs-sampling"><i class="fa fa-check"></i><b>8.2.6</b> Gibbs Sampling </a></li>
<li class="chapter" data-level="8.2.7" data-path="8.2-simulation-and-sampling.html"><a href="8.2-simulation-and-sampling.html#importance-sampling"><i class="fa fa-check"></i><b>8.2.7</b> Importance Sampling </a></li>
<li class="chapter" data-level="8.2.8" data-path="8.2-simulation-and-sampling.html"><a href="8.2-simulation-and-sampling.html#rejection-sampling"><i class="fa fa-check"></i><b>8.2.8</b> Rejection Sampling </a></li>
<li class="chapter" data-level="8.2.9" data-path="8.2-simulation-and-sampling.html"><a href="8.2-simulation-and-sampling.html#jags-modeling"><i class="fa fa-check"></i><b>8.2.9</b> JAGS Modeling </a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="8.3-bayesian-analysis.html"><a href="8.3-bayesian-analysis.html"><i class="fa fa-check"></i><b>8.3</b> Bayesian Analysis</a><ul>
<li class="chapter" data-level="8.3.1" data-path="8.3-bayesian-analysis.html"><a href="8.3-bayesian-analysis.html#autocorrelation"><i class="fa fa-check"></i><b>8.3.1</b> Autocorrelation </a></li>
<li class="chapter" data-level="8.3.2" data-path="8.3-bayesian-analysis.html"><a href="8.3-bayesian-analysis.html#predictive-probability"><i class="fa fa-check"></i><b>8.3.2</b> Predictive Probability </a></li>
<li class="chapter" data-level="8.3.3" data-path="8.3-bayesian-analysis.html"><a href="8.3-bayesian-analysis.html#posterior-interval"><i class="fa fa-check"></i><b>8.3.3</b> Posterior Interval </a></li>
<li class="chapter" data-level="8.3.4" data-path="8.3-bayesian-analysis.html"><a href="8.3-bayesian-analysis.html#bayes-factor"><i class="fa fa-check"></i><b>8.3.4</b> Bayes Factor </a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="8.4-summary-5.html"><a href="8.4-summary-5.html"><i class="fa fa-check"></i><b>8.4</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="9-machinelearning1.html"><a href="9-machinelearning1.html"><i class="fa fa-check"></i><b>9</b> Computational Learning I</a><ul>
<li class="chapter" data-level="9.1" data-path="9.1-observation-and-measurement.html"><a href="9.1-observation-and-measurement.html"><i class="fa fa-check"></i><b>9.1</b> Observation and Measurement</a><ul>
<li class="chapter" data-level="9.1.1" data-path="9.1-observation-and-measurement.html"><a href="9.1-observation-and-measurement.html#levels-of-measurements"><i class="fa fa-check"></i><b>9.1.1</b> Levels of Measurements</a></li>
<li class="chapter" data-level="9.1.2" data-path="9.1-observation-and-measurement.html"><a href="9.1-observation-and-measurement.html#levels-of-categorical-measurements"><i class="fa fa-check"></i><b>9.1.2</b> Levels of Categorical measurements</a></li>
<li class="chapter" data-level="9.1.3" data-path="9.1-observation-and-measurement.html"><a href="9.1-observation-and-measurement.html#levels-of-continuous-measurements"><i class="fa fa-check"></i><b>9.1.3</b> Levels of Continuous measurements</a></li>
<li class="chapter" data-level="9.1.4" data-path="9.1-observation-and-measurement.html"><a href="9.1-observation-and-measurement.html#discrete-vs-continuous-measurements"><i class="fa fa-check"></i><b>9.1.4</b> Discrete vs Continuous measurements</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="9.2-input-data.html"><a href="9.2-input-data.html"><i class="fa fa-check"></i><b>9.2</b> Input Data</a><ul>
<li class="chapter" data-level="9.2.1" data-path="9.2-input-data.html"><a href="9.2-input-data.html#structured-data"><i class="fa fa-check"></i><b>9.2.1</b> Structured Data</a></li>
<li class="chapter" data-level="9.2.2" data-path="9.2-input-data.html"><a href="9.2-input-data.html#non-structured-data"><i class="fa fa-check"></i><b>9.2.2</b> Non-Structured Data</a></li>
<li class="chapter" data-level="9.2.3" data-path="9.2-input-data.html"><a href="9.2-input-data.html#statistical-data"><i class="fa fa-check"></i><b>9.2.3</b> Statistical Data</a></li>
<li class="chapter" data-level="9.2.4" data-path="9.2-input-data.html"><a href="9.2-input-data.html#real-time-and-near-real-time-data"><i class="fa fa-check"></i><b>9.2.4</b> Real-Time and Near Real-Time Data</a></li>
<li class="chapter" data-level="9.2.5" data-path="9.2-input-data.html"><a href="9.2-input-data.html#oltp-and-datawarehouse"><i class="fa fa-check"></i><b>9.2.5</b> OLTP and Datawarehouse</a></li>
<li class="chapter" data-level="9.2.6" data-path="9.2-input-data.html"><a href="9.2-input-data.html#data-lake"><i class="fa fa-check"></i><b>9.2.6</b> Data lake</a></li>
<li class="chapter" data-level="9.2.7" data-path="9.2-input-data.html"><a href="9.2-input-data.html#natural-language-nl"><i class="fa fa-check"></i><b>9.2.7</b> Natural Language (NL)</a></li>
<li class="chapter" data-level="9.2.8" data-path="9.2-input-data.html"><a href="9.2-input-data.html#multimedia-md"><i class="fa fa-check"></i><b>9.2.8</b> Multimedia (MD)</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="9.3-primitive-methods.html"><a href="9.3-primitive-methods.html"><i class="fa fa-check"></i><b>9.3</b> Primitive Methods</a><ul>
<li class="chapter" data-level="9.3.1" data-path="9.3-primitive-methods.html"><a href="9.3-primitive-methods.html#weighting"><i class="fa fa-check"></i><b>9.3.1</b> Weighting</a></li>
<li class="chapter" data-level="9.3.2" data-path="9.3-primitive-methods.html"><a href="9.3-primitive-methods.html#smoothing"><i class="fa fa-check"></i><b>9.3.2</b> Smoothing</a></li>
<li class="chapter" data-level="9.3.3" data-path="9.3-primitive-methods.html"><a href="9.3-primitive-methods.html#normalizing"><i class="fa fa-check"></i><b>9.3.3</b> Normalizing</a></li>
<li class="chapter" data-level="9.3.4" data-path="9.3-primitive-methods.html"><a href="9.3-primitive-methods.html#standardizing"><i class="fa fa-check"></i><b>9.3.4</b> Standardizing </a></li>
<li class="chapter" data-level="9.3.5" data-path="9.3-primitive-methods.html"><a href="9.3-primitive-methods.html#centering"><i class="fa fa-check"></i><b>9.3.5</b> Centering </a></li>
<li class="chapter" data-level="9.3.6" data-path="9.3-primitive-methods.html"><a href="9.3-primitive-methods.html#scaling-1"><i class="fa fa-check"></i><b>9.3.6</b> Scaling </a></li>
<li class="chapter" data-level="9.3.7" data-path="9.3-primitive-methods.html"><a href="9.3-primitive-methods.html#transforming"><i class="fa fa-check"></i><b>9.3.7</b> Transforming</a></li>
<li class="chapter" data-level="9.3.8" data-path="9.3-primitive-methods.html"><a href="9.3-primitive-methods.html#clipping"><i class="fa fa-check"></i><b>9.3.8</b> Clipping </a></li>
<li class="chapter" data-level="9.3.9" data-path="9.3-primitive-methods.html"><a href="9.3-primitive-methods.html#regularizing"><i class="fa fa-check"></i><b>9.3.9</b> Regularizing</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="9.4-distance-metrics.html"><a href="9.4-distance-metrics.html"><i class="fa fa-check"></i><b>9.4</b> Distance Metrics</a><ul>
<li class="chapter" data-level="9.4.1" data-path="9.4-distance-metrics.html"><a href="9.4-distance-metrics.html#cosine-similarity"><i class="fa fa-check"></i><b>9.4.1</b> Cosine Similarity</a></li>
<li class="chapter" data-level="9.4.2" data-path="9.4-distance-metrics.html"><a href="9.4-distance-metrics.html#manhattan-and-euclidean-distance"><i class="fa fa-check"></i><b>9.4.2</b> Manhattan and Euclidean Distance  </a></li>
<li class="chapter" data-level="9.4.3" data-path="9.4-distance-metrics.html"><a href="9.4-distance-metrics.html#minkowski-and-chebyshev-supremum-distance"><i class="fa fa-check"></i><b>9.4.3</b> Minkowski and Chebyshev (Supremum) Distance  </a></li>
<li class="chapter" data-level="9.4.4" data-path="9.4-distance-metrics.html"><a href="9.4-distance-metrics.html#jaccard-similarity-and-distance"><i class="fa fa-check"></i><b>9.4.4</b> Jaccard (Similarity and Distance) </a></li>
<li class="chapter" data-level="9.4.5" data-path="9.4-distance-metrics.html"><a href="9.4-distance-metrics.html#hamming-distance"><i class="fa fa-check"></i><b>9.4.5</b> Hamming Distance </a></li>
<li class="chapter" data-level="9.4.6" data-path="9.4-distance-metrics.html"><a href="9.4-distance-metrics.html#mahalanobis-distance"><i class="fa fa-check"></i><b>9.4.6</b> Mahalanobis Distance </a></li>
<li class="chapter" data-level="9.4.7" data-path="9.4-distance-metrics.html"><a href="9.4-distance-metrics.html#precision-and-accuracy"><i class="fa fa-check"></i><b>9.4.7</b> Precision and Accuracy  </a></li>
<li class="chapter" data-level="9.4.8" data-path="9.4-distance-metrics.html"><a href="9.4-distance-metrics.html#auc-on-roc"><i class="fa fa-check"></i><b>9.4.8</b> AUC on ROC </a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="9.5-exploratory-data-analysis.html"><a href="9.5-exploratory-data-analysis.html"><i class="fa fa-check"></i><b>9.5</b> Exploratory Data Analysis</a><ul>
<li class="chapter" data-level="9.5.1" data-path="9.5-exploratory-data-analysis.html"><a href="9.5-exploratory-data-analysis.html#data-cleaning-wrangling"><i class="fa fa-check"></i><b>9.5.1</b> Data Cleaning (Wrangling)  </a></li>
<li class="chapter" data-level="9.5.2" data-path="9.5-exploratory-data-analysis.html"><a href="9.5-exploratory-data-analysis.html#association"><i class="fa fa-check"></i><b>9.5.2</b> Association</a></li>
<li class="chapter" data-level="9.5.3" data-path="9.5-exploratory-data-analysis.html"><a href="9.5-exploratory-data-analysis.html#pattern-discovery"><i class="fa fa-check"></i><b>9.5.3</b> Pattern Discovery</a></li>
<li class="chapter" data-level="9.5.4" data-path="9.5-exploratory-data-analysis.html"><a href="9.5-exploratory-data-analysis.html#null-invariance"><i class="fa fa-check"></i><b>9.5.4</b> Null Invariance </a></li>
<li class="chapter" data-level="9.5.5" data-path="9.5-exploratory-data-analysis.html"><a href="9.5-exploratory-data-analysis.html#correlation-and-collinearity"><i class="fa fa-check"></i><b>9.5.5</b> Correlation and Collinearity  </a></li>
<li class="chapter" data-level="9.5.6" data-path="9.5-exploratory-data-analysis.html"><a href="9.5-exploratory-data-analysis.html#covariance"><i class="fa fa-check"></i><b>9.5.6</b> Covariance </a></li>
<li class="chapter" data-level="9.5.7" data-path="9.5-exploratory-data-analysis.html"><a href="9.5-exploratory-data-analysis.html#outliers-leverage-influence"><i class="fa fa-check"></i><b>9.5.7</b> Outliers, Leverage, Influence   </a></li>
<li class="chapter" data-level="9.5.8" data-path="9.5-exploratory-data-analysis.html"><a href="9.5-exploratory-data-analysis.html#dominating-factors"><i class="fa fa-check"></i><b>9.5.8</b> Dominating Factors </a></li>
<li class="chapter" data-level="9.5.9" data-path="9.5-exploratory-data-analysis.html"><a href="9.5-exploratory-data-analysis.html#missingness-and-imputation"><i class="fa fa-check"></i><b>9.5.9</b> Missingness and Imputation  </a></li>
<li class="chapter" data-level="9.5.10" data-path="9.5-exploratory-data-analysis.html"><a href="9.5-exploratory-data-analysis.html#confounding-variable"><i class="fa fa-check"></i><b>9.5.10</b> Confounding Variable </a></li>
<li class="chapter" data-level="9.5.11" data-path="9.5-exploratory-data-analysis.html"><a href="9.5-exploratory-data-analysis.html#data-leakage"><i class="fa fa-check"></i><b>9.5.11</b> Data Leakage </a></li>
<li class="chapter" data-level="9.5.12" data-path="9.5-exploratory-data-analysis.html"><a href="9.5-exploratory-data-analysis.html#one-hot-encoding"><i class="fa fa-check"></i><b>9.5.12</b> One Hot Encoding </a></li>
<li class="chapter" data-level="9.5.13" data-path="9.5-exploratory-data-analysis.html"><a href="9.5-exploratory-data-analysis.html#winsorization-and-trimming"><i class="fa fa-check"></i><b>9.5.13</b> Winsorization and Trimming  </a></li>
<li class="chapter" data-level="9.5.14" data-path="9.5-exploratory-data-analysis.html"><a href="9.5-exploratory-data-analysis.html#discretization"><i class="fa fa-check"></i><b>9.5.14</b> Discretization </a></li>
<li class="chapter" data-level="9.5.15" data-path="9.5-exploratory-data-analysis.html"><a href="9.5-exploratory-data-analysis.html#stratification"><i class="fa fa-check"></i><b>9.5.15</b> Stratification </a></li>
<li class="chapter" data-level="9.5.16" data-path="9.5-exploratory-data-analysis.html"><a href="9.5-exploratory-data-analysis.html#fine-and-coarse-classing"><i class="fa fa-check"></i><b>9.5.16</b> Fine and Coarse Classing</a></li>
<li class="chapter" data-level="9.5.17" data-path="9.5-exploratory-data-analysis.html"><a href="9.5-exploratory-data-analysis.html#embedding"><i class="fa fa-check"></i><b>9.5.17</b> Embedding </a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="9.6-featureengineering.html"><a href="9.6-featureengineering.html"><i class="fa fa-check"></i><b>9.6</b> Feature Engineering</a><ul>
<li class="chapter" data-level="9.6.1" data-path="9.6-featureengineering.html"><a href="9.6-featureengineering.html#machine-learning-features"><i class="fa fa-check"></i><b>9.6.1</b> Machine Learning Features</a></li>
<li class="chapter" data-level="9.6.2" data-path="9.6-featureengineering.html"><a href="9.6-featureengineering.html#dimensionality-reduction"><i class="fa fa-check"></i><b>9.6.2</b> Dimensionality Reduction </a></li>
<li class="chapter" data-level="9.6.3" data-path="9.6-featureengineering.html"><a href="9.6-featureengineering.html#principal-component-analysis"><i class="fa fa-check"></i><b>9.6.3</b> Principal Component Analysis  </a></li>
<li class="chapter" data-level="9.6.4" data-path="9.6-featureengineering.html"><a href="9.6-featureengineering.html#linear-discriminant-analysis-lda"><i class="fa fa-check"></i><b>9.6.4</b> Linear Discriminant Analysis (LDA)  </a></li>
<li class="chapter" data-level="9.6.5" data-path="9.6-featureengineering.html"><a href="9.6-featureengineering.html#feature-construction"><i class="fa fa-check"></i><b>9.6.5</b> Feature Construction </a></li>
<li class="chapter" data-level="9.6.6" data-path="9.6-featureengineering.html"><a href="9.6-featureengineering.html#featureselection"><i class="fa fa-check"></i><b>9.6.6</b> Feature Selection</a></li>
<li class="chapter" data-level="9.6.7" data-path="9.6-featureengineering.html"><a href="9.6-featureengineering.html#feature-transformation"><i class="fa fa-check"></i><b>9.6.7</b> Feature Transformation </a></li>
<li class="chapter" data-level="9.6.8" data-path="9.6-featureengineering.html"><a href="9.6-featureengineering.html#model-specification-1"><i class="fa fa-check"></i><b>9.6.8</b> Model Specification </a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="9.7-general-modeling.html"><a href="9.7-general-modeling.html"><i class="fa fa-check"></i><b>9.7</b> General Modeling</a><ul>
<li class="chapter" data-level="9.7.1" data-path="9.7-general-modeling.html"><a href="9.7-general-modeling.html#training-learning"><i class="fa fa-check"></i><b>9.7.1</b> Training (Learning)</a></li>
<li class="chapter" data-level="9.7.2" data-path="9.7-general-modeling.html"><a href="9.7-general-modeling.html#validation-tuning"><i class="fa fa-check"></i><b>9.7.2</b> Validation (Tuning) </a></li>
<li class="chapter" data-level="9.7.3" data-path="9.7-general-modeling.html"><a href="9.7-general-modeling.html#testing-assessing"><i class="fa fa-check"></i><b>9.7.3</b> Testing (Assessing) </a></li>
<li class="chapter" data-level="9.7.4" data-path="9.7-general-modeling.html"><a href="9.7-general-modeling.html#cross-validation-cv"><i class="fa fa-check"></i><b>9.7.4</b> Cross-Validation (CV)  </a></li>
<li class="chapter" data-level="9.7.5" data-path="9.7-general-modeling.html"><a href="9.7-general-modeling.html#bias-and-variance"><i class="fa fa-check"></i><b>9.7.5</b> Bias and Variance </a></li>
<li class="chapter" data-level="9.7.6" data-path="9.7-general-modeling.html"><a href="9.7-general-modeling.html#loss-and-cost-functions"><i class="fa fa-check"></i><b>9.7.6</b> Loss and Cost Functions  </a></li>
<li class="chapter" data-level="9.7.7" data-path="9.7-general-modeling.html"><a href="9.7-general-modeling.html#global-and-local-minima"><i class="fa fa-check"></i><b>9.7.7</b> Global and Local Minima  </a></li>
<li class="chapter" data-level="9.7.8" data-path="9.7-general-modeling.html"><a href="9.7-general-modeling.html#regularization"><i class="fa fa-check"></i><b>9.7.8</b> Regularization</a></li>
</ul></li>
<li class="chapter" data-level="9.8" data-path="9.8-supervised-vs.unsupervised-learning.html"><a href="9.8-supervised-vs.unsupervised-learning.html"><i class="fa fa-check"></i><b>9.8</b> Supervised vs.Â Unsupervised Learning  </a></li>
<li class="chapter" data-level="9.9" data-path="9.9-summary-6.html"><a href="9.9-summary-6.html"><i class="fa fa-check"></i><b>9.9</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="10-machinelearning2.html"><a href="10-machinelearning2.html"><i class="fa fa-check"></i><b>10</b> Computational Learning II</a><ul>
<li class="chapter" data-level="10.1" data-path="10.1-regression.html"><a href="10.1-regression.html"><i class="fa fa-check"></i><b>10.1</b> Regression (Supervised)</a><ul>
<li class="chapter" data-level="10.1.1" data-path="10.1-regression.html"><a href="10.1-regression.html#regression-trees"><i class="fa fa-check"></i><b>10.1.1</b> Regression Trees </a></li>
<li class="chapter" data-level="10.1.2" data-path="10.1-regression.html"><a href="10.1-regression.html#ensemble-methods"><i class="fa fa-check"></i><b>10.1.2</b> Ensemble Methods </a></li>
<li class="chapter" data-level="10.1.3" data-path="10.1-regression.html"><a href="10.1-regression.html#random-forest"><i class="fa fa-check"></i><b>10.1.3</b> Random Forest </a></li>
<li class="chapter" data-level="10.1.4" data-path="10.1-regression.html"><a href="10.1-regression.html#Adaoost"><i class="fa fa-check"></i><b>10.1.4</b> AdaBoost</a></li>
<li class="chapter" data-level="10.1.5" data-path="10.1-regression.html"><a href="10.1-regression.html#gradient-boost"><i class="fa fa-check"></i><b>10.1.5</b> Gradient Boost </a></li>
<li class="chapter" data-level="10.1.6" data-path="10.1-regression.html"><a href="10.1-regression.html#xgboost"><i class="fa fa-check"></i><b>10.1.6</b> XGBoost </a></li>
<li class="chapter" data-level="10.1.7" data-path="10.1-regression.html"><a href="10.1-regression.html#generalized-linear-modeling-glm"><i class="fa fa-check"></i><b>10.1.7</b> Generalized Linear Modeling (GLM)  </a></li>
<li class="chapter" data-level="10.1.8" data-path="10.1-regression.html"><a href="10.1-regression.html#logisticregression"><i class="fa fa-check"></i><b>10.1.8</b> Logistic Regression (GLM)</a></li>
<li class="chapter" data-level="10.1.9" data-path="10.1-regression.html"><a href="10.1-regression.html#poisson"><i class="fa fa-check"></i><b>10.1.9</b> Poisson Regression (GLM)</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="10.2-binary-classification-supervised.html"><a href="10.2-binary-classification-supervised.html"><i class="fa fa-check"></i><b>10.2</b> Binary Classification (Supervised)</a><ul>
<li class="chapter" data-level="10.2.1" data-path="10.2-binary-classification-supervised.html"><a href="10.2-binary-classification-supervised.html#linear-svm-sgdpegasos"><i class="fa fa-check"></i><b>10.2.1</b> Linear SVM (SGD/PEGASOS)  </a></li>
<li class="chapter" data-level="10.2.2" data-path="10.2-binary-classification-supervised.html"><a href="10.2-binary-classification-supervised.html#kernel-svm-smo"><i class="fa fa-check"></i><b>10.2.2</b> Kernel SVM (SMO)  </a></li>
<li class="chapter" data-level="10.2.3" data-path="10.2-binary-classification-supervised.html"><a href="10.2-binary-classification-supervised.html#sdca-based-svm"><i class="fa fa-check"></i><b>10.2.3</b> SDCA-based SVM </a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="10.3-multi-class-classification-supervised.html"><a href="10.3-multi-class-classification-supervised.html"><i class="fa fa-check"></i><b>10.3</b> Multi-class Classification (Supervised) </a><ul>
<li class="chapter" data-level="10.3.1" data-path="10.3-multi-class-classification-supervised.html"><a href="10.3-multi-class-classification-supervised.html#bayesian-classification"><i class="fa fa-check"></i><b>10.3.1</b> Bayesian Classification </a></li>
<li class="chapter" data-level="10.3.2" data-path="10.3-multi-class-classification-supervised.html"><a href="10.3-multi-class-classification-supervised.html#classification-trees"><i class="fa fa-check"></i><b>10.3.2</b> Classification Trees </a></li>
<li class="chapter" data-level="10.3.3" data-path="10.3-multi-class-classification-supervised.html"><a href="10.3-multi-class-classification-supervised.html#ensemble-methods-1"><i class="fa fa-check"></i><b>10.3.3</b> Ensemble Methods </a></li>
<li class="chapter" data-level="10.3.4" data-path="10.3-multi-class-classification-supervised.html"><a href="10.3-multi-class-classification-supervised.html#random-forest-1"><i class="fa fa-check"></i><b>10.3.4</b> Random Forest </a></li>
<li class="chapter" data-level="10.3.5" data-path="10.3-multi-class-classification-supervised.html"><a href="10.3-multi-class-classification-supervised.html#AdaBoost"><i class="fa fa-check"></i><b>10.3.5</b> AdaBoost &amp; SAMME</a></li>
<li class="chapter" data-level="10.3.6" data-path="10.3-multi-class-classification-supervised.html"><a href="10.3-multi-class-classification-supervised.html#logitboost-j-classes"><i class="fa fa-check"></i><b>10.3.6</b> LogitBoost (J Classes)</a></li>
<li class="chapter" data-level="10.3.7" data-path="10.3-multi-class-classification-supervised.html"><a href="10.3-multi-class-classification-supervised.html#gradient-boost-1"><i class="fa fa-check"></i><b>10.3.7</b> Gradient Boost </a></li>
<li class="chapter" data-level="10.3.8" data-path="10.3-multi-class-classification-supervised.html"><a href="10.3-multi-class-classification-supervised.html#k-next-neighbors-knn"><i class="fa fa-check"></i><b>10.3.8</b> K-Next Neighbors (KNN)  </a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="11-machinelearning3.html"><a href="11-machinelearning3.html"><i class="fa fa-check"></i><b>11</b> Computational Learning III</a><ul>
<li class="chapter" data-level="11.1" data-path="11.1-clustering-unsupervised.html"><a href="11.1-clustering-unsupervised.html"><i class="fa fa-check"></i><b>11.1</b> Clustering (Unsupervised) </a><ul>
<li class="chapter" data-level="11.1.1" data-path="11.1-clustering-unsupervised.html"><a href="11.1-clustering-unsupervised.html#k-means-clustering"><i class="fa fa-check"></i><b>11.1.1</b> K-means (clustering) </a></li>
<li class="chapter" data-level="11.1.2" data-path="11.1-clustering-unsupervised.html"><a href="11.1-clustering-unsupervised.html#hierarchical-clustering"><i class="fa fa-check"></i><b>11.1.2</b> Hierarchical (clustering) </a></li>
<li class="chapter" data-level="11.1.3" data-path="11.1-clustering-unsupervised.html"><a href="11.1-clustering-unsupervised.html#dbscan-clustering"><i class="fa fa-check"></i><b>11.1.3</b> DBSCAN (clustering) </a></li>
<li class="chapter" data-level="11.1.4" data-path="11.1-clustering-unsupervised.html"><a href="11.1-clustering-unsupervised.html#quality-of-clustering"><i class="fa fa-check"></i><b>11.1.4</b> Quality of Clustering</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="11.2-meta-learning.html"><a href="11.2-meta-learning.html"><i class="fa fa-check"></i><b>11.2</b> Meta-Learning </a></li>
<li class="chapter" data-level="11.3" data-path="11.3-natural-language-processing-nlp.html"><a href="11.3-natural-language-processing-nlp.html"><i class="fa fa-check"></i><b>11.3</b> Natural Language Processing (NLP)  </a><ul>
<li class="chapter" data-level="11.3.1" data-path="11.3-natural-language-processing-nlp.html"><a href="11.3-natural-language-processing-nlp.html#pre-processing-texts"><i class="fa fa-check"></i><b>11.3.1</b> Pre-Processing Texts</a></li>
<li class="chapter" data-level="11.3.2" data-path="11.3-natural-language-processing-nlp.html"><a href="11.3-natural-language-processing-nlp.html#ranking-and-scoring"><i class="fa fa-check"></i><b>11.3.2</b> Ranking and Scoring </a></li>
<li class="chapter" data-level="11.3.3" data-path="11.3-natural-language-processing-nlp.html"><a href="11.3-natural-language-processing-nlp.html#document-similarity"><i class="fa fa-check"></i><b>11.3.3</b> Document Similarity </a></li>
<li class="chapter" data-level="11.3.4" data-path="11.3-natural-language-processing-nlp.html"><a href="11.3-natural-language-processing-nlp.html#linguistic-analysis"><i class="fa fa-check"></i><b>11.3.4</b> Linguistic Analysis </a></li>
<li class="chapter" data-level="11.3.5" data-path="11.3-natural-language-processing-nlp.html"><a href="11.3-natural-language-processing-nlp.html#lexical-analysis"><i class="fa fa-check"></i><b>11.3.5</b> Lexical Analysis </a></li>
<li class="chapter" data-level="11.3.6" data-path="11.3-natural-language-processing-nlp.html"><a href="11.3-natural-language-processing-nlp.html#semantic-analysis"><i class="fa fa-check"></i><b>11.3.6</b> Semantic Analysis </a></li>
<li class="chapter" data-level="11.3.7" data-path="11.3-natural-language-processing-nlp.html"><a href="11.3-natural-language-processing-nlp.html#named-entity-recognition-ner"><i class="fa fa-check"></i><b>11.3.7</b> Named Entity Recognition (NER)  </a></li>
<li class="chapter" data-level="11.3.8" data-path="11.3-natural-language-processing-nlp.html"><a href="11.3-natural-language-processing-nlp.html#sentiment-and-opinion-analysis"><i class="fa fa-check"></i><b>11.3.8</b> Sentiment and Opinion Analysis  </a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="11.4-time-series-forecasting.html"><a href="11.4-time-series-forecasting.html"><i class="fa fa-check"></i><b>11.4</b> Time-Series Forecasting </a><ul>
<li class="chapter" data-level="11.4.1" data-path="11.4-time-series-forecasting.html"><a href="11.4-time-series-forecasting.html#seasonal-trend-decomposition-using-loess-stl"><i class="fa fa-check"></i><b>11.4.1</b> Seasonal Trend Decomposition using LOESS (STL)  </a></li>
<li class="chapter" data-level="11.4.2" data-path="11.4-time-series-forecasting.html"><a href="11.4-time-series-forecasting.html#forecasting-models"><i class="fa fa-check"></i><b>11.4.2</b> Forecasting Models </a></li>
<li class="chapter" data-level="11.4.3" data-path="11.4-time-series-forecasting.html"><a href="11.4-time-series-forecasting.html#time-series-linear-model-tslm"><i class="fa fa-check"></i><b>11.4.3</b> Time-Series Linear Model (TSLM)  </a></li>
<li class="chapter" data-level="11.4.4" data-path="11.4-time-series-forecasting.html"><a href="11.4-time-series-forecasting.html#autoregressive-integrated-moving-average-arima"><i class="fa fa-check"></i><b>11.4.4</b> AutoRegressive Integrated Moving Average (ARIMA)  </a></li>
<li class="chapter" data-level="11.4.5" data-path="11.4-time-series-forecasting.html"><a href="11.4-time-series-forecasting.html#multiplicative-seasonal-arima-sarima"><i class="fa fa-check"></i><b>11.4.5</b> Multiplicative Seasonal ARIMA (SARIMA) </a></li>
<li class="chapter" data-level="11.4.6" data-path="11.4-time-series-forecasting.html"><a href="11.4-time-series-forecasting.html#time-series-decomposition"><i class="fa fa-check"></i><b>11.4.6</b> Time-Series Decomposition </a></li>
<li class="chapter" data-level="11.4.7" data-path="11.4-time-series-forecasting.html"><a href="11.4-time-series-forecasting.html#stl-with-aicbic"><i class="fa fa-check"></i><b>11.4.7</b> STL with AIC/BIC</a></li>
<li class="chapter" data-level="11.4.8" data-path="11.4-time-series-forecasting.html"><a href="11.4-time-series-forecasting.html#multivariate-time-series"><i class="fa fa-check"></i><b>11.4.8</b> Multivariate Time-Series</a></li>
<li class="chapter" data-level="11.4.9" data-path="11.4-time-series-forecasting.html"><a href="11.4-time-series-forecasting.html#forecasting-considerations"><i class="fa fa-check"></i><b>11.4.9</b> Forecasting Considerations</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="11.5-recommender-systems.html"><a href="11.5-recommender-systems.html"><i class="fa fa-check"></i><b>11.5</b> Recommender Systems </a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="12-deeplearning1.html"><a href="12-deeplearning1.html"><i class="fa fa-check"></i><b>12</b> Computational Deep Learning I</a><ul>
<li class="chapter" data-level="12.1" data-path="12.1-simple-perceptron.html"><a href="12.1-simple-perceptron.html"><i class="fa fa-check"></i><b>12.1</b> Simple Perceptron  </a></li>
<li class="chapter" data-level="12.2" data-path="12.2-adaptive-linear-neuron-adaline.html"><a href="12.2-adaptive-linear-neuron-adaline.html"><i class="fa fa-check"></i><b>12.2</b> Adaptive Linear Neuron (ADALINE)  </a></li>
<li class="chapter" data-level="12.3" data-path="12.3-multi-layer-perceptron-mlp.html"><a href="12.3-multi-layer-perceptron-mlp.html"><i class="fa fa-check"></i><b>12.3</b> Multi Layer Perceptron (MLP)  </a><ul>
<li class="chapter" data-level="12.3.1" data-path="12.3-multi-layer-perceptron-mlp.html"><a href="12.3-multi-layer-perceptron-mlp.html#forward-feed"><i class="fa fa-check"></i><b>12.3.1</b> Forward Feed </a></li>
<li class="chapter" data-level="12.3.2" data-path="12.3-multi-layer-perceptron-mlp.html"><a href="12.3-multi-layer-perceptron-mlp.html#backward-feed"><i class="fa fa-check"></i><b>12.3.2</b> Backward Feed </a></li>
<li class="chapter" data-level="12.3.3" data-path="12.3-multi-layer-perceptron-mlp.html"><a href="12.3-multi-layer-perceptron-mlp.html#backpropagation"><i class="fa fa-check"></i><b>12.3.3</b> BackPropagation </a></li>
<li class="chapter" data-level="12.3.4" data-path="12.3-multi-layer-perceptron-mlp.html"><a href="12.3-multi-layer-perceptron-mlp.html#mlp-example"><i class="fa fa-check"></i><b>12.3.4</b> MLP Example</a></li>
<li class="chapter" data-level="12.3.5" data-path="12.3-multi-layer-perceptron-mlp.html"><a href="12.3-multi-layer-perceptron-mlp.html#activation-function"><i class="fa fa-check"></i><b>12.3.5</b> Activation Function </a></li>
<li class="chapter" data-level="12.3.6" data-path="12.3-multi-layer-perceptron-mlp.html"><a href="12.3-multi-layer-perceptron-mlp.html#mlp-implementation"><i class="fa fa-check"></i><b>12.3.6</b> MLP Implementation</a></li>
<li class="chapter" data-level="12.3.7" data-path="12.3-multi-layer-perceptron-mlp.html"><a href="12.3-multi-layer-perceptron-mlp.html#deep-neural-network-dnn"><i class="fa fa-check"></i><b>12.3.7</b> Deep Neural Network (DNN)  </a></li>
<li class="chapter" data-level="12.3.8" data-path="12.3-multi-layer-perceptron-mlp.html"><a href="12.3-multi-layer-perceptron-mlp.html#vanishing-and-exploding-gradient"><i class="fa fa-check"></i><b>12.3.8</b> Vanishing and Exploding Gradient  </a></li>
<li class="chapter" data-level="12.3.9" data-path="12.3-multi-layer-perceptron-mlp.html"><a href="12.3-multi-layer-perceptron-mlp.html#dead-relu"><i class="fa fa-check"></i><b>12.3.9</b> Dead Relu </a></li>
<li class="chapter" data-level="12.3.10" data-path="12.3-multi-layer-perceptron-mlp.html"><a href="12.3-multi-layer-perceptron-mlp.html#gradient-clipping-gc"><i class="fa fa-check"></i><b>12.3.10</b> Gradient Clipping (GC) </a></li>
<li class="chapter" data-level="12.3.11" data-path="12.3-multi-layer-perceptron-mlp.html"><a href="12.3-multi-layer-perceptron-mlp.html#parameter-initialization"><i class="fa fa-check"></i><b>12.3.11</b> Parameter Initialization </a></li>
<li class="chapter" data-level="12.3.12" data-path="12.3-multi-layer-perceptron-mlp.html"><a href="12.3-multi-layer-perceptron-mlp.html#regularization-by-dropouts"><i class="fa fa-check"></i><b>12.3.12</b> Regularization by Dropouts </a></li>
<li class="chapter" data-level="12.3.13" data-path="12.3-multi-layer-perceptron-mlp.html"><a href="12.3-multi-layer-perceptron-mlp.html#batch-normalization"><i class="fa fa-check"></i><b>12.3.13</b> Batch Normalization </a></li>
<li class="chapter" data-level="12.3.14" data-path="12.3-multi-layer-perceptron-mlp.html"><a href="12.3-multi-layer-perceptron-mlp.html#optimization"><i class="fa fa-check"></i><b>12.3.14</b> Optimization </a></li>
<li class="chapter" data-level="12.3.15" data-path="12.3-multi-layer-perceptron-mlp.html"><a href="12.3-multi-layer-perceptron-mlp.html#interpretability"><i class="fa fa-check"></i><b>12.3.15</b> Interpretability</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="12.4-convolutional-neural-network-cnn.html"><a href="12.4-convolutional-neural-network-cnn.html"><i class="fa fa-check"></i><b>12.4</b> Convolutional Neural Network (CNN)  </a><ul>
<li class="chapter" data-level="12.4.1" data-path="12.4-convolutional-neural-network-cnn.html"><a href="12.4-convolutional-neural-network-cnn.html#computer-graphics"><i class="fa fa-check"></i><b>12.4.1</b> Computer Graphics</a></li>
<li class="chapter" data-level="12.4.2" data-path="12.4-convolutional-neural-network-cnn.html"><a href="12.4-convolutional-neural-network-cnn.html#convolution"><i class="fa fa-check"></i><b>12.4.2</b> Convolution </a></li>
<li class="chapter" data-level="12.4.3" data-path="12.4-convolutional-neural-network-cnn.html"><a href="12.4-convolutional-neural-network-cnn.html#stride-and-padding"><i class="fa fa-check"></i><b>12.4.3</b> Stride and Padding  </a></li>
<li class="chapter" data-level="12.4.4" data-path="12.4-convolutional-neural-network-cnn.html"><a href="12.4-convolutional-neural-network-cnn.html#kernels-and-filters"><i class="fa fa-check"></i><b>12.4.4</b> Kernels And Filters</a></li>
<li class="chapter" data-level="12.4.5" data-path="12.4-convolutional-neural-network-cnn.html"><a href="12.4-convolutional-neural-network-cnn.html#dilation"><i class="fa fa-check"></i><b>12.4.5</b> Dilation </a></li>
<li class="chapter" data-level="12.4.6" data-path="12.4-convolutional-neural-network-cnn.html"><a href="12.4-convolutional-neural-network-cnn.html#pooling"><i class="fa fa-check"></i><b>12.4.6</b> Pooling </a></li>
<li class="chapter" data-level="12.4.7" data-path="12.4-convolutional-neural-network-cnn.html"><a href="12.4-convolutional-neural-network-cnn.html#cnn-architectures"><i class="fa fa-check"></i><b>12.4.7</b> CNN Architectures</a></li>
<li class="chapter" data-level="12.4.8" data-path="12.4-convolutional-neural-network-cnn.html"><a href="12.4-convolutional-neural-network-cnn.html#forward-feed-1"><i class="fa fa-check"></i><b>12.4.8</b> Forward Feed </a></li>
<li class="chapter" data-level="12.4.9" data-path="12.4-convolutional-neural-network-cnn.html"><a href="12.4-convolutional-neural-network-cnn.html#backpropagation-1"><i class="fa fa-check"></i><b>12.4.9</b> BackPropagation </a></li>
<li class="chapter" data-level="12.4.10" data-path="12.4-convolutional-neural-network-cnn.html"><a href="12.4-convolutional-neural-network-cnn.html#optimization-1"><i class="fa fa-check"></i><b>12.4.10</b> Optimization</a></li>
<li class="chapter" data-level="12.4.11" data-path="12.4-convolutional-neural-network-cnn.html"><a href="12.4-convolutional-neural-network-cnn.html#normalization"><i class="fa fa-check"></i><b>12.4.11</b> Normalization</a></li>
<li class="chapter" data-level="12.4.12" data-path="12.4-convolutional-neural-network-cnn.html"><a href="12.4-convolutional-neural-network-cnn.html#step-decay"><i class="fa fa-check"></i><b>12.4.12</b> Step Decay</a></li>
<li class="chapter" data-level="12.4.13" data-path="12.4-convolutional-neural-network-cnn.html"><a href="12.4-convolutional-neural-network-cnn.html#gemm-matrix-multiplication"><i class="fa fa-check"></i><b>12.4.13</b> GEMM (Matrix Multiplication) </a></li>
<li class="chapter" data-level="12.4.14" data-path="12.4-convolutional-neural-network-cnn.html"><a href="12.4-convolutional-neural-network-cnn.html#depthwise-separable-convolution-dsc"><i class="fa fa-check"></i><b>12.4.14</b> Depthwise Separable Convolution (DSC)  </a></li>
<li class="chapter" data-level="12.4.15" data-path="12.4-convolutional-neural-network-cnn.html"><a href="12.4-convolutional-neural-network-cnn.html#cnn-implementation"><i class="fa fa-check"></i><b>12.4.15</b> CNN Implementation</a></li>
<li class="chapter" data-level="12.4.16" data-path="12.4-convolutional-neural-network-cnn.html"><a href="12.4-convolutional-neural-network-cnn.html#cnn-application"><i class="fa fa-check"></i><b>12.4.16</b> CNN Application</a></li>
<li class="chapter" data-level="12.4.17" data-path="12.4-convolutional-neural-network-cnn.html"><a href="12.4-convolutional-neural-network-cnn.html#summary-7"><i class="fa fa-check"></i><b>12.4.17</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="13-deeplearning2.html"><a href="13-deeplearning2.html"><i class="fa fa-check"></i><b>13</b> Computational Deep Learning II</a><ul>
<li class="chapter" data-level="13.1" data-path="13.1-residual-network-resnet.html"><a href="13.1-residual-network-resnet.html"><i class="fa fa-check"></i><b>13.1</b> Residual Network (ResNet)  </a></li>
<li class="chapter" data-level="13.2" data-path="13.2-recurrent-neural-network-rnn.html"><a href="13.2-recurrent-neural-network-rnn.html"><i class="fa fa-check"></i><b>13.2</b> Recurrent Neural Network (RNN)  </a><ul>
<li class="chapter" data-level="13.2.1" data-path="13.2-recurrent-neural-network-rnn.html"><a href="13.2-recurrent-neural-network-rnn.html#vanilla-rnn"><i class="fa fa-check"></i><b>13.2.1</b> Vanilla RNN</a></li>
<li class="chapter" data-level="13.2.2" data-path="13.2-recurrent-neural-network-rnn.html"><a href="13.2-recurrent-neural-network-rnn.html#long-short-term-memory-lstm"><i class="fa fa-check"></i><b>13.2.2</b> Long Short-Term Memory (LSTM)  </a></li>
<li class="chapter" data-level="13.2.3" data-path="13.2-recurrent-neural-network-rnn.html"><a href="13.2-recurrent-neural-network-rnn.html#gated-recurrent-units-gru"><i class="fa fa-check"></i><b>13.2.3</b> Gated Recurrent Units (GRU)  </a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="13.3-deep-stacked-rnn.html"><a href="13.3-deep-stacked-rnn.html"><i class="fa fa-check"></i><b>13.3</b> Deep Stacked RNN </a></li>
<li class="chapter" data-level="13.4" data-path="13.4-deep-stacked-bidirectional-rnn.html"><a href="13.4-deep-stacked-bidirectional-rnn.html"><i class="fa fa-check"></i><b>13.4</b> Deep Stacked Bidirectional RNN </a></li>
<li class="chapter" data-level="13.5" data-path="13.5-transformer-neural-network-tnn.html"><a href="13.5-transformer-neural-network-tnn.html"><i class="fa fa-check"></i><b>13.5</b> Transformer Neural Network (TNN)  </a><ul>
<li class="chapter" data-level="13.5.1" data-path="13.5-transformer-neural-network-tnn.html"><a href="13.5-transformer-neural-network-tnn.html#attention"><i class="fa fa-check"></i><b>13.5.1</b> Attention </a></li>
<li class="chapter" data-level="13.5.2" data-path="13.5-transformer-neural-network-tnn.html"><a href="13.5-transformer-neural-network-tnn.html#self-attention-and-trainability"><i class="fa fa-check"></i><b>13.5.2</b> Self-Attention and Trainability </a></li>
<li class="chapter" data-level="13.5.3" data-path="13.5-transformer-neural-network-tnn.html"><a href="13.5-transformer-neural-network-tnn.html#multi-head-attention"><i class="fa fa-check"></i><b>13.5.3</b> Multi-Head Attention </a></li>
<li class="chapter" data-level="13.5.4" data-path="13.5-transformer-neural-network-tnn.html"><a href="13.5-transformer-neural-network-tnn.html#word-embedding"><i class="fa fa-check"></i><b>13.5.4</b> Word Embedding </a></li>
<li class="chapter" data-level="13.5.5" data-path="13.5-transformer-neural-network-tnn.html"><a href="13.5-transformer-neural-network-tnn.html#positional-embedding"><i class="fa fa-check"></i><b>13.5.5</b> Positional Embedding </a></li>
<li class="chapter" data-level="13.5.6" data-path="13.5-transformer-neural-network-tnn.html"><a href="13.5-transformer-neural-network-tnn.html#sequence-alignment"><i class="fa fa-check"></i><b>13.5.6</b> Sequence Alignment</a></li>
<li class="chapter" data-level="13.5.7" data-path="13.5-transformer-neural-network-tnn.html"><a href="13.5-transformer-neural-network-tnn.html#transformer-architectures"><i class="fa fa-check"></i><b>13.5.7</b> Transformer Architectures </a></li>
</ul></li>
<li class="chapter" data-level="13.6" data-path="13.6-applications-using-tnn-and-rnn.html"><a href="13.6-applications-using-tnn-and-rnn.html"><i class="fa fa-check"></i><b>13.6</b> Applications using TNN (and RNN)</a><ul>
<li class="chapter" data-level="13.6.1" data-path="13.6-applications-using-tnn-and-rnn.html"><a href="13.6-applications-using-tnn-and-rnn.html#speech-recognition"><i class="fa fa-check"></i><b>13.6.1</b> Speech Recognition </a></li>
<li class="chapter" data-level="13.6.2" data-path="13.6-applications-using-tnn-and-rnn.html"><a href="13.6-applications-using-tnn-and-rnn.html#mel-coefficients-feature-extraction"><i class="fa fa-check"></i><b>13.6.2</b> Mel Coefficients (Feature Extraction) </a></li>
<li class="chapter" data-level="13.6.3" data-path="13.6-applications-using-tnn-and-rnn.html"><a href="13.6-applications-using-tnn-and-rnn.html#connectionist-temporal-classification-ctc"><i class="fa fa-check"></i><b>13.6.3</b> Connectionist Temporal Classification (CTC)  </a></li>
<li class="chapter" data-level="13.6.4" data-path="13.6-applications-using-tnn-and-rnn.html"><a href="13.6-applications-using-tnn-and-rnn.html#model-evaluation"><i class="fa fa-check"></i><b>13.6.4</b> Model Evaluation</a></li>
</ul></li>
<li class="chapter" data-level="13.7" data-path="13.7-generative-adversarial-network-gan.html"><a href="13.7-generative-adversarial-network-gan.html"><i class="fa fa-check"></i><b>13.7</b> Generative Adversarial Network (GAN)  </a></li>
<li class="chapter" data-level="13.8" data-path="13.8-deep-reinforcement-network-dqn.html"><a href="13.8-deep-reinforcement-network-dqn.html"><i class="fa fa-check"></i><b>13.8</b> Deep Reinforcement Network (DQN)  </a></li>
<li class="chapter" data-level="13.9" data-path="13.9-summary-8.html"><a href="13.9-summary-8.html"><i class="fa fa-check"></i><b>13.9</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="14-distributedcomputation.html"><a href="14-distributedcomputation.html"><i class="fa fa-check"></i><b>14</b> Distributed Computation</a><ul>
<li class="chapter" data-level="14.1" data-path="14.1-integration-and-interoperability.html"><a href="14.1-integration-and-interoperability.html"><i class="fa fa-check"></i><b>14.1</b> Integration and Interoperability</a></li>
<li class="chapter" data-level="14.2" data-path="14.2-ml-pipelines.html"><a href="14.2-ml-pipelines.html"><i class="fa fa-check"></i><b>14.2</b> ML Pipelines</a></li>
<li class="chapter" data-level="14.3" data-path="14.3-open-standards.html"><a href="14.3-open-standards.html"><i class="fa fa-check"></i><b>14.3</b> Open Standards</a><ul>
<li class="chapter" data-level="14.3.1" data-path="14.3-open-standards.html"><a href="14.3-open-standards.html#predictive-model-markup-language-pmml"><i class="fa fa-check"></i><b>14.3.1</b> Predictive Model Markup Language (PMML)</a></li>
<li class="chapter" data-level="14.3.2" data-path="14.3-open-standards.html"><a href="14.3-open-standards.html#portable-format-for-analytics-pfa"><i class="fa fa-check"></i><b>14.3.2</b> Portable Format for Analytics (PFA)</a></li>
<li class="chapter" data-level="14.3.3" data-path="14.3-open-standards.html"><a href="14.3-open-standards.html#open-neural-network-exchange-onnx"><i class="fa fa-check"></i><b>14.3.3</b> Open Neural Network Exchange (ONNX)</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="14.4-general-summary.html"><a href="14.4-general-summary.html"><i class="fa fa-check"></i><b>14.4</b> General Summary</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="15-appendix.html"><a href="15-appendix.html"><i class="fa fa-check"></i><b>15</b> Appendix</a><ul>
<li class="chapter" data-level="15.1" data-path="15.1-appendix-a.html"><a href="15.1-appendix-a.html"><i class="fa fa-check"></i><b>15.1</b> Appendix A</a><ul>
<li class="chapter" data-level="15.1.1" data-path="15.1-appendix-a.html"><a href="15.1-appendix-a.html#trigonometry"><i class="fa fa-check"></i><b>15.1.1</b> Trigonometry</a></li>
<li class="chapter" data-level="15.1.2" data-path="15.1-appendix-a.html"><a href="15.1-appendix-a.html#logarithms"><i class="fa fa-check"></i><b>15.1.2</b> Logarithms</a></li>
<li class="chapter" data-level="15.1.3" data-path="15.1-appendix-a.html"><a href="15.1-appendix-a.html#category-theory"><i class="fa fa-check"></i><b>15.1.3</b> Category Theory</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="15.2-appendix-b.html"><a href="15.2-appendix-b.html"><i class="fa fa-check"></i><b>15.2</b> Appendix B</a><ul>
<li class="chapter" data-level="15.2.1" data-path="15.2-appendix-b.html"><a href="15.2-appendix-b.html#on-random-chances"><i class="fa fa-check"></i><b>15.2.1</b> On Random chances</a></li>
<li class="chapter" data-level="15.2.2" data-path="15.2-appendix-b.html"><a href="15.2-appendix-b.html#on-replacements"><i class="fa fa-check"></i><b>15.2.2</b> On Replacements</a></li>
<li class="chapter" data-level="15.2.3" data-path="15.2-appendix-b.html"><a href="15.2-appendix-b.html#on-permutations-and-combinations"><i class="fa fa-check"></i><b>15.2.3</b> On Permutations and Combinations</a></li>
<li class="chapter" data-level="15.2.4" data-path="15.2-appendix-b.html"><a href="15.2-appendix-b.html#on-conditional-probabilities"><i class="fa fa-check"></i><b>15.2.4</b> On Conditional Probabilities</a></li>
<li class="chapter" data-level="15.2.5" data-path="15.2-appendix-b.html"><a href="15.2-appendix-b.html#the-arithmetic-of-probabilities"><i class="fa fa-check"></i><b>15.2.5</b> The Arithmetic of Probabilities</a></li>
<li class="chapter" data-level="15.2.6" data-path="15.2-appendix-b.html"><a href="15.2-appendix-b.html#on-dependent-and-independent-events"><i class="fa fa-check"></i><b>15.2.6</b> On Dependent and Independent Events</a></li>
<li class="chapter" data-level="15.2.7" data-path="15.2-appendix-b.html"><a href="15.2-appendix-b.html#on-mutual-exclusivity"><i class="fa fa-check"></i><b>15.2.7</b> On Mutual Exclusivity</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="15.3-appendix-c.html"><a href="15.3-appendix-c.html"><i class="fa fa-check"></i><b>15.3</b> Appendix C</a></li>
<li class="chapter" data-level="15.4" data-path="15.4-appendix-d.html"><a href="15.4-appendix-d.html"><i class="fa fa-check"></i><b>15.4</b> Appendix D</a><ul>
<li class="chapter" data-level="15.4.1" data-path="15.4-appendix-d.html"><a href="15.4-appendix-d.html#lubridate-library"><i class="fa fa-check"></i><b>15.4.1</b> Lubridate Library</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="bibliography.html"><a href="bibliography.html"><i class="fa fa-check"></i>Bibliography</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">The Power and Art of Approximation</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="multiple-comparison-tests" class="section level2 hasAnchor">
<h2><span class="header-section-number">6.5</span> Multiple Comparison Tests <a href="6.5-multiple-comparison-tests.html#multiple-comparison-tests" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We now discuss a few popular <strong>multiple comparison tests</strong> in statistics <span class="citation">(Rodger R.S. and Roberts M. <a href="bibliography.html#ref-ref912r">2013</a>; Lee S. and Lee D. K. <a href="bibliography.html#ref-ref903s">2018</a>)</span>. The idea is essentially to compare groups and determine which groups contribute to a significant difference. Note that we can only use any of the <strong>Post-HOC</strong> tests if we determine from our previous analysis, e.g., <strong>ANOVA</strong>, that the <strong>null hypothesis</strong> does not hold.</p>
<p><span class="math display" id="eq:equate1080044" id="eq:equate1080043">\[\begin{align}
\mathbf{H_0} {}&amp;: \ \ \ \mu_i = \mu_j\ \ \ \leftarrow\ \ \ rejected \tag{6.46} \\
\mathbf{H_1} &amp;: \ \ \ \ \mu_i \ne \mu_j\ \ \ \leftarrow\ \ \ this\ holds \tag{6.47} 
\end{align}\]</span></p>
<p>A key point to emphasize here is that if we run our <strong>ANOVA</strong> test against hundred groups (supposition) and have determined that there are significant differences amongst groups, it may help to use one of the following <strong>multiple comparisons</strong> approaches:</p>
<ul>
<li>use a few groups for comparison instead of all of them</li>
<li>or compare all of them</li>
<li>or use one of them as a control group and compare it against the other experimental groups.</li>
<li>or compare a subset of groups orthogonal to another subset of groups.</li>
</ul>
<p>A few of the methods that follow next in our discussion, such as <strong>Tukeyâs Test</strong> and <strong>Dunnettâs Test</strong>, fall under any of those approaches.</p>
<div id="scheffes-test" class="section level3 hasAnchor">
<h3><span class="header-section-number">6.5.1</span> Scheffeâs Test <a href="6.5-multiple-comparison-tests.html#scheffes-test" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Scheffeâs Test</strong> is a <strong>Post-HOC</strong> multiple comparison test. We use the <strong>mtcars</strong> dataset as before to illustrate a pairwise comparison.</p>
<p><strong>First</strong>, let us determine the groups, e.g. <span class="math inline">\((4,\ 6,\ 8)\)</span>, to be compared from a factor variable, e.g. <strong>cyl</strong> (number of cylinders).</p>

<div class="sourceCode" id="cb518"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb518-1" data-line-number="1">(<span class="dt">groups =</span> <span class="kw">levels</span>(<span class="kw">as.factor</span>(mtcars<span class="op">$</span>cyl)))</a></code></pre></div>
<pre><code>## [1] &quot;4&quot; &quot;6&quot; &quot;8&quot;</code></pre>

<p><strong>Second</strong>, let us perform a <strong>One-Way ANOVA</strong> against the corresponding scaled metrics, <strong>mpg</strong> (fuel consumption), using our implementation: </p>

<div class="sourceCode" id="cb520"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb520-1" data-line-number="1">mtc =<span class="st"> </span><span class="kw">list</span>()</a>
<a class="sourceLine" id="cb520-2" data-line-number="2">m =<span class="st"> </span><span class="kw">length</span>(groups)</a>
<a class="sourceLine" id="cb520-3" data-line-number="3"><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>m) { mtc[[i]] =<span class="st"> </span>mtcars[mtcars<span class="op">$</span>cyl <span class="op">==</span><span class="st"> </span>groups[i],]<span class="op">$</span>mpg }</a>
<a class="sourceLine" id="cb520-4" data-line-number="4">(<span class="dt">anova_outcome =</span> <span class="dt">anova =</span> <span class="kw">one_way_anova</span>(mtc))</a></code></pre></div>
<pre><code>##    SSB    SSW    dfB    dfW    MSB    MSW      F 
## 824.78 301.26   2.00  29.00 412.39  10.39  39.70</code></pre>
<div class="sourceCode" id="cb522"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb522-1" data-line-number="1">(<span class="dt">anova_outcome =</span> <span class="dt">anova =</span> <span class="kw">one_way_anova</span>(mtcars<span class="op">$</span>mpg, mtcars<span class="op">$</span>cyl))</a></code></pre></div>
<pre><code>##    SSB    SSW    dfB    dfW    MSB    MSW      F 
## 824.78 301.26   2.00  29.00 412.39  10.39  39.70</code></pre>

<p><strong>Third</strong>, compute for the <strong>Critical value</strong> of the F-test (assume a 95% confidence level):</p>

<div class="sourceCode" id="cb524"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb524-1" data-line-number="1">(<span class="dt">cv_anova =</span> <span class="kw">qf</span>(<span class="fl">0.95</span>,  anova[<span class="st">&quot;dfB&quot;</span>],  anova[<span class="st">&quot;dfW&quot;</span>]) )</a></code></pre></div>
<pre><code>## [1] 3.328</code></pre>

<p><strong>Fourth</strong>, compute for the <strong>Critical value</strong> of the <strong>Scheffe Test</strong> using:</p>
<p><span class="math display" id="eq:equate1080045">\[\begin{align}
F&#39; = dfB \times (\text{Critical value of F-test})  \tag{6.48} 
\end{align}\]</span></p>
<div class="sourceCode" id="cb526"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb526-1" data-line-number="1">(<span class="dt">cv_scheffe =</span> <span class="kw">as.numeric</span>(anova[<span class="st">&quot;dfB&quot;</span>]) <span class="op">*</span><span class="st"> </span>cv_anova )</a></code></pre></div>
<pre><code>## [1] 6.655</code></pre>
<p><strong>Finally</strong>, with the <strong>ANOVA</strong> result, let us perform a <strong>Post-HOC</strong> analysis using <strong>Scheffeâs Method</strong>:</p>
<p><span class="math display" id="eq:equate1080046">\[\begin{align}
F_{scheffe} = \frac{(\bar{x}_i - \bar{x}_j)^2}{s^2_w\left(\frac{1}{n_i} + \frac{1}{n_j}\right)} \tag{6.49} 
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(\mathbf{\bar{x}_i}\)</span> is the mean of the first group being compared</li>
<li><span class="math inline">\(\mathbf{\bar{x}_j}\)</span> is the mean of the second group being compared</li>
<li><span class="math inline">\(\mathbf{n_i}\)</span> is the group size of the first group being compared</li>
<li><span class="math inline">\(\mathbf{n_j}\)</span> is the group size of the second group being compared</li>
<li><span class="math inline">\(\mathbf{F_{scheffe}}\)</span> is the F statistic of Scheffe Test</li>
<li><span class="math inline">\(\mathbf{s^2_w}\)</span> is the within-group mean square (MSW or MSE) error, the outcome from ANOVA</li>
</ul>
<p>Below is a naive implementation of <strong>Scheffeâs comparison</strong> test in R code:</p>

<div class="sourceCode" id="cb528"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb528-1" data-line-number="1">scheffe.comparison &lt;-<span class="st"> </span><span class="cf">function</span>(dependent, factor) {</a>
<a class="sourceLine" id="cb528-2" data-line-number="2">  factors =<span class="st"> </span><span class="kw">levels</span>(factor)</a>
<a class="sourceLine" id="cb528-3" data-line-number="3">  groups =<span class="st"> </span><span class="kw">split</span>( dependent, factor)</a>
<a class="sourceLine" id="cb528-4" data-line-number="4">  anova =<span class="st"> </span><span class="kw">one_way_anova</span>(groups)</a>
<a class="sourceLine" id="cb528-5" data-line-number="5">  m =<span class="st"> </span><span class="kw">length</span>(groups) <span class="co"># number of groups</span></a>
<a class="sourceLine" id="cb528-6" data-line-number="6">  scheffe =<span class="st"> </span><span class="kw">c</span>();  rname =<span class="st"> </span><span class="kw">c</span>()</a>
<a class="sourceLine" id="cb528-7" data-line-number="7">  <span class="co"># Critical value for the F-Test at %95</span></a>
<a class="sourceLine" id="cb528-8" data-line-number="8">  cv_anova =<span class="st"> </span><span class="kw">qf</span>(<span class="fl">0.95</span>,  anova[<span class="st">&quot;dfB&quot;</span>],  anova[<span class="st">&quot;dfW&quot;</span>]) </a>
<a class="sourceLine" id="cb528-9" data-line-number="9">  <span class="co"># Critical value for Scheffe Test</span></a>
<a class="sourceLine" id="cb528-10" data-line-number="10">  cv_scheffe=<span class="st"> </span><span class="kw">as.numeric</span>( anova[<span class="st">&quot;dfB&quot;</span>] <span class="op">*</span><span class="st"> </span>cv_anova )</a>
<a class="sourceLine" id="cb528-11" data-line-number="11">  <span class="co"># Get the s2w</span></a>
<a class="sourceLine" id="cb528-12" data-line-number="12">  s2w =<span class="st"> </span>anova[<span class="st">&quot;MSW&quot;</span>]</a>
<a class="sourceLine" id="cb528-13" data-line-number="13">  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>m) {</a>
<a class="sourceLine" id="cb528-14" data-line-number="14">    n.i =<span class="st"> </span><span class="kw">length</span>(groups[[i]]);  u.i =<span class="st"> </span><span class="kw">mean</span>(groups[[i]]);  </a>
<a class="sourceLine" id="cb528-15" data-line-number="15">    g.i =<span class="st"> </span>factors[i]</a>
<a class="sourceLine" id="cb528-16" data-line-number="16">    <span class="cf">for</span> (j <span class="cf">in</span> i<span class="op">:</span>m) {</a>
<a class="sourceLine" id="cb528-17" data-line-number="17">      <span class="cf">if</span> (i <span class="op">!=</span><span class="st"> </span>j) {</a>
<a class="sourceLine" id="cb528-18" data-line-number="18">        n.j =<span class="st"> </span><span class="kw">length</span>(groups[[j]]);  u.j =<span class="st"> </span><span class="kw">mean</span>(groups[[j]]); </a>
<a class="sourceLine" id="cb528-19" data-line-number="19">        g.j =<span class="st"> </span>factors[j]</a>
<a class="sourceLine" id="cb528-20" data-line-number="20">        d   =<span class="st"> </span>u.j <span class="op">-</span><span class="st"> </span>u.i <span class="co"># difference</span></a>
<a class="sourceLine" id="cb528-21" data-line-number="21">        f_scheffe =<span class="st"> </span>(u.i <span class="op">-</span><span class="st"> </span>u.j)<span class="op">^</span><span class="dv">2</span><span class="op">/</span><span class="st"> </span>( s2w <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span><span class="op">/</span>n.i <span class="op">+</span><span class="st"> </span><span class="dv">1</span><span class="op">/</span>n.j))  </a>
<a class="sourceLine" id="cb528-22" data-line-number="22">        signif =<span class="st"> &#39;&#39;</span></a>
<a class="sourceLine" id="cb528-23" data-line-number="23">        <span class="cf">if</span> (f_scheffe <span class="op">&gt;</span><span class="st"> </span>cv_scheffe) { signif =<span class="st"> &#39;*&#39;</span> }</a>
<a class="sourceLine" id="cb528-24" data-line-number="24">        rname =<span class="st"> </span><span class="kw">c</span>(rname, <span class="kw">paste0</span>(g.j, <span class="st">&quot;-&quot;</span>, g.i, signif))</a>
<a class="sourceLine" id="cb528-25" data-line-number="25">        scheffe =<span class="st"> </span><span class="kw">rbind</span>(scheffe, </a>
<a class="sourceLine" id="cb528-26" data-line-number="26">                  <span class="kw">c</span>(<span class="kw">round</span>(d,<span class="dv">5</span>),  f_scheffe, cv_scheffe ))</a>
<a class="sourceLine" id="cb528-27" data-line-number="27">      }</a>
<a class="sourceLine" id="cb528-28" data-line-number="28">    }</a>
<a class="sourceLine" id="cb528-29" data-line-number="29">  }</a>
<a class="sourceLine" id="cb528-30" data-line-number="30">  <span class="kw">colnames</span>(scheffe) =<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;diff&quot;</span>,  <span class="st">&quot;F&quot;</span>, <span class="st">&quot;critical value&quot;</span> )</a>
<a class="sourceLine" id="cb528-31" data-line-number="31">  <span class="kw">rownames</span>(scheffe) =<span class="st"> </span>rname</a>
<a class="sourceLine" id="cb528-32" data-line-number="32">  scheffe</a>
<a class="sourceLine" id="cb528-33" data-line-number="33">}</a>
<a class="sourceLine" id="cb528-34" data-line-number="34"><span class="kw">scheffe.comparison</span>(mtcars<span class="op">$</span>mpg, <span class="kw">as.factor</span>( mtcars<span class="op">$</span>cyl))</a></code></pre></div>
<pre><code>##         diff      F critical value
## 6-4*  -6.921 19.723          6.655
## 8-4* -11.564 79.291          6.655
## 8-6*  -4.643  9.683          6.655</code></pre>

<p>Here, an asterisk(*) implies a significant difference between the pair of means because the f-statistic is greater than the critical value.</p>
</div>
<div id="fishers-test" class="section level3 hasAnchor">
<h3><span class="header-section-number">6.5.2</span> Fisherâs Test <a href="6.5-multiple-comparison-tests.html#fishers-test" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Fisherâs Test</strong>, also called <strong>Tukeyâs LSD (least significant difference)</strong>, is another <strong>Post-HOC</strong> multiple comparison test.</p>
<p><strong>First</strong>, let us perform a <strong>One-Way ANOVA</strong> using our R implementation. Here, we use the <strong>mtcars</strong> dataset as before to illustrate a pairwise comparison:</p>

<div class="sourceCode" id="cb530"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb530-1" data-line-number="1">(<span class="dt">anova_outcome =</span> <span class="dt">anova =</span> <span class="kw">one_way_anova</span>(mtcars<span class="op">$</span>mpg, mtcars<span class="op">$</span>cyl))</a></code></pre></div>
<pre><code>##    SSB    SSW    dfB    dfW    MSB    MSW      F 
## 824.78 301.26   2.00  29.00 412.39  10.39  39.70</code></pre>

<p>We can validate the result using <strong>aov()</strong>. First and foremost, we convert one of the variables into a factor variable: <strong>number of cylinders (cyl)</strong>.</p>

<div class="sourceCode" id="cb532"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb532-1" data-line-number="1">mtcars_ =<span class="st"> </span>mtcars</a>
<a class="sourceLine" id="cb532-2" data-line-number="2">mtcars_<span class="op">$</span>cyl_factor =<span class="st"> </span><span class="kw">as.factor</span>(mtcars_<span class="op">$</span>cyl)</a>
<a class="sourceLine" id="cb532-3" data-line-number="3">aov.model =<span class="st"> </span><span class="kw">aov</span>(mpg <span class="op">~</span><span class="st"> </span>cyl_factor, <span class="dt">data =</span> mtcars_) <span class="co"># One-Way Anova</span></a>
<a class="sourceLine" id="cb532-4" data-line-number="4"><span class="kw">summary</span>(aov.model)</a></code></pre></div>
<pre><code>##             Df Sum Sq Mean Sq F value Pr(&gt;F)    
## cyl_factor   2    825     412    39.7  5e-09 ***
## Residuals   29    301      10                   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>

<p><strong>Second</strong>, compute for the standard error (SE) per comparison:</p>
<p><span class="math display" id="eq:equate1080049" id="eq:equate1080048" id="eq:equate1080047">\[\begin{align}
SE_{(within\ comparison)} {}&amp;= \sqrt{\frac{MS_W}{n}} = \sqrt{\frac{s^2_W}{n}} = \frac{s_w}{\sqrt{n}} \tag{6.50} \\
&amp;or \nonumber \\ 
SE_{(within\ comparison)} &amp;=  \sqrt{\frac{MS_W}{2}\left(\frac{1}{n_i}+\frac{1}{n_j}\right)}\ \leftarrow \text{if different group sizes} \tag{6.51} \\
&amp;= s_w \sqrt{\frac{1}{2}\left(\frac{1}{n_i}+\frac{1}{n_j}\right)} \tag{6.52} 
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(SE_{(within\ comparison)}\)</span> is the standard error per within-comparison</li>
<li><span class="math inline">\(\mathbf{MS_W}\)</span> is the within-group mean square (error)</li>
<li><strong>n</strong> is the group size</li>
<li><span class="math inline">\(\mathbf{n_i}\)</span> is the size of the first group</li>
<li><span class="math inline">\(\mathbf{n_j}\)</span> is the size of the second group</li>
</ul>

<div class="sourceCode" id="cb534"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb534-1" data-line-number="1">groups =<span class="st"> </span><span class="kw">split</span>( mtcars<span class="op">$</span>mpg, <span class="kw">as.factor</span>(mtcars<span class="op">$</span>cyl))</a>
<a class="sourceLine" id="cb534-2" data-line-number="2">n<span class="fl">.1</span> =<span class="st"> </span><span class="kw">length</span>(groups[[<span class="dv">1</span>]]); n<span class="fl">.2</span> =<span class="st"> </span><span class="kw">length</span>(groups[[<span class="dv">2</span>]])</a>
<a class="sourceLine" id="cb534-3" data-line-number="3">(<span class="dt">SE =</span> <span class="kw">sqrt</span>(<span class="kw">as.numeric</span>(anova[<span class="st">&quot;MSW&quot;</span>]) <span class="op">*</span><span class="st"> </span>( <span class="dv">1</span> <span class="op">/</span><span class="st"> </span>n<span class="fl">.1</span> <span class="op">+</span><span class="st"> </span><span class="dv">1</span> <span class="op">/</span><span class="st"> </span>n<span class="fl">.2</span>))) </a></code></pre></div>
<pre><code>## [1] 1.558</code></pre>

<p><strong>Third</strong>, compute for <strong>Fisherâs LSD</strong> using the following formula:</p>
<p><span class="math display" id="eq:equate1080050">\[\begin{align}
Fisher&#39;s\ LSD_{i,j} =  t_{\alpha/2}{(  df_w)} \times SE \tag{6.53} 
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li><strong>LSD</strong> is Fisherâs Significance range value, also called <strong>Fisherâs Criterion</strong></li>
<li><strong>SE</strong> is the standard error</li>
<li><strong>t</strong> is the t-critical value (we can use built-in R function <strong>qt()</strong>)</li>
<li><span class="math inline">\(\mathbf{\alpha}\)</span> is the alpha representing type I error</li>
<li><span class="math inline">\(\mathbf{df_w}\)</span> is degrees of freedom (residual or within-group df)</li>
</ul>
<p>Note: if group sizes are different, then <span class="math inline">\(n_i\)</span> is the size of the first group in pair, <span class="math inline">\(n_j\)</span> is the size of the second group in pair)</p>
<p>Here, we use a built-in R function called <strong>qt()</strong> to calculate <strong>t-critical value</strong>. Then with an assumed 95% confidence level, we now compute for the <strong>LSD</strong>:</p>

<div class="sourceCode" id="cb536"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb536-1" data-line-number="1">t =<span class="st"> </span><span class="kw">qt</span>(<span class="dt">p =</span> <span class="fl">0.05</span><span class="op">/</span><span class="dv">2</span>,  <span class="dt">df =</span> anova[<span class="st">&quot;dfW&quot;</span>] , <span class="dt">lower.tail=</span><span class="ot">FALSE</span> )</a>
<a class="sourceLine" id="cb536-2" data-line-number="2">(<span class="dt">lsd =</span> t <span class="op">*</span><span class="st"> </span>SE) </a></code></pre></div>
<pre><code>## [1] 3.187</code></pre>

<p><strong>Fourth</strong>, determine the significance.</p>
<p><span class="math display" id="eq:equate1080051">\[\begin{align}
(\bar{x}_i - \bar{x}_j) &gt; LSD_{i,j}\ \ \ \ \leftarrow\ \ \ \ \text{there is a significant difference} \tag{6.54} 
\end{align}\]</span></p>
<p><strong>Fifth</strong>, repeat the process for every pair.</p>
<p>Here is a naive implementation of <strong>Fisherâs LSD</strong> test using R code:</p>

<div class="sourceCode" id="cb538"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb538-1" data-line-number="1">fisher.comparison &lt;-<span class="st"> </span><span class="cf">function</span>(dependent, factor) {</a>
<a class="sourceLine" id="cb538-2" data-line-number="2">  factors =<span class="st"> </span><span class="kw">levels</span>(<span class="kw">as.factor</span>(factor))</a>
<a class="sourceLine" id="cb538-3" data-line-number="3">  groups =<span class="st"> </span><span class="kw">split</span>( dependent, <span class="kw">as.factor</span>(factor))</a>
<a class="sourceLine" id="cb538-4" data-line-number="4">  anova =<span class="st"> </span><span class="kw">one_way_anova</span>(groups)</a>
<a class="sourceLine" id="cb538-5" data-line-number="5">  m =<span class="st"> </span><span class="kw">length</span>(groups) <span class="co"># number of groups</span></a>
<a class="sourceLine" id="cb538-6" data-line-number="6">  fisher =<span class="st"> </span><span class="kw">c</span>();  rname =<span class="st"> </span><span class="kw">c</span>()</a>
<a class="sourceLine" id="cb538-7" data-line-number="7">  <span class="co">#  (t - critical value)</span></a>
<a class="sourceLine" id="cb538-8" data-line-number="8">  dfW =<span class="st"> </span><span class="kw">as.numeric</span>(anova[<span class="st">&quot;dfW&quot;</span>])</a>
<a class="sourceLine" id="cb538-9" data-line-number="9">  q =<span class="st"> </span><span class="kw">qt</span>(<span class="dt">p =</span> <span class="fl">0.05</span><span class="op">/</span><span class="dv">2</span>, <span class="dt">df =</span> dfW , <span class="dt">lower.tail=</span><span class="ot">FALSE</span> )</a>
<a class="sourceLine" id="cb538-10" data-line-number="10">  msw =<span class="st"> </span><span class="kw">as.numeric</span>(anova[<span class="st">&quot;MSW&quot;</span>]) </a>
<a class="sourceLine" id="cb538-11" data-line-number="11">  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>m) {</a>
<a class="sourceLine" id="cb538-12" data-line-number="12">        n.i =<span class="st"> </span><span class="kw">length</span>(groups[[i]]); u.i =<span class="st"> </span><span class="kw">mean</span>(groups[[i]]);  </a>
<a class="sourceLine" id="cb538-13" data-line-number="13">        g.i =<span class="st"> </span>factors[i]</a>
<a class="sourceLine" id="cb538-14" data-line-number="14">    <span class="cf">for</span> (j <span class="cf">in</span> i<span class="op">:</span>m) {</a>
<a class="sourceLine" id="cb538-15" data-line-number="15">      <span class="cf">if</span> (i <span class="op">!=</span><span class="st"> </span>j) {</a>
<a class="sourceLine" id="cb538-16" data-line-number="16">        n.j =<span class="st"> </span><span class="kw">length</span>(groups[[j]]); u.j =<span class="st"> </span><span class="kw">mean</span>(groups[[j]]); </a>
<a class="sourceLine" id="cb538-17" data-line-number="17">        g.j =<span class="st"> </span>factors[j]</a>
<a class="sourceLine" id="cb538-18" data-line-number="18">        d =<span class="st">  </span><span class="kw">abs</span>(u.j <span class="op">-</span><span class="st"> </span>u.i)  <span class="co"># difference</span></a>
<a class="sourceLine" id="cb538-19" data-line-number="19">        se =<span class="st"> </span><span class="kw">sqrt</span>( (msw <span class="op">/</span><span class="st"> </span><span class="dv">2</span>) <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span><span class="op">/</span>n.i <span class="op">+</span><span class="st"> </span><span class="dv">1</span><span class="op">/</span>n.j)) <span class="co"># different size</span></a>
<a class="sourceLine" id="cb538-20" data-line-number="20">        t =<span class="st"> </span>d <span class="op">/</span><span class="st"> </span>se <span class="co"># Fisher&#39;s LSD</span></a>
<a class="sourceLine" id="cb538-21" data-line-number="21">        lsd =<span class="st"> </span>q <span class="op">*</span><span class="st"> </span>se <span class="co"># critical range</span></a>
<a class="sourceLine" id="cb538-22" data-line-number="22">        p =<span class="st"> </span><span class="kw">pt</span>( t <span class="op">*</span><span class="st"> </span><span class="kw">sqrt</span>(<span class="dv">2</span>), <span class="dt">df =</span> dfW, <span class="dt">lower.tail=</span><span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb538-23" data-line-number="23">        lower =<span class="st"> </span>d <span class="op">-</span><span class="st"> </span>lsd  <span class="co"># lower boundary of conf. interval</span></a>
<a class="sourceLine" id="cb538-24" data-line-number="24">        upper =<span class="st"> </span>d <span class="op">+</span><span class="st"> </span>lsd  <span class="co"># upper boundary of conf. interval</span></a>
<a class="sourceLine" id="cb538-25" data-line-number="25">        signif =<span class="st"> &#39;&#39;</span></a>
<a class="sourceLine" id="cb538-26" data-line-number="26">        <span class="cf">if</span> (d <span class="op">&gt;</span><span class="st"> </span>lsd) { signif =<span class="st"> &#39;*&#39;</span> }</a>
<a class="sourceLine" id="cb538-27" data-line-number="27">        rname =<span class="st"> </span><span class="kw">c</span>(rname, <span class="kw">paste0</span>(g.j, <span class="st">&quot;-&quot;</span>, g.i, signif))</a>
<a class="sourceLine" id="cb538-28" data-line-number="28">        fisher =<span class="st"> </span><span class="kw">rbind</span>(fisher, </a>
<a class="sourceLine" id="cb538-29" data-line-number="29">                  <span class="kw">c</span>(se, dfW, <span class="kw">round</span>(d,<span class="dv">5</span>), lower, upper, lsd, q, p))</a>
<a class="sourceLine" id="cb538-30" data-line-number="30">      }</a>
<a class="sourceLine" id="cb538-31" data-line-number="31">    }</a>
<a class="sourceLine" id="cb538-32" data-line-number="32">  }</a>
<a class="sourceLine" id="cb538-33" data-line-number="33">  <span class="kw">colnames</span>(fisher) =<span class="st"> </span></a>
<a class="sourceLine" id="cb538-34" data-line-number="34"><span class="st">    </span><span class="kw">c</span>(<span class="st">&quot;se&quot;</span>, <span class="st">&quot;dfW&quot;</span>, <span class="st">&quot;diff&quot;</span>, <span class="st">&quot;lower&quot;</span>, <span class="st">&quot;upper&quot;</span>,  <span class="st">&quot;Qlsd&quot;</span>,  <span class="st">&quot;Qcrit&quot;</span>, <span class="st">&quot;pvalue&quot;</span>)</a>
<a class="sourceLine" id="cb538-35" data-line-number="35">  <span class="kw">rownames</span>(fisher) =<span class="st"> </span>rname</a>
<a class="sourceLine" id="cb538-36" data-line-number="36">  fisher</a>
<a class="sourceLine" id="cb538-37" data-line-number="37">}</a>
<a class="sourceLine" id="cb538-38" data-line-number="38"><span class="kw">fisher.comparison</span>(mtcars<span class="op">$</span>mpg, mtcars<span class="op">$</span>cyl)</a></code></pre></div>
<pre><code>##          se dfW   diff lower  upper  Qlsd Qcrit    pvalue
## 6-4* 1.1019  29  6.921 4.667  9.174 2.254 2.045 4.521e-10
## 8-4* 0.9183  29 11.564 9.686 13.442 1.878 2.045 1.857e-17
## 8-6* 1.0550  29  4.643 2.485  6.801 2.158 2.045 4.320e-07</code></pre>

<p>In our result, the absolute difference of each pair of groups is larger than the <strong>Fisherâs LSD criterion (lsd)</strong>, e.g., diff &gt; lsd. Additionally, we also show that the <strong>p-value</strong> is lesser than our alpha, e.g., <span class="math inline">\(p &lt; \alpha\)</span> (at 0.05); therefore, there is a significant difference for all pairs of means, as shown by the asterisk(*) in the table.</p>
</div>
<div id="tukeys-test" class="section level3 hasAnchor">
<h3><span class="header-section-number">6.5.3</span> Tukeyâs Test <a href="6.5-multiple-comparison-tests.html#tukeys-test" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Tukeyâs Test</strong>, also called <strong>Tukeyâs HSD (honestly significant difference)</strong>, is another <strong>Post-HOC</strong> multiple comparison test. It becomes a <strong>Tukey-Kramerâs Test</strong> if group sizes are not the same (See computation of <strong>standard error (SE)</strong> later).</p>
<p>Here, we use the <strong>mtcars</strong> dataset as before to illustrate a pairwise comparison. Let us convert one of the variables into a factor variable: <strong>number of cylinders (cyl)</strong> while at the same time, view the outcome from <strong>aov()</strong> as a review:</p>

<div class="sourceCode" id="cb540"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb540-1" data-line-number="1">mtcars_ =<span class="st"> </span>mtcars</a>
<a class="sourceLine" id="cb540-2" data-line-number="2">mtcars_<span class="op">$</span>cyl_factor =<span class="st"> </span><span class="kw">as.factor</span>(mtcars_<span class="op">$</span>cyl)</a>
<a class="sourceLine" id="cb540-3" data-line-number="3">aov.model =<span class="st"> </span><span class="kw">aov</span>(mpg <span class="op">~</span><span class="st"> </span>cyl_factor, <span class="dt">data =</span> mtcars_) <span class="co"># One-Way Anova</span></a>
<a class="sourceLine" id="cb540-4" data-line-number="4"><span class="kw">summary</span>(aov.model)</a></code></pre></div>
<pre><code>##             Df Sum Sq Mean Sq F value Pr(&gt;F)    
## cyl_factor   2    825     412    39.7  5e-09 ***
## Residuals   29    301      10                   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>

<p><strong>First</strong>, there are a few assumptions we need to take note of when working with <strong>Tukeyâs Method</strong>:</p>
<ul>
<li><p>assumption of <strong>independence</strong> - samples are independent of each other (no association).</p></li>
<li><p>assumption of <strong>normality</strong> - samples follow a normal distribution. We can use <strong>Shapiro-Wilk</strong> test as an example to test normality. We can use the <strong>Dâagostino-Pearson</strong> test for skewness and kurtosis. There are also other methods available to use. </p></li>
</ul>

<div class="sourceCode" id="cb542"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb542-1" data-line-number="1"><span class="kw">shapiro.test</span>(<span class="kw">residuals</span>(aov.model))</a></code></pre></div>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  residuals(aov.model)
## W = 0.97, p-value = 0.5</code></pre>

<ul>
<li>assumption of <strong>homogeneity</strong> - samples have the same variance. We can use <strong>Bartlettâs test</strong> to test <strong>homogeneity</strong> of variance. See also <strong>Games-Howell Test</strong> in the next section.  </li>
</ul>

<div class="sourceCode" id="cb544"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb544-1" data-line-number="1"><span class="kw">bartlett.test</span>(mpg <span class="op">~</span><span class="st"> </span>cyl_factor, <span class="dt">data =</span> mtcars_)</a></code></pre></div>
<pre><code>## 
##  Bartlett test of homogeneity of variances
## 
## data:  mpg by cyl_factor
## Bartlett&#39;s K-squared = 8.4, df = 2, p-value = 0.02</code></pre>

<p><strong>Second</strong>, determine the groups, e.g. <span class="math inline">\((4,\ 6,\ 8)\)</span>, to be compared from the factor variable, e.g. <strong>cyl</strong> (number of cylinders).</p>

<div class="sourceCode" id="cb546"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb546-1" data-line-number="1">(<span class="dt">groups =</span> <span class="kw">levels</span>(<span class="kw">as.factor</span>(mtcars<span class="op">$</span>cyl)))</a></code></pre></div>
<pre><code>## [1] &quot;4&quot; &quot;6&quot; &quot;8&quot;</code></pre>

<p><strong>Third</strong>, perform a <strong>One-Way ANOVA</strong> using our R implementation: </p>

<div class="sourceCode" id="cb548"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb548-1" data-line-number="1">(<span class="dt">anova_outcome =</span> <span class="dt">anova =</span> <span class="kw">one_way_anova</span>(mtcars<span class="op">$</span>mpg, mtcars<span class="op">$</span>cyl))</a></code></pre></div>
<pre><code>##    SSB    SSW    dfB    dfW    MSB    MSW      F 
## 824.78 301.26   2.00  29.00 412.39  10.39  39.70</code></pre>

<p><strong>Fourth</strong>, compute for the <strong>standard error (SE)</strong> per comparison: </p>
<p><span class="math display" id="eq:eqnnumber28" id="eq:equate1080053" id="eq:equate1080052">\[\begin{align}
SE_{(within\ comparison)} {}&amp;= \sqrt{\frac{MS_W}{n}} = \sqrt{\frac{s^2_W}{n}} = \frac{s_w}{\sqrt{n}} \tag{6.55} \\
&amp;or\nonumber \\ 
SE_{(within\ comparison)} &amp;=  \sqrt{\frac{MS_W}{2}\left(\frac{1}{n_i}+\frac{1}{n_j}\right)}\ \leftarrow \text{if different group sizes} \tag{6.56} \\
&amp;= s_w \sqrt{\frac{1}{2}\left(\frac{1}{n_i}+\frac{1}{n_j}\right)} \tag{6.57}
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(SE_{(within\ comparison)}\)</span> is the standard error per within-comparison</li>
<li><span class="math inline">\(\mathbf{MS_W}\)</span> is the within-group mean square (error)</li>
<li><strong>n</strong> is the group size</li>
<li><span class="math inline">\(\mathbf{n_i}\)</span> is the size of the first group</li>
<li><span class="math inline">\(\mathbf{n_j}\)</span> is the size of the second group</li>
</ul>

<div class="sourceCode" id="cb550"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb550-1" data-line-number="1">n =<span class="st"> </span>sample_size</a>
<a class="sourceLine" id="cb550-2" data-line-number="2">(<span class="dt">SE =</span> <span class="kw">sqrt</span>(<span class="kw">as.numeric</span>(anova[<span class="st">&quot;MSW&quot;</span>]) <span class="op">/</span><span class="st"> </span>n)) <span class="co"># using groups of same size</span></a></code></pre></div>
<pre><code>## [1] 1.019</code></pre>

<p><strong>Fifth</strong>, compute for <strong>Tukeyâs HSD</strong> using the following formula: </p>
<p><span class="math display" id="eq:equate1080054">\[\begin{align}
Q_{hsd} =  q_{\alpha}{( m, df_w)} \times SE \tag{6.58} 
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(\mathbf{Q_{hsd}}\)</span> is Tukeyâs Significance range value, also called <strong>Tukeyâs Criterion</strong></li>
<li><strong>SE</strong> is the standard error</li>
<li><strong>q</strong> is the Tukeyâs studentized range value (we can use built-in R function <strong>qtukey()</strong>)</li>
<li><span class="math inline">\(\mathbf{\alpha}\)</span> is the alpha representing type I error</li>
<li><strong>m</strong> is total number of groups</li>
<li><span class="math inline">\(\mathbf{df_w}\)</span> is degrees of freedom (residual or within-group df)</li>
</ul>
<p>Note: if group sizes are different, then <span class="math inline">\(n_i\)</span> is the size of the first group in pair, <span class="math inline">\(n_j\)</span> is the size of the second group in pair)</p>
<p>Here, we use a built-in R function called <strong>qtukey()</strong> to calculate <strong>Tukeyâs studentized range value</strong>. Then with an assumed 95% confidence level, we now compute for the <strong>HSD</strong>:</p>

<div class="sourceCode" id="cb552"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb552-1" data-line-number="1">m =<span class="st"> </span><span class="kw">length</span>(groups) <span class="co"># Number of Groups</span></a>
<a class="sourceLine" id="cb552-2" data-line-number="2">q =<span class="st"> </span><span class="kw">qtukey</span>(<span class="dt">p =</span> <span class="fl">0.05</span>, <span class="dt">nmeans =</span> m,  <span class="dt">df =</span> anova[<span class="st">&quot;dfW&quot;</span>] , <span class="dt">lower.tail=</span><span class="ot">FALSE</span> )</a>
<a class="sourceLine" id="cb552-3" data-line-number="3">(<span class="dt">hsd =</span> q <span class="op">*</span><span class="st"> </span>SE) <span class="co"># with same group sizes</span></a></code></pre></div>
<pre><code>## [1] 3.56</code></pre>

<p><strong>Sixth</strong>, determine the significance.</p>
<p><span class="math display" id="eq:equate1080055">\[\begin{align}
(\bar{x}_i - \bar{x}_j) &gt; Q_{hsd}\ \ \ \ \leftarrow\ \ \ \ \text{there is a significant difference} \tag{6.59} 
\end{align}\]</span></p>
<p><strong>Seventh</strong>, compute for the <strong>Tukeyâs Test statistic (T)</strong> using the following formula:</p>
<p><span class="math display" id="eq:equate1080056">\[\begin{align}
T = \frac{(\bar{x}_i - \bar{x}_j)}{SE} \tag{6.60} 
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li><strong>T</strong> is Tukeyâs observed t statistic</li>
<li><span class="math inline">\(\bar{x}_{i}\)</span> is the larger of a pair of group means</li>
<li><span class="math inline">\(\bar{x}_{j}\)</span> is the smaller of a pair of group means</li>
<li><strong>SE</strong> is the standard error</li>
</ul>
<p><strong>Eight</strong>, compute for the <strong>difference of means</strong> and the <strong>confidence interval</strong>:</p>
<p>The <strong>confidence interval</strong> is computed using the following formula:</p>
<p><span class="math display" id="eq:equate1080057">\[\begin{align}
C.I. = (\bar{x}_{2} - \bar{x}_1) \pm HSD \tag{6.61} 
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(\bar{x}_{2}\)</span> is the larger of a pair of group means</li>
<li><span class="math inline">\(\bar{x}_{1}\)</span> is the smaller of a pair of group means</li>
<li><strong>HSD</strong> is Tukeyâs HSD (honestly significant difference)</li>
</ul>
<p>Here is a naive implementation of <strong>Tukeyâs comparison</strong> test in R code:</p>

<div class="sourceCode" id="cb554"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb554-1" data-line-number="1">tukey.comparison &lt;-<span class="st"> </span><span class="cf">function</span>(dependent, factor) {</a>
<a class="sourceLine" id="cb554-2" data-line-number="2">  factors =<span class="st"> </span><span class="kw">levels</span>(<span class="kw">as.factor</span>(factor))</a>
<a class="sourceLine" id="cb554-3" data-line-number="3">  groups =<span class="st"> </span><span class="kw">split</span>( dependent, <span class="kw">as.factor</span>(factor))</a>
<a class="sourceLine" id="cb554-4" data-line-number="4">  anova =<span class="st"> </span><span class="kw">one_way_anova</span>(groups)</a>
<a class="sourceLine" id="cb554-5" data-line-number="5">  m =<span class="st"> </span><span class="kw">length</span>(groups) <span class="co"># number of groups</span></a>
<a class="sourceLine" id="cb554-6" data-line-number="6">  tukey =<span class="st"> </span><span class="kw">c</span>();  rname =<span class="st"> </span><span class="kw">c</span>()</a>
<a class="sourceLine" id="cb554-7" data-line-number="7">  msw =<span class="st"> </span><span class="kw">as.numeric</span>(anova[<span class="st">&quot;MSW&quot;</span>]) </a>
<a class="sourceLine" id="cb554-8" data-line-number="8">  dfW =<span class="st"> </span><span class="kw">as.numeric</span>(anova[<span class="st">&quot;dfW&quot;</span>]) </a>
<a class="sourceLine" id="cb554-9" data-line-number="9">  <span class="co"># tukey&#39;s HSD (tukey criterion - critical value)</span></a>
<a class="sourceLine" id="cb554-10" data-line-number="10">  q =<span class="st"> </span><span class="kw">qtukey</span>(<span class="dt">p =</span> <span class="fl">0.05</span>, <span class="dt">nmeans =</span> m,  <span class="dt">df =</span> dfW , <span class="dt">lower.tail=</span><span class="ot">FALSE</span> )</a>
<a class="sourceLine" id="cb554-11" data-line-number="11">  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>m) {</a>
<a class="sourceLine" id="cb554-12" data-line-number="12">        n.i =<span class="st"> </span><span class="kw">length</span>(groups[[i]]); u.i =<span class="st"> </span><span class="kw">mean</span>(groups[[i]]);  </a>
<a class="sourceLine" id="cb554-13" data-line-number="13">        g.i =<span class="st"> </span>factors[i]</a>
<a class="sourceLine" id="cb554-14" data-line-number="14">    <span class="cf">for</span> (j <span class="cf">in</span> i<span class="op">:</span>m) {</a>
<a class="sourceLine" id="cb554-15" data-line-number="15">      <span class="cf">if</span> (i <span class="op">!=</span><span class="st"> </span>j) {</a>
<a class="sourceLine" id="cb554-16" data-line-number="16">        n.j =<span class="st"> </span><span class="kw">length</span>(groups[[j]]); u.j =<span class="st"> </span><span class="kw">mean</span>(groups[[j]]); </a>
<a class="sourceLine" id="cb554-17" data-line-number="17">        g.j =<span class="st"> </span>factors[j]</a>
<a class="sourceLine" id="cb554-18" data-line-number="18">        d =<span class="st">  </span><span class="kw">abs</span>(u.j <span class="op">-</span><span class="st"> </span>u.i)  <span class="co"># difference</span></a>
<a class="sourceLine" id="cb554-19" data-line-number="19">        se =<span class="st"> </span><span class="kw">sqrt</span>( (msw <span class="op">/</span><span class="st"> </span><span class="dv">2</span>) <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span><span class="op">/</span>n.i <span class="op">+</span><span class="st"> </span><span class="dv">1</span><span class="op">/</span>n.j)) <span class="co"># different size</span></a>
<a class="sourceLine" id="cb554-20" data-line-number="20">        t =<span class="st"> </span>d <span class="op">/</span><span class="st"> </span>se <span class="co"># Tukey&#39;s Observed q</span></a>
<a class="sourceLine" id="cb554-21" data-line-number="21">        hsd =<span class="st"> </span>q <span class="op">*</span><span class="st"> </span>se <span class="co"># critical range</span></a>
<a class="sourceLine" id="cb554-22" data-line-number="22">        p =<span class="st"> </span><span class="kw">ptukey</span>( t <span class="op">*</span><span class="st"> </span><span class="kw">sqrt</span>(<span class="dv">2</span>), <span class="dt">nmeans =</span> m, <span class="dt">df =</span> dfW, <span class="dt">lower.tail=</span><span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb554-23" data-line-number="23">        lower =<span class="st"> </span>d <span class="op">-</span><span class="st"> </span>hsd  <span class="co"># lower boundary of conf. interval</span></a>
<a class="sourceLine" id="cb554-24" data-line-number="24">        upper =<span class="st"> </span>d <span class="op">+</span><span class="st"> </span>hsd  <span class="co"># upper boundary of conf. interval</span></a>
<a class="sourceLine" id="cb554-25" data-line-number="25">        signif =<span class="st"> &#39;&#39;</span></a>
<a class="sourceLine" id="cb554-26" data-line-number="26">        <span class="cf">if</span> (d <span class="op">&gt;</span><span class="st"> </span>hsd) { signif =<span class="st"> &#39;*&#39;</span> }</a>
<a class="sourceLine" id="cb554-27" data-line-number="27">        rname =<span class="st"> </span><span class="kw">c</span>(rname, <span class="kw">paste0</span>(g.j, <span class="st">&quot;-&quot;</span>, g.i, signif))</a>
<a class="sourceLine" id="cb554-28" data-line-number="28">        tukey =<span class="st"> </span><span class="kw">rbind</span>(tukey, </a>
<a class="sourceLine" id="cb554-29" data-line-number="29">                  <span class="kw">c</span>(se, dfW, <span class="kw">round</span>(d,<span class="dv">5</span>), lower, upper, hsd, q, p))</a>
<a class="sourceLine" id="cb554-30" data-line-number="30">      }</a>
<a class="sourceLine" id="cb554-31" data-line-number="31">    }</a>
<a class="sourceLine" id="cb554-32" data-line-number="32">  }</a>
<a class="sourceLine" id="cb554-33" data-line-number="33">  <span class="kw">colnames</span>(tukey) =<span class="st"> </span></a>
<a class="sourceLine" id="cb554-34" data-line-number="34"><span class="st">    </span><span class="kw">c</span>(<span class="st">&quot;se&quot;</span>, <span class="st">&quot;dfW&quot;</span>, <span class="st">&quot;diff&quot;</span>, <span class="st">&quot;lower&quot;</span>, <span class="st">&quot;upper&quot;</span>,  <span class="st">&quot;Qhsd&quot;</span>,  <span class="st">&quot;Qcrit&quot;</span>, </a>
<a class="sourceLine" id="cb554-35" data-line-number="35">      <span class="st">&quot;pvalue&quot;</span>)</a>
<a class="sourceLine" id="cb554-36" data-line-number="36">  <span class="kw">rownames</span>(tukey) =<span class="st"> </span>rname</a>
<a class="sourceLine" id="cb554-37" data-line-number="37">  tukey</a>
<a class="sourceLine" id="cb554-38" data-line-number="38">}</a>
<a class="sourceLine" id="cb554-39" data-line-number="39"><span class="kw">tukey.comparison</span>(mtcars<span class="op">$</span>mpg, mtcars<span class="op">$</span>cyl)</a></code></pre></div>
<pre><code>##          se dfW   diff  lower  upper  Qhsd Qcrit    pvalue
## 6-4* 1.1019  29  6.921 3.0722 10.769 3.849 3.493 2.174e-06
## 8-4* 0.9183  29 11.564 8.3565 14.771 3.207 3.493 8.404e-13
## 8-6* 1.0550  29  4.643 0.9581  8.328 3.685 3.493 3.823e-04</code></pre>

<p>In our result, the absolute difference of each pair of groups is larger than the <strong>tukey criterion (hsd)</strong>, e.g., diff &gt; hsd. Additionally, we also show that the <strong>Tukeyâs P-value</strong> is lesser than our alpha, e.g., <span class="math inline">\(p &lt; \alpha\)</span> (at 0.05); therefore, there is a significant difference for all pairs of means, as shown by the asterisk(*) in the table.</p>
<p>Alternatively, we can also use the built-in R function <strong>TukeyHSD()</strong>.</p>
<p>Let us first perform a <strong>One-Way ANOVA</strong>: </p>

<div class="sourceCode" id="cb556"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb556-1" data-line-number="1">mtcars_ =<span class="st"> </span>mtcars</a>
<a class="sourceLine" id="cb556-2" data-line-number="2">mtcars_<span class="op">$</span>cyl_factor =<span class="st"> </span><span class="kw">as.factor</span>(mtcars_<span class="op">$</span>cyl)</a>
<a class="sourceLine" id="cb556-3" data-line-number="3">aov.model =<span class="st"> </span><span class="kw">aov</span>(mpg <span class="op">~</span><span class="st"> </span>cyl_factor, <span class="dt">data =</span> mtcars_) <span class="co"># One-Way Anova</span></a>
<a class="sourceLine" id="cb556-4" data-line-number="4"><span class="kw">summary</span>(aov.model)</a></code></pre></div>
<pre><code>##             Df Sum Sq Mean Sq F value Pr(&gt;F)    
## cyl_factor   2    825     412    39.7  5e-09 ***
## Residuals   29    301      10                   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>

<p>Then, we can use <strong>TukeyHSD()</strong> to perform a <strong>Tukey multiple comparisons of means</strong> (assuming a confidence level of 95%):</p>

<div class="sourceCode" id="cb558"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb558-1" data-line-number="1">(<span class="dt">tukey_outcome =</span> <span class="kw">TukeyHSD</span>(aov.model, <span class="dt">conf.level=</span><span class="fl">0.95</span>, <span class="dt">ordered=</span><span class="ot">FALSE</span>))</a></code></pre></div>
<pre><code>##   Tukey multiple comparisons of means
##     95% family-wise confidence level
## 
## Fit: aov(formula = mpg ~ cyl_factor, data = mtcars_)
## 
## $cyl_factor
##        diff     lwr     upr  p adj
## 6-4  -6.921 -10.769 -3.0722 0.0003
## 8-4 -11.564 -14.771 -8.3565 0.0000
## 8-6  -4.643  -8.328 -0.9581 0.0112</code></pre>

<p>To visualize the difference, we plot the Tukey outcome like so:</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:TukeyHSD"></span>
<img src="DS_files/figure-html/TukeyHSD-1.png" alt="Family-wise Confidence Level" width="70%" />
<p class="caption">
Figure 6.15: Family-wise Confidence Level
</p>
</div>
<p>Note that we also want to compare adjusted P-values corresponding to each pairwise comparison and the difference and confidence intervals. We cover <strong>Bonferroni correction</strong> in a later section to introduce one way of handling adjusted P-values.</p>
</div>
<div id="newman-keul-test" class="section level3 hasAnchor">
<h3><span class="header-section-number">6.5.4</span> Newman-Keul Test  <a href="6.5-multiple-comparison-tests.html#newman-keul-test" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Newman-Keul Test</strong>, also called <strong>Student-Newman-Keul (SNK) test</strong>, is another <strong>Post-HOC</strong> multiple comparison test similar to <strong>Tukeyâs HSD</strong> done sequentially.</p>
<p><strong>First</strong>, because this is done sequentially, we list the means of groups in descending or ascending order:</p>

<div class="sourceCode" id="cb560"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb560-1" data-line-number="1">group_means =<span class="st"> </span><span class="kw">aggregate</span>(<span class="dt">x =</span> mtcars<span class="op">$</span>mpg, <span class="dt">by =</span> <span class="kw">list</span>(mtcars<span class="op">$</span>cyl), </a>
<a class="sourceLine" id="cb560-2" data-line-number="2">                        <span class="dt">FUN=</span><span class="st">&quot;mean&quot;</span>)</a>
<a class="sourceLine" id="cb560-3" data-line-number="3">means_descend =<span class="st"> </span><span class="kw">sort</span>(<span class="dt">x =</span> group_means<span class="op">$</span>x, <span class="dt">decreasing=</span><span class="ot">TRUE</span>, </a>
<a class="sourceLine" id="cb560-4" data-line-number="4">                     <span class="dt">index.return =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb560-5" data-line-number="5"><span class="kw">names</span>(means_descend<span class="op">$</span>x) =<span class="st">  </span>groups[means_descend<span class="op">$</span>ix]</a>
<a class="sourceLine" id="cb560-6" data-line-number="6">(<span class="dt">means_descend =</span> means_descend<span class="op">$</span>x)</a></code></pre></div>
<pre><code>##     4     6     8 
## 26.66 19.74 15.10</code></pre>

<p>We then get the difference between the greater means and the lesser means amongst all of them. Here, we use a table:</p>

<div class="sourceCode" id="cb562"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb562-1" data-line-number="1">n =<span class="st"> </span><span class="kw">length</span>(means_descend)</a>
<a class="sourceLine" id="cb562-2" data-line-number="2">d =<span class="st"> </span><span class="kw">matrix</span>(<span class="st">&#39;.&#39;</span>, n, n)</a>
<a class="sourceLine" id="cb562-3" data-line-number="3"><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n) {</a>
<a class="sourceLine" id="cb562-4" data-line-number="4">  <span class="cf">for</span> (j <span class="cf">in</span> n<span class="op">:</span><span class="dv">1</span>) {</a>
<a class="sourceLine" id="cb562-5" data-line-number="5">    <span class="cf">if</span> (means_descend[i] <span class="op">&gt;</span><span class="st"> </span>means_descend[j]) { </a>
<a class="sourceLine" id="cb562-6" data-line-number="6">      d[i, n <span class="op">-</span><span class="st"> </span>j <span class="op">+</span><span class="st"> </span><span class="dv">1</span>] =<span class="st">  </span>means_descend[i] <span class="op">-</span><span class="st"> </span>means_descend[j]</a>
<a class="sourceLine" id="cb562-7" data-line-number="7">    }</a>
<a class="sourceLine" id="cb562-8" data-line-number="8">  }</a>
<a class="sourceLine" id="cb562-9" data-line-number="9">}</a>
<a class="sourceLine" id="cb562-10" data-line-number="10"><span class="kw">rownames</span>(d) =<span class="st"> </span><span class="kw">round</span>(means_descend,<span class="dv">3</span>)</a>
<a class="sourceLine" id="cb562-11" data-line-number="11"><span class="kw">colnames</span>(d) =<span class="st"> </span><span class="kw">round</span>(<span class="kw">sort</span>(means_descend, <span class="dt">decreasing=</span><span class="ot">FALSE</span>),<span class="dv">3</span>)</a>
<a class="sourceLine" id="cb562-12" data-line-number="12">knitr<span class="op">::</span><span class="kw">kable</span>( d, <span class="dt">caption =</span> <span class="st">&quot;Newman-Keul Diff Table&quot;</span> )</a></code></pre></div>
<table>
<caption><span id="tab:unnamed-chunk-246">Table 6.13: </span>Newman-Keul Diff Table</caption>
<thead>
<tr class="header">
<th align="left"></th>
<th align="left">15.1</th>
<th align="left">19.743</th>
<th align="left">26.664</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">26.664</td>
<td align="left">11.5636363636364</td>
<td align="left">6.92077922077922</td>
<td align="left">.</td>
</tr>
<tr class="even">
<td align="left">19.743</td>
<td align="left">4.64285714285714</td>
<td align="left">.</td>
<td align="left">.</td>
</tr>
<tr class="odd">
<td align="left">15.1</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">.</td>
</tr>
</tbody>
</table>

<p><strong>Second</strong>, perform a <strong>One-Way ANOVA</strong> using our R implementation (still using <strong>mtcars</strong> dataset):</p>

<div class="sourceCode" id="cb563"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb563-1" data-line-number="1">(<span class="dt">anova_outcome =</span> <span class="dt">anova =</span> <span class="kw">one_way_anova</span>(mtcars<span class="op">$</span>mpg, mtcars<span class="op">$</span>cyl))</a></code></pre></div>
<pre><code>##    SSB    SSW    dfB    dfW    MSB    MSW      F 
## 824.78 301.26   2.00  29.00 412.39  10.39  39.70</code></pre>

<p>Here we know that <span class="math inline">\(\mathbf{H_0}\)</span> is rejected, so we continue to investigate the difference.</p>
<p><strong>Third</strong>, calculate the <strong>standard error (SE)</strong> for each comparison with the same formula used for <strong>Tukeyâs Test</strong> (See <strong>SE</strong> formula from <strong>Tukeyâs test</strong>). Each comparison will have a different <strong>SE</strong> as we use mtcars with different group sizes.  </p>
<p><span class="math display" id="eq:equate1080059" id="eq:equate1080058">\[\begin{align}
SE_{(within\ comparison)} &amp;=  \sqrt{\frac{MS_W}{2}\left(\frac{1}{n_i}+\frac{1}{n_j}\right)}\ \leftarrow \text{if different group sizes} \tag{6.62} \\
&amp;= s_w \sqrt{\frac{1}{2}\left(\frac{1}{n_i}+\frac{1}{n_j}\right)} \tag{6.63} 
\end{align}\]</span></p>
<p><strong>Fourth</strong>, calculate the <strong>Newman-Keulâs criterion</strong>: </p>
<p><span class="math display" id="eq:equate1080060">\[\begin{align}
Q_{nk} = q_{\alpha}(r, df) \times SE \tag{6.64} 
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(\mathbf{Q_{nk}}\)</span> is Newman-Keulâs criterion</li>
<li><strong>q</strong> is the Tukey range value (for which we can use <strong>qtukey()</strong> function)</li>
<li><span class="math inline">\(\mathbf{\alpha}\)</span> is the alpha (e.g.Â 0.05)</li>
<li><strong>r</strong> is the rank distance between pairs.
<strong>Fifth</strong>, determine the significance.</li>
</ul>
<p><span class="math display" id="eq:equate1080061">\[\begin{align}
(\bar{x}_i - \bar{x}_j)_r &gt; Q_{nk}\ \ \ \ \leftarrow\ \ \ \ \text{there is a significant difference} \tag{6.65} 
\end{align}\]</span></p>
<p>Here is a naive implementation of the <strong>Newman-Keulâs comparison</strong> test in R code:</p>

<div class="sourceCode" id="cb565"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb565-1" data-line-number="1">newmankeul.comparison &lt;-<span class="st"> </span><span class="cf">function</span>(group_means, anova) {</a>
<a class="sourceLine" id="cb565-2" data-line-number="2">  means_descend =<span class="st"> </span><span class="kw">sort</span>(<span class="dt">x =</span> group_means<span class="op">$</span>x, <span class="dt">decreasing=</span><span class="ot">TRUE</span>, </a>
<a class="sourceLine" id="cb565-3" data-line-number="3">                       <span class="dt">index.return =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb565-4" data-line-number="4">  group_length =<span class="st"> </span><span class="kw">aggregate</span>(<span class="dt">x =</span> mtcars<span class="op">$</span>mpg, <span class="dt">by =</span> <span class="kw">list</span>(mtcars<span class="op">$</span>cyl), </a>
<a class="sourceLine" id="cb565-5" data-line-number="5">                           <span class="dt">FUN=</span><span class="st">&quot;length&quot;</span>)</a>
<a class="sourceLine" id="cb565-6" data-line-number="6">  <span class="kw">colnames</span>(group_length) =<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;groups&quot;</span>, <span class="st">&quot;n&quot;</span>)</a>
<a class="sourceLine" id="cb565-7" data-line-number="7">  n =<span class="st"> </span><span class="kw">length</span>(means_descend<span class="op">$</span>x)</a>
<a class="sourceLine" id="cb565-8" data-line-number="8">  nkr =<span class="st"> </span><span class="kw">c</span>(); rname =<span class="st"> </span><span class="kw">c</span>()</a>
<a class="sourceLine" id="cb565-9" data-line-number="9">  msw =<span class="st"> </span><span class="kw">as.numeric</span>(anova[<span class="st">&quot;MSW&quot;</span>]) </a>
<a class="sourceLine" id="cb565-10" data-line-number="10">  dfw =<span class="st"> </span><span class="kw">as.numeric</span>(anova[<span class="st">&quot;dfW&quot;</span>]) </a>
<a class="sourceLine" id="cb565-11" data-line-number="11">  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n) {</a>
<a class="sourceLine" id="cb565-12" data-line-number="12">    <span class="cf">for</span> (j <span class="cf">in</span> n<span class="op">:</span><span class="dv">1</span>) {</a>
<a class="sourceLine" id="cb565-13" data-line-number="13">      <span class="cf">if</span> (means_descend<span class="op">$</span>x[i] <span class="op">&gt;</span><span class="st"> </span>means_descend<span class="op">$</span>x[j]) { </a>
<a class="sourceLine" id="cb565-14" data-line-number="14">        d =<span class="st">  </span>means_descend<span class="op">$</span>x[i] <span class="op">-</span><span class="st"> </span>means_descend<span class="op">$</span>x[j]</a>
<a class="sourceLine" id="cb565-15" data-line-number="15">        i.index =<span class="st"> </span>means_descend<span class="op">$</span>ix[i]</a>
<a class="sourceLine" id="cb565-16" data-line-number="16">        j.index =<span class="st"> </span>means_descend<span class="op">$</span>ix[j]</a>
<a class="sourceLine" id="cb565-17" data-line-number="17">        n.i =<span class="st"> </span>group_length<span class="op">$</span>n[i.index]; </a>
<a class="sourceLine" id="cb565-18" data-line-number="18">        g.i =<span class="st"> </span>group_length<span class="op">$</span>groups[i.index]</a>
<a class="sourceLine" id="cb565-19" data-line-number="19">        n.j =<span class="st"> </span>group_length<span class="op">$</span>n[j.index]; </a>
<a class="sourceLine" id="cb565-20" data-line-number="20">        g.j =<span class="st"> </span>group_length<span class="op">$</span>groups[j.index]</a>
<a class="sourceLine" id="cb565-21" data-line-number="21">        rank =<span class="st"> </span>j.index <span class="op">-</span><span class="st"> </span>i.index <span class="op">+</span><span class="st"> </span><span class="dv">1</span></a>
<a class="sourceLine" id="cb565-22" data-line-number="22">        se =<span class="st"> </span><span class="kw">sqrt</span>( (msw <span class="op">/</span><span class="st"> </span><span class="dv">2</span>) <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span><span class="op">/</span>n.i <span class="op">+</span><span class="st"> </span><span class="dv">1</span><span class="op">/</span>n.j))</a>
<a class="sourceLine" id="cb565-23" data-line-number="23">        q =<span class="st"> </span><span class="kw">qtukey</span>(<span class="dt">p =</span> <span class="fl">0.05</span>, <span class="dt">nmeans =</span> rank, <span class="dt">df =</span> dfw, <span class="dt">lower.tail=</span><span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb565-24" data-line-number="24">        nk =<span class="st"> </span>q <span class="op">*</span><span class="st"> </span>se</a>
<a class="sourceLine" id="cb565-25" data-line-number="25">        t =<span class="st"> </span>d <span class="op">/</span><span class="st"> </span>se <span class="co"># Tukey&#39;s Observed q</span></a>
<a class="sourceLine" id="cb565-26" data-line-number="26">        p =<span class="st"> </span><span class="kw">ptukey</span>( t <span class="op">*</span><span class="st"> </span><span class="kw">sqrt</span>(<span class="dv">2</span>), <span class="dt">nmeans =</span> rank, <span class="dt">df =</span> dfw, </a>
<a class="sourceLine" id="cb565-27" data-line-number="27">                    <span class="dt">lower.tail=</span><span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb565-28" data-line-number="28">        signif =<span class="st"> &#39;&#39;</span></a>
<a class="sourceLine" id="cb565-29" data-line-number="29">        <span class="cf">if</span> (d <span class="op">&gt;</span><span class="st"> </span>nk ) { signif =<span class="st"> &#39;*&#39;</span> }</a>
<a class="sourceLine" id="cb565-30" data-line-number="30">        rname =<span class="st"> </span><span class="kw">c</span>(rname, <span class="kw">paste0</span>(g.j, <span class="st">&quot;-&quot;</span>, g.i,signif))</a>
<a class="sourceLine" id="cb565-31" data-line-number="31">        nkr =<span class="st"> </span><span class="kw">rbind</span>(nkr, <span class="kw">c</span>(se, d, rank, dfw,   nk, q, p))</a>
<a class="sourceLine" id="cb565-32" data-line-number="32">      }</a>
<a class="sourceLine" id="cb565-33" data-line-number="33">    }</a>
<a class="sourceLine" id="cb565-34" data-line-number="34">  }</a>
<a class="sourceLine" id="cb565-35" data-line-number="35">  <span class="kw">colnames</span>(nkr) =<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;se&quot;</span>, <span class="st">&quot;diff&quot;</span>, <span class="st">&quot;rank&quot;</span>, <span class="st">&quot;dfw&quot;</span>, <span class="st">&quot;Qnk&quot;</span>, <span class="st">&quot;Qcrit&quot;</span>, </a>
<a class="sourceLine" id="cb565-36" data-line-number="36">                    <span class="st">&quot;adj. pval&quot;</span>)</a>
<a class="sourceLine" id="cb565-37" data-line-number="37">  <span class="kw">rownames</span>(nkr) =<span class="st"> </span>rname</a>
<a class="sourceLine" id="cb565-38" data-line-number="38">  nkr</a>
<a class="sourceLine" id="cb565-39" data-line-number="39">}</a>
<a class="sourceLine" id="cb565-40" data-line-number="40">(<span class="dt">nkr =</span> <span class="kw">newmankeul.comparison</span>(group_means, anova))</a></code></pre></div>
<pre><code>##          se   diff rank dfw   Qnk Qcrit adj. pval
## 8-4* 0.9183 11.564    3  29 3.207 3.493 8.404e-13
## 6-4* 1.1019  6.921    2  29 3.187 2.892 7.397e-07
## 8-6* 1.0550  4.643    2  29 3.051 2.892 1.335e-04</code></pre>

<p>We see that all the pairs (comparisons) have an asterisk(*), meaning that each of the mean differences is greater than <span class="math inline">\(\mathbf{Q_{(nk)}}\)</span>, e.g., diff &gt; <span class="math inline">\(Q_{nk}\)</span> - equivalent to being significant. For example, the difference of the pair <strong>8-4</strong> is greater than the computed <strong>Newman-Keulâs criterion</strong>, <span class="math inline">\(\mathbf{NK_{(3)}}\)</span> with a rank of 3, e.g.Â 11.5636 &gt; 3.4926. Therefore, this shows a significant difference between the pair of group means.</p>
</div>
<div id="games-howell-test" class="section level3 hasAnchor">
<h3><span class="header-section-number">6.5.5</span> Games-Howell Test <a href="6.5-multiple-comparison-tests.html#games-howell-test" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We use this test if there is a violation of <strong>homogeneity of variance</strong>, meaning variances across multiple groups are not constant (not equal). We leave readers to investigate different tests of homogeneity, e.g., <strong>Bartlettâs Test</strong> and <strong>Leveneâs Test</strong>.</p>
<p>Let us continue to use the <strong>mtcars</strong> dataset as before to illustrate a pairwise comparison.</p>
<p><strong>First</strong>, to solve for the <strong>violation of homogeneity</strong> - the unequal variances - we apply <strong>Welchâs correction</strong> using a t-test; hence, this is also called <strong>Welchâs t-test</strong> in which we use the following equation:</p>
<p><span class="math display" id="eq:equate1080062">\[\begin{align}
t_{(welch)} = \frac{\bar{x}_i - \bar{x}_j}{S_p}\ \ \leftarrow \ \ S_p = 
{\sqrt{\frac{\sigma^2_i}{n_i} + \frac{\sigma^2_j}{n_j}}} \tag{6.66} 
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li><strong>t</strong> is Welchâs T statistic</li>
<li><span class="math inline">\(S_p^2\)</span> is the pooled variance. <span class="math inline">\(S_p\)</span> is the pooled standard deviation.</li>
<li><span class="math inline">\(\bar{x}_i\ ,\ \bar{x}_j\)</span> are means of the first and second group in a pair</li>
<li><span class="math inline">\(\sigma_i\ ,\ \sigma_j\)</span> are standard deviations of the first and second group</li>
<li><span class="math inline">\(n_i\ ,\ n_j\)</span> are sizes of first and second group</li>
</ul>
<p><strong>Second</strong>, compute for the degrees of freedom.</p>
<p>Note that unlike <strong>Tukeyâs Test</strong> in which we use the ANOVAâs within-group degrees of freedom (dfW), here in <strong>Games-Howell Test</strong>, we compute the degrees of freedom from each comparison (pair of group means):</p>
<p><span class="math display" id="eq:equate1080063">\[\begin{align}
df = \frac{(S_p^2)^2}
{\frac{\left(\frac{\sigma^2_i}{n_i}\right)^2}{n_i-1} + 
 \frac{\left(\frac{\sigma^2_j}{n_j}\right)^2}{n_j-1}}\ \ \leftarrow \ \ S_p^2 = \left(\frac{\sigma^2_i}{n_i} + \frac{\sigma^2_j}{n_j}\right). \tag{6.67} 
\end{align}\]</span></p>
<p><strong>Third</strong>, compute for the pairwise standard error:</p>
<p><span class="math display" id="eq:equate1080064">\[\begin{align}
SE = \frac{S_p}{\sqrt{2}} = \sqrt{\frac{S^2_p}{2}} = \sqrt{\frac{1}{2}\left(\frac{\sigma^2_i}{n_i} + \frac{\sigma^2_j}{n_j}\right)} \tag{6.68} 
\end{align}\]</span></p>
<p><strong>Fourth</strong>, compute for the <strong>Games-Howell Significance range value</strong></p>
<p><span class="math display" id="eq:equate1080065">\[\begin{align}
Q_{gh} = q_{\alpha}(m, df) \times SE \tag{6.69} 
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(\mathbf{Q_{gh}}\)</span> is Games-Howellâs criterion</li>
<li><strong>q</strong> is the Tukey range value (for which we can use <strong>qtukey()</strong> function)</li>
<li><span class="math inline">\(\mathbf{\alpha}\)</span> is the alpha (e.g.Â 0.05)</li>
<li><strong>m</strong> is the total number of groups</li>
</ul>
<p><strong>Fifth</strong>, determine the significance.</p>
<p><span class="math display" id="eq:equate1080066">\[\begin{align}
(\bar{x}_i - \bar{x}_j) &gt; Q_{gh}\ \ \ \ \leftarrow\ \ \ \ \text{there is a significant difference} \tag{6.70} 
\end{align}\]</span></p>
<p><strong>Finally</strong>, similar to <strong>Tukeyâs confidence interval</strong>, here is the lower and upper estimate of our confidence interval:</p>
<p><span class="math display" id="eq:equate1080067">\[\begin{align}
C.I. = (\bar{x}_{i} - \bar{x}_j) \pm R  \tag{6.71} 
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(\bar{x}_{i}\)</span> is the larger of a pair of group means</li>
<li><span class="math inline">\(\bar{x}_{j}\)</span> is the smaller of a pair of group means</li>
<li><strong>R</strong> is Games-Howellâs R (ghr)</li>
</ul>
<p>Here is a naive implementation of the <strong>Games-Howell test</strong> in R code:</p>

<div class="sourceCode" id="cb567"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb567-1" data-line-number="1">gameshowell.comparison &lt;-<span class="st"> </span><span class="cf">function</span>(dependent, factor) {</a>
<a class="sourceLine" id="cb567-2" data-line-number="2">  factors =<span class="st"> </span><span class="kw">levels</span>(<span class="kw">as.factor</span>(factor))</a>
<a class="sourceLine" id="cb567-3" data-line-number="3">  groups =<span class="st"> </span><span class="kw">split</span>( dependent, <span class="kw">as.factor</span>(factor))</a>
<a class="sourceLine" id="cb567-4" data-line-number="4">  anova =<span class="st"> </span><span class="kw">one_way_anova</span>(groups)</a>
<a class="sourceLine" id="cb567-5" data-line-number="5">  m =<span class="st"> </span><span class="kw">length</span>(groups) <span class="co"># number of groups</span></a>
<a class="sourceLine" id="cb567-6" data-line-number="6">  ghr =<span class="st"> </span><span class="kw">c</span>(); rname =<span class="st"> </span><span class="kw">c</span>()</a>
<a class="sourceLine" id="cb567-7" data-line-number="7">  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>m) {</a>
<a class="sourceLine" id="cb567-8" data-line-number="8">    n.i =<span class="st"> </span><span class="kw">length</span>(groups[[i]]); u.i =<span class="st"> </span><span class="kw">mean</span>(groups[[i]]); </a>
<a class="sourceLine" id="cb567-9" data-line-number="9">    s.i =<span class="st"> </span><span class="kw">var</span>(groups[[i]])</a>
<a class="sourceLine" id="cb567-10" data-line-number="10">    g.i =<span class="st"> </span>factors[i]</a>
<a class="sourceLine" id="cb567-11" data-line-number="11">    <span class="cf">for</span> (j <span class="cf">in</span> i<span class="op">:</span>m) {</a>
<a class="sourceLine" id="cb567-12" data-line-number="12">      <span class="cf">if</span> (i <span class="op">!=</span><span class="st"> </span>j) {</a>
<a class="sourceLine" id="cb567-13" data-line-number="13">        n.j =<span class="st"> </span><span class="kw">length</span>(groups[[j]]); u.j =<span class="st"> </span><span class="kw">mean</span>(groups[[j]]);  </a>
<a class="sourceLine" id="cb567-14" data-line-number="14">        s.j =<span class="st"> </span><span class="kw">var</span>(groups[[j]])</a>
<a class="sourceLine" id="cb567-15" data-line-number="15">        g.j =<span class="st"> </span>factors[j]</a>
<a class="sourceLine" id="cb567-16" data-line-number="16">        std.i =<span class="st">  </span>s.i <span class="op">/</span><span class="st"> </span>n.i; std.j =<span class="st"> </span>s.j <span class="op">/</span><span class="st"> </span>n.j</a>
<a class="sourceLine" id="cb567-17" data-line-number="17">        d =<span class="st"> </span><span class="kw">abs</span>( u.i <span class="op">-</span><span class="st"> </span>u.j )</a>
<a class="sourceLine" id="cb567-18" data-line-number="18">        s2p =<span class="st"> </span>( std.i <span class="op">+</span><span class="st"> </span>std.j )</a>
<a class="sourceLine" id="cb567-19" data-line-number="19">        se =<span class="st">  </span><span class="kw">sqrt</span>( s2p <span class="op">/</span><span class="st"> </span><span class="dv">2</span> ) </a>
<a class="sourceLine" id="cb567-20" data-line-number="20">        df =<span class="st"> </span>s2p<span class="op">^</span><span class="dv">2</span> <span class="op">/</span><span class="st"> </span>( (std.i<span class="op">^</span><span class="dv">2</span> <span class="op">/</span><span class="st"> </span>(n.i <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)) <span class="op">+</span><span class="st"> </span>(std.j<span class="op">^</span><span class="dv">2</span> <span class="op">/</span><span class="st"> </span>(n.j <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)) )</a>
<a class="sourceLine" id="cb567-21" data-line-number="21">        t =<span class="st"> </span>d <span class="op">/</span><span class="st"> </span><span class="kw">sqrt</span>( s2p ) <span class="co"># welch&#39;s t</span></a>
<a class="sourceLine" id="cb567-22" data-line-number="22">        q =<span class="st"> </span><span class="kw">qtukey</span>(<span class="dt">p =</span> <span class="fl">0.05</span>, <span class="dt">nmeans =</span> m, <span class="dt">df =</span> df, <span class="dt">lower.tail =</span> <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb567-23" data-line-number="23">        p =<span class="st"> </span><span class="kw">ptukey</span>( t <span class="op">*</span><span class="st"> </span><span class="kw">sqrt</span>(<span class="dv">2</span>), <span class="dt">nmeans =</span> m, <span class="dt">df =</span> df, <span class="dt">lower.tail=</span><span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb567-24" data-line-number="24">        gh =<span class="st"> </span>q <span class="op">*</span><span class="st"> </span>se</a>
<a class="sourceLine" id="cb567-25" data-line-number="25">        lower =<span class="st"> </span>d <span class="op">-</span><span class="st"> </span>gh </a>
<a class="sourceLine" id="cb567-26" data-line-number="26">        upper =<span class="st"> </span>d <span class="op">+</span><span class="st"> </span>gh</a>
<a class="sourceLine" id="cb567-27" data-line-number="27">        signif =<span class="st"> &#39;&#39;</span></a>
<a class="sourceLine" id="cb567-28" data-line-number="28">        <span class="cf">if</span> (d <span class="op">&gt;</span><span class="st"> </span>gh ) { signif =<span class="st"> &#39;*&#39;</span> }</a>
<a class="sourceLine" id="cb567-29" data-line-number="29">        rname =<span class="st"> </span><span class="kw">c</span>(rname, <span class="kw">paste0</span>(g.j, <span class="st">&quot;-&quot;</span>, g.i,signif))</a>
<a class="sourceLine" id="cb567-30" data-line-number="30">        ghr =<span class="st"> </span><span class="kw">rbind</span>(ghr, <span class="kw">c</span>(se, df, d, lower, upper, gh, q, p ))</a>
<a class="sourceLine" id="cb567-31" data-line-number="31">      }</a>
<a class="sourceLine" id="cb567-32" data-line-number="32">    }</a>
<a class="sourceLine" id="cb567-33" data-line-number="33">  }</a>
<a class="sourceLine" id="cb567-34" data-line-number="34">  <span class="kw">colnames</span>(ghr) =<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;se&quot;</span>, <span class="st">&quot;df&quot;</span>, <span class="st">&quot;diff&quot;</span>, <span class="st">&quot;lower&quot;</span>, <span class="st">&quot;upper&quot;</span>, <span class="st">&quot;Qgh&quot;</span>, </a>
<a class="sourceLine" id="cb567-35" data-line-number="35">                    <span class="st">&quot;Qcrit&quot;</span>, <span class="st">&quot;adj. pval&quot;</span>)</a>
<a class="sourceLine" id="cb567-36" data-line-number="36">  <span class="kw">rownames</span>(ghr) =<span class="st"> </span>rname</a>
<a class="sourceLine" id="cb567-37" data-line-number="37">  ghr</a>
<a class="sourceLine" id="cb567-38" data-line-number="38">}</a>
<a class="sourceLine" id="cb567-39" data-line-number="39"><span class="kw">round</span>(<span class="kw">gameshowell.comparison</span>(mtcars<span class="op">$</span>mpg, mtcars<span class="op">$</span>cyl),<span class="dv">3</span>)</a></code></pre></div>
<pre><code>##         se    df   diff lower  upper   Qgh Qcrit adj. pval
## 6-4* 1.037 12.96  6.921 3.047 10.795 3.874 3.736     0.001
## 8-4* 1.076 14.97 11.564 7.609 15.518 3.955 3.674     0.000
## 8-6* 0.620 18.50  4.643 2.409  6.877 2.234 3.601     0.000</code></pre>

</div>
<div id="dunnetts-test" class="section level3 hasAnchor">
<h3><span class="header-section-number">6.5.6</span> Dunnettâs Test <a href="6.5-multiple-comparison-tests.html#dunnetts-test" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Dunnettâs Test</strong> is another <strong>Post-HOC</strong> multiple comparison test. It uses the mean of one fixed <strong>control group</strong> to compare against the means of other <strong>experiment groups</strong>.</p>
<p><strong>First</strong>, let us use the <strong>mtcars</strong> dataset as before with <strong>cyl</strong> as the factor variable of three groups:
</p>
<div class="sourceCode" id="cb569"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb569-1" data-line-number="1">(<span class="dt">groups =</span> <span class="kw">levels</span>(<span class="kw">as.factor</span>(mtcars<span class="op">$</span>cyl)))</a></code></pre></div>
<pre><code>## [1] &quot;4&quot; &quot;6&quot; &quot;8&quot;</code></pre>

<p>For illustration, let us use <strong>group 4</strong> for our <strong>control group</strong>, while <strong>groups 6 and 8</strong> are our <strong>experiment groups</strong>. That tells us that the group with cars having four cylinders is our model (or control group) for comparison of fuel consumption against cars that are not with four cylinders.</p>
<p><strong>Second</strong>, run <strong>One-Way ANOVA</strong> for analysis.</p>

<div class="sourceCode" id="cb571"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb571-1" data-line-number="1">(<span class="dt">anova_outcome =</span> <span class="dt">anova =</span> <span class="kw">one_way_anova</span>(mtcars<span class="op">$</span>mpg, mtcars<span class="op">$</span>cyl))</a></code></pre></div>
<pre><code>##    SSB    SSW    dfB    dfW    MSB    MSW      F 
## 824.78 301.26   2.00  29.00 412.39  10.39  39.70</code></pre>

<p>We know that <span class="math inline">\(\mathbf{H_0}\)</span> is rejected, so we continue to investigate the difference.</p>
<p><strong>Third</strong>, recall the <strong>standard error (SE)</strong> formula we used in <strong>Tukeyâs Test</strong> (See Equation <span class="math inline">\(\@ref(eq:eqnnumber28)\)</span>).</p>
<p><span class="math display" id="eq:equate1080069" id="eq:equate1080068">\[\begin{align}
SE_{(within\ comparison)} &amp;=  \sqrt{\frac{MS_W}{2}\left(\frac{1}{n_i}+\frac{1}{n_c}\right)}\ \leftarrow \text{if different group sizes} \tag{6.72} \\
&amp;= s_w \sqrt{\frac{1}{2}\left(\frac{1}{n_i}+\frac{1}{n_c}\right)} \tag{6.73} 
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(\mathbf{n_c}\)</span> is sample size of the control group</li>
<li><span class="math inline">\(\mathbf{n_i}\)</span> is sample size of the ith experiment group</li>
</ul>
<p><strong>Fourth</strong>, compute for Dunnettâs statistic:</p>
<p><span class="math display" id="eq:equate1080070">\[\begin{align}
Q_{dunn} = q_{\alpha}(n, df) \times SE \tag{6.74} 
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(\mathbf{Q_{dunn}}\)</span> is Dunnettâs criterion</li>
<li><strong>q</strong> is Dunnettâs Critical value ( we can use 3rd party function, <strong>cvSDDT()</strong> )</li>
<li><strong>n</strong> is the nth experiment group</li>
</ul>
<p><strong>Fifth</strong>, to determine significance, we use the following equation:</p>
<p><span class="math display" id="eq:equate1080071">\[\begin{align}
(\bar{x}_i - \bar{x}_j)_n &gt; Q_{dunn} \ \ \ \ \leftarrow\ \ \ \ \text{there is a significant difference} \tag{6.75} 
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(\bar{x}_{i}\)</span> is the larger of a pair of group means</li>
<li><span class="math inline">\(\bar{x}_{j}\)</span> is the smaller of a pair of group means</li>
</ul>
<p>Here is a naive implementation of <strong>Dunnettâs comparison</strong> in R code. We use a library called <strong>DunnettTests</strong> for the function <strong>cvsDDT()</strong> to determine Dunnettâs <strong>Critical value</strong>.</p>
<div class="sourceCode" id="cb573"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb573-1" data-line-number="1"><span class="kw">library</span>(DunnettTests)</a></code></pre></div>
<p>Note that the <strong>cvSDDT()</strong> uses <strong>pmvnorm()</strong> for a <strong>multivariate cumulative normal distribution</strong>. This is the function curve in which <strong>cvSDDT()</strong> also uses <strong>uniroot()</strong> for <strong>root finding</strong>. See Chapter <strong>3</strong> (<strong>Numerical Linear Algebra II</strong>) for <strong>Root Finding</strong> using <strong>Bisection method</strong>. The <strong>roots</strong> become the <strong>critical values</strong> used to construct the <strong>Dunnettâs table</strong>.</p>

<div class="sourceCode" id="cb574"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb574-1" data-line-number="1">dunnett.comparison &lt;-<span class="st"> </span><span class="cf">function</span>(dependent, factor) {</a>
<a class="sourceLine" id="cb574-2" data-line-number="2">  factors =<span class="st"> </span><span class="kw">levels</span>(<span class="kw">as.factor</span>(factor))</a>
<a class="sourceLine" id="cb574-3" data-line-number="3">  groups =<span class="st"> </span><span class="kw">split</span>( dependent, <span class="kw">as.factor</span>(factor))</a>
<a class="sourceLine" id="cb574-4" data-line-number="4">  anova =<span class="st"> </span><span class="kw">one_way_anova</span>(groups)</a>
<a class="sourceLine" id="cb574-5" data-line-number="5">  m =<span class="st"> </span><span class="kw">length</span>(groups) <span class="co"># number of groups</span></a>
<a class="sourceLine" id="cb574-6" data-line-number="6">  dunr =<span class="st"> </span><span class="kw">c</span>(); rname =<span class="st"> </span><span class="kw">c</span>()</a>
<a class="sourceLine" id="cb574-7" data-line-number="7">  control =<span class="st"> </span>groups[[<span class="dv">1</span>]]</a>
<a class="sourceLine" id="cb574-8" data-line-number="8">  <span class="co"># use first group as control group</span></a>
<a class="sourceLine" id="cb574-9" data-line-number="9">  n.c =<span class="st"> </span><span class="kw">length</span>(control); u.c =<span class="st"> </span><span class="kw">mean</span>(control); s.c =<span class="st"> </span><span class="kw">var</span>(control)</a>
<a class="sourceLine" id="cb574-10" data-line-number="10">  std.c =<span class="st">  </span>s.c <span class="op">/</span><span class="st"> </span>n.c; g.c =<span class="st"> </span>factors[<span class="dv">1</span>]</a>
<a class="sourceLine" id="cb574-11" data-line-number="11">  msw =<span class="st"> </span><span class="kw">as.numeric</span>(anova[<span class="st">&quot;MSW&quot;</span>]) </a>
<a class="sourceLine" id="cb574-12" data-line-number="12">  dfW =<span class="st"> </span><span class="kw">as.numeric</span>(anova[<span class="st">&quot;dfW&quot;</span>]) </a>
<a class="sourceLine" id="cb574-13" data-line-number="13">  q =<span class="st"> </span><span class="kw">cvSDDT</span>(<span class="dt">k=</span>m, <span class="dt">alpha=</span><span class="fl">0.05</span>, <span class="dt">alternative=</span><span class="st">&quot;U&quot;</span>, <span class="dt">corr=</span><span class="fl">0.5</span>, <span class="dt">df=</span>dfW)</a>
<a class="sourceLine" id="cb574-14" data-line-number="14">  <span class="co"># use the rest of group as experiment groups</span></a>
<a class="sourceLine" id="cb574-15" data-line-number="15">  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">2</span><span class="op">:</span>m) {</a>
<a class="sourceLine" id="cb574-16" data-line-number="16">    n.i =<span class="st"> </span><span class="kw">length</span>(groups[[i]]); u.i =<span class="st"> </span><span class="kw">mean</span>(groups[[i]]); </a>
<a class="sourceLine" id="cb574-17" data-line-number="17">    s.i =<span class="st"> </span><span class="kw">var</span>(groups[[i]])</a>
<a class="sourceLine" id="cb574-18" data-line-number="18">    g.i =<span class="st"> </span>factors[i]</a>
<a class="sourceLine" id="cb574-19" data-line-number="19">    std.i =<span class="st"> </span>s.i <span class="op">/</span><span class="st"> </span>n.i</a>
<a class="sourceLine" id="cb574-20" data-line-number="20">    d =<span class="st"> </span><span class="kw">abs</span>( u.c <span class="op">-</span><span class="st"> </span>u.i )</a>
<a class="sourceLine" id="cb574-21" data-line-number="21">    s2p =<span class="st"> </span>( std.c <span class="op">+</span><span class="st"> </span>std.i )</a>
<a class="sourceLine" id="cb574-22" data-line-number="22">    se =<span class="st"> </span><span class="kw">sqrt</span>( (msw <span class="op">/</span><span class="st"> </span><span class="dv">2</span>) <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span><span class="op">/</span>n.i <span class="op">+</span><span class="st"> </span><span class="dv">1</span><span class="op">/</span>n.c))</a>
<a class="sourceLine" id="cb574-23" data-line-number="23">    t =<span class="st"> </span>d <span class="op">/</span><span class="st"> </span><span class="kw">sqrt</span>( s2p ) <span class="co"># welch&#39;s t</span></a>
<a class="sourceLine" id="cb574-24" data-line-number="24">    p =<span class="st"> </span><span class="kw">ptukey</span>( t <span class="op">*</span><span class="st"> </span><span class="kw">sqrt</span>(<span class="dv">2</span>), <span class="dt">nmeans =</span> m, <span class="dt">df =</span> dfW, <span class="dt">lower.tail=</span><span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb574-25" data-line-number="25">    dunn =<span class="st"> </span>q[i] <span class="op">*</span><span class="st"> </span>se</a>
<a class="sourceLine" id="cb574-26" data-line-number="26">    lower =<span class="st"> </span>d <span class="op">-</span><span class="st"> </span>dunn </a>
<a class="sourceLine" id="cb574-27" data-line-number="27">    upper =<span class="st"> </span>d <span class="op">+</span><span class="st"> </span>dunn</a>
<a class="sourceLine" id="cb574-28" data-line-number="28">    signif =<span class="st"> &#39;&#39;</span></a>
<a class="sourceLine" id="cb574-29" data-line-number="29">    <span class="cf">if</span> (d <span class="op">&gt;</span><span class="st"> </span>dunn ) { signif =<span class="st"> &#39;*&#39;</span> }</a>
<a class="sourceLine" id="cb574-30" data-line-number="30">    rname =<span class="st"> </span><span class="kw">c</span>(rname, <span class="kw">paste0</span>(g.i, <span class="st">&quot;-&quot;</span>, g.c,signif))</a>
<a class="sourceLine" id="cb574-31" data-line-number="31">    dunr =<span class="st"> </span><span class="kw">rbind</span>(dunr, <span class="kw">c</span>(se, dfW, d, lower, upper, dunn, q[i], p ))</a>
<a class="sourceLine" id="cb574-32" data-line-number="32">  }</a>
<a class="sourceLine" id="cb574-33" data-line-number="33">  <span class="kw">colnames</span>(dunr) =<span class="st"> </span></a>
<a class="sourceLine" id="cb574-34" data-line-number="34"><span class="st">    </span><span class="kw">c</span>(<span class="st">&quot;se&quot;</span>, <span class="st">&quot;df&quot;</span>, <span class="st">&quot;diff&quot;</span>, <span class="st">&quot;lower&quot;</span>, <span class="st">&quot;upper&quot;</span>, <span class="st">&quot;Qdunn&quot;</span>,</a>
<a class="sourceLine" id="cb574-35" data-line-number="35">      <span class="st">&quot;Qcrit&quot;</span>,  <span class="st">&quot;adj. pval&quot;</span>)</a>
<a class="sourceLine" id="cb574-36" data-line-number="36">  <span class="kw">rownames</span>(dunr) =<span class="st"> </span>rname</a>
<a class="sourceLine" id="cb574-37" data-line-number="37">  dunr</a>
<a class="sourceLine" id="cb574-38" data-line-number="38">}</a>
<a class="sourceLine" id="cb574-39" data-line-number="39"><span class="kw">dunnett.comparison</span>(mtcars<span class="op">$</span>mpg, mtcars<span class="op">$</span>cyl)</a></code></pre></div>
<pre><code>##          se df   diff lower  upper Qdunn Qcrit adj. pval
## 6-4* 1.1019 29  6.921 4.726  9.116 2.195 1.992 1.596e-04
## 8-4* 0.9183 29 11.564 9.589 13.538 1.974 2.150 6.646e-08</code></pre>

<p>The result shows that all the experiment groups differ significantly from the control group, as indicated by the asterisk(*).</p>
</div>
<div id="duncans-test" class="section level3 hasAnchor">
<h3><span class="header-section-number">6.5.7</span> Duncanâs Test <a href="6.5-multiple-comparison-tests.html#duncans-test" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Duncanâs Multiple Range Test</strong> is another <strong>Post-HOC</strong> test that compares differences in group means based on rank. It is a variant of <strong>SNK</strong>.</p>
<p>To illustrate, let us perform <strong>Duncanâs Multiple Range Test</strong>.</p>
<p><strong>First</strong>, let us use the <strong>mtcars</strong> dataset as before with <strong>cyl</strong> as the factor variable of three groups:</p>

<div class="sourceCode" id="cb576"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb576-1" data-line-number="1">(<span class="dt">groups =</span> <span class="kw">levels</span>(<span class="kw">as.factor</span>(mtcars<span class="op">$</span>cyl)))</a></code></pre></div>
<pre><code>## [1] &quot;4&quot; &quot;6&quot; &quot;8&quot;</code></pre>

<p><strong>Second</strong>, rank the means of groups in ascending order.</p>

<div class="sourceCode" id="cb578"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb578-1" data-line-number="1">rank &lt;-<span class="cf">function</span>(dependent, factor) {</a>
<a class="sourceLine" id="cb578-2" data-line-number="2">  group_means =<span class="st"> </span><span class="kw">aggregate</span>(<span class="dt">x =</span> dependent, <span class="dt">by =</span> <span class="kw">list</span>(factor), <span class="dt">FUN=</span><span class="st">&quot;mean&quot;</span>)</a>
<a class="sourceLine" id="cb578-3" data-line-number="3">  means_ascend =<span class="st"> </span><span class="kw">sort</span>(<span class="dt">x =</span> group_means<span class="op">$</span>x, <span class="dt">decreasing=</span><span class="ot">FALSE</span>, </a>
<a class="sourceLine" id="cb578-4" data-line-number="4">                      <span class="dt">index.return =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb578-5" data-line-number="5">  r =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">1</span>, <span class="kw">length</span>(groups))</a>
<a class="sourceLine" id="cb578-6" data-line-number="6">  <span class="kw">names</span>(r) =<span class="st"> </span>groups[means_ascend<span class="op">$</span>ix]</a>
<a class="sourceLine" id="cb578-7" data-line-number="7">  r =<span class="st"> </span><span class="kw">rbind</span>(r, means_ascend<span class="op">$</span>x)</a>
<a class="sourceLine" id="cb578-8" data-line-number="8">  <span class="kw">rownames</span>(r) =<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;rank&quot;</span>, <span class="st">&quot;mean&quot;</span>)</a>
<a class="sourceLine" id="cb578-9" data-line-number="9">  r</a>
<a class="sourceLine" id="cb578-10" data-line-number="10">}</a>
<a class="sourceLine" id="cb578-11" data-line-number="11"><span class="kw">rank</span>(mtcars<span class="op">$</span>mpg, mtcars<span class="op">$</span>cyl)</a></code></pre></div>
<pre><code>##         8     6     4
## rank  1.0  2.00  3.00
## mean 15.1 19.74 26.66</code></pre>

<p><strong>Third</strong>, run <strong>One-Way ANOVA</strong> for analysis.</p>

<div class="sourceCode" id="cb580"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb580-1" data-line-number="1">(<span class="dt">anova_outcome =</span> <span class="dt">anova =</span> <span class="kw">one_way_anova</span>(mtcars<span class="op">$</span>mpg, mtcars<span class="op">$</span>cyl))</a></code></pre></div>
<pre><code>##    SSB    SSW    dfB    dfW    MSB    MSW      F 
## 824.78 301.26   2.00  29.00 412.39  10.39  39.70</code></pre>

<p><strong>Fourth</strong>, recall the <strong>standard error (SE)</strong> formula we used in <strong>Tukeyâs Test</strong> (See Equation <span class="math inline">\(\@ref(eq:eqnnumber28)\)</span>).</p>
<p><span class="math display" id="eq:equate1080073" id="eq:equate1080072">\[\begin{align}
SE_{(within\ comparison)} &amp;=  \sqrt{\frac{MS_W}{2}\left(\frac{1}{n_i}+\frac{1}{n_j}\right)}\ \leftarrow \text{if different group sizes} \tag{6.76} \\
&amp;= s_w \sqrt{\frac{1}{2}\left(\frac{1}{n_i}+\frac{1}{n_j}\right)} \tag{6.77} 
\end{align}\]</span></p>
<p><strong>Fifth</strong>, compute for Duncanâs statistic:</p>
<p><span class="math display" id="eq:equate1080074">\[\begin{align}
Q_{dunc} = q_{\alpha}{(r,df_W)} \times SE \tag{6.78} 
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(\mathbf{Q_{dunc}}\)</span> is Duncanâs Significance range value, the <strong>Duncanâs Criterion</strong></li>
<li><strong>SE</strong> is the standard error</li>
<li><strong>q</strong> is Duncanâs range value</li>
<li><span class="math inline">\(\mathbf{\alpha}\)</span> is the alpha representing type I error</li>
<li><strong>r</strong> is the rank distance</li>
<li><span class="math inline">\(\mathbf{df_W}\)</span> is degrees of freedom (residual or within-group df)</li>
</ul>
<p><strong>Sixth</strong>, to determine significance, we use the following equation:</p>
<p><span class="math display" id="eq:equate1080075">\[\begin{align}
(\bar{x}_i - \bar{x}_j)_n &gt; Q_{dunc} \ \ \ \ \leftarrow\ \ \ \ \text{there is a significant difference} \tag{6.79} 
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(\bar{x}_{i}\)</span> is the mean of the first group in a pair</li>
<li><span class="math inline">\(\bar{x}_{j}\)</span> is the mean of the second group in a pair</li>
</ul>
<p>Here is a naive implementation of <strong>Duncanâs MRT</strong> in R code. Here, we use the <strong>Tukeyâs studentized range table</strong>:</p>

<div class="sourceCode" id="cb582"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb582-1" data-line-number="1">duncan.comparison &lt;-<span class="st"> </span><span class="cf">function</span>(dependent, factor) {</a>
<a class="sourceLine" id="cb582-2" data-line-number="2">  factors =<span class="st"> </span><span class="kw">levels</span>(<span class="kw">as.factor</span>(factor))</a>
<a class="sourceLine" id="cb582-3" data-line-number="3">  groups =<span class="st"> </span><span class="kw">split</span>( dependent, <span class="kw">as.factor</span>(factor))</a>
<a class="sourceLine" id="cb582-4" data-line-number="4">  anova =<span class="st"> </span><span class="kw">one_way_anova</span>(groups)</a>
<a class="sourceLine" id="cb582-5" data-line-number="5">  rank =<span class="st"> </span><span class="kw">rank</span>(dependent, factor)</a>
<a class="sourceLine" id="cb582-6" data-line-number="6">  m =<span class="st"> </span><span class="kw">length</span>(groups) <span class="co"># number of groups</span></a>
<a class="sourceLine" id="cb582-7" data-line-number="7">  dunr =<span class="st"> </span><span class="kw">c</span>(); rname =<span class="st"> </span><span class="kw">c</span>()</a>
<a class="sourceLine" id="cb582-8" data-line-number="8">  msw =<span class="st"> </span><span class="kw">as.numeric</span>(anova[<span class="st">&quot;MSW&quot;</span>])</a>
<a class="sourceLine" id="cb582-9" data-line-number="9">  dfW =<span class="st"> </span><span class="kw">as.numeric</span>(anova[<span class="st">&quot;dfW&quot;</span>])</a>
<a class="sourceLine" id="cb582-10" data-line-number="10">  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>m) {</a>
<a class="sourceLine" id="cb582-11" data-line-number="11">    idx =<span class="st"> </span>factors[i] </a>
<a class="sourceLine" id="cb582-12" data-line-number="12">    group =<span class="st"> </span>groups[[idx]]</a>
<a class="sourceLine" id="cb582-13" data-line-number="13">    n.i =<span class="st"> </span><span class="kw">length</span>(group); u.i =<span class="st"> </span><span class="kw">mean</span>(group); g.i =<span class="st"> </span>idx</a>
<a class="sourceLine" id="cb582-14" data-line-number="14">    r.i =<span class="st"> </span>rank[,idx]</a>
<a class="sourceLine" id="cb582-15" data-line-number="15">    <span class="cf">for</span> (j <span class="cf">in</span> i<span class="op">:</span>m) {</a>
<a class="sourceLine" id="cb582-16" data-line-number="16">      <span class="cf">if</span> (i <span class="op">!=</span><span class="st"> </span>j) {</a>
<a class="sourceLine" id="cb582-17" data-line-number="17">        idx =<span class="st"> </span>factors[j] </a>
<a class="sourceLine" id="cb582-18" data-line-number="18">        group =<span class="st"> </span>groups[[idx]]</a>
<a class="sourceLine" id="cb582-19" data-line-number="19">        n.j =<span class="st"> </span><span class="kw">length</span>(group); u.j =<span class="st"> </span><span class="kw">mean</span>(group); g.j =<span class="st"> </span>idx</a>
<a class="sourceLine" id="cb582-20" data-line-number="20">        r.j =<span class="st"> </span>rank[,idx]</a>
<a class="sourceLine" id="cb582-21" data-line-number="21">        r_dist =<span class="st"> </span>r.i[<span class="st">&quot;rank&quot;</span>] <span class="op">-</span><span class="st"> </span>r.j[<span class="st">&quot;rank&quot;</span>] <span class="op">+</span><span class="st"> </span><span class="dv">1</span></a>
<a class="sourceLine" id="cb582-22" data-line-number="22">        r =<span class="st"> </span>rank[,r_dist]</a>
<a class="sourceLine" id="cb582-23" data-line-number="23">        se =<span class="st"> </span><span class="kw">sqrt</span>( (msw <span class="op">/</span><span class="st"> </span><span class="dv">2</span>) <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span><span class="op">/</span>n.i <span class="op">+</span><span class="st"> </span><span class="dv">1</span><span class="op">/</span>n.j))</a>
<a class="sourceLine" id="cb582-24" data-line-number="24">        q =<span class="st"> </span><span class="kw">qtukey</span>(<span class="dt">p =</span> <span class="fl">0.05</span>, <span class="dt">nmeans =</span> rank[<span class="dv">2</span>,i], <span class="dt">df =</span> dfW, </a>
<a class="sourceLine" id="cb582-25" data-line-number="25">                   <span class="dt">lower.tail=</span><span class="ot">FALSE</span>) </a>
<a class="sourceLine" id="cb582-26" data-line-number="26">        p =<span class="st"> </span><span class="kw">qtukey</span>(<span class="dt">p =</span> <span class="fl">0.05</span>, <span class="dt">nmeans =</span> rank[<span class="dv">2</span>,i], <span class="dt">df =</span> dfW, </a>
<a class="sourceLine" id="cb582-27" data-line-number="27">                   <span class="dt">lower.tail=</span><span class="ot">FALSE</span>) </a>
<a class="sourceLine" id="cb582-28" data-line-number="28">        dunc =<span class="st"> </span>q <span class="op">*</span><span class="st"> </span>se</a>
<a class="sourceLine" id="cb582-29" data-line-number="29">        d =<span class="st"> </span><span class="kw">abs</span>( u.i <span class="op">-</span><span class="st"> </span>u.j )</a>
<a class="sourceLine" id="cb582-30" data-line-number="30">        lower =<span class="st"> </span>d <span class="op">-</span><span class="st"> </span>dunc </a>
<a class="sourceLine" id="cb582-31" data-line-number="31">        upper =<span class="st"> </span>d <span class="op">+</span><span class="st"> </span>dunc</a>
<a class="sourceLine" id="cb582-32" data-line-number="32">        signif =<span class="st"> &#39;&#39;</span></a>
<a class="sourceLine" id="cb582-33" data-line-number="33">        <span class="cf">if</span> (d <span class="op">&gt;</span><span class="st"> </span>dunc ) { signif =<span class="st"> &#39;*&#39;</span> }</a>
<a class="sourceLine" id="cb582-34" data-line-number="34">        rname =<span class="st"> </span><span class="kw">c</span>(rname, <span class="kw">paste0</span>(g.j, <span class="st">&quot;-&quot;</span>, g.i,signif))</a>
<a class="sourceLine" id="cb582-35" data-line-number="35">        dunr =<span class="st"> </span><span class="kw">rbind</span>(dunr, <span class="kw">c</span>(se, dfW, d, lower, upper, r_dist, dunc,  </a>
<a class="sourceLine" id="cb582-36" data-line-number="36">                             q, p ))</a>
<a class="sourceLine" id="cb582-37" data-line-number="37">      }</a>
<a class="sourceLine" id="cb582-38" data-line-number="38">    }</a>
<a class="sourceLine" id="cb582-39" data-line-number="39">  }</a>
<a class="sourceLine" id="cb582-40" data-line-number="40">  <span class="kw">colnames</span>(dunr) =<span class="st"> </span></a>
<a class="sourceLine" id="cb582-41" data-line-number="41"><span class="st">    </span><span class="kw">c</span>(<span class="st">&quot;se&quot;</span>, <span class="st">&quot;df&quot;</span>, <span class="st">&quot;diff&quot;</span>, <span class="st">&quot;lower&quot;</span>, <span class="st">&quot;upper&quot;</span>, <span class="st">&quot;dist.&quot;</span>, <span class="st">&quot;Qdunc&quot;</span>, </a>
<a class="sourceLine" id="cb582-42" data-line-number="42">      <span class="st">&quot;Qcrit&quot;</span>, <span class="st">&quot;adj.pval&quot;</span>)</a>
<a class="sourceLine" id="cb582-43" data-line-number="43">  <span class="kw">rownames</span>(dunr) =<span class="st"> </span>rname</a>
<a class="sourceLine" id="cb582-44" data-line-number="44">  dunr</a>
<a class="sourceLine" id="cb582-45" data-line-number="45">}</a>
<a class="sourceLine" id="cb582-46" data-line-number="46"><span class="kw">duncan.comparison</span>(mtcars<span class="op">$</span>mpg, mtcars<span class="op">$</span>cyl)</a></code></pre></div>
<pre><code>##          se df   diff  lower upper dist. Qdunc Qcrit adj.pval
## 6-4* 1.1019 29  6.921  1.155 12.69     2 5.766 5.232    5.232
## 8-4* 0.9183 29 11.564  6.759 16.37     3 4.805 5.232    5.232
## 8-6  1.0550 29  4.643 -1.138 10.42     2 5.781 5.479    5.479</code></pre>

<p>The outcome shows the first and second mean differences to be significant.</p>
<p>Let us validate.</p>
<p><strong>First</strong>, let us generate a summary of ANOVA using <strong>aov()</strong>:</p>

<div class="sourceCode" id="cb584"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb584-1" data-line-number="1">mtcars_<span class="op">$</span>cyl_factor =<span class="st"> </span><span class="kw">as.factor</span>(mtcars_<span class="op">$</span>cyl)</a>
<a class="sourceLine" id="cb584-2" data-line-number="2">aov.model =<span class="st"> </span><span class="kw">aov</span>(mpg <span class="op">~</span><span class="st"> </span>cyl_factor, <span class="dt">data =</span> mtcars_) <span class="co"># One-Way Anova</span></a>
<a class="sourceLine" id="cb584-3" data-line-number="3"><span class="kw">summary</span>(aov.model)</a></code></pre></div>
<pre><code>##             Df Sum Sq Mean Sq F value Pr(&gt;F)    
## cyl_factor   2    825     412    39.7  5e-09 ***
## Residuals   29    301      10                   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>

<p><strong>Second</strong>, use <strong>duncan.test()</strong> to perform the <strong>Duncanâs test</strong>.</p>
<p>Here, we use a third-party library called <strong>agricolae</strong> which comes with a function called <strong>duncan.test()</strong>.</p>

<div class="sourceCode" id="cb586"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb586-1" data-line-number="1"><span class="kw">library</span>(agricolae)</a></code></pre></div>
<pre><code>## This version of &#39;bslib&#39; is designed to work with &#39;shiny&#39; &gt;= 1.6.0.
##     Please upgrade via install.packages(&#39;shiny&#39;).</code></pre>
<div class="sourceCode" id="cb588"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb588-1" data-line-number="1">(<span class="dt">duncan.model =</span> <span class="kw">duncan.test</span>(aov.model,<span class="st">&quot;cyl_factor&quot;</span>))</a></code></pre></div>
<pre><code>## $statistics
##   MSerror Df  Mean    CV
##     10.39 29 20.09 16.04
## 
## $parameters
##     test     name.t ntr alpha
##   Duncan cyl_factor   3  0.05
## 
## $duncan
## NULL
## 
## $means
##     mpg   std  r  Min  Max   Q25  Q50   Q75
## 4 26.66 4.510 11 21.4 33.9 22.80 26.0 30.40
## 6 19.74 1.454  7 17.8 21.4 18.65 19.7 21.00
## 8 15.10 2.560 14 10.4 19.2 14.40 15.2 16.25
## 
## $comparison
## NULL
## 
## $groups
##     mpg groups
## 4 26.66      a
## 6 19.74      b
## 8 15.10      c
## 
## attr(,&quot;class&quot;)
## [1] &quot;group&quot;</code></pre>

<p><strong>Third</strong>, to visualize, let us plot the variance:</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:duncantest"></span>
<img src="DS_files/figure-html/duncantest-1.png" alt="Groups and Interquantile range" width="70%" />
<p class="caption">
Figure 6.16: Groups and Interquantile range
</p>
</div>

</div>
<div id="meta-analysis-test" class="section level3 hasAnchor">
<h3><span class="header-section-number">6.5.8</span> Meta-Analysis Test <a href="6.5-multiple-comparison-tests.html#meta-analysis-test" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A single study of observation may sometimes not suffice in analyzing data. There is a benefit when merging data from many different studies at times. This <strong>meta-analysis</strong> of results from different studies may render a different range of values of variables.</p>
<p>Also, specific data are manipulated or manufactured rather than observed from real-world events - we call this data <strong>synthetic data</strong>. We compare the differences and similarities of data properties across studies in analyzing synthetic data. There are two qualities we are looking for in <strong>synthetic data</strong>:</p>
<p><strong>Heterogeneity of variances</strong> refers to the differences in quality or property of data (possibly synthesized and) merged from different studies. </p>
<p><strong>Homogeneity of variances</strong> refers to the similarities in quality or property of data (possibly synthesized and) merged from different studies. </p>
<p>Here, we show a forest plot of <strong>synthetic data</strong> from different studies (See Figure <a href="6.5-multiple-comparison-tests.html#fig:heterogeniety">6.17</a>) to check if data is either <strong>homogenous</strong> or <strong>heterogenous</strong>.</p>

<div class="sourceCode" id="cb590"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb590-1" data-line-number="1"><span class="kw">library</span>(forestplot)</a>
<a class="sourceLine" id="cb590-2" data-line-number="2"><span class="kw">set.seed</span>(<span class="dv">142</span>)</a>
<a class="sourceLine" id="cb590-3" data-line-number="3">beta0 =<span class="st"> </span><span class="fl">0.5</span></a>
<a class="sourceLine" id="cb590-4" data-line-number="4">beta1 =<span class="st"> </span><span class="fl">1.4</span></a>
<a class="sourceLine" id="cb590-5" data-line-number="5">X =<span class="st"> </span><span class="kw">matrix</span> ( <span class="kw">runif</span>(<span class="dv">45</span>, <span class="dt">min=</span><span class="op">-</span><span class="dv">2</span>, <span class="dt">max=</span><span class="dv">2</span>), <span class="dt">nrow=</span><span class="dv">5</span>, <span class="dt">ncol=</span><span class="dv">9</span> )</a>
<a class="sourceLine" id="cb590-6" data-line-number="6">coefs =<span class="st">  </span><span class="kw">matrix</span>(<span class="dv">0</span>, <span class="dt">nrow=</span><span class="dv">9</span>, <span class="dt">ncol=</span><span class="dv">3</span> )</a>
<a class="sourceLine" id="cb590-7" data-line-number="7"><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">9</span>) {</a>
<a class="sourceLine" id="cb590-8" data-line-number="8">  x =<span class="st"> </span><span class="kw">as.vector</span>( X[,i] )</a>
<a class="sourceLine" id="cb590-9" data-line-number="9">  random_noise =<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n=</span><span class="dv">5</span>, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb590-10" data-line-number="10">  y =<span class="st">  </span>beta0 <span class="op">+</span><span class="st"> </span>beta1 <span class="op">*</span><span class="st"> </span>x <span class="op">+</span><span class="st">  </span>random_noise </a>
<a class="sourceLine" id="cb590-11" data-line-number="11">  model =<span class="st"> </span><span class="kw">lm</span>( y <span class="op">~</span><span class="st"> </span>x)</a>
<a class="sourceLine" id="cb590-12" data-line-number="12">  coefs[i,] =<span class="st"> </span><span class="kw">c</span>( <span class="dt">Mean =</span> <span class="kw">coef</span>(model)[<span class="dv">2</span>], <span class="dt">Lower =</span> <span class="kw">confint</span>(model)[<span class="dv">2</span>,<span class="dv">1</span>], </a>
<a class="sourceLine" id="cb590-13" data-line-number="13">                 <span class="dt">Upper=</span><span class="kw">confint</span>(model)[<span class="dv">2</span>,<span class="dv">2</span>] ) </a>
<a class="sourceLine" id="cb590-14" data-line-number="14">}</a>
<a class="sourceLine" id="cb590-15" data-line-number="15">labels =<span class="st"> </span><span class="kw">matrix</span>( <span class="kw">c</span>( <span class="st">&quot;Studies&quot;</span>, <span class="kw">paste0</span>(<span class="st">&quot;Study &quot;</span>, <span class="dv">1</span><span class="op">:</span><span class="dv">9</span>), <span class="st">&quot;Coefficients&quot;</span>, </a>
<a class="sourceLine" id="cb590-16" data-line-number="16">                    <span class="kw">round</span>(coefs[,<span class="dv">1</span>],<span class="dv">2</span>)), <span class="dt">nrow=</span><span class="dv">10</span>, <span class="dt">ncol=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb590-17" data-line-number="17">coefs =<span class="st"> </span><span class="kw">rbind</span>(<span class="ot">NA</span>, coefs)</a>
<a class="sourceLine" id="cb590-18" data-line-number="18"><span class="kw">forestplot</span>(<span class="dt">labeltext =</span> labels, </a>
<a class="sourceLine" id="cb590-19" data-line-number="19">        <span class="dt">mean=</span>coefs[,<span class="dv">1</span>], <span class="dt">lower=</span> coefs[,<span class="dv">2</span>], <span class="dt">upper=</span> coefs[,<span class="dv">3</span>], </a>
<a class="sourceLine" id="cb590-20" data-line-number="20">        <span class="dt">title=</span><span class="st">&quot;Meta-Analysis Study&quot;</span> , </a>
<a class="sourceLine" id="cb590-21" data-line-number="21">        <span class="dt">col=</span><span class="kw">fpColors</span>(<span class="dt">box=</span><span class="st">&quot;black&quot;</span>, <span class="dt">line=</span><span class="st">&quot;red&quot;</span>), </a>
<a class="sourceLine" id="cb590-22" data-line-number="22">        <span class="dt">grid =</span> <span class="kw">structure</span>(<span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>), <span class="dt">gp =</span> <span class="kw">gpar</span>(<span class="dt">col =</span> <span class="st">&quot;grey&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>)),</a>
<a class="sourceLine" id="cb590-23" data-line-number="23">        <span class="dt">new_page =</span> <span class="ot">TRUE</span>,  <span class="dt">boxsize=</span><span class="fl">0.25</span>,   <span class="dt">xlab=</span><span class="st">&quot;Coef Index&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:heterogeniety"></span>
<img src="DS_files/figure-html/heterogeniety-1.png" alt="Heterogeniety" width="60%" />
<p class="caption">
Figure 6.17: Heterogeniety
</p>
</div>

<p>It shows in the forest plot above that studies 1 through 9 render results that seem reasonably within neighboring means and ranges. However, studies 3 and 9 may require some attention since they have confidence intervals whose ranges are further apart. Thus, that can be considered to have a higher heterogeneity than the other studies - meaning, studies 3 and 9 have more significant differences than the other studies (in the context of the confident interval).</p>
<p>If we are more strict regarding the placement of the blue box (the coefficient mean), then study 9 has a negative value and is placed almost outside the grid between 0 and 3. So in this context, we can say that study 9 has a higher heterogeneity in our being strict about placement.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="6.4-post-hoc-analysis.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="6.6-statistical-modeling.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["DS.pdf", "DS.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
